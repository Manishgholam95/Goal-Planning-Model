import streamlit as st
import pandas as pd
from datetime import datetime, timedelta, date
from sqlalchemy import create_engine
import psycopg2
from calendar import monthrange
from plotly.subplots import make_subplots
import plotly.graph_objects as go
from fpdf import FPDF, HTMLMixin
from sqlalchemy import inspect, text
import kaleido
from fpdf import FPDF  # For PDF creation
import os
from plotly.io import write_image  # Ensure this import is present for image saving
from dateutil.relativedelta import relativedelta
from streamlit.runtime.scriptrunner import get_script_run_ctx
from streamlit.runtime.state.session_state import SessionState
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
#from selenium.webdriver.chrome.service import Service

#from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# import warnings
# warnings.filterwarnings(
#     "ignore",
#     message="Support for Kaleido versions less than 1.0.0",
#     category=DeprecationWarning,
# )
# --- new imports for non-kaleido image rendering ---
from io import BytesIO
import tempfile
import time
import plotly.io as pio

#from selenium import webdriver
#from selenium.webdriver.chrome.options import Options
#from selenium.webdriver.common.by import By
#from webdriver_manager.chrome import ChromeDriverManager
#from selenium.webdriver.chrome.service import Service

#chrome_options = Options()
options = webdriver.ChromeOptions()
options.binary_location = "/usr/bin/chromium"
options.add_argument("--headless=new")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")
options.add_argument("--window-size=1920,1080")


#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
driver = webdriver.Chrome(service=Service("/usr/bin/chromedriver"), options=options)
#chrome_options.binary_location = "/usr/bin/chromium"
#chrome_options.add_argument("--headless=new")
#chrome_options.add_argument("--no-sandbox")
#chrome_options.add_argument("--disable-dev-shm-usage")
#chrome_options.add_argument("--disable-gpu")
#chrome_options.add_argument("--window-size=1920,1080")





chrome_options = Options()
chrome_options.binary_location = "/usr/bin/chromium"
chrome_options.add_argument("--headless=new")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--disable-gpu")

# IMPORTANT: explicitly pass chromedriver path
service = Service("/usr/bin/chromedriver")

driver = webdriver.Chrome(service=service, options=chrome_options)




#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
#driver = webdriver.Chrome(options=chrome_options)


# ---------- helpers: render Plotly + DataFrames to PNG via headless Chrome ----------
def fig_to_png_via_selenium(fig, width=None, height=None, timeout=30, div_id="plotly2img"):
    """
    Render a Plotly figure to PNG using Selenium (no Kaleido).
    Includes:
      âœ“ Modebar removal
      âœ“ DPI scaling
      âœ“ Bounding-box resizing
      âœ“ Stable export for all PDF pages
    """

    # Clean layout
    fig.update_layout(
        margin=dict(l=40, r=40, t=50, b=40),
        showlegend=True
    )

    # Disable modebar completely
    html = pio.to_html(
        fig,
        include_plotlyjs=True,
        full_html=True,
        div_id=div_id,
        config={"displayModeBar": False}   # ðŸ”¥ removes zoom/pan/camera toolbar
    )

    # Fallback defaults
    fig_w = int(getattr(fig.layout, "width", 1400) or 1400)
    fig_h = int(getattr(fig.layout, "height", 850) or 850)
    if width is None: width = fig_w
    if height is None: height = fig_h

    # Browser window larger than figure
    win_w = width + 240
    win_h = height + 260

    # Save HTML
    with tempfile.NamedTemporaryFile("w", suffix=".html", delete=False, encoding="utf-8") as f:
        f.write(html)
        html_path = f.name

    # Chrome options
    chrome_opts = Options()
    chrome_opts.add_argument("--headless=new")
    chrome_opts.add_argument(f"--window-size={win_w},{win_h}")
    chrome_opts.add_argument("--disable-gpu")
    chrome_opts.add_argument("--no-sandbox")
    chrome_opts.add_argument("--disable-dev-shm-usage")
    chrome_opts.add_argument("--force-device-scale-factor=2")   # ðŸ”¥ Retina-quality PNG

    service = Service("/usr/bin/chromedriver")
    driver = webdriver.Chrome(service=service, options=chrome_opts)

    try:
        driver.get("file://" + html_path)

        # Wait until plot div is ready
        wait = WebDriverWait(driver, timeout)
        elem = wait.until(EC.presence_of_element_located((By.ID, div_id)))

        driver.execute_script("arguments[0].scrollIntoView(true);", elem)
        time.sleep(0.5)

        # ðŸ”¥ IMPORTANT â€” BOUNDING BOX CORRECTION
        rect = driver.execute_script("""
            var r = arguments[0].getBoundingClientRect();
            return {w: Math.ceil(r.width), h: Math.ceil(r.height)};
        """, elem)

        need_w = max(win_w, rect["w"] + 100)
        need_h = max(win_h, rect["h"] + 180)

        if need_w != win_w or need_h != win_h:
            driver.set_window_size(need_w, need_h)
            time.sleep(0.5)

        # Finally capture screenshot
        return elem.screenshot_as_png

    finally:
        driver.quit()
        try: os.remove(html_path)
        except: pass



def html_to_png_via_selenium(html: str, width=1400, height=900, timeout=10, node_id="root"):
    """Screenshot arbitrary HTML (containing a #root element) to PNG bytes."""
    with tempfile.NamedTemporaryFile("w", suffix=".html", delete=False, encoding="utf-8") as f:
        f.write(html)
        html_path = f.name

    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument(f"--window-size={width},{height}")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--no-sandbox")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=opts)
    try:
        driver.get("file://" + html_path)
        deadline = time.time() + timeout
        elem = None
        while time.time() < deadline:
            try:
                elem = driver.find_element(By.ID, node_id)
                if elem.size.get("height", 0) > 0:
                    break
            except Exception:
                pass
            time.sleep(0.2)
        if not elem:
            raise RuntimeError("HTML container not found or failed to render.")
        return elem.screenshot_as_png
    finally:
        driver.quit()
        try:
            os.remove(html_path)
        except Exception:
            pass


def df_to_png_via_selenium(df: pd.DataFrame, title="Table", width=1400, height=900):
    """Render a DataFrame to simple styled HTML and screenshot it as PNG bytes."""
    css = """
    <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    h2 { margin: 0 0 12px 0; }
    table { border-collapse: collapse; width: 100%; font-size: 13px; }
    th, td { border: 1px solid #ddd; padding: 6px 8px; text-align: left; vertical-align: top; }
    th { background: #e9f0ff; }
    tr:nth-child(even) td { background: #fafafa; }
    </style>
    """
    table_html = df.to_html(index=False, escape=False)
    html = f"""<!doctype html>
<html>
<head><meta charset="utf-8">{css}</head>
<body>
  <div id="root">
    <h2>{title}</h2>
    {table_html}
  </div>
</body>
</html>"""
    return html_to_png_via_selenium(html, width=width, height=height, node_id="root")
# ------------------------------------------------------------------------------------


class PDF(FPDF, HTMLMixin):
    def __init__(self):
        super().__init__(orientation='P', unit='mm', format=(210,250))
        self.set_auto_page_break(auto=True, margin=10)
        self.set_margins(left=10, top=10, right=10)

    def add_custom_page(self, name, logo_path, goal_table):
        self.add_page()
        # Add title
        self.set_font('Arial', 'B', 16)
        self.cell(0, 10, f'Goal Planning for {name}', ln=True, align='C')
        # Add logo
        if os.path.exists(logo_path):
            self.image(logo_path, x=180, y=10, w=20)  

        # Add Goal Planning table title
        self.set_y(60)
        self.set_font('Arial', 'B', 14)
        self.cell(0, 10, 'Goal Planning Table', ln=True, align='C')

        # Add Goal Planning Table
        self.set_font('Arial', 'B', 12)
        self.ln(10)
        self.set_x(5)  # Set horizontal position
        self.set_fill_color(200, 220, 255)
        self.cell(85, 10, 'Goal Name', border=1, fill=True, align='C')
        self.cell(40, 10, 'Target Year', border=1, fill=True, align='C')
        self.cell(30, 10, 'Current Value', border=1, fill=True, align='C')
        self.cell(25, 10, 'Future Value', border=1, fill=True, align='C')
        self.cell(20, 10, 'Achieved', border=1, fill=True, align='C')
        self.ln()

        for _, row in goal_table.iterrows():
            self.set_font('Arial', '', 12)
            self.set_x(5)
            self.cell(85, 10, row['Goal Name'], border=1, align='C')
            self.cell(40, 10, row['Target Year'].replace('â€“', '-'), border=1, align='C')  # Fix here
            self.cell(30, 10, row['Current Value'], border=1, align='C')
            self.cell(25, 10, row['Future Value'], border=1, align='C')
            self.cell(20, 10, row['Achieved'], border=1, align='C')
            self.ln()    

    def add_blank_pages(self, num_pages):
        for _ in range(num_pages):
            self.add_page()

# Database connection and ProjectionUpdater class
class ProjectionUpdater:
    def __init__(self, db_config):
        self.db_config = db_config
        self.connection = self.connect_db()

    def connect_db(self):
        try:
            connection = psycopg2.connect(**self.db_config)
            print("Database connection successful")
            return connection
        except Exception as error:
            print(f"Error connecting to the database: {error}")
            return None

    def fetch_user_data(self, user_code):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT dob, retirement_age 
            FROM milestone_customer_profile 
            WHERE user_code = %s AND is_active = true;
        """, (user_code,))
        dob, retirement_age = cursor.fetchone()
        cursor.close()
        return dob, retirement_age    
    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(first_name,''), ' ', COALESCE(last_name,'')) AS Name 
            FROM milestone_customer_profile 
            WHERE user_code = %s;
        """, (user_id,))
        user_name = cursor.fetchone()[0]
        cursor.close()
        return user_name
    
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day): 
            age -= 1
        return age
    
    def transpose_and_sort_dates(self, df):
        df['entry_date'] = pd.to_datetime(df['entry_date'], format='%d-%m-%Y')
        df = df.sort_values(by='entry_date')
        df['entry_date'] = df['entry_date'].dt.strftime('%d-%m-%Y')
        return df
    
    def load_milestone_list(self):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT category_id, milestone_name
            FROM milestone_master
            ORDER BY category_id;
        """)
        rows = cursor.fetchall()
        cursor.close()
        return {row[0]: row[1] for row in rows}
    
    def load_asset_category_list(self):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT id, name
            FROM milestones_category
            ORDER BY id;
        """)
        rows = cursor.fetchall()
        cursor.close()
        return {row[0]: row[1] for row in rows}
        
    
    def initialize_user_if_first_time(self, user_id):
        """
        Run copy functions only once for each user_id.
        """
        cursor = self.connection.cursor()

        # 1. Check if user_id exists in tracker
        cursor.execute("""
            SELECT initialized 
            FROM user_initialization_tracker 
            WHERE user_id = %s;
        """, (user_id,))
        result = cursor.fetchone()

        # -----------------------------
        # CASE 1: FIRST TIME USER
        # -----------------------------
        if result is None:
            st.info(f"Running first-time setup for user: {user_id}")

            # Create tracker entry
            cursor.execute("""
                INSERT INTO user_initialization_tracker (user_id, initialized)
                VALUES (%s, FALSE);
            """, (user_id,))
            self.connection.commit()

            # Execute your one-time functions
            self.copy_customer_profile_to_milestone_customer_profile(user_id)
            self.copy_life_stage_growth_to_milestone(user_id)
            self.copy_income_to_milestone_income(user_id)
            self.copy_customer_details_to_milestone_customer_details(user_id)
            self.copy_expenses_to_milestone_expenses(user_id)
            self.copy_assets_to_assets_milestones(user_id)
            self.copy_liabilities_to_liabilities_milestones(user_id)
            

            # Mark as initialized
            cursor.execute("""
                UPDATE user_initialization_tracker
                SET initialized = TRUE
                WHERE user_id = %s;
            """, (user_id,))
            self.connection.commit()

            st.success("First-time initialization completed successfully.")

        # -----------------------------
        # CASE 2: USER ALREADY INITIALIZED
        # -----------------------------
        else:
            st.warning("User already initialized. Copy functions skipped.")

        cursor.close()

    
    # New Functionality for Milestones Liabilities
    def manage_milestones_liabilities(self, user_id_1):
        #st.write("### Manage Milestones Liabilities")

        # Define milestone categories and purposes
        milestone_list = self.load_milestone_list()
        asset_category_list = self.load_asset_category_list()

        # Insert New Record
        st.subheader("Insert New Record")
        #user_id = st.text_input("Enter User ID for New Record", key = "milestone_insert_user_id")
        user_id_insert = st.radio( "Do you want to insert the records in milestone table?", ["No", "Yes"], index=0, key='insert_into_milestone_table')

        if user_id_insert == 'Yes':
            # ---- UPDATED LOGIC START ----

            st.write("### Select or Enter Milestone Purpose")

            # Existing milestone names + option for custom entry
            existing_names = list(milestone_list.values())
            user_choice = st.selectbox("Choose milestone:", existing_names + ["Other (enter manually)"], key="milestone_insert_choice")
            max_milestone_category_id = max(milestone_list.keys())
            max_asset_category_id = max(asset_category_list.keys())

            custom_goal = None
            if user_choice == "Other (enter manually)":
                custom_goal = st.text_input( "Enter custom milestone name:", key="milestone_custom_goal").strip()

                if custom_goal:
                    # CASE 1 â†’ user entered an existing name
                    if custom_goal in milestone_list.values():
                        purpose = custom_goal
                        category_id = next( k for k, v in milestone_list.items() if v == custom_goal)
                        st.info(f"Goal already exists. Using category_id = {category_id}")

                    # CASE 2 â†’ NEW GOAL â†’ assign next category_id
                    else:
                        #new_category_id = max(milestone_list.keys(),asset_category_list.keys()) + 1
                        new_category_id = max(max_milestone_category_id, max_asset_category_id) + 1

                        # Insert permanently into DB
                        cursor = self.connection.cursor()
                        cursor.execute("""INSERT INTO milestone_master (category_id, milestone_name) VALUES (%s, %s);""", (new_category_id, custom_goal))
                        self.connection.commit()
                        cursor.close()

                        # Update local dictionary
                        milestone_list[new_category_id] = custom_goal

                        st.success(f"New milestone added permanently â†’ {new_category_id}: {custom_goal}")
                        purpose = custom_goal
                        category_id = new_category_id
                else:
                    purpose = None
                    category_id = None

            else:
                # User picked an existing milestone
                purpose = user_choice
                category_id = next( key for key, value in milestone_list.items() if value == purpose)

            # ---- UPDATED LOGIC END ----

            # Continue only if purpose is known
            if purpose and category_id:
                pending_tenure = st.number_input("Pending Tenure (in months)", min_value=0, step=1, key="milestone_insert_pending_tenure")
                milestone_year = st.date_input("Milestone Year (YYYY-MM-DD)",key="milestone_insert_entry_date").strftime("%Y-%m-%d")

                loan_funded = st.selectbox("Loan Funded", ["Yes", "No"], key="milestone_insert_loan_funded")
                amount = st.number_input("Enter Amount", min_value=0.0, key="milestone_insert_amount")
                inflation = st.number_input("Inflation (%)", min_value=0.0, key="milestone_insert_inflation") / 100
                your_percent_share = st.number_input("Your Percent Share (%)", min_value=0.0, key="milestone_insert_your_percent_share") / 100
                interest_rate = st.number_input("Your Interest Rate(%)", min_value=0.0, key="milestone_insert_your_interest_rate") / 100

                if st.button("Insert Milestones Liabilities Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                INSERT INTO milestones_liabilities (
                                    created_at, last_updated_at, user_code, category_id,
                                    outstanding_amount, pending_tenure, is_manual_entry,
                                    months, name, is_active, interest_rate, purpose,
                                    milestone_year, loan_funded, amount, inflation,
                                    your_percent_share
                                ) VALUES (
                                    NOW(), NOW(), %s, %s, 0, %s, TRUE, 1, %s, TRUE,
                                    %s, %s, %s, %s, %s, %s, %s
                                );
                            """, (
                                user_id_1, category_id, pending_tenure, purpose,
                                interest_rate, purpose, milestone_year, loan_funded,
                                amount, inflation, your_percent_share
                            ))
                            self.connection.commit()
                            st.success("Record inserted successfully!")

                    except Exception as e:
                        st.error(f"Error inserting record: {e}")

        # Update Existing Record
        st.subheader("Update Existing Milestones Liabilities Record")
        user_id_update = st.radio("Do you want to update the milestone table?", ["No", "Yes"], index=0, key = 'update milestone table')
        if user_id_update == 'Yes':
            try:
                # Fetch unique purposes for the user_id
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT purpose FROM milestones_liabilities 
                        WHERE user_code = %s;
                    """, (user_id_1,))
                    unique_purposes = [row[0] for row in cursor.fetchall()]

                selected_purpose = st.selectbox("Select Purpose to Update", unique_purposes, key= "milestone_update_records")
                update_options = {
                    "pending_tenure": st.selectbox("Pending Tenure", ["Same", "New"], key= "milestone_update_pending_tenure_option"),
                    "milestone_year": st.selectbox("Milestone Year", ["Same", "New"], key= "milestone_update_milestone_year_option"),
                    "loan_funded": st.selectbox("Loan Funded", ["Same", "New"], key= "milestone_update_loan_funded_option"),
                    "amount": st.selectbox("Amount", ["Same", "New"], key= "milestone_update_amount_option"),
                    "inflation": st.selectbox("Inflation", ["Same", "New"], key="milestone_update_inflation_option"),
                    "your_percent_share": st.selectbox("Your Percent Share", ["Same", "New"], key= "milestone_update_your_percent_share_option"),
                    "interest_rate": st.selectbox("Your Interest Rate", ["Same", "New"], key= "milestone_update_interest_rate_option")
                }

                updates = {}
                if update_options["pending_tenure"] == "New":
                    updates["pending_tenure"] = st.number_input("New Pending Tenure", min_value=0, step=1, key= "milestone_update_pending_tenure")
                if update_options["milestone_year"] == "New":
                    updates["milestone_year"] = st.date_input("New Milestone Year (YYYY-MM-DD)",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key= "milestone_update_milestone_year").strftime("%Y-%m-%d")
                if update_options["loan_funded"] == "New":
                    updates["loan_funded"] = st.selectbox("New Loan Funded", ["Yes", "No"], key= "milestone_update_loan_funded")
                if update_options["amount"] == "New":
                    updates["amount"] = st.number_input("New Amount", min_value=0.0, key= "milestone_update_amount")
                if update_options["inflation"] == "New":
                    updates["inflation"] = st.number_input("New Inflation (%)", min_value=0.0, key= "milestone_update_inflation") / 100
                if update_options["your_percent_share"] == "New":
                    updates["your_percent_share"] = st.number_input("New Your Percent Share (%)", min_value=0.0, key= "milestone_update_your_percent_share") / 100
                if update_options["interest_rate"] == "New":
                    updates["interest_rate"] = st.number_input("New Interest rate (%)", min_value=0.0, key= "milestone_update_interest_rate") / 100    

                if st.button("Update Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            for column, value in updates.items():
                                cursor.execute(f"""
                                    UPDATE milestones_liabilities 
                                    SET {column} = %s, last_updated_at = NOW() 
                                    WHERE user_code = %s AND purpose = %s;
                                """, (value, user_id_1, selected_purpose))
                            self.connection.commit()
                            st.success("Record updated successfully!")
                    except Exception as e:
                        st.error(f"Error updating record: {e}")

            except Exception as e:
                st.error(f"Error fetching purposes: {e}")

        # Delete Existing Record
        st.subheader("Delete Milestones Liabilities Record")
        user_id_delete = st.radio("Do you want to delete the single milestone of the user?", ["No", "Yes"], index=0, key = 'delete a single milestone')
        if user_id_delete == 'Yes':
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT purpose FROM milestones_liabilities 
                        WHERE user_code = %s;
                    """, (user_id_1,))
                    unique_purposes_delete = [row[0] for row in cursor.fetchall()]

                selected_purpose_delete = st.selectbox("Select Purpose to Delete", unique_purposes_delete, key= "milestone_delete_records")
                if st.button("Delete Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM milestones_liabilities 
                                WHERE user_code = %s AND purpose = %s;
                            """, (user_id_1, selected_purpose_delete))
                            self.connection.commit()
                            st.success("Record deleted successfully!")
                    except Exception as e:
                        st.error(f"Error deleting record: {e}")

            except Exception as e:
                st.error(f"Error fetching purposes for deletion: {e}")
       
        if st.button('display the goal table',key = 'goal table display'):
            st.write("### User Milestones")
            projection_updater.display_milestones_liabilities(user_id_1)        

    def transpose_and_sort_dates(self, df):
        df['entry_date'] = pd.to_datetime(df['entry_date'], format='%d-%m-%Y')
        df = df.sort_values(by='entry_date')
        df['entry_date'] = df['entry_date'].dt.strftime('%d-%m-%Y')
        return df
    
    #Milestone_calculation    
    def fetch_distinct_milestones_liabilities_purpose(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT TRIM(purpose) AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND purpose <> 'None';
        """, (user_id,))

        liabilities_purpose = cursor.fetchall()
        cursor.close()

        return liabilities_purpose
    
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age 


    def create_milestone_calculation_projection_table(self, dob, retirement_age, liabilities_purpose, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for purpose, category_id in liabilities_purpose:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'milestone_name': purpose,
                    'milestone_value': 0  # Initialize milestone value to 0
                }
                projections.append(projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return projections
    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM milestone_customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()

    def update_milestone_data_in_db(self, user_id, milestone_name, milestone_data):
        """
        Update milestone fields, then recompute and lock pdf_outstanding so it stays stable in future runs.
        """
        with self.connection.cursor() as cursor:
            cursor.execute("""
                UPDATE milestones_liabilities
                SET milestone_year = %s,
                    amount = %s,
                    your_percent_share = %s,
                    inflation = %s,
                    loan_funded = %s,
                    interest_rate = %s
                WHERE user_code = %s AND purpose = %s;
            """, (
                milestone_data['milestone_year'],
                milestone_data['amount'],
                milestone_data['your_percent_share'],
                milestone_data['inflation'],
                milestone_data['loan_funded'],
                milestone_data['interest_rate'],
                user_id,
                milestone_name
            ))

            # Lock the value after any change
            dob, _ = self.fetch_user_data(user_id)
            locked = self._compute_outstanding_locked(
                dob,
                milestone_data['milestone_year'],
                milestone_data['amount'],
                milestone_data['your_percent_share'],
                milestone_data['inflation']
            )
            cursor.execute("""
                UPDATE milestones_liabilities
                SET pdf_outstanding = %s,
                    outstanding_amount = %s       
                WHERE user_code = %s AND purpose = %s;
            """, (locked, locked, user_id, milestone_name))

            self.connection.commit()

    # (Kept from your original â€“ not used in the new locked flow, but harmless)
    def recalculate_outstanding_amount(self, user_id, dob, milestone_name, milestone_year, current_age):
        current_date = date.today()
        current_year = current_date.year
        current_month = current_date.month
        last_day = monthrange(current_year, current_month)[1]
        last_date = date(current_year, current_month, last_day)
        st.write('last_day', last_date)

        current_age = self.calculate_age_on_date(dob, last_date)
        st.write('current_age', current_age)

        cursor = self.connection.cursor()
        last_day_of_milestone_month = milestone_year.replace(day=monthrange(milestone_year.year, milestone_year.month)[1])

        milestone_age = self.calculate_age_on_date(dob, last_day_of_milestone_month)
        st.write('milestone_age', milestone_age)

        query = """
        UPDATE milestones_liabilities
        SET outstanding_amount = (your_percent_share * amount *
                                  POWER(1 + inflation, %s))
        WHERE user_code = %s AND purpose = %s;
        """
        cursor.execute(query, (milestone_age - current_age, user_id, milestone_name))
        self.connection.commit()

        cursor.execute("""
        SELECT outstanding_amount
        FROM milestones_liabilities
        WHERE user_code = %s AND purpose = %s AND milestone_year = %s;
        """, (user_id, milestone_name, milestone_year))
        result = cursor.fetchone()
        cursor.close()

        if result is not None:
            return result[0]
        else:
            return None
        
        
    def update_milestone_calculation_projections(self, milestone_calculation_projections_df, distinct_milestones_names, user_id, dob):
        # Select milestone name from distinct milestone names
        milestone_name = st.selectbox("Select milestone name:", distinct_milestones_names, key="milestone_name_input")

        # Fetch current data for the selected milestone from the database
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT milestone_year, amount, your_percent_share, inflation, loan_funded, interest_rate
            FROM milestones_liabilities
            WHERE user_code = %s AND purpose = %s;
        """, (user_id, milestone_name))
        current_data = cursor.fetchone()
        cursor.close()

        # Provide option to keep the existing data ("Same") or enter new values
        entry_date_option = st.selectbox("Milestone year:", ["Same", "New"], key="milestone_year_option")
        if entry_date_option == "New":
            entry_date = st.date_input("Enter the milestone year:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="milestone_entry_date")
        else:
            entry_date = current_data[0]

        amount_option = st.selectbox("Amount:", ["Same", "New"], key="milestone_amount_option")
        if amount_option == "New":
            amount = st.number_input("Enter the amount:", key="milestone_amount")
        else:
            amount = current_data[1]

        your_percent_share_option = st.selectbox("Your percent share:", ["Same", "New"], key="milestone_percent_share_option")
        if your_percent_share_option == "New":
            your_percent_share = st.number_input("Enter your percent share:", key="milestone_percent_share") / 100
        else:
            your_percent_share = current_data[2]

        inflation_option = st.selectbox("Inflation rate:", ["Same", "New"], key="milestone_inflation_option")
        if inflation_option == "New":
            inflation = st.number_input("Enter the inflation rate:", key="milestone_inflation") / 100
        else:
            inflation = current_data[3]

        loan_funded_option = st.selectbox("Loan funded status:", ["Same", "New"], key="milestone_loan_funded_option")
        if loan_funded_option == "New":
            loan_funded = st.selectbox("Enter the loan funded status:", ['Yes', 'No'], key="milestone_loan_funded")
        else:
            loan_funded = current_data[4]

        interest_rate_option = st.selectbox("Interest rate status:", ["Same", "New"], key="milestone_interest_rate_option")
        if interest_rate_option == "New":
            interest_rate = st.selectbox("Enter the interest rate status:", ['Yes', 'No'], key="milestone_interest_rate")
        else:
            interest_rate = current_data[5]

        if st.button("change milestone data"):
            # Prepare the milestone data based on user inputs
            milestone_data = {
                'milestone_year': entry_date if entry_date_option == "New" else current_data[0],
                'amount': float(amount) if amount_option == "New" else current_data[1],
                'your_percent_share': float(your_percent_share) if your_percent_share_option == "New" else current_data[2],
                'inflation': float(inflation) if inflation_option == "New" else current_data[3],
                'loan_funded': loan_funded if loan_funded_option == "New" else current_data[4],
                'interest_rate': interest_rate if interest_rate_option == "New" else current_data[5],
            }

            # Update DB and lock pdf_outstanding based on current parameters
            self.update_milestone_data_in_db(user_id, milestone_name, milestone_data)
            st.success("Milestone saved and locked for PDF (pdf_outstanding).")

        # --------- ALWAYS lock missing pdf_outstanding for ALL milestones before merging ---------
        self._ensure_all_pdf_outstanding(user_id)

        # Pull the (now locked) values for merge
        milestones_liabilities_query = """
            SELECT user_code, pdf_outstanding, milestone_year, category_id
            FROM milestones_liabilities
            WHERE user_code = %s;
        """
        cursor = self.connection.cursor()
        cursor.execute(milestones_liabilities_query, (user_id,))
        milestones_liabilities_data = cursor.fetchall()
        cursor.close()

        milestones_liabilities_df = pd.DataFrame(
            milestones_liabilities_data,
            columns=['user_code', 'pdf_outstanding', 'milestone_year', 'category_id']
        )

        # Convert types for merging
        milestones_liabilities_df['user_code'] = milestones_liabilities_df['user_code'].astype(str)
        milestones_liabilities_df['milestone_year'] = milestones_liabilities_df['milestone_year'].astype(str)

        milestone_calculation_projections_df['entry_date'] = milestone_calculation_projections_df['entry_date'].astype(str)
        milestone_calculation_projections_df['user_code'] = milestone_calculation_projections_df['user_code'].astype(str)

        # Step 1: Reset milestone_value to 0 for each combination (same intent as your original)
        for _, row in milestones_liabilities_df.iterrows():
            u = row['user_code']
            cat = row['category_id']
            indices_to_zero = milestone_calculation_projections_df[
                (milestone_calculation_projections_df['user_code'] == u) &
                (milestone_calculation_projections_df['category_id'] == cat)
            ].index
            milestone_calculation_projections_df.loc[indices_to_zero, 'milestone_value'] = 0

        # Step 2: Merge on the exact month equality (entry_date == milestone_year)
        updated_df = pd.merge(
            milestone_calculation_projections_df,
            milestones_liabilities_df,
            how='left',
            left_on=['user_code', 'category_id', 'entry_date'],
            right_on=['user_code', 'category_id', 'milestone_year']
        )

        # Step 3: Use the LOCKED value
        updated_df['milestone_value'] = updated_df['pdf_outstanding'].fillna(updated_df['milestone_value'])

        updated_df = updated_df.drop(columns=['pdf_outstanding', 'milestone_year'])
        milestone_calculation_projections_df = updated_df

        # Save back
        self.save_milestone_calculation_projections_to_db(milestone_calculation_projections_df)
        st.success("Milestone projections updated with locked values and saved.")
        return milestone_calculation_projections_df    
    

    def _ensure_all_pdf_outstanding(self, user_id):
        """
        For this user, compute & set pdf_outstanding ONCE per milestone (if NULL).
        """
        with self.connection.cursor() as cur:
            dob, _ = self.fetch_user_data(user_id)
            cur.execute("""
                SELECT purpose, milestone_year, amount, your_percent_share, inflation, pdf_outstanding
                FROM milestones_liabilities
                WHERE user_code = %s;
            """, (user_id,))
            rows = cur.fetchall()

            changed = False
            for purpose, ms_year, amount, share, infl, pdf_val in rows:
                if pdf_val is None and all(v is not None for v in (ms_year, amount, share, infl)):
                    locked = self._compute_outstanding_locked(dob, ms_year, amount, share, infl)
                    cur.execute("""
                        UPDATE milestones_liabilities
                        SET pdf_outstanding = %s,
                            outstanding_amount = %s    
                        WHERE user_code = %s AND purpose = %s;
                    """, (locked, locked, user_id, purpose))
                    changed = True

            if changed:
                self.connection.commit()
        
    
    def save_milestone_calculation_projections_to_db(self, milestone_calculation_projections_df):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table
        milestone_calculation_projections_df.to_sql('milestone_calculation_projections', engine, if_exists='replace', index=False, method='multi',chunksize=1000, schema='public' )

        st.success("Milestone calculations saved to the database.")

    def load_milestone_calculation_projections_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'milestone_calculation_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            st.write("Table 'milestone_calculation_projections' does not exist.")
            return pd.DataFrame()
        else:
            return pd.read_sql('milestone_calculation_projections', engine)
        
    # Function to delete records with entry_date less than the current date
    def delete_old_milestone_calculation_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM milestone_calculation_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")


    def _build_monthly_skeleton_for_goals(self, dob, retirement_age, liabilities_subset, user_id, user_name, month_choice):
        """
        Build the same monthly skeleton as create_milestone_calculation_projection_table,
        but only for the goals in liabilities_subset which is a list of (purpose, category_id).
        """
        from calendar import monthrange
        rows = []

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month

        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        d = start_date
        while (d.year < age_limit_year) or (d.year == age_limit_year and d.month <= month_choice):
            last_day = d.replace(day=monthrange(d.year, d.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day.date())

            for purpose, category_id in liabilities_subset:
                rows.append({
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'milestone_name': purpose,
                    'milestone_value': 0.0
                })

            # jump to first day of next month then set to its last day
            d = (last_day + timedelta(days=1)).replace(day=1)

        return rows    
    
    def _last_day_of(self, y, m):
        return date(y, m, monthrange(y, m)[1])

    def _compute_outstanding_locked(self, dob, milestone_year, amount, share, inflation):
        """
        Compute once, anchored on the last day of the current calendar month when we lock it.
        """
        today = date.today()
        anchor_day = self._last_day_of(today.year, today.month)  # fixed reference day
        milestone_day = self._last_day_of(milestone_year.year, milestone_year.month)

        current_age = self.calculate_age_on_date(dob, anchor_day)
        milestone_age = self.calculate_age_on_date(dob, milestone_day)
        years = max(0, milestone_age - current_age)

        return float(share) * float(amount) * ((1.0 + float(inflation)) ** years)


    def _append_missing_goals_for_user(self, df, liabilities_purpose, user_id, user_name, dob, retirement_age, month_choice):
        """
        Ensure the projections table has rows for any NEW goals for this user.
        liabilities_purpose is list of (purpose, category_id).
        """
        if df is None or df.empty:
            return df  # nothing to do here

        # Filter existing rows for this user
        user_df = df[df['user_code'].astype(str) == str(user_id)]
        # What (category_id, milestone_name) pairs does the user already have?
        existing_pairs = set(zip(user_df.get('category_id', []), user_df.get('milestone_name', [])))
        # What pairs are required from DB now?
        needed_pairs = [(cid, name) for (name, cid) in liabilities_purpose if (cid, name) not in existing_pairs]

        if not needed_pairs:
            return df  # already complete

        # Build skeleton rows only for missing pairs
        liabilities_subset = [(name, cid) for (name, cid) in liabilities_purpose if (cid, name) in needed_pairs]
        add_rows = self._build_monthly_skeleton_for_goals(dob, retirement_age, liabilities_subset, user_id, user_name, month_choice)
        add_df = pd.DataFrame(add_rows)

        # Align columns and concat
        for col in df.columns:
            if col not in add_df.columns:
                add_df[col] = None
        add_df = add_df[df.columns]
        df = pd.concat([df, add_df], ignore_index=True)

        # De-duplicate just in case
        if {'user_code','category_id','entry_date'}.issubset(df.columns):
            df.drop_duplicates(subset=['user_code','category_id','entry_date'], keep='last', inplace=True)

        return df

    def fetch_milestone_sort_order(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT TRIM(purpose) AS milestone_name, milestone_year
            FROM milestones_liabilities
            WHERE user_code = %s
            AND purpose IS NOT NULL
            AND purpose <> 'None'
            ORDER BY milestone_year ASC;
        """, (user_id,))

        rows = cursor.fetchall()
        cursor.close()

        # Return milestone_name in sorted order
        return [name for name, _ in rows]   
     
    
    def delete_milestone_from_milestone_calculation_projections(self, milestone_calculation_projections_df, user_id, milestone_name):
        """Remove all rows for (user_id, milestone_name) from the projections DF."""
        mask = ~(
            (milestone_calculation_projections_df['user_code'].astype(str) == str(user_id)) &
            (milestone_calculation_projections_df['milestone_name'].astype(str) == str(milestone_name))
        )
        return milestone_calculation_projections_df.loc[mask].copy()


    def run_milestone_calculation_projections(self, user_id, month_choice):
        drop_table = st.radio("Do you want to drop the milestone_calculation_projections table?", ["No", "Yes"], index=0)

        # Check if table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if drop_table == "Yes":
            if inspector.has_table('milestone_calculation_projections', schema='public'):
                with engine.connect() as connection:
                    connection.execute(text("DROP TABLE milestone_calculation_projections;"))
                    st.success("milestone_calculation_projections table has been dropped successfully.")
                    return
            else:
                st.warning("The milestone_calculation_projections table does not exist.")

        if inspector.has_table('milestone_calculation_projections'):
            self.delete_old_milestone_calculation_records()

        update_milestones_1 = st.radio( "Do you want to update the milestone_calculation_projections table?", ('No', 'Yes'), key="update_milestones_toggle_1")    
        if update_milestones_1 == 'Yes':

            liabilities_purpose = self.fetch_distinct_milestones_liabilities_purpose(user_id)
            #st.write('liabilities_purpose',liabilities_purpose)
            dob, retirement_age = self.fetch_user_data(user_id)
            user_name = self.fetch_user_name(user_id)
            distinct_milestones_names = [milestones for milestones, _ in liabilities_purpose]

            # Always load current projections (could be empty)
            milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()

            # If the table is missing/empty, build everything for the user
            if milestone_calculation_projections_df is None or milestone_calculation_projections_df.empty:
                new_projections = self.create_milestone_calculation_projection_table(
                    dob, retirement_age, liabilities_purpose, user_id, user_name, month_choice
                )
                milestone_calculation_projections_df = pd.DataFrame(new_projections)
                st.write('built fresh projections for user')
            else:
                # Normalize types for presence check
                user_present = str(user_id) in milestone_calculation_projections_df['user_code'].astype(str).unique()

                if not user_present:
                    # Add the full user if missing
                    new_projections = self.create_milestone_calculation_projection_table(
                        dob, retirement_age, liabilities_purpose, user_id, user_name, month_choice
                    )
                    milestone_calculation_projections_df = pd.concat(
                        [milestone_calculation_projections_df, pd.DataFrame(new_projections)],
                        ignore_index=True
                    )
                    st.write('added user projections')
                else:
                    # Append only missing goals (new category_id) for this user
                    milestone_calculation_projections_df = self._append_missing_goals_for_user(
                        milestone_calculation_projections_df,
                        liabilities_purpose,
                        user_id,
                        user_name,
                        dob,
                        retirement_age,
                        month_choice
                    )
                    st.write('appended missing goals for this user')
    
            # Update milestone projections via UI (locks pdf_outstanding and merges the LOCKED values)
            milestone_calculation_projections_df = self.update_milestone_calculation_projections(
                milestone_calculation_projections_df, distinct_milestones_names, user_id, dob
            )

            # Save (already saved inside update), but keep your original save for safety
            self.save_milestone_calculation_projections_to_db(milestone_calculation_projections_df)
            # st.write("### Milestone Calculation Projections after changes:")
            # milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
            # reshaped_df = self.display_reshape_milestone_projections(milestone_calculation_projections_df, user_id)
            # st.dataframe(reshaped_df)

        # === Manual milestone updates (same UX as code number 1) ===
        update_milestones = st.radio(
            "Do you want to update the milestone_calculation_projections table by using single and range option?", ('No', 'Yes'), key="update_milestones_toggle")

        if update_milestones == 'Yes':
            # Always pull fresh (so the user edits whatâ€™s actually stored)
            mcp_df = self.load_milestone_calculation_projections_from_db()
            mcp_df = self.update_dynamic_milestone_values(user_id, mcp_df)
            st.write("Milestone projections updated and saved.")

        # ---------- DELETE A MILESTONE NAME (new UI) ----------
        st.write("## Delete a Milestone Name")

        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        if milestone_calculation_projections_df is None or milestone_calculation_projections_df.empty:
            st.info("No projections found to delete.")
        else:
            # Filter to this user, list unique milestone names
            user_rows = milestone_calculation_projections_df[
                milestone_calculation_projections_df['user_code'].astype(str) == str(user_id)
            ]
            unique_milestone_names = sorted(
                user_rows['milestone_name'].dropna().astype(str).unique().tolist()
            )

            if not unique_milestone_names:
                st.info("No milestones available for this user.")
            else:
                milestone_to_delete = st.selectbox(
                    "Select milestone name to delete from projections:",
                    unique_milestone_names,
                    key="mcp_delete_milestone"
                )

                if st.button("Delete Selected Milestone Name", key="delete_milestone_name"):
                    updated_df = self.delete_milestone_from_milestone_calculation_projections(
                        milestone_calculation_projections_df, user_id, milestone_to_delete
                    )
                    self.save_milestone_calculation_projections_to_db(updated_df)
                    st.success(f"Milestone name '{milestone_to_delete}' has been deleted from projections for user_id {user_id}.")
                    # Reload for display
                    milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()    

        # Display the updated milestone projections in a table
        st.write("### Milestone Calculation Projections after changes:")
        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        reshaped_df = self.display_reshape_milestone_projections(milestone_calculation_projections_df, user_id)
        st.dataframe(reshaped_df)

    def reshape_milestone_projections(self, milestone_calculation_projections_df, user_id):
        # Filter data for the specified user
        user_df = milestone_calculation_projections_df[milestone_calculation_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get milestone names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='milestone_name', 
                                          columns=['entry_date', 'age'],
                                          values='milestone_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring milestone_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        milestone_sort_order = self.fetch_milestone_sort_order(user_id)

        # Convert milestone_name to ordered categorical
        reshaped_df['milestone_name'] = pd.Categorical(
            reshaped_df['milestone_name'],
            categories=milestone_sort_order,
            ordered=True
        )

        # Apply sort
        reshaped_df = reshaped_df.sort_values('milestone_name')
        
        return reshaped_df
    
    def display_reshape_milestone_projections(self, milestone_calculation_projections_df, user_id):
        # Work on a copy
        df = milestone_calculation_projections_df.copy()

        # Normalize types so filtering & pivot work reliably
        df['user_code'] = df['user_code'].astype(str)
        user_id_str = str(user_id)
        df = df[df['user_code'] == user_id_str]

        # Clean names and ensure numeric
        df['milestone_name'] = df['milestone_name'].astype(str).str.strip()
        df['milestone_value'] = pd.to_numeric(df['milestone_value'], errors='coerce').fillna(0)
        df['age'] = pd.to_numeric(df['age'], errors='coerce').astype('Int64')

        # Robust date handling + sort
        df['entry_date'] = pd.to_datetime(df['entry_date'], errors='coerce')
        df = df.dropna(subset=['entry_date']).sort_values('entry_date')

        # Use string dates for column headers in the pivot (keeps order stable)
        df['entry_date'] = df['entry_date'].dt.strftime('%Y-%m-%d')

        # Pivot to the wide view you want
        reshaped_df = df.pivot_table(
            index='milestone_name',
            columns=['entry_date', 'age'],
            values='milestone_value',
            aggfunc='sum',
            fill_value=0
        ).reset_index()

         # âœ” STEP: GET SORT ORDER FROM milestones_liabilities
        milestone_sort_order = self.fetch_milestone_sort_order(user_id)

        # âœ” Apply custom order using Categorical
        reshaped_df['milestone_name'] = pd.Categorical(
            reshaped_df['milestone_name'],
            categories=milestone_sort_order,
            ordered=True
        )

        reshaped_df = reshaped_df.sort_values("milestone_name")

        # Make milestone_name index again
        reshaped_df.set_index("milestone_name", inplace=True)

        return reshaped_df


    def copy_assets_to_assets_milestones(self, user_code):
        try:
            cursor = self.connection.cursor()

            # Fetch all records for the given user_code from the assets table
            cursor.execute("""
                SELECT * FROM assets WHERE user_code = %s AND is_active = TRUE AND (current_amount > 0 OR monthly_investment > 0);
            """, (user_code,))
            assets_records = cursor.fetchall()
            #st.write('assets_records', assets_records)

            if not assets_records:
                st.error(f"No records found in the assets table for user_code: {user_code}")
                return

            # Insert the fetched records into the assets_milestones table
            insert_query = """
                INSERT INTO assets_milestones (
                    id, created_at, last_updated_at, user_code, category_id, current_amount,
                    monthly_investment, expiry, is_manual_entry, fetched_source,
                    months, name, is_active, custom_name
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            for record in assets_records:
                cursor.execute(insert_query, record)

            self.connection.commit()
            st.success("Assets successfully copied to the assets_milestones table.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            cursor.close()


    def copy_customer_profile_to_milestone_customer_profile(self, user_code):
        """
        Copy matching rows from customer_profile -> milestone_customer_profile
        for the given user_code, preserving column order/types as requested.
        """
        try:
            cursor = self.connection.cursor()

            # Fetch all rows for this user from customer_profile
            cursor.execute("""
                SELECT
                    id, user_code, first_name, last_name, dob, gender, email, city, state, country, money_sign,
                    marital_status, created_at, updated_at, education, retirement_age, member_id, pan_no, pan_name,
                    is_active, email_verified, ms_completed_date
                FROM customer_profile
                WHERE user_code = %s
                AND is_active = TRUE;
            """, (user_code,))

            rows = cursor.fetchall()

            if not rows:
                st.error(f"No active customer_profile records found for user_code: {user_code}")
                return

            # Insert into milestone_customer_profile with explicit column list
            insert_sql = """
                INSERT INTO milestone_customer_profile (
                    id, user_code, first_name, last_name, dob, gender, email, city, state, country,
                    money_sign, marital_status, created_at, updated_at, education, retirement_age, member_id, pan_no, pan_name,
                    is_active, email_verified, ms_completed_date
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
            """

            for rec in rows:
                cursor.execute(insert_sql, rec)

            self.connection.commit()
            st.success("Successfully copied customer_profile records to milestone_customer_profile.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            try:
                cursor.close()
            except Exception:
                pass


    def copy_income_to_milestone_income(self, user_code):
        """
        Copy matching rows from income -> milestone_income
        for the given user_code, preserving column order/types.
        """
        try:
            cursor = self.connection.cursor()

            # Fetch all rows for this user from income
            cursor.execute("""
                SELECT
                    id, created_at, last_updated_at, user_code, category_id, yearly_amount, expiry, is_manual_entry,
                    fetched_source, months, name, is_active
                FROM income
                WHERE user_code = %s
                AND is_active = TRUE;
            """, (user_code,))

            rows = cursor.fetchall()

            if not rows:
                st.error(f"No active income records found for user_code: {user_code}")
                return

            # Insert into milestone_income with explicit column list
            insert_sql = """
                INSERT INTO milestone_income (
                    id, created_at, last_updated_at, user_code, category_id, yearly_amount, expiry,
                    is_manual_entry, fetched_source, months, name, is_active
                ) VALUES (
                    %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s
                )
            """

            for rec in rows:
                cursor.execute(insert_sql, rec)

            self.connection.commit()
            st.success("Successfully copied income records to milestone_income.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            try:
                cursor.close()
            except Exception:
                pass  

    def copy_customer_details_to_milestone_customer_details(self, user_code):
        """
        Copy matching rows from customer_details -> milestone_customer_details
        for the given user_code, preserving column order/types.
        """
        try:
            cursor = self.connection.cursor()

            # Fetch all active rows for this user from customer_details
            cursor.execute("""
                SELECT
                    id,
                    user_code,
                    category_id,
                    value,
                    description,
                    is_active,
                    created_at,
                    updated_at,
                    cycle,
                    created_by,
                    updated_by,
                    is_mannual_update
                FROM customer_details
                WHERE user_code = %s
                AND is_active = TRUE;
            """, (user_code,))

            rows = cursor.fetchall()

            if not rows:
                st.error(f"No active customer_details records found for user_code: {user_code}")
                return

            # Insert into milestone_customer_details with explicit column list
            insert_sql = """
                INSERT INTO milestone_customer_details (
                    id, user_code, category_id, value, description, is_active,
                    created_at, updated_at, cycle, created_by, updated_by, is_mannual_update
                ) VALUES (
                    %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s
                )
            """

            for rec in rows:
                cursor.execute(insert_sql, rec)

            self.connection.commit()
            st.success("Successfully copied customer_details records to milestone_customer_details.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            try:
                cursor.close()
            except Exception:
                pass
    
    
    def copy_expenses_to_milestone_expenses(self, user_code):
        """
        Copy matching rows from expenses -> milestone_expenses
        for the given user_code, preserving column order/types.
        """
        try:
            cursor = self.connection.cursor()

            # Fetch all rows for this user from expenses
            cursor.execute("""
                SELECT
                    id, created_at, last_updated_at, user_code, category_id, yearly_amount, expiry, is_manual_entry,
                    fetched_source, months, name, is_active
                FROM expenses
                WHERE user_code = %s
                AND is_active = TRUE;
            """, (user_code,))

            rows = cursor.fetchall()

            if not rows:
                st.error(f"No active expenses records found for user_code: {user_code}")
                return

            # Insert into milestone_expenses with explicit column list
            insert_sql = """
                INSERT INTO milestone_expenses (
                    id, created_at, last_updated_at, user_code, category_id, yearly_amount, expiry,
                    is_manual_entry, fetched_source, months, name, is_active
                ) VALUES (
                    %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s
                )
            """

            for rec in rows:
                cursor.execute(insert_sql, rec)

            self.connection.commit()
            st.success("Successfully copied expenses records to milestone_expenses.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            try:
                cursor.close()
            except Exception:
                pass

    
    def copy_life_stage_growth_to_milestone(self, user_code):
        """
        Copy rows from life_stage_growth -> life_stage_growth_milestone
        for the given user_code, preserving column order.
        """

        try:
            cursor = self.connection.cursor()

            # -------------------------------------------
            # 1. Fetch rows from life_stage_growth
            # -------------------------------------------
            cursor.execute("""
                SELECT
                    id, user_code, category_id, min_age_range, max_age_range, growth_rate, name,
                    is_active, created_at, updated_at
                FROM life_stage_growth
                WHERE user_code = %s
                AND is_active = True;
            """, (user_code,))

            rows = cursor.fetchall()

            if not rows:
                st.error(f"No life_stage_growth records found for user_code: {user_code}")
                return

            # -------------------------------------------
            # 2. Insert into life_stage_growth_milestone
            # -------------------------------------------
            insert_sql = """
                INSERT INTO life_stage_growth_milestone (
                    id, user_code, category_id, min_age_range, max_age_range, growth_rate, name,
                    is_active, created_at, updated_at
                ) VALUES (
                    %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s
                )
            """

            for rec in rows:
                cursor.execute(insert_sql, rec)

            # Commit after all inserts
            self.connection.commit()
            st.success("Successfully copied life_stage_growth records to life_stage_growth_milestone.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"Error while copying life stage growth data: {e}")

        finally:
            try:
                cursor.close()
            except:
                pass


    def manage_life_stage_growth_milestone(self, user_id):
        st.subheader("Update Existing life_stage_growth_milestone Records")
        do_update = st.radio( "Do you want to update growth rate values?", ["No", "Yes"], index=0, key="lsgm_update_radio")

        if do_update == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user_code above before updating.")
                else:
                    st.info("Enter NEW growth_rate values for each category:")
                    
                    # Same/New controls per category
                    update_options = {
                        "cat_239": st.selectbox("Growth Rate (26-35)", ["Same", "New"], key="mi_update_cat239_option"),
                        "cat_240": st.selectbox("Growth Rate (36-45)", ["Same", "New"], key="mi_update_cat240_option"),
                        "cat_241": st.selectbox("Growth Rate (46-55)", ["Same", "New"], key="mi_update_cat241_option"),
                        "cat_242": st.selectbox("Growth Rate (56-65)", ["Same", "New"], key="mi_update_cat242_option"),
                    }
                    
                    updates = {}
                    if update_options["cat_239"] == "New":
                        updates["cat_239"] = st.number_input( "New Growth Rate (26-35)", value=0.0, key="mi_update_cat239_amount")/100
                        
                    if update_options["cat_240"] == "New":
                        updates["cat_240"] = st.number_input( "New Growth Rate (36-45)", value=0.0, key="mi_update_cat240_amount")/100	
                        
                    if update_options["cat_241"] == "New":
                        updates["cat_241"] = st.number_input( "New Growth Rate (46-55)", value=0.0, key="mi_update_cat241_amount")/100		

                    if update_options["cat_242"] == "New":
                        updates["cat_242"] = st.number_input( "New Growth Rate (56-65)", value=0.0, key="mi_update_cat242_amount")/100
                        
                    if st.button("Update Growth Rate", key="mi_update_growth_rate_1"):
                            if not updates:
                                st.info("No changes selected (both set to Same). Nothing to update.")
                            else:
                                try:
                                    msgs = []
                                    with self.connection.cursor() as cursor:
                                        # Separate update for category_id = 239
                                        if "cat_239" in updates:
                                            cursor.execute(
                                                """
                                                UPDATE life_stage_growth_milestone
                                                SET growth_rate = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 239
                                                AND is_active = TRUE;
                                                """,
                                                (float(updates["cat_239"]), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated the growth rate (26-35)")
                                            else:
                                                msgs.append("No row to update growth rate (26-35)")

                                        # Separate update for category_id = 240
                                        if "cat_240" in updates:
                                            cursor.execute(
                                                """
                                                UPDATE life_stage_growth_milestone
                                                SET growth_rate = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 240
                                                AND is_active = TRUE;
                                                """,
                                                (float(updates["cat_240"]), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated the growth rate (36-45)")
                                            else:
                                                msgs.append("No row to update growth rate (36-45)")
                                                
                                                
                                        # Separate update for category_id = 241
                                        if "cat_241" in updates:
                                            cursor.execute(
                                                """
                                                UPDATE life_stage_growth_milestone
                                                SET growth_rate = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 241
                                                AND is_active = TRUE;
                                                """,
                                                (float(updates["cat_241"]), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated the growth rate (46-55)")
                                            else:
                                                msgs.append("No row to update growth rate (46-55)")
                                        
                                        # Separate update for category_id = 242
                                        if "cat_242" in updates:
                                            cursor.execute(
                                                """
                                                UPDATE life_stage_growth_milestone
                                                SET growth_rate = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 242
                                                AND is_active = TRUE;
                                                """,
                                                (float(updates["cat_242"]), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated the growth rate (56-65)")
                                            else:
                                                msgs.append("No row to update growth rate (56-65)")									
                                        

                                    self.connection.commit()
                                    # Show combined result
                                    if msgs:
                                        for m in msgs:
                                            st.success(m)
                                except Exception as e:
                                    self.connection.rollback()
                                    st.error(f"Error updating milestone_income: {e}")
            except Exception as e:
                st.error(f"Error setting up update UI: {e}")
        
        
    def manage_milestone_income(self):
        # ---------- UPDATE (yearly_amount for category_id 65 and 306) ----------
        st.subheader("Update Existing milestone_income Records")
        do_update_mi = st.radio(
            "Do you want to update yearly_amount for Category 65 and/or 306?",
            ["No", "Yes"],
            index=0,
            key="mi_update_radio",
        )

        if do_update_mi == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before updating.")
                else:
                    # Same/New controls per category
                    update_options = {
                        "cat_65": st.selectbox("Annual Salary (yearly_amount)", ["Same", "New"], key="mi_update_cat65_option"),
                        "cat_306": st.selectbox("Rental Income (commercial or residential) (yearly_amount)", ["Same", "New"], key="mi_update_cat306_option"),
                    }

                    updates = {}
                    if update_options["cat_65"] == "New":
                        updates["cat_65"] = st.number_input(
                            "New Annual Salary",
                            min_value=0.0,
                            step=1000.0,
                            key="mi_update_cat65_amount",
                        )
                    if update_options["cat_306"] == "New":
                        updates["cat_306"] = st.number_input(
                            "New Rental Income (commercial or residential)",
                            min_value=0.0,
                            step=1000.0,
                            key="mi_update_cat306_amount",
                        )

                    if st.button("Update milestone_income", key="mi_update_btn"):
                        if not updates:
                            st.info("No changes selected (both set to Same). Nothing to update.")
                        else:
                            try:
                                msgs = []
                                with self.connection.cursor() as cursor:
                                    # Separate update for category_id = 65
                                    if "cat_65" in updates:
                                        cursor.execute(
                                            """
                                            UPDATE milestone_income
                                            SET yearly_amount = %s,
                                                last_updated_at = NOW()
                                            WHERE user_code = %s
                                            AND category_id = 65
                                            AND is_active = TRUE;
                                            """,
                                            (float(updates["cat_65"]), str(user_id)),
                                        )
                                        if cursor.rowcount > 0:
                                            msgs.append("Updated the annual salary")
                                        else:
                                            msgs.append("No row to update annual salary")

                                    # Separate update for category_id = 306
                                    if "cat_306" in updates:
                                        cursor.execute(
                                            """
                                            UPDATE milestone_income
                                            SET yearly_amount = %s,
                                                last_updated_at = NOW()
                                            WHERE user_code = %s
                                            AND category_id = 306
                                            AND is_active = TRUE;
                                            """,
                                            (float(updates["cat_306"]), str(user_id)),
                                        )
                                        if cursor.rowcount > 0:
                                            msgs.append("Updated Rental Income (commercial or residential)")
                                        else:
                                            msgs.append("No row to update Rental Income (commercial or residential)")

                                self.connection.commit()
                                # Show combined result
                                if msgs:
                                    for m in msgs:
                                        st.success(m)
                            except Exception as e:
                                self.connection.rollback()
                                st.error(f"Error updating milestone_income: {e}")
            except Exception as e:
                st.error(f"Error setting up update UI: {e}")

        # ---------- DELETE (by user_id only) ----------
        st.subheader("Delete milestone_income Records")
        do_delete_mi = st.radio(
            "Do you want to delete ALL milestone_income rows for this user?",
            ["No", "Yes"],
            index=0,
            key="mi_delete_radio",
        )

        if do_delete_mi == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before deleting.")
                else:
                    if st.button("Delete milestone_income", key="mi_delete_btn"):
                        try:
                            with self.connection.cursor() as cursor:
                                cursor.execute(
                                    """
                                    DELETE FROM milestone_income
                                    WHERE user_code = %s;
                                    """,
                                    (str(user_id),),
                                )
                                self.connection.commit()
                                if cursor.rowcount > 0:
                                    st.success("Deleted milestone_income record(s) for this user.")
                                else:
                                    st.warning("No milestone_income record found for this user_code to delete.")
                        except Exception as e:
                            self.connection.rollback()
                            st.error(f"Error deleting milestone_income: {e}")
            except Exception as e:
                st.error(f"Error setting up delete UI: {e}")


    def manage_milestone_customer_details(self, user_id):
        """
        UI + actions to:
        1) Update milestone_customer_details.value for Tax Deduction Amount and Non Taxable Income
        2) Delete ALL milestone_customer_details rows for the given user_id
        """
        st.subheader("Update Existing milestone_customer_details Records")
        do_update_mcd = st.radio(
            "Do you want to update 'value' Tax Deduction Amount and Non Taxable Income?",
            ["No", "Yes"],
            index=0,
            key="mcd_update_radio",
        )

        if do_update_mcd == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before updating.")
                else:
                    # Same/New controls per category
                    update_options = {
                        "cat_211": st.selectbox(
                            "Tax Deduction Amount",
                            ["Same", "New"],
                            key="mcd_update_cat211_option",
                        ),
                        "cat_343": st.selectbox(
                            "Non Taxable Income",
                            ["Same", "New"],
                            key="mcd_update_cat343_option",
                        ),
                    }

                    updates = {}
                    # You can switch these to number_input if your 'value' is numeric.
                    if update_options["cat_211"] == "New":
                        updates["cat_211"] = st.text_input(
                            "New value for Tax Deduction Amount",
                            key="mcd_update_cat211_value",
                        )

                    if update_options["cat_343"] == "New":
                        updates["cat_343"] = st.text_input(
                            "New value for Non Taxable Income",
                            key="mcd_update_cat343_value",
                        )

                    if st.button("Update milestone_customer_details", key="mcd_update_btn"):
                        if not updates:
                            st.info("No changes selected (both set to Same). Nothing to update.")
                        else:
                            try:
                                msgs = []
                                with self.connection.cursor() as cursor:
                                    # Separate update for category_id = 211
                                    if "cat_211" in updates:
                                        new_val = updates["cat_211"]
                                        if new_val is None or str(new_val).strip() == "":
                                            st.warning("Tax Deduction Amount: New value is empty; skip updating.")
                                        else:
                                            cursor.execute(
                                                """
                                                UPDATE milestone_customer_details
                                                SET value = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 211
                                                AND is_active = TRUE;
                                                """,
                                                (str(new_val), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated Tax Deduction Amount.")
                                            else:
                                                msgs.append("No row found to update for Tax Deduction Amount.")

                                    # Separate update for category_id = 343
                                    if "cat_343" in updates:
                                        new_val = updates["cat_343"]
                                        if new_val is None or str(new_val).strip() == "":
                                            st.warning("Non Taxable Income: New value is empty; skip updating.")
                                        else:
                                            cursor.execute(
                                                """
                                                UPDATE milestone_customer_details
                                                SET value = %s,
                                                    updated_at = NOW()
                                                WHERE user_code = %s
                                                AND category_id = 343
                                                AND is_active = TRUE;
                                                """,
                                                (str(new_val), str(user_id)),
                                            )
                                            if cursor.rowcount > 0:
                                                msgs.append("Updated Non Taxable Income.")
                                            else:
                                                msgs.append("No row found to update for Non Taxable Income.")

                                self.connection.commit()
                                for m in msgs:
                                    st.success(m)
                            except Exception as e:
                                self.connection.rollback()
                                st.error(f"Error updating milestone_customer_details: {e}")
            except Exception as e:
                st.error(f"Error setting up update UI: {e}")

        # ---------- DELETE (by user_id only) ----------
        st.subheader("Delete milestone_customer_details Records")
        do_delete_mcd = st.radio(
            "Do you want to delete ALL milestone_customer_details rows for this user?",
            ["No", "Yes"],
            index=0,
            key="mcd_delete_radio",
        )

        if do_delete_mcd == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before deleting.")
                else:
                    if st.button("Delete milestone_customer_details", key="mcd_delete_btn"):
                        try:
                            with self.connection.cursor() as cursor:
                                cursor.execute(
                                    """
                                    DELETE FROM milestone_customer_details
                                    WHERE user_code = %s;
                                    """,
                                    (str(user_id),),
                                )
                                self.connection.commit()
                                if cursor.rowcount > 0:
                                    st.success("Deleted milestone_customer_details record(s) for this user.")
                                else:
                                    st.warning("No milestone_customer_details record found for this user_code to delete.")
                        except Exception as e:
                            self.connection.rollback()
                            st.error(f"Error deleting milestone_customer_details: {e}")
            except Exception as e:
                st.error(f"Error setting up delete UI: {e}")
            

    def manage_milestone_customer_profile(self):
        # ========== milestone_customer_profile CRUD (Insert/Update/Delete) ==========

        # ---------- INSERT (only dob & retirement_age; others NULL; booleans TRUE; timestamps NOW) ----------
        st.subheader("Insert New milestone_customer_profile Record")
        do_insert_mcp = st.radio(
            "Do you want to insert into milestone_customer_profile?",
            ["No", "Yes"],
            index=0,
            key="mcp_insert_radio",
        )

        if do_insert_mcp == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before inserting.")
                else:
                    first_name = st.text_input("First Name", key="mcp_ins_first_name")
                    last_name = st.text_input("Last Name", key="mcp_ins_last_name")
                    dob_val = st.date_input("Date of Birth",value=date.today(), min_value=date(1950, 1, 1), max_value=date(2100, 12, 31), key="mcp_ins_dob")
                    retirement_age_val = st.number_input(
                        "Retirement Age (years)", value=60, step=1, min_value=0, key="mcp_ins_ret_age"
                    )

                    if st.button("Insert milestone_customer_profile", key="mcp_insert_btn"):
                        try:
                            with self.connection.cursor() as cursor:
                                cursor.execute("""
                                    INSERT INTO milestone_customer_profile (
                                        user_code, first_name, last_name, dob, retirement_age, created_at, updated_at,
                                        is_active, email_verified, ms_completed_date)
                                    VALUES (       
                                        %s,         -- user_code
                                        %s, %s,     -- first name, last name
                                        %s,         -- dob
                                        %s,         -- retirement_age
                                        NOW(),      -- created_at
                                        NOW(),      -- updated_at
                                        TRUE,       -- is_active
                                        TRUE,       -- email_verified
                                        NOW()::text -- ms_completed_date (text)
                                    );
                                """, (str(user_id),first_name, last_name, dob_val, int(retirement_age_val)))
                                self.connection.commit()
                                st.success("Record inserted successfully (only DOB & Retirement Age)!")
                        except Exception as e:
                            self.connection.rollback()
                            st.error(f"Error inserting record: {e}")
            except Exception as e:
                st.error(f"Error setting up insert UI: {e}")

        # ---------- UPDATE (DOB & Retirement Age with Same/New options) ----------
        st.subheader("Update Existing milestone_customer_profile Record")
        do_update_mcp = st.radio(
            "Do you want to update DOB and/or Retirement Age?",
            ["No", "Yes"],
            index=0,
            key="mcp_update_radio",
        )

        if do_update_mcp == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before updating.")
                else:
                    update_options = {
                        "dob": st.selectbox("DOB", ["Same", "New"], key="mcp_update_dob_option"),
                        "retirement_age": st.selectbox("Retirement Age", ["Same", "New"], key="mcp_update_ret_age_option"),
                    }

                    updates = {}
                    if update_options["dob"] == "New":
                        updates["dob"] = st.date_input("New DOB",value=date.today(), min_value=date(1950, 1, 1), max_value=date(2100, 12, 31),  key="mcp_update_new_dob")

                    if update_options["retirement_age"] == "New":
                        updates["retirement_age"] = st.number_input(
                            "New Retirement Age (years)", min_value=0, step=1, key="mcp_update_new_ret_age"
                        )

                    if st.button("Update milestone_customer_profile", key="mcp_update_btn"):
                        if not updates:
                            st.info("No changes selected (both set to Same). Nothing to update.")
                        else:
                            try:
                                set_parts = []
                                params = []
                                if "dob" in updates:
                                    set_parts.append("dob = %s")
                                    params.append(updates["dob"])
                                if "retirement_age" in updates:
                                    set_parts.append("retirement_age = %s")
                                    params.append(int(updates["retirement_age"]))
                                set_parts.append("updated_at = NOW()")

                                sql = f"""
                                    UPDATE milestone_customer_profile
                                    SET {', '.join(set_parts)}
                                    WHERE user_code = %s;
                                """
                                params.append(str(user_id))

                                with self.connection.cursor() as cursor:
                                    cursor.execute(sql, tuple(params))
                                    self.connection.commit()
                                    if cursor.rowcount > 0:
                                        st.success("Record updated successfully!")
                                    else:
                                        st.warning("No record found for this user_code to update.")
                            except Exception as e:
                                self.connection.rollback()
                                st.error(f"Error updating record: {e}")
            except Exception as e:
                st.error(f"Error setting up update UI: {e}")

        # ---------- DELETE (by user_id only) ----------
        st.subheader("Delete milestone_customer_profile Record")
        do_delete_mcp = st.radio(
            "Do you want to delete the record for this user?",
            ["No", "Yes"],
            index=0,
            key="mcp_delete_radio",
        )

        if do_delete_mcp == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before deleting.")
                else:
                    if st.button("Delete milestone_customer_profile", key="mcp_delete_btn"):
                        try:
                            with self.connection.cursor() as cursor:
                                cursor.execute("""
                                    DELETE FROM milestone_customer_profile
                                    WHERE user_code = %s;
                                """, (str(user_id),))
                                self.connection.commit()
                                if cursor.rowcount > 0:
                                    st.success("Record deleted successfully!")
                                else:
                                    st.warning("No record found for this user_code to delete.")
                        except Exception as e:
                            self.connection.rollback()
                            st.error(f"Error deleting record: {e}")
            except Exception as e:
                st.error(f"Error setting up delete UI: {e}")


    def manage_milestone_expenses(self, user_id):
        """
        UI + actions to:
        1) Update milestone_expenses.yearly_amount (Same/New logic) for a selected expense row
        2) Delete ALL milestone_expenses rows for the given user_id
        """
        # ---------- UPDATE ----------
        st.subheader("Update Existing milestone_expenses Records")
        do_update_me = st.radio(
            "Do you want to update the yearly_amount for a milestone_expenses row?",
            ["No", "Yes"],
            index=0,
            key="me_update_radio",
        )

        if do_update_me == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before updating.")
                else:

                    amt_choice = st.selectbox(
                        "yearly_amount",
                        ["Same", "New"],
                        key="me_update_amount_choice",
                    )

                    new_amount = None
                    if amt_choice == "New":
                        new_amount = st.number_input(
                            "New yearly_amount",
                            min_value=0.0,
                            step=1000.0,
                            key="me_update_new_amount",
                        )

                    if st.button("Update milestone_expenses", key="me_update_btn"):
                        if amt_choice == "Same":
                            st.info("No change selected (yearly_amount = Same). Nothing to update.")
                        else:
                            try:
                                with self.connection.cursor() as cursor:
                                    cursor.execute(
                                        """
                                        UPDATE milestone_expenses
                                        SET yearly_amount = %s,
                                            last_updated_at = NOW() where
                                        user_code = %s
                                        AND is_active = TRUE;
                                        """,
                                        (float(new_amount), str(user_id)),
                                    )
                                self.connection.commit()
                                if cursor.rowcount > 0:
                                    st.success("Record updated successfully!")
                                else:
                                    st.warning("No record updated (check that the row is active and belongs to this user).")
                            except Exception as e:
                                self.connection.rollback()
                                st.error(f"Error updating milestone_expenses: {e}")
            except Exception as e:
                st.error(f"Error setting up update UI: {e}")

        # ---------- DELETE (by user_id only) ----------
        st.subheader("Delete milestone_expenses Records")
        do_delete_me = st.radio(
            "Do you want to delete ALL milestone_expenses rows for this user?",
            ["No", "Yes"],
            index=0,
            key="me_delete_radio",
        )

        if do_delete_me == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code above before deleting.")
                else:
                    if st.button("Delete milestone_expenses", key="me_delete_btn"):
                        try:
                            with self.connection.cursor() as cursor:
                                cursor.execute(
                                    """
                                    DELETE FROM milestone_expenses
                                    WHERE user_code = %s;
                                    """,
                                    (str(user_id),),
                                )
                            self.connection.commit()
                            if cursor.rowcount > 0:
                                st.success("Deleted milestone_expenses record(s) for this user.")
                            else:
                                st.warning("No milestone_expenses record found for this user_code to delete.")
                        except Exception as e:
                            self.connection.rollback()
                            st.error(f"Error deleting milestone_expenses: {e}")
            except Exception as e:
                st.error(f"Error setting up delete UI: {e}")



    # New Functionality for Assets Milestones
    def manage_assets_milestones(self):
        st.write("### Manage Assets Milestones")

        asset_dict = {
            327: "Multi Asset Allocation",
            320: "Arbitrage Funds",
            18: "Public Stock (India)",
            19: "Equity Mutual Funds",
            21: "Unlisted Stocks",
            22: "Public Stocks (International)",
            23: "Equity ETFs",
            24: "International Funds",
            25: "Direct Bonds",
            26: "Liquid Debt Funds",
            27: "Debt Funds",
            28: "Hybrid Funds",
            29: "Rental Yielding (Residential)",
            30: "Rental Yielding (Commercial)",
            31: "Non-Yielding (Residential)",
            32: "Non-Yielding (Commercial)",
            33: "Occupied Home",
            34: "Physical Gold",
            35: "Gold ETFs",
            36: "Sovereign Gold Bonds",
            37: "Bank FD",
            38: "Corporate FD",
            39: "Post Office Monthly Income Scheme (POMIS)",
            40: "Senior Citizen Savings Scheme (SCSS)",
            41: "Sukanya Samriddhi Yojana (SSY)",
            42: "National Savings Certificate (NSC)",
            43: "EPF",
            44: "PPF",
            45: "Savings",
            46: "NPS Tier I",
            47: "NPS Tier II",
            48: "Pradhan Mantri Vaya Vandana Yojana (PMVVY)",
            49: "Atal Pension Yojana (APY)",
            50: "Direct Cryptos",
            51: "Coin Baskets",
            53: "Loans Given",
            54: "Free Debt Instruments",
            90: "Physical Silver",
            91: "Silver ETFs",
            120: "Free Debt Instruments",
            235: "ESOP",
            236: "REITs/InvITs",
            237: "Bank RD",
            238: "P2P Lending",
            627: "debt fund - swp",
            631: "Rental Yielding (Residential) 2",
            634: "Passive income from occupied home",
            642: "Occupied Home 3"
        }

        # Insert New Record
        st.subheader("Insert New Record")
        #user_id = st.text_input("Enter User ID for New Record", key="asset_insert_user_id")
        user_id_insert = st.radio("Do you want to insert the assets table?", ["No", "Yes"], index=0, key = 'insert asset milestone table')
        if user_id_insert == 'Yes':

            try:
                name = st.selectbox("Select asset", list(asset_dict.values()), key= "asset_insert_name")
                category_id = next(key for key, value in asset_dict.items() if value == name)
                current_amount = st.number_input("Current Amount", min_value=0.0, key="asset_insert_current_amount")
                monthly_investment = st.number_input("Monthly Investment", min_value=0.0, key="asset_insert_monthly_investment")
                # Check if the asset_name already exists for the user
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT name FROM assets_milestones WHERE user_code = %s;
                """, (user_id,))
                existing_assets = [row[0].strip().lower() for row in cursor.fetchall()]

                stripped_asset_name = name.strip().lower()
                if stripped_asset_name in existing_assets:
                    existing_count = sum(1 for existing in existing_assets if existing.startswith(stripped_asset_name))
                    new_asset_name = f"{name.strip()} {existing_count + 1}"
                else:
                    new_asset_name = name

                if st.button("Insert Record"):   
                    try:     
                        cursor.execute("""
                            INSERT INTO assets_milestones (
                                created_at, last_updated_at, user_code, category_id, current_amount, 
                                monthly_investment, expiry, is_manual_entry, fetched_source, 
                                months, name, is_active
                            ) VALUES (
                                NOW(), NOW(), %s, %s, %s, %s, NULL, TRUE, NULL, 1, %s, TRUE
                            );
                        """, (user_id, category_id, current_amount, monthly_investment, new_asset_name))
                        self.connection.commit()
                        st.success("Record inserted successfully!")
                    except Exception as e:
                            st.error(f"Error Insert record: {e}")    
            except Exception as e:
                st.error(f"Error inserting record: {e}")

        # Update Existing Record
        st.subheader("Update Existing Assets Milestones Record")
        user_id_update = st.radio("Do you want to update the assets table?", ["No", "Yes"], index=0, key = 'update asset milestone table')
        if user_id_update == 'Yes':
            try:
                # Fetch unique names for the user_id
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT name FROM assets_milestones a
                        WHERE user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
                    """, (user_id,))
                    unique_names = [row[0] for row in cursor.fetchall()]

                selected_name = st.selectbox("Select Name to Update", unique_names)
                update_options = {
                    "current_amount": st.selectbox("Current Amount", ["Same", "New"], key="milestone_update_current_amount_option"),
                    "monthly_investment": st.selectbox("Monthly Investment", ["Same", "New"], key="milestone_update_monthly_investment_option")
                }

                updates = {}
                if update_options["current_amount"] == "New":
                    updates["current_amount"] = st.number_input("New Current Amount", min_value=0.0, key="milestone_update_current_amount")
                if update_options["monthly_investment"] == "New":
                    updates["monthly_investment"] = st.number_input("New Monthly Investment", min_value=0.0, key="milestone_update_monthly_investment")


                if st.button("Update Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            for column, value in updates.items():
                                cursor.execute(f"""
                                    UPDATE assets_milestones 
                                    SET {column} = %s, last_updated_at = NOW() 
                                    WHERE user_code = %s AND name = %s and is_active = true;
                                """, (value, user_id, selected_name))
                            self.connection.commit()
                            st.success("Record updated successfully!")
                    except Exception as e:
                        st.error(f"Error updating record: {e}")

                # if st.button('display the asset table',key = 'asset table display 1'):
                #     st.write("### User Assets")
                #     projection_updater.display_assets_data(user_id)        

            except Exception as e:
                st.error(f"Error fetching names: {e}")

        # Delete Existing asset Record
        st.subheader("Delete Assets Milestones Record")
        user_id_delete = st.radio("Do you want to delete the single asset of the user?", ["No", "Yes"], index=0, key = 'delete asset milestone table')
        if user_id_delete == 'Yes':
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT name FROM assets_milestones a
                        WHERE user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
                    """, (user_id,))
                    unique_names_delete = [row[0] for row in cursor.fetchall()]

                selected_name_delete = st.selectbox("Select Name to Delete", unique_names_delete, key="milestone_delete_records")
                if st.button("Delete Asset Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM assets_milestones 
                                WHERE user_code = %s AND name = %s and is_active = true;
                            """, (user_id, selected_name_delete))
                            self.connection.commit()
                            st.success("Record deleted successfully!")
                    except Exception as e:
                        st.error(f"Error deleting record: {e}")

            except Exception as e:
                st.error(f"Error fetching names for deletion: {e}")  


        # Delete Existing all records of user
        st.subheader("Delete Assets Milestones Record")
        user_id_input_delete = st.radio("Do you want to delete the all records of user from assets table?", ["No", "Yes"], index=0, key = 'delete all asset milestone table')
        if user_id_input_delete == 'Yes':
            try:
                if st.button("Delete All Records of user", key = 'all asset records deleted'):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM assets_milestones 
                                WHERE user_code = %s
                            """, (user_id,))
                            self.connection.commit()
                            st.success("Record deleted successfully!")
                    except Exception as e:
                        st.error(f"Error deleting record: {e}")

            except Exception as e:
                st.error(f"Error fetching names for deletion: {e}") 

    def display_assets_data(self, user_code):
        """Fetch and display the formatted assets table"""
        assets_df = self.fetch_asset_milestones_table(user_code)
        if assets_df is not None:
            #st.write("### asset table Table")
            st.dataframe(assets_df)	

    def fetch_asset_milestones_table(self, user_id):
        """Fetch assets of the user from the database for the given user."""
        query = """
            SELECT a.name AS asset_name, a.category_id, a.current_amount, a.monthly_investment, c.weightage
            FROM assets_milestones a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            asset_milestones_df = pd.DataFrame(data, columns=columns)

            if asset_milestones_df.empty:
                st.warning("No assets found for the given user.")
                return None

            return asset_milestones_df

        except Exception as e:
            print(f"Error fetching assets data: {e}")
            return None			

    #Customer Profile    
    def display_customer_profile_data(self, user_code):
        """Fetch and display the formatted customer profile table"""
        customer_profile_df = self.fetch_customer_profile_table(user_code)
        if customer_profile_df is not None:
            #st.write("### Customer Profile (DOB and Retirement Age) Table")
            st.dataframe(customer_profile_df)	


    def fetch_customer_profile_table(self, user_id):
        """Fetch customer profile of the user from the database for the given user."""
        query = """
            SELECT a.first_name , a.last_name, a.dob, a.retirement_age, a.city, a.money_sign
            FROM milestone_customer_profile a
            WHERE a.user_code = %s AND a.first_name IS NOT NULL AND a.first_name <> 'None' and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            customer_profile_df = pd.DataFrame(data, columns=columns)

            if customer_profile_df.empty:
                st.warning("No customer profile found for the given user.")
                return None

            return customer_profile_df

        except Exception as e:
            print(f"Error fetching customer profile data: {e}")
            return None 

    #milestone category table   
    def display_milestone_category_data(self, user_code):
        """Fetch and display the formatted milestone category table"""
        milestone_category_df = self.fetch_milestone_category_table(user_code)
        if milestone_category_df is not None:
            #st.write("### Customer Profile (DOB and Retirement Age) Table")
            st.dataframe(milestone_category_df)	


    def fetch_milestone_category_table(self, user_id):
        """Fetch milestone category of the user from the database for the given user."""
        query = """
            SELECT a.category_id , a.milestone_name
            FROM milestone_master a;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            milestone_category_df = pd.DataFrame(data, columns=columns)

            if milestone_category_df.empty:
                st.warning("No milestone category data found for the given user.")
                return None

            return milestone_category_df

        except Exception as e:
            print(f"Error fetching milestone category data: {e}")
            return None 


    #asset category table   
    def display_asset_category_data(self, user_code):
        """Fetch and display the formatted asset category table"""
        asset_category_df = self.fetch_asset_category_table(user_code)
        if asset_category_df is not None:
            #st.write("### asset category Table")
            st.dataframe(asset_category_df)	


    def fetch_asset_category_table(self, user_id):
        """Fetch asset category of the user from the database for the given user."""
        query = """
            SELECT a.id , a.name, a.weightage
            FROM milestones_category a;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            asset_category_df = pd.DataFrame(data, columns=columns)

            if asset_category_df.empty:
                st.warning("No asset category data found for the given user.")
                return None

            return asset_category_df

        except Exception as e:
            print(f"Error fetching asset category data: {e}")
            return None        

        
    #life stage growth milestone    
    def display_life_stage_growth_data(self, user_code):
        """Fetch and display the formatted life stage growth data"""
        life_stage_growth_df = self.fetch_life_stage_growth_table(user_code)
        if life_stage_growth_df is not None:
            #st.write("### life stage growth Table")
            st.dataframe(life_stage_growth_df)	


    def fetch_life_stage_growth_table(self, user_id):
        """Fetch life stage growth of the user from the database for the given user."""
        query = """
            SELECT a.name , a.min_age_range, a.max_age_range, a.growth_rate
            FROM life_stage_growth_milestone a
            WHERE a.user_code = %s and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            life_stage_growth_df = pd.DataFrame(data, columns=columns)

            if life_stage_growth_df.empty:
                st.warning("No life stage growth percentage found for the given user.")
                return None

            return life_stage_growth_df

        except Exception as e:
            print(f"Error fetching customer profile data: {e}")
            return None     

    #income table
    def display_income_data(self, user_code):
        """Fetch and display the formatted income table"""
        income_df = self.fetch_income_table(user_code)
        if income_df is not None:
            #st.write("### Income Table")
            st.dataframe(income_df)	


    def fetch_income_table(self, user_id):
        """Fetch income of the user from the database for the given user."""
        query = """
            SELECT a.category_id, c.name, a.yearly_amount AS income_value 
            FROM milestone_income a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            income_milestones_df = pd.DataFrame(data, columns=columns)

            if income_milestones_df.empty:
                st.warning("No income found for the given user.")
                return None

            return income_milestones_df

        except Exception as e:
            print(f"Error fetching income data: {e}")
            return None


    #customer details table
    def display_customer_details_data(self, user_code):
        """Fetch and display the formatted customer details table"""
        customer_details_df = self.fetch_customer_details_table(user_code)
        if customer_details_df is not None:
            #st.write("### customer details Table")
            st.dataframe(customer_details_df)	


    def fetch_customer_details_table(self, user_id):
        """Fetch customer details of the user from the database for the given user."""
        query = """
            SELECT a.category_id, a.value, a.description, c.name
            FROM milestone_customer_details a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            customer_details_df = pd.DataFrame(data, columns=columns)

            if customer_details_df.empty:
                st.warning("No customer details found for the given user.")
                return None

            return customer_details_df

        except Exception as e:
            print(f"Error fetching customer details data: {e}")
            return None               

    #customer expense                   
    def display_customer_expense_data(self, user_code):
        """Fetch and display the formatted customer expense table"""
        customer_expense_df = self.fetch_customer_expense_table(user_code)
        if customer_expense_df is not None:
            #st.write("### customer expense Table")
            st.dataframe(customer_expense_df)	


    def fetch_customer_expense_table(self, user_id):
        """Fetch customer expense of the user from the database for the given user."""
        query = """
            SELECT a.yearly_amount as user_expense
            FROM milestone_expenses a
            WHERE a.user_code = %s and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            customer_expense_df = pd.DataFrame(data, columns=columns)

            if customer_expense_df.empty:
                st.warning("No customer expense found for the given user.")
                return None

            return customer_expense_df

        except Exception as e:
            print(f"Error fetching customer expense data: {e}")
            return None	

    
    #Customer liabilities
    def display_customer_liabilities_data(self, user_code):
        """Fetch and display the formatted customer liabilities table"""
        customer_liabilities_df = self.fetch_customer_liabilities_table(user_code)
        if customer_liabilities_df is not None:
            #st.write("### customer liabilities Table")
            st.dataframe(customer_liabilities_df)	


    def fetch_customer_liabilities_table(self, user_id):
        """Fetch customer liabilities of the user from the database for the given user."""
        query = """
            SELECT a.created_at, a.last_updated_at, a.category_id, a.name, a.outstanding_amount, a.pending_tenure, a.interest_rate, a.account_age
            FROM liabilities_milestone_table a
            WHERE a.user_code = %s and a.is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_id,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            customer_liabilties_df = pd.DataFrame(data, columns=columns)

            if customer_liabilties_df.empty:
                st.warning("No customer liabilities found for the given user.")
                return None

            return customer_liabilties_df

        except Exception as e:
            print(f"Error fetching customer liabilities data: {e}")
            return None


    # New Functionality for asset category
    def manage_asset_category_table(self):
        st.write("### Manage asset Category Table")

        # -------- INSERT NEW RECORD --------
        st.subheader("Insert New Category Record")
        if st.radio("Do you want to insert a new category?", ["No", "Yes"], key="insert_category_option") == "Yes":
            try:
                category_name = st.text_input("Enter New Category Name", key="insert_category_name")
                weightage = st.number_input("Enter Weightage (float)", format="%.3f", key="insert_category_weightage")/100

                if st.button("Insert New Category"):
                    cursor = self.connection.cursor()
                    cursor.execute("SELECT MAX(id) FROM milestones_category")
                    max_id = cursor.fetchone()[0] or 0
                    new_id = max_id + 1

                    cursor.execute("""
                        INSERT INTO milestones_category (id, is_active, name, parent_category_id, guidance, weightage)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (new_id, True, category_name, None, None, weightage))

                    self.connection.commit()
                    cursor.close()
                    st.success(f"Category '{category_name}' inserted successfully with ID {new_id}!")
            except Exception as e:
                st.error(f"Insert failed: {e}")

        # -------- UPDATE RECORD --------
        st.subheader("Update Weightage for Existing Category")
        if st.radio("Do you want to update a category weightage?", ["No", "Yes"], key="update_category_option") == "Yes":
            try:
                # âœ… Fetch unique category names for dropdown
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT DISTINCT name FROM milestones_category
                    WHERE is_active = true AND name IS NOT NULL AND name <> 'None'
                """)
                category_names = [row[0] for row in cursor.fetchall()]
                cursor.close()  

                if not category_names:
                    st.warning("No categories available to update.")
                else:
                    update_name = st.selectbox("Select Category Name to Update", category_names, key="update_category_name")
                    new_weightage = st.number_input("Enter New Weightage (float)", key="update_category_weightage")/100

                    if st.button("Update Category Weightage"):
                        cursor = self.connection.cursor()
                        cursor.execute("""
                            UPDATE milestones_category
                            SET weightage = %s
                            WHERE name = %s
                        """, (new_weightage, update_name))

                        self.connection.commit()
                        cursor.close()
                        st.success(f"Weightage for category '{update_name}' updated to {new_weightage}!")
            except Exception as e:
                st.error(f"Update failed: {e}")

        # -------- DELETE RECORD --------
        st.subheader("Delete Category Record")
        if st.radio("Do you want to delete a category?", ["No", "Yes"], key="delete_category_option") == "Yes":
            try:
                # âœ… Fetch unique category names for dropdown
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT DISTINCT name FROM milestones_category
                    WHERE is_active = true AND name IS NOT NULL AND name <> 'None'
                """)
                category_names = [row[0] for row in cursor.fetchall()]
                cursor.close()  

                if not category_names:
                    st.warning("No categories available to delete.")
                else:
                    delete_name = st.selectbox("Select Category Name to Delete", category_names, key="delete_category_name")

                    if st.button("Delete Category"):
                        cursor = self.connection.cursor()
                        cursor.execute("""
                            DELETE FROM milestones_category
                            WHERE name = %s
                        """, (delete_name,))
                        self.connection.commit()
                        cursor.close()
                        st.success(f"Category '{delete_name}' deleted successfully!")
            except Exception as e:
                st.error(f"Delete failed: {e}")  

    # New Functionality for milestone category
    def manage_milestones_category(self):
        st.write("### Manage Milestones Category Table")

        # -------- INSERT NEW RECORD --------
        st.subheader("Insert New milestone Category Record")
        if st.radio("Do you want to insert a new category?", ["No", "Yes"], key="insert_category_option") == "Yes":
            try:
                category_name = st.text_input("Enter New Milestone Category Name", key="insert_milestone_category_name")
                #weightage = st.number_input("Enter Weightage (float)", format="%.3f", key="insert_milestone_category_weightage")/100

                if st.button("Insert New milestone Category"):
                    cursor = self.connection.cursor()
                    cursor.execute("SELECT MAX(category_id) FROM milestone_master")
                    max_id = cursor.fetchone()[0] or 0
                    new_id = max_id + 1

                    cursor.execute("""
                        INSERT INTO milestone_master (category_id, milestone_name, created_at)
                        VALUES (%s, %s, NOW())
                    """, (new_id, category_name))

                    self.connection.commit()
                    cursor.close()
                    st.success(f"Category '{category_name}' inserted successfully with ID {new_id}!")
            except Exception as e:
                st.error(f"Insert failed: {e}")

        # # -------- UPDATE RECORD --------
        # st.subheader("Update name for Existing Milestone Category")
        # if st.radio("Do you want to update a category weightage?", ["No", "Yes"], key="update_milestone_category_option") == "Yes":
        #     try:
        #         # âœ… Fetch unique category names for dropdown
        #         cursor = self.connection.cursor()
        #         cursor.execute("""
        #             SELECT DISTINCT milestone_name FROM milestone_master
        #             milestone_name IS NOT NULL AND milestone_name <> 'None'
        #         """)
        #         category_names = [row[0] for row in cursor.fetchall()]
        #         cursor.close()  

        #         if not category_names:
        #             st.warning("No milestone categories available to update.")
        #         else:
        #             update_name = st.selectbox("Select milestone Category Name to Update", category_names, key="update_Milestone_category_name")
        #             #new_weightage = st.number_input("Enter New Weightage (float)", key="update_category_weightage")/100

        #             if st.button("Update Category Weightage"):
        #                 cursor = self.connection.cursor()
        #                 cursor.execute("""
        #                     UPDATE milestones_category
        #                     SET weightage = %s
        #                     WHERE name = %s
        #                 """, (new_weightage, update_name))

        #                 self.connection.commit()
        #                 cursor.close()
        #                 st.success(f"Weightage for category '{update_name}' updated to {new_weightage}!")
        #     except Exception as e:
        #         st.error(f"Update failed: {e}")

        # -------- DELETE RECORD --------
        st.subheader("Delete Milestone Category Record")
        if st.radio("Do you want to delete a milestone category?", ["No", "Yes"], key="delete_milestone_category_option") == "Yes":
            try:
                # âœ… Fetch unique category names for dropdown
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT DISTINCT milestone_name FROM milestone_master
                    WHERE milestone_name IS NOT NULL AND milestone_name <> 'None'
                """)
                category_names = [row[0] for row in cursor.fetchall()]
                cursor.close()  

                if not category_names:
                    st.warning("No Milestone categories available to delete.")
                else:
                    delete_name = st.selectbox("Select Milestone Category Name to Delete", category_names, key="delete_milestone_category_name")

                    if st.button("Delete Milestone Category"):
                        cursor = self.connection.cursor()
                        cursor.execute("""
                            DELETE FROM milestone_master
                            WHERE milestone_name = %s
                        """, (delete_name,))
                        self.connection.commit()
                        cursor.close()
                        st.success(f"Milestone Category Name '{delete_name}' deleted successfully!")
            except Exception as e:
                st.error(f"Delete failed: {e}")             


    def copy_liabilities_to_liabilities_milestones(self, user_code):
        try:
            cursor = self.connection.cursor()

            # Fetch all records for the given user_code from the assets table
            cursor.execute("""
                SELECT * FROM liabilities WHERE user_code = %s;
            """, (user_code,))
            liabilities_records = cursor.fetchall()

            if not liabilities_records:
                st.error(f"No records found in the assets table for user_code: {user_code}")
                return

            # Insert the fetched records into the assets_milestones table
            insert_query = """
                INSERT INTO liabilities_milestone_table (
                    id, created_at, last_updated_at, user_code, category_id, outstanding_amount,
                    pending_tenure, monthly_installment, expiry, is_manual_entry, fetched_source,
                    months, name, is_active, account_age, interest_rate
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            for record in liabilities_records:
                cursor.execute(insert_query, record)

            self.connection.commit()
            st.success("Liabilities successfully copied to the liabilities_milestones table.")

        except Exception as e:
            self.connection.rollback()
            st.error(f"An error occurred while copying data: {e}")
        finally:
            cursor.close()

    # New Functionality for Assets Milestones
    def manage_liabilities_milestones(self):
        st.write("### Manage Liabilities Milestones")

        asset_dict = {
            15: "Loans",
            55: "Auto Loan",
            56: "Property Loan",
            57: "Housing Loan",
            58: "Car Loan",
            59: "Personal Loan",
            60: "Two-Wheeler Loan",
            61: "Consumer Loan",
            104: "Credit Card Loan",
            53: "Loans Given",
            175: "Education Loan",
            209: "Other Loan",
            209: "Gold Loan",
            209: "Loan Against Property"
        }

        # Insert New Record
        st.subheader("Insert New liabilities Record")
        #user_id = st.text_input("Enter User ID for New Record", key="asset_insert_user_id")
        user_id_insert = st.radio("Do you want to insert the assets table?", ["No", "Yes"], index=0, key = 'insert liabilities milestone table')
        if user_id_insert == 'Yes':

            try:
                name = st.selectbox("Select asset", list(asset_dict.values()), key= "liabilities_insert_name")
                category_id = next(key for key, value in asset_dict.items() if value == name)
                outstanding_amount = st.number_input("Outstanding Amount", min_value=0.0, key="liabilities_insert_outstanding_amount")
                pending_tenure = st.number_input("Pending Tenure", min_value=0.0, key="liabilities_insert_Pending_tenure")
                monthly_installment = st.number_input("Monthly Installment", min_value=0.0, key="liabilities_insert_monthly_installment")
                accound_age = st.number_input("Accound Age", min_value=0.0, key="liabilities_insert_account_age")
                interest_rate = st.number_input("Interest Rate", min_value=0.0, key="liabilities_insert_interest_rate")/100
                # Check if the asset_name already exists for the user
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT name FROM liabilities_milestone_table WHERE user_code = %s;
                """, (user_id,))
                existing_liabilities = [row[0].strip().lower() for row in cursor.fetchall()]

                stripped_liabilities_name = name.strip().lower()
                if stripped_liabilities_name in existing_liabilities:
                    existing_count = sum(1 for existing in existing_liabilities if existing.startswith(stripped_liabilities_name))
                    new_asset_name = f"{name.strip()} {existing_count + 1}"
                else:
                    new_asset_name = name

                if st.button("Insert Record"):   
                    try:     
                        cursor.execute("""
                            INSERT INTO liabilities_milestone_table (
                                created_at, last_updated_at, user_code, category_id, outstanding_amount,
                                pending_tenure, monthly_installment, expiry, is_manual_entry, fetched_source,
                                months, name, is_active, account_age, interest_rate
                            ) VALUES (
                                NOW(), NOW(), %s, %s, %s, %s, %s, NULL, TRUE, NULL, 12, %s, TRUE, %s, %s
                            );
                        """, (user_id, category_id, outstanding_amount, pending_tenure, monthly_installment, new_asset_name, accound_age, interest_rate))
                        self.connection.commit()
                        st.success("Record inserted successfully!")
                    except Exception as e:
                            st.error(f"Error Insert record: {e}")    
            except Exception as e:
                st.error(f"Error inserting record: {e}")

        # Update Existing Record
        st.subheader("Update Existing Liabilities Milestones Record")
        user_id_update = st.radio("Do you want to update the liabilities table?", ["No", "Yes"], index=0, key = 'update liabilities milestone table')
        if user_id_update == 'Yes':
            try:
                # Fetch unique names for the user_id
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT name FROM liabilities_milestone_table a
                        WHERE user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
                    """, (user_id,))
                    unique_names = [row[0] for row in cursor.fetchall()]

                selected_name = st.selectbox("Select Name to Update", unique_names)
                update_options = {
                    "outstanding_amount": st.selectbox("Outstanding Amount", ["Same", "New"], key="milestone_update_outstanding_amount_option"),
                    "pending_tenure": st.selectbox("Pending Tenure", ["Same", "New"], key="milestone_update_pending_tenure_option"),
                    "monthly_installment": st.selectbox("Monthly Installment", ["Same", "New"], key="milestone_update_monthly_installment_option"),
                    "accound_age": st.selectbox("Accound Age", ["Same", "New"], key="milestone_update_accound_age_option"),
                    "interest_rate": st.selectbox("Interest Rate", ["Same", "New"], key="milestone_update_interest_rate_option"),
                }

                updates = {}
                if update_options["outstanding_amount"] == "New":
                    updates["outstanding_amount"] = st.number_input("New Outstanding Amount", min_value=0.0, key="milestone_update_outstanding_amount")
                if update_options["pending_tenure"] == "New":
                    updates["pending_tenure"] = st.number_input("New Pending Tenure", min_value=0.0, key="milestone_update_pending_tenure")
                if update_options["monthly_installment"] == "New":
                    updates["monthly_installment"] = st.number_input("New Monthly Installment", min_value=0.0, key="milestone_update_monthly_installment")    
                if update_options["accound_age"] == "New":
                    updates["accound_age"] = st.number_input("New accound age", min_value=0.0, key="milestone_update_accound_age")   
                if update_options["interest_rate"] == "New":
                    updates["interest_rate"] = st.number_input("New interest rate", min_value=0.0, key="milestone_update_interest_rate")/100      


                if st.button("Update Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            for column, value in updates.items():
                                cursor.execute(f"""
                                    UPDATE liabilities_milestone_table 
                                    SET {column} = %s, last_updated_at = NOW() 
                                    WHERE user_code = %s AND name = %s and is_active = true;
                                """, (value, user_id, selected_name))
                            self.connection.commit()
                            st.success("Record updated successfully!")
                    except Exception as e:
                        st.error(f"Error updating record: {e}")

            except Exception as e:
                st.error(f"Error fetching names: {e}")

        # Delete Existing asset Record
        st.subheader("Delete liabilities Milestones Record")
        user_id_delete = st.radio("Do you want to delete the single liability of the user?", ["No", "Yes"], index=0, key = 'delete liability milestone table')
        if user_id_delete == 'Yes':
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT name FROM liabilities_milestone_table a
                        WHERE user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
                    """, (user_id,))
                    unique_names_delete = [row[0] for row in cursor.fetchall()]

                selected_name_delete = st.selectbox("Select liability Name to Delete", unique_names_delete, key="milestone_liability_delete_records")
                if st.button("Delete liability Record"):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM liabilities_milestone_table 
                                WHERE user_code = %s AND name = %s and is_active = true;
                            """, (user_id, selected_name_delete))
                            self.connection.commit()
                            st.success("Record deleted successfully!")
                    except Exception as e:
                        st.error(f"Error deleting record: {e}")

            except Exception as e:
                st.error(f"Error fetching names for deletion: {e}")  


        # Delete Existing all records of user
        st.subheader("Delete liability Milestones Record")
        user_id_input_delete = st.radio("Do you want to delete the all records of user from liability table?", ["No", "Yes"], index=0, key = 'delete all liability milestone table')
        if user_id_input_delete == 'Yes':
            try:
                if st.button("Delete All Records of liability of user", key = 'all liability records deleted'):
                    try:
                        with self.connection.cursor() as cursor:
                            cursor.execute("""
                                DELETE FROM liabilities_milestone_table 
                                WHERE user_code = %s
                            """, (user_id,))
                            self.connection.commit()
                            st.success("Record deleted successfully!")
                    except Exception as e:
                        st.error(f"Error deleting record: {e}")

            except Exception as e:
                st.error(f"Error fetching names for deletion: {e}")             
    

    #calculate income projections
    def run_income_projections_pgsql_procedure(self, user_code, tax_regime, appraisal_end_date, growth_expense_month):
        try:
            cursor = self.connection.cursor()

            cursor.execute("""
                CALL generate_income_projection_amount_table_fn_v3(%s, %s, %s, %s)
            """, (user_code, tax_regime, appraisal_end_date, growth_expense_month,))

            self.connection.commit()

            print("Procedure executed successfully.")

        except Exception as e:
            print(f"An error occurred: {e}")
            self.connection.rollback() 

        finally:
            cursor.close()

    def copy_temp_to_dynamic_income_projection(self, user_code):
        # Clear the dynamic_income_projection table
        self.clear_dynamic_income_projection_table()

        # Query to copy data from Gross_income_projection_amount_table
        query = "SELECT * FROM Gross_income_projection_amount_table ORDER BY entry_date"
        new_user_data = pd.read_sql(query, self.connection)

        # Load the existing data from dynamic_income_projection
        dynamic_income_projection = self.load_dynamic_income_projection_from_db()

        # If the table is empty, initialize it with new data
        if dynamic_income_projection.empty:
            dynamic_income_projection = new_user_data

        # Save the updated DataFrame back to the database
        self.save_dynamic_income_projection_to_db(dynamic_income_projection)

    def copy_temp_to_dynamic_nominee_income_projection(self, user_code):
        # Clear the dynamic_income_projection table
        self.clear_dynamic_nominee_income_projection_table()

        # Query to copy data from Gross_income_projection_amount_table
        query = "SELECT * FROM Gross_income_projection_amount_table ORDER BY entry_date"
        new_user_data = pd.read_sql(query, self.connection)

        # Load the existing data from dynamic_income_projection
        dynamic_income_projection = self.load_dynamic_nominee_income_projection_from_db()

        # If the table is empty, initialize it with new data
        if dynamic_income_projection.empty:
            dynamic_income_projection = new_user_data

        # Save the updated DataFrame back to the database
        self.save_dynamic_nominee_income_projection_to_db(dynamic_income_projection)     

    def clear_dynamic_income_projection_table(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_income_projection")
            self.connection.commit()
            print("Cleared the dynamic_income_projection table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_income_projection table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()

    def clear_dynamic_nominee_income_projection_table(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_nominee_income_projection")
            self.connection.commit()
            print("Cleared the dynamic_nominee_income_projection table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_nominee_income_projection table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()        

    def load_dynamic_income_projection_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_income_projection'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_income_projection' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('dynamic_income_projection', engine)
        
    def load_dynamic_nominee_income_projection_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_nominee_income_projection'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_nominee_income_projection' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('dynamic_nominee_income_projection', engine)
        
    def load_dynamic_combine_income_projection_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_combine_income_projection'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_combine_income_projection' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('dynamic_combine_income_projection', engine)    


    def save_dynamic_income_projection_to_db(self, dynamic_income_projection):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_income_projection.to_sql(
            'dynamic_income_projection',
            engine,
            if_exists='replace',
            index=False
        )
        st.write("Data saved to PostgreSQL table 'dynamic_income_projection'")


    def save_dynamic_nominee_income_projection_to_db(self, dynamic_income_projection):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_income_projection.to_sql(
            'dynamic_nominee_income_projection',
            engine,
            if_exists='replace',
            index=False
        )
        st.write("Data saved to PostgreSQL table 'dynamic_nominee_income_projection'") 

    def save_dynamic_combine_income_projection_to_db(self, dynamic_income_projection):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_income_projection.to_sql(
            'dynamic_combine_income_projection',
            engine,
            if_exists='replace',
            index=False
        )
        st.write("Data saved to PostgreSQL table 'dynamic_combine_income_projection'")         

    #Method to transpose the dynamic_income_projection data
    def transpose_dynamic_income_projection_1(self, dynamic_income_projection_df):
        # Drop unnecessary columns
        dynamic_income_projection_df = dynamic_income_projection_df.drop(columns=['user_code', 'fin_year_entry', 'fin_year_in_words','est_income_growth_percentage','est_expense_growth_percentage'])

        # Ensure entry_date is in string format
        #dynamic_income_projection_df['entry_date'] = dynamic_income_projection_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_income_projection_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed    

    # Method to transpose the dynamic_income_projection data
    def transpose_dynamic_income_projection(self, dynamic_income_projection_df):
        dynamic_income_projection_df = self.transpose_and_sort_dates(dynamic_income_projection_df)
        # Drop unnecessary columns
        dynamic_income_projection_df = dynamic_income_projection_df.drop(columns=['user_code', 'fin_year_entry', 'fin_year_in_words','est_income_growth_percentage','est_expense_growth_percentage'])

        # Ensure entry_date is in string format
        #dynamic_income_projection_df['entry_date'] = dynamic_income_projection_df['entry_date'].dt.strftime('%d-%m-%Y')

        # Transpose the table
        df_transposed = dynamic_income_projection_df.set_index('entry_date').T

        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)


        return df_transposed
    


    # Run dynamic income projections
    def run_dynamic_income_projection(self, user_code):
        # Pop-up for selecting growth option
        add_growth_option = st.radio(
            "Which income projection type would you like to run?",
            ('Default Growth', 'Dynamic Growth', 'Custom Growth with Additional Inputs'),
            key="add_growth_option_input"
        )

        if add_growth_option == 'Dynamic Growth':
            # Inputs for dynamic growth percentage
            tax_regime = st.selectbox("Select the tax regime", ['old', 'new'], key="tax_regime_input")
            #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'], key="income_appraisal_end_date")
            # Generate last day of each month in MM-DD format
            year_1 = date.today().year
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(year_1, month)[1]).zfill(2)}" for month in range(1, 13)]
            # Selectbox to choose appraisal end date
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="income_appraisal_end_date")
            income_growth_1 = st.number_input("Enter income growth percentage for age <35:", value=5.0, key="income_growth_1_input") / 100
            income_growth_2 = st.number_input("Enter income growth percentage for age 36-45:", value=4.0, key="income_growth_2_input") / 100
            income_growth_3 = st.number_input("Enter income growth percentage for age 46-55:", value=3.0, key="income_growth_3_input") / 100
            income_growth_4 = st.number_input("Enter income growth percentage for age >55:", value=2.0, key="income_growth_4_input") / 100
            expense_growth = st.number_input("Enter the expense growth percentage:", value=10.0, key="expense_growth_input") / 100
            # List of all months in "MM" format
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='dynamic_growth'):
                try:
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        CALL generate_income_projection_amount_table_fn_v2(%s, %s, %s, %s, %s, %s, %s, %s, %s);
                    """, (user_code, tax_regime, appraisal_end_date, 
                        income_growth_1, income_growth_2, income_growth_3, 
                        income_growth_4, expense_growth, growth_expense_month))
                    self.connection.commit()
                    st.success("Income projections generated successfully using dynamic growth percentages.")
                except Exception as e:
                    st.error(f"An error occurred while generating projections: {e}")
                    self.connection.rollback()
                finally:
                    cursor.close()

                # Copy data to `dynamic_income_projection` table and display
                self.copy_temp_to_dynamic_income_projection(user_code)
                dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")

        elif add_growth_option == 'Custom Growth with Additional Inputs':
            # Inputs for custom growth
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="income_appraisal_end_date")
            income_growth_1 = st.number_input("Enter income growth percentage for age <35:", value=5.0, key="income_growth_1_input") / 100
            income_growth_2 = st.number_input("Enter income growth percentage for age 36-45:", value=4.0, key="income_growth_2_input") / 100
            income_growth_3 = st.number_input("Enter income growth percentage for age 46-55:", value=3.0, key="income_growth_3_input") / 100
            income_growth_4 = st.number_input("Enter income growth percentage for age >55:", value=2.0, key="income_growth_4_input") / 100
            expense_growth = st.number_input("Enter the expense growth percentage:", value=11.0, key="expense_growth_input") / 100
            user_income = st.number_input("Enter the user's primary income:", value= 0, key="user_income_input")
            user_other_income = st.number_input("Enter the user's other income:", value= 0, key="user_other_income_input")
            user_deduction_amount = st.number_input("Enter the user's deduction amount:", value= 0, key="user_deduction_amount_input")
            user_household_lifestyle_expenses = st.number_input("Enter household lifestyle expenses:", value= 0, key="household_expense_input")
            tax_projection_percentage = st.number_input("Enter the tax projection percentage:", value=1.0, key="tax_projection_percentage")/100
            #growth_expense_month = st.selectbox("Enter the month for growth expense (MM):", ['04', '01'], key="growth_expense_month_input")
            # List of all months in "MM" format
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='custom_growth'):
                try:
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        CALL generate_income_projection_amount_table_fn_v7(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
                    """, (user_code, appraisal_end_date,
                        income_growth_1, income_growth_2, income_growth_3, 
                        income_growth_4, expense_growth, 
                        user_income, user_other_income, user_deduction_amount,
                        user_household_lifestyle_expenses, tax_projection_percentage, 
                        growth_expense_month))
                    self.connection.commit()
                    st.success("Income projections generated successfully using custom growth inputs.")
                except Exception as e:
                    st.error(f"An error occurred while generating projections: {e}")
                    self.connection.rollback()
                finally:
                    cursor.close()

                # Copy data to `dynamic_income_projection` table and display
                self.copy_temp_to_dynamic_income_projection(user_code)
                dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")

        elif add_growth_option == 'Default Growth':
            # Default growth inputs
            tax_regime = st.selectbox("Select the tax regime", ['old', 'new'], key="tax_regime_input")
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="income_appraisal_end_date")
            #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'], key="income_appraisal_end_date")
            #growth_expense_month = st.selectbox("Enter the month for growth expense (MM):", ['04', '12'], key="growth_expense_month_input")
            # List of all months in "MM" format
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='default_growth'):
                self.run_income_projections_pgsql_procedure(user_code, tax_regime, appraisal_end_date, growth_expense_month)
                self.copy_temp_to_dynamic_income_projection(user_code)
                st.success("Income projections generated and saved to the database.")

                dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")


    # Run dynamic income projections
    def run_dynamic_nominee_income_projection(self, user_code):
        # Pop-up for selecting growth option
        add_growth_option = st.radio(
            "Which income projection type would you like to run?",
            ('Default Growth', 'Dynamic Growth', 'Custom Growth with Additional Inputs'),
            key="add_nominee_growth_option_input"
        )

        if add_growth_option == 'Dynamic Growth':
            # Inputs for dynamic growth percentage
            tax_regime = st.selectbox("Select the tax regime", ['old', 'new'], key="tax_nominee_regime_input")
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="nominee_income_appraisal_end_date")
            #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'], key="nominee_income_appraisal_end_date")
            income_growth_1 = st.number_input("Enter income growth percentage for age <35:", value=5.0, key="nominee_income_growth_1_input") / 100
            income_growth_2 = st.number_input("Enter income growth percentage for age 36-45:", value=4.0, key="nominee_income_growth_2_input") / 100
            income_growth_3 = st.number_input("Enter income growth percentage for age 46-55:", value=3.0, key="nominee_income_growth_3_input") / 100
            income_growth_4 = st.number_input("Enter income growth percentage for age >55:", value=2.0, key="nominee_income_growth_4_input") / 100
            expense_growth = st.number_input("Enter the expense growth percentage:", value=10.0, key="nominee_expense_growth_input") / 100
            #growth_expense_month = st.selectbox("Enter the month for growth expense (MM)", ['04', '01'], key="nominee_growth_expense_month_input")
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='nominee_dynamic_growth'):
                try:
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        CALL generate_income_projection_amount_table_fn_v2(%s, %s, %s, %s, %s, %s, %s, %s, %s);
                    """, (user_code, tax_regime, appraisal_end_date, 
                        income_growth_1, income_growth_2, income_growth_3, 
                        income_growth_4, expense_growth, growth_expense_month))
                    self.connection.commit()
                    st.success("Income projections generated successfully using dynamic growth percentages.")
                except Exception as e:
                    st.error(f"An error occurred while generating projections: {e}")
                    self.connection.rollback()
                finally:
                    cursor.close()

                # Copy data to `dynamic_income_projection` table and display
                self.copy_temp_to_dynamic_nominee_income_projection(user_code)
                dynamic_income_projection_df = self.load_dynamic_nominee_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")

        elif add_growth_option == 'Custom Growth with Additional Inputs':
            # Inputs for custom growth
            #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'], key="nominee_income_appraisal_end_date")
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="nominee_income_appraisal_end_date")
            income_growth_1 = st.number_input("Enter income growth percentage for age <35:", value=5.0, key="nominee_income_growth_1_input") / 100
            income_growth_2 = st.number_input("Enter income growth percentage for age 36-45:", value=4.0, key="nominee_income_growth_2_input") / 100
            income_growth_3 = st.number_input("Enter income growth percentage for age 46-55:", value=3.0, key="nominee_income_growth_3_input") / 100
            income_growth_4 = st.number_input("Enter income growth percentage for age >55:", value=2.0, key="nominee_income_growth_4_input") / 100
            expense_growth = st.number_input("Enter the expense growth percentage:", value=11.0, key="nominee_expense_growth_input") / 100
            user_income = st.number_input("Enter the user's primary income:", value= 0, key="nominee_user_income_input")
            user_other_income = st.number_input("Enter the user's other income:", value= 0, key="nominee_user_other_income_input")
            user_deduction_amount = st.number_input("Enter the user's deduction amount:", value= 0, key="nominee_user_deduction_amount_input")
            user_household_lifestyle_expenses = st.number_input("Enter household lifestyle expenses:", value= 0, key="nominee_household_expense_input")
            tax_projection_percentage = st.number_input("Enter the tax projection percentage:", value=1.0, key="nominee_tax_projection_percentage")/100
            #growth_expense_month = st.selectbox("Enter the month for growth expense (MM):", ['04', '01'], key="nominee_growth_expense_month_input")
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='nominee_custom_growth'):
                try:
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        CALL generate_income_projection_amount_table_fn_v7(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
                    """, (user_code, appraisal_end_date,
                        income_growth_1, income_growth_2, income_growth_3, 
                        income_growth_4, expense_growth, 
                        user_income, user_other_income, user_deduction_amount,
                        user_household_lifestyle_expenses, tax_projection_percentage, 
                        growth_expense_month))
                    self.connection.commit()
                    st.success("Income projections generated successfully using custom growth inputs.")
                except Exception as e:
                    st.error(f"An error occurred while generating projections: {e}")
                    self.connection.rollback()
                finally:
                    cursor.close()

                # Copy data to `dynamic_income_projection` table and display
                self.copy_temp_to_dynamic_nominee_income_projection(user_code)
                dynamic_income_projection_df = self.load_dynamic_nominee_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")

        elif add_growth_option == 'Default Growth':
            # Default growth inputs
            tax_regime = st.selectbox("Select the tax regime", ['old', 'new'], key="nominee_tax_regime_input")
            month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]
            appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="nominee_income_appraisal_end_date")
            #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'], key="nominee_income_appraisal_end_date")
            #growth_expense_month = st.selectbox("Enter the month for growth expense (MM):", ['04', '12'], key="nominee_growth_expense_month_input")
            growth_expense_month = st.selectbox( "Enter the month for growth expense (MM):",['04', '01', '02', '03', '05', '06', '07', '08', '09', '10', '11', '12'],
                                                 key="growth_expense_month_input")

            if st.button("Run Income Projections", key='nominee_default_growth'):
                self.run_income_projections_pgsql_procedure(user_code, tax_regime, appraisal_end_date, growth_expense_month)
                self.copy_temp_to_dynamic_nominee_income_projection(user_code)
                st.success("Income projections generated and saved to the database.")

                dynamic_income_projection_df = self.load_dynamic_nominee_income_projection_from_db()
                transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
                st.write("Reshaped Income Projection")
                st.dataframe(transposed_df)
                st.success("Income projections generated, transposed, and saved to the database.")  

    def run_dynamic_combine_income_projection(self):
        # Step 1: Load both tables from DB
        df_user = self.load_dynamic_income_projection_from_db()
        df_nominee = self.load_dynamic_nominee_income_projection_from_db()

        if df_user.empty:
            print("dynamic_income_projection is empty or missing.")
            return

        if df_nominee.empty:
            print("dynamic_nominee_income_projection is empty or missing.")
            # Use zero-filled DataFrame with only entry_date
            df_nominee = df_user[['entry_date']].copy()
            for col in [
                'gross_income_amount', 'post_income', 'tax_projection_values', 'net_income_post_tax',
                'household_lifestyle_expense_amount', 'total_expense', 'active_income_2', 'passive_income_2'
            ]:
                df_nominee[col] = 0.0

        # Step 2: Keep only financial columns + entry_date in nominee
        df_nominee_reduced = df_nominee[['entry_date',
            'gross_income_amount', 'post_income', 'tax_projection_values', 'net_income_post_tax',
            'household_lifestyle_expense_amount', 'total_expense', 'active_income_2', 'passive_income_2'
        ]].copy()

        # Step 3: Merge on entry_date
        combined_df = pd.merge(
            df_user,
            df_nominee_reduced,
            on='entry_date',
            how='left',
            suffixes=('', '_nominee')
        )

        # Step 4: Create final combined table using user values + summed values
        combined_projection = pd.DataFrame()

        # These columns are taken directly from user table
        columns_direct = [
            'user_code', 'entry_date', 'fin_year_entry', 'fin_year_in_words',
            'age', 'est_income_growth_percentage', 'est_expense_growth_percentage'
        ]
        for col in columns_direct:
            combined_projection[col] = combined_df[col]

        # Sum financial columns from user and nominee
        financial_columns = [
            'gross_income_amount', 'post_income', 'tax_projection_values', 'net_income_post_tax',
            'household_lifestyle_expense_amount', 'total_expense', 'active_income_2', 'passive_income_2'
        ]
        for col in financial_columns:
            combined_projection[col] = (
                combined_df[col].fillna(0) +
                combined_df[f'{col}_nominee'].fillna(0)
            )

        # Step 5: Save the final DataFrame
        combined_projection['entry_date'] = pd.to_datetime(combined_projection['entry_date']).dt.date
        combined_projection['fin_year_entry'] = pd.to_datetime(combined_projection['entry_date']).dt.date
        self.save_dynamic_combine_income_projection_to_db(combined_projection)
        #self.alter_combine_income_column_types()
        dynamic_income_projection_df = self.load_dynamic_combine_income_projection_from_db()
        transposed_df = self.transpose_dynamic_income_projection_1(dynamic_income_projection_df)
        st.write("Reshaped Income Projection")
        st.dataframe(transposed_df)
        st.success("Income projections combine, transposed, and saved to the database.")
        


    def alter_combine_income_column_types(self):
        try:
            cursor = self.connection.cursor()
            alter_query = """
                ALTER TABLE dynamic_combine_income_projection 
                    ALTER COLUMN entry_date TYPE DATE USING entry_date::date,
                    ALTER COLUMN fin_year_entry DATE USING fin_year_entry::date;
            """
            cursor.execute(alter_query)
            self.connection.commit()
            print("Column datatypes updated successfully.")
        except Exception as e:
            print(f"Error occurred while altering column datatypes: {e}")
            self.connection.rollback()
        finally:
            cursor.close()    
                      


    def save_tax_projections_to_db(self, dynamic_income_projection_df, user_id):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        inspector = inspect(engine)
        if not inspector.has_table('dynamic_income_projection'):
            print("Table 'dynamic_income_projection' does not exist. Creating the table.")
            dynamic_income_projection_df.head(0).to_sql(
                'dynamic_income_projection',
                engine,
                if_exists='replace',
                index=False
            )
        else:
            print(f"Table 'dynamic_income_projection' already exists.")

        with engine.connect() as connection:
            existing_data = pd.read_sql('dynamic_income_projection', connection)

        existing_data = existing_data[existing_data['user_code'] != user_id]
        updated_data = pd.concat([existing_data, dynamic_income_projection_df[dynamic_income_projection_df['user_code'] == user_id]])
        updated_data = updated_data.drop_duplicates().reset_index(drop=True)

        updated_data.to_sql('dynamic_income_projection', engine, if_exists='replace', index=False)
        print("Tax projections saved to the PostgreSQL database.")            

    #calculate outstanding amount 
    def _get_user_current_month_age(self, dob):
        """Compute current age as of the last day of the current month."""
        from calendar import monthrange
        today = date.today()
        last_day = monthrange(today.year, today.month)[1]
        last_date = date(today.year, today.month, last_day)
        current_age = self.calculate_age_on_date(dob, last_date)
        return last_date, current_age

    def _recompute_outstanding_for_rows(self, rows, dob, current_age):
        """
        Given iterable of rows: (id, milestone_year, your_percent_share, amount, inflation),
        compute outstanding and return list of (outstanding_amount, id).
        """
        import math
        updates = []
        for (liability_id, milestone_year, your_percent_share, amount, inflation) in rows:
            # coerce types safely
            your_percent_share = float(your_percent_share) if your_percent_share is not None else 0.0
            amount = float(amount) if amount is not None else 0.0
            inflation = float(inflation) if inflation is not None else 0.0

            if milestone_year is not None:
                # age at milestone month-end
                from calendar import monthrange
                last_day_m = monthrange(milestone_year.year, milestone_year.month)[1]
                milestone_last_date = date(milestone_year.year, milestone_year.month, last_day_m)
                milestone_age = self.calculate_age_on_date(dob, milestone_last_date)
                years = (milestone_age - current_age)
                outstanding = your_percent_share * amount * math.pow(1.0 + inflation, years)
            else:
                outstanding = your_percent_share * amount

            updates.append((outstanding, liability_id))
        return updates

    def _apply_outstanding_updates(self, updates):
        """Apply (outstanding, id) to both outstanding_amount and pdf_outstanding."""
        with self.connection.cursor() as cursor:
            for (outstanding, liability_id) in updates:
                cursor.execute("""
                    UPDATE milestones_liabilities
                    SET outstanding_amount = %s,
                        pdf_outstanding    = %s
                    WHERE id = %s AND is_active = TRUE;
                """, (outstanding, outstanding, liability_id))
        self.connection.commit()

    def _recompute_outstanding_amount_for_all(self, user_code):
        """
        Your original calculate_outstanding_amount logic, extracted to a helper
        and kept intact (recomputes ALL milestones for the user).
        """
        dob, retirement_age = self.fetch_user_data(user_code)
        if not dob or retirement_age is None:
            st.error(f"Error fetching user data for user {user_code}")
            return

        last_date, current_age = self._get_user_current_month_age(dob)

        with self.connection.cursor() as cursor:
            cursor.execute("""
                SELECT id, milestone_year, your_percent_share, amount, inflation
                FROM milestones_liabilities
                WHERE user_code = %s AND is_active = TRUE;
            """, (user_code,))
            rows = cursor.fetchall()

        updates = self._recompute_outstanding_for_rows(rows, dob, current_age)
        self._apply_outstanding_updates(updates)

    def _recompute_outstanding_amount_for_one_purpose(self, user_code, purpose):
        """
        Recompute outstanding/pdf_outstanding ONLY for the selected purpose.
        """
        dob, retirement_age = self.fetch_user_data(user_code)
        if not dob or retirement_age is None:
            st.error(f"Error fetching user data for user {user_code}")
            return

        last_date, current_age = self._get_user_current_month_age(dob)

        with self.connection.cursor() as cursor:
            cursor.execute("""
                SELECT id, milestone_year, your_percent_share, amount, inflation
                FROM milestones_liabilities
                WHERE user_code = %s AND purpose = %s AND is_active = TRUE;
            """, (user_code, purpose))
            rows = cursor.fetchall()

        if not rows:
            st.warning("No matching milestone rows found for this purpose.")
            return

        updates = self._recompute_outstanding_for_rows(rows, dob, current_age)
        self._apply_outstanding_updates(updates)

    def _fetch_distinct_purposes(self, user_code):
        """Return sorted distinct purposes for the user."""
        with self.connection.cursor() as cursor:
            cursor.execute("""
                SELECT DISTINCT TRIM(purpose)
                FROM milestones_liabilities
                WHERE user_code = %s
                AND is_active = TRUE
                AND purpose IS NOT NULL
                AND TRIM(purpose) <> 'None'
                ORDER BY 1;
            """, (user_code,))
            return [r[0] for r in cursor.fetchall()]

    def manage_outstanding_and_pdf_updates(self, user_id):
        """
        3-part UI:
        1) Recompute all milestones
        2) Recompute one milestone (by purpose)
        3) Manually set outstanding/pdf_outstanding for one milestone with Same/New logic
        """
        st.subheader("Outstanding & PDF Outstanding Updates")

        # -------- Part 1: Recompute ALL --------
        do_all = st.radio(
            "Do you want to update outstanding_amount and pdf_outstanding for ALL milestones?",
            ["No", "Yes"],
            index=0,
            key="upd_all_milestones_radio",
        )
        if do_all == "Yes":
            if st.button("Recompute ALL milestones", key="btn_recompute_all"):
                try:
                    if not user_id:
                        st.error("Please enter a valid user code first.")
                    else:
                        self._recompute_outstanding_amount_for_all(user_id)
                        st.success("Recomputed outstanding_amount and pdf_outstanding for ALL milestones.")
                except Exception as e:
                    self.connection.rollback()
                    st.error(f"Error recomputing ALL milestones: {e}")

        # st.markdown("---")

        # -------- Part 2: Recompute ONE (by purpose) --------
        do_one = st.radio(
            "Do you want to update outstanding_amount and pdf_outstanding for ONE milestone (by name/purpose)?",
            ["No", "Yes"],
            index=0,
            key="upd_one_milestone_radio",
        )
        if do_one == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code first.")
                else:
                    purposes = self._fetch_distinct_purposes(user_id)
                    if not purposes:
                        st.warning("No milestones found for this user.")
                    else:
                        sel_purpose = st.selectbox("Select milestone (purpose):", purposes, key="sel_purpose_recompute")
                        if st.button("Recompute selected milestone", key="btn_recompute_one"):
                            try:
                                self._recompute_outstanding_amount_for_one_purpose(user_id, sel_purpose)
                                st.success(f"Recomputed outstanding/pdf_outstanding for '{sel_purpose}'.")
                            except Exception as e:
                                self.connection.rollback()
                                st.error(f"Error recomputing the selected milestone: {e}")
            except Exception as e:
                st.error(f"Error setting up single-milestone UI: {e}")

        # st.markdown("---")

        # -------- Part 3: Manual override for ONE (Same/New) --------
        do_manual = st.radio(
            "Do you want to manually set outstanding_amount/pdf_outstanding for ONE milestone?",
            ["No", "Yes"],
            index=0,
            key="upd_one_manual_radio",
        )
        if do_manual == "Yes":
            try:
                if not user_id:
                    st.error("Please enter a valid user code first.")
                else:
                    purposes2 = self._fetch_distinct_purposes(user_id)
                    if not purposes2:
                        st.warning("No milestones found for this user.")
                    else:
                        sel_purpose2 = st.selectbox(
                            "Select milestone (purpose) to override:",
                            purposes2,
                            key="sel_purpose_manual",
                        )

                        update_options = {
                            "outstanding_amount": st.selectbox(
                                "Outstanding Amount", ["Same", "New"], key="opt_outstanding_amount"
                            ),
                            "pdf_outstanding": st.selectbox(
                                "PDF Outstanding", ["Same", "New"], key="opt_pdf_outstanding"
                            ),
                        }

                        updates = {}
                        if update_options["outstanding_amount"] == "New":
                            updates["outstanding_amount"] = st.number_input(
                                "New Outstanding Amount", min_value=0.0, step=1000.0, key="inp_outstanding_amount"
                            )
                        if update_options["pdf_outstanding"] == "New":
                            updates["pdf_outstanding"] = st.number_input(
                                "New PDF Outstanding", min_value=0.0, step=1000.0, key="inp_pdf_outstanding"
                            )

                        if st.button("Update selected milestone (manual override)", key="btn_manual_update"):
                            if not updates:
                                st.info("No changes selected (both set to Same). Nothing to update.")
                            else:
                                try:
                                    set_parts = []
                                    params = []
                                    if "outstanding_amount" in updates:
                                        set_parts.append("outstanding_amount = %s")
                                        params.append(float(updates["outstanding_amount"]))
                                    if "pdf_outstanding" in updates:
                                        set_parts.append("pdf_outstanding = %s")
                                        params.append(float(updates["pdf_outstanding"]))

                                    sql = f"""
                                        UPDATE milestones_liabilities
                                        SET {', '.join(set_parts)}
                                        WHERE user_code = %s
                                        AND purpose   = %s
                                        AND is_active = TRUE;
                                    """
                                    params.extend([str(user_id), sel_purpose2])

                                    with self.connection.cursor() as cursor:
                                        cursor.execute(sql, tuple(params))
                                        self.connection.commit()
                                        if cursor.rowcount > 0:
                                            st.success("Milestone overridden successfully.")
                                        else:
                                            st.warning("No row found for this user & purpose to update.")
                                except Exception as e:
                                    self.connection.rollback()
                                    st.error(f"Error updating milestone manually: {e}")
            except Exception as e:
                st.error(f"Error setting up manual override UI: {e}")

    def run_outstanding_amount_table(self, user_code):
        self.manage_outstanding_and_pdf_updates(user_code)
        #st.write('oustanding amount of milestone updated')


    #calculate existing and milestones liabilities
    def check_category_142_liability(self, user_code):
        """Check if the user has category_id 142 in the liabilities table"""
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM liabilities 
                WHERE user_code = %s AND category_id = 142;
            """, (user_code,))
            category_142_exists = cursor.fetchone() is not None
            cursor.close()
            return category_142_exists
        except Exception as e:
            print(f"An error occurred while checking for category_id 142: {e}")
            return False

    def run_all_cf_calculation_projection(self, user_code):

        if st.button("Run milestone and liabilties projections"):
            # Step 1: Check if the user has category_id 142
            if not self.check_category_142_liability(user_code):
                # If no category 142, run liabilities CF procedure
                self.run_liabilities_cf_pgsql_procedure(user_code)
            else:
                print(f"User {user_code} has category_id 142, skipping liabilities CF procedure.")

            # Step 2: Check and run Flexi Term Loan procedure if necessary
            if self.check_flexi_term_loan_liability(user_code):
                appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'],key="flexi_appraisal_end_date")
                self.run_flexi_term_liabilities_cf_pgsql_procedure(user_code, appraisal_end_date)
            else:
                print("No Flexi Term Loan liability found for the user.")

            # Step 3: Run milestone liabilities CF procedure
            self.run_milestone_liabilities_cf_pgsql_procedure(user_code)

            # Step 4: If no category 142, merge CF Loan and Flexi Term Loan data
            if not self.check_category_142_liability(user_code):
                self.merge_cf_loan_and_flexi_term(user_code)
            else:
                print(f"User {user_code} has category_id 142, skipping merge of CF Loan and Flexi Term data.")
            
            #st.write('all existing liabilities projections') 
            # Reshape and display the existing liabilities projections for the user
            #reshaped_df = self.transpose_all_cf_liabilities_calculation_df_1()
            #st.dataframe(reshaped_df)   

            #st.write('all milestones liabilities projections') 
            # Reshape and display the existing liabilities projections for the user
            #reshaped_df = self.transpose_cf_milestone_loan_calculation_df_1()
            #st.dataframe(reshaped_df)   

            st.write('all liabilities and milestones liabilities projections updated')    

    def run_liabilities_cf_pgsql_procedure(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("CALL generate_dynamic_loan_calculation(%s)", (user_code,))
            self.connection.commit()
            print("Liabilities CF procedure executed successfully.")
        except Exception as e:
            print(f"An error occurred: {e}")
            self.connection.rollback()
        finally:
            cursor.close()

    def check_flexi_term_loan_liability(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT DISTINCT name, created_at, category_id
                FROM liabilities 
                WHERE user_code = %s AND (name = 'Flexi Term Loan' OR name = 'Flexi Term Loan ');
            """, (user_code,))
            flexi_loan_exists = cursor.fetchone() is not None
            cursor.close()
            return flexi_loan_exists
        except Exception as e:
            print(f"An error occurred while checking Flexi Term Loan: {e}")
            return False

    def run_flexi_term_liabilities_cf_pgsql_procedure(self, user_code, appraisal_end_date):
        try:
            cursor = self.connection.cursor()
            cursor.execute("CALL generate_dynamic_liability_projections(%s,%s)", (user_code, appraisal_end_date,))
            self.connection.commit()
            print("Flexi Term Loan liability procedure executed successfully.")
        except Exception as e:
            print(f"An error occurred: {e}")
            self.connection.rollback()
        finally:
            cursor.close()

    def run_milestone_liabilities_cf_pgsql_procedure(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("CALL generate_dynamic_milestone_loan_calculation(%s)", (user_code,))
            self.connection.commit()
            print("Milestone liabilities CF procedure executed successfully.")
        except Exception as e:
            print(f"An error occurred: {e}")
            self.connection.rollback()
        finally:
            cursor.close()
    

    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_all_cf_liabilities_calculation_df(self):

        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Load the table directly
        all_cf_liabilities_calculation_df = pd.read_sql('all_cf_liabilities_calculation', engine)

        # Drop unnecessary columns
        all_cf_liabilities_calculation_df = all_cf_liabilities_calculation_df.drop(columns=['user_code', 'fin_year_entry','fin_year_in_words','age','category_id','months'])

        # Ensure entry_date is in string format
        #all_cf_liabilities_calculation_df['entry_date'] = all_cf_liabilities_calculation_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = all_cf_liabilities_calculation_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True) 

        return df_transposed
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_all_cf_liabilities_calculation_df_1(self):

        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Load the table directly
        all_cf_liabilities_calculation_df = pd.read_sql('all_cf_liabilities_calculation', engine) 

        # Drop unnecessary columns
        all_cf_liabilities_calculation_df = all_cf_liabilities_calculation_df.drop(columns=['user_code', 'fin_year_entry','fin_year_in_words','age','category_id','months'])

        # Ensure entry_date is in string format
        #all_cf_liabilities_calculation_df['entry_date'] = all_cf_liabilities_calculation_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = all_cf_liabilities_calculation_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_cf_milestone_loan_calculation_df(self):

        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Load the table directly
        cf_milestone_loan_calculation_df = pd.read_sql('cf_milestone_loan_calculation', engine)

        # Drop unnecessary columns
        cf_milestone_loan_calculation_df = cf_milestone_loan_calculation_df.drop(columns=['user_code', 'fin_year_entry','fin_year_in_words','age','category_id','months'])

        # Ensure entry_date is in string format
        #all_cf_liabilities_calculation_df['entry_date'] = all_cf_liabilities_calculation_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = cf_milestone_loan_calculation_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True) 

        return df_transposed
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_cf_milestone_loan_calculation_df_1(self):

        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Load the table directly
        cf_milestone_loan_calculation_df = pd.read_sql('cf_milestone_loan_calculation', engine)

        # Drop unnecessary columns
        cf_milestone_loan_calculation_df = cf_milestone_loan_calculation_df.drop(columns=['user_code', 'fin_year_entry','fin_year_in_words','age','category_id','months'])

        # Ensure entry_date is in string format
        #all_cf_liabilities_calculation_df['entry_date'] = all_cf_liabilities_calculation_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = cf_milestone_loan_calculation_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed



    def merge_cf_loan_and_flexi_term(self, user_code):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        # CHANGED: run everything inside one transaction/connection
        with engine.begin() as connection:  # CHANGED

            try:
                # Check if Flexi Term Loan exists
                query_check_flexi_loan = text("""   -- CHANGED: wrap with text() + named param + TRIM + schema
                    SELECT DISTINCT name, created_at, category_id
                    FROM public.liabilities
                    WHERE user_code = :user_code
                    AND TRIM(name) = 'Flexi Term Loan'
                """)
                flexi_loan_exists = pd.read_sql_query(query_check_flexi_loan, connection, params={"user_code": user_code})  # CHANGED

                if not flexi_loan_exists.empty:
                    query_cf_loan = text("SELECT * FROM public.cf_loan_calculation WHERE user_code = :user_code")  # CHANGED
                    cf_loan_calculation = pd.read_sql_query(query_cf_loan, connection, params={"user_code": user_code})     # CHANGED

                    query_flexi_loan = text("SELECT * FROM public.liability_projection_flexi_term_loan WHERE user_code = :user_code")  # CHANGED
                    cf_flexi_loan_calculation = pd.read_sql_query(query_flexi_loan, connection, params={"user_code": user_code})      # CHANGED

                    combined_df = pd.merge(
                        cf_loan_calculation,
                        cf_flexi_loan_calculation[['user_code', 'category_id', 'entry_date', 'liability_name', 'emi', 'interest', 'principal_remaining', 'principal', 'end_balance']],
                        on=['user_code', 'category_id', 'entry_date', 'liability_name'],
                        how='left',
                        suffixes=('', '_flexi')
                    )

                    for column in ['emi', 'interest', 'principal_remaining', 'principal', 'end_balance']:
                        combined_df[column] = combined_df.get(f"{column}_flexi", combined_df[column]).combine_first(combined_df[column])

                    combined_df.drop(columns=[c for c in combined_df.columns if c.endswith('_flexi')], inplace=True)

                    # CHANGED: specify schema + use same connection (in-transaction)
                    combined_df.to_sql('all_cf_liabilities_calculation', connection, if_exists='replace', index=False, schema='public')  # CHANGED
                    print("Merged Flexi Term Loan data with CF Loan Calculation data and saved to 'all_cf_liabilities_calculation'.")
                else:
                    query_cf_loan = text("SELECT * FROM public.cf_loan_calculation WHERE user_code = :user_code")  # CHANGED
                    all_cf_liabilities_calculation = pd.read_sql_query(query_cf_loan, connection, params={"user_code": user_code})      # CHANGED
                    # CHANGED: specify schema + same connection (in-transaction)
                    all_cf_liabilities_calculation.to_sql('all_cf_liabilities_calculation', connection, if_exists='replace', index=False, schema='public')  # CHANGED
                    print("User does not have Flexi Term Loan. Created a copy of CF Loan Calculation data as 'all_cf_liabilities_calculation'.")
            finally:
                pass      

    #add pre planning tables
    def create_dynamic_pre_goal_asset(self, dob, retirement_age, user_id, user_name, month_choice):
        # -- Find all category_ids the user actually uses in cf_assets_projections
        cat_cursor = self.connection.cursor()
        cat_cursor.execute(
            """
            SELECT DISTINCT c.id, c.name
            FROM milestones_category c
            JOIN cf_assets_projections a ON a.category_id = c.id
            WHERE a.user_code = %s
            """,
            (user_id,)
        )
        cat_rows = cat_cursor.fetchall()
        cat_cursor.close()

        if not cat_rows:
            # If user doesn't have any categories in cf_assets_projections,
            # just return an empty list
            return []

        # Prepare a list of (category_id, category_name)
        categories = [(str(r[0]), r[1]) for r in cat_rows]

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        #age_limit_year = current_year + (80 - current_age)
        age_limit_year = current_year + (retirement_age - current_age +1 )
        print('age_limit_year',age_limit_year)
        dynamic_pre_goal_cashflow_projections = []

        # Generate a monthly date skeleton until user is 80 or month_choice
        while (start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice)):
            last_day_of_month = start_date.replace( day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # For each category, we create one row
            for cat_id, cat_name in categories:
                data_row = {
                    "user_code": user_id,
                    "user_name": user_name,
                    "entry_date": last_day_of_month.strftime("%Y-%m-%d"),
                    "age": iter_age,
                    # We'll keep category_id internally to match up in update function
                    "category_id": cat_id,
                    "assets_name": cat_name,
                    "assets_value": 0.0
                }
                dynamic_pre_goal_cashflow_projections.append(data_row)

            # Move to the next month
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return dynamic_pre_goal_cashflow_projections
                       
    
    def fetch_asset_cf_projections(self, user_code):
        query = """
            SELECT category_id, entry_date, value
            FROM cf_assets_projections
            WHERE user_code = %s
            ORDER BY entry_date ASC;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            cf_proj_df = pd.DataFrame(data, columns=columns)
            if cf_proj_df.empty:
                st.warning("No data found in cf_assets_projections for the given user.")
                return None

            return cf_proj_df

        except Exception as e:
            print(f"Error fetching cf_assets_projections: {e}")
            return None
        
    def save_dynamic_pre_goal_asset_df_to_db(self, dynamic_pre_goal_asset_df, db_config):
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
        connection_string = (
            f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}"
            f"@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        )
        engine = create_engine(connection_string)

        # -----------------------------------------------------------------------------------
        #    REMOVE the code that drops "category_id" from the DataFrame.
        #    Because we DO want to store it for subsequent loads/updates.
        # -----------------------------------------------------------------------------------

        # Define the table schema with specific data types, including category_id
        table_schema = {
            "user_code": UUID(as_uuid=True),
            "user_name": TEXT,
            "entry_date": DATE,
            "age": BIGINT,
            "category_id": BIGINT,       # <--- or TEXT, if your category_id is a string in DB
            "assets_name": TEXT,
            "assets_value": NUMERIC
        }

        # Save the DataFrame to PostgreSQL table
        dynamic_pre_goal_asset_df.to_sql(
            "pre_goal_assets_cashflow",
            engine,
            if_exists="replace",
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'pre_goal_assets_cashflow'")    


    def load_dynamic_pre_goal_asset_df_from_db(self, db_config):
       
        connection_string = (f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}" f"@{db_config['host']}:{db_config['port']}/{db_config['database']}")
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'pre_goal_assets_cashflow');
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'pre_goal_assets_cashflow' does not exist.")
            dynamic_pre_goal_asset_df = pd.DataFrame()
        else:
            dynamic_pre_goal_asset_df = pd.read_sql("pre_goal_assets_cashflow", engine)

        return dynamic_pre_goal_asset_df    
    
    def transpose_dynamic_pre_goal_asset_df_1(self, dynamic_pre_goal_asset_df):

        # Work on a copy so we don't mutate the original DataFrame
        df = dynamic_pre_goal_asset_df.copy()

        # Sort by date
        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')

        # Convert date to string, for pivot columns
        df['entry_date'] = df['entry_date'].astype(str)

        # Create pivot
        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        ).reset_index()

        return reshaped_df


    def transpose_dynamic_pre_goal_asset_df_2(self, dynamic_pre_goal_asset_df):
        df = dynamic_pre_goal_asset_df.copy()

        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')
        df['entry_date'] = df['entry_date'].astype(str)

        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        ).reset_index()

        return reshaped_df    
    
    def update_dynamic_pre_goal_asset(self, dynamic_pre_goal_asset_df, user_id):
        cf_assets_df = self.fetch_asset_cf_projections(user_id)
        if cf_assets_df is None or cf_assets_df.empty:
            return dynamic_pre_goal_asset_df

        # Convert entry_date from dd-mm-yyyy
        cf_assets_df["entry_date"] = pd.to_datetime(cf_assets_df["entry_date"], format="%Y-%m-%d")

        for idx, row in cf_assets_df.iterrows():
            fy_end_date = row["entry_date"]  # e.g. 31-Mar-2025
            cat_id = str(row["category_id"])
            val = row["value"] if row["value"] else 0.0

            # If it's 31-Mar-Year => that covers 1-Apr-(Year-1) to 31-Mar-Year
            year_ending = fy_end_date.year

            monthly_val = val / 12.0

            start_fy = pd.to_datetime(f"{year_ending - 1}-04-01")
            end_fy   = pd.to_datetime(f"{year_ending}-03-31")

            # Update all skeleton rows matching category_id and date in [start_fy, end_fy]
            mask = (
                (dynamic_pre_goal_asset_df["category_id"] == cat_id) &
                (pd.to_datetime(dynamic_pre_goal_asset_df["entry_date"]) >= start_fy) &
                (pd.to_datetime(dynamic_pre_goal_asset_df["entry_date"]) <= end_fy)
            )
            dynamic_pre_goal_asset_df.loc[mask, "assets_value"] = monthly_val

        return dynamic_pre_goal_asset_df

    def convert_to_annual_asset_multiplication_1(self, df):
        
        df["entry_date"] = pd.to_datetime(df["entry_date"], format="%d-%m-%Y")
        # Filter only March
        df_march = df[df["entry_date"].dt.month == 3].copy()
        df_march["assets_value"] = df_march["assets_value"] * 12
        return df_march    
    
    def filter_data_by_date_range(self, df, start_date, end_date):
        df["entry_date"] = pd.to_datetime(df["entry_date"])
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)
        return df[(df["entry_date"] >= start_date) & (df["entry_date"] <= end_date)]
    
    def run_create_dynamic_pre_goal_asset(self, user_id, dob, retirement_age, month_choice):
        connection = self.connect_db()
        if connection is None:
            return

        # Load existing data from 'pre_goal_cashflow_1'
        dynamic_pre_goal_asset_df = self.load_dynamic_pre_goal_asset_df_from_db(self.db_config)
        user_name = self.fetch_user_name(user_id)

        # If empty or user_id not present, create fresh skeleton
        if dynamic_pre_goal_asset_df.empty:
            asset_new_projections = self.create_dynamic_pre_goal_asset(dob, retirement_age, user_id, user_name, month_choice)
            dynamic_pre_goal_asset_df = pd.DataFrame(asset_new_projections)
        else:
            if user_id not in dynamic_pre_goal_asset_df["user_code"].unique():
                asset_new_projections = self.create_dynamic_pre_goal_asset(dob, retirement_age, user_id, user_name, month_choice)
                dynamic_pre_goal_asset_df = pd.DataFrame(asset_new_projections)

        # Update 'assets_value' using the distribution logic
        dynamic_pre_goal_asset_df = self.update_dynamic_pre_goal_asset(dynamic_pre_goal_asset_df, user_id)
        st.write("### User Assets Projections")
        transposed_df = self.transpose_dynamic_pre_goal_asset_df_1(dynamic_pre_goal_asset_df)
        st.dataframe(transposed_df) 
        # Finally, save the updated DataFrame into 'pre_goal_cashflow'
        self.save_dynamic_pre_goal_asset_df_to_db(dynamic_pre_goal_asset_df, self.db_config)
        st.write("Pre goal planning asset table updated and saved to the database.")

        # Close connection
        connection.close()


    def create_pre_liabilities_projections_table(self, dob, retirement_age, liabilities_with_categories, user_id, user_name, month_choice):

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)
        
        liabilities_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1) 

        return liabilities_projections 

    def update_dynamic_pre_liabilities_projections(self, dynamic_liabilities_projections_df, user_code):
        # Check if user has category_id 142
        category_142_exists = self.check_category_142_liability(user_code)

        # Check if the DataFrame is empty and create one with required columns if it is
        if dynamic_liabilities_projections_df.empty:
            st.warning(f"No liabilities available for user {user_code}. Creating an empty projection table.")
            
            # Define the required columns for the DataFrame
            columns = ['user_code', 'user_name', 'entry_date', 'age', 'category_id', 'liabilities_name', 'liabilities_value']
            dtypes = {
            'user_code': 'string',           # equivalent to text in PostgreSQL
            'user_name': 'string',           # equivalent to text in PostgreSQL
            'entry_date': 'string',          # storing as text
            'age': 'int64',                  # equivalent to bigint in PostgreSQL
            'category_id': 'int64',          # equivalent to bigint in PostgreSQL
            'liabilities_name': 'string',    # equivalent to text in PostgreSQL
            'liabilities_value': 'float64'   # equivalent to double precision in PostgreSQL
            }

            # Create an empty DataFrame with these columns and data types
            dynamic_liabilities_projections_df = pd.DataFrame(columns=columns).astype(dtypes)             
        
            
            # Save the empty DataFrame to the database as the initial structure
            self.save_dynamic_pre_liabilities_projections_df_to_db(dynamic_liabilities_projections_df)
            st.write(f"Empty liabilities projections table created for user {user_code}.")
            return dynamic_liabilities_projections_df
        
        #print('first dynamic_liabilities_projections_df', dynamic_liabilities_projections_df)
        for idx, projection in dynamic_liabilities_projections_df.iterrows():
            entry_date = projection['entry_date']
            #print('first entry_date',entry_date)
            category_id = projection['category_id']
            liabilities_name = projection['liabilities_name']

            # Fetch liabilities_value from dynamic_loan_repayment_projections (this should always run)
            cursor = self.connection.cursor()

            if not category_142_exists:
                # Fetch principal_remaining from all_cf_liabilities_calculation if category_id 142 is not present
                cursor.execute("""
                    SELECT principal_remaining 
                    FROM all_cf_liabilities_calculation
                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                """, (user_code, entry_date, category_id, liabilities_name))
                end_balance_value_1 = cursor.fetchone()
                end_balance_value_1 = float(end_balance_value_1[0]) if end_balance_value_1 and end_balance_value_1[0] is not None else 0.0
                #print('existing entry_date', entry_date)
                #print('existing liabilities total', liabilities_total)

            # Update the DataFrame
            dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = end_balance_value_1

        return dynamic_liabilities_projections_df   
    
    def update_dynamic_pre_liabilities_projections_with_flexi_term_loan(self, dynamic_liabilities_projections_df, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT 1
            FROM liabilities
            WHERE user_code = %s AND name = 'Flexi Term Loan ';
        """, (user_id,))

        flexi_term_loan_exists = cursor.fetchone() is not None

        if not flexi_term_loan_exists:
            return dynamic_liabilities_projections_df

        # Determine the first date for the Flexi Term Loan
        first_flexi_term_loan_date = dynamic_liabilities_projections_df.loc[
            dynamic_liabilities_projections_df['liabilities_name'] == 'Flexi Term Loan ', 'entry_date'
        ].min()

        if isinstance(first_flexi_term_loan_date, str):
            try:
                first_flexi_term_loan_date = datetime.strptime(first_flexi_term_loan_date, '%Y-%m-%d %H:%M:%S')
            except ValueError:
                first_flexi_term_loan_date = datetime.strptime(first_flexi_term_loan_date, '%Y-%m-%d')
        elif isinstance(entry_date, pd.Timestamp):
            first_flexi_term_loan_date = first_flexi_term_loan_date.to_pydatetime()
        #print(first_flexi_term_loan_date)

        # Iterate through the projections to update 'Flexi Term Loan'
        for idx, projection in dynamic_liabilities_projections_df.iterrows():
            if projection['liabilities_name'] == 'Flexi Term Loan ':
                entry_date = projection['entry_date']
                category_id = projection['category_id']

                        # Ensure entry_date is a datetime object
                if isinstance(entry_date, str):
                    try:
                        entry_date = datetime.strptime(entry_date, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        entry_date = datetime.strptime(entry_date, '%Y-%m-%d')
                elif isinstance(entry_date, pd.Timestamp):
                    entry_date = entry_date.to_pydatetime()

                # Convert entry_date to the text format used in dynamic_loan_repayment_projections
                entry_date_text = entry_date.strftime('%Y-%m-%d')

                # Check if the entry_date is the first date for 'Flexi Term Loan'
                if entry_date == first_flexi_term_loan_date:
                    # Fetch the value from all_cf_liabilities_calculation for the current month
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        SELECT principal_remaining 
                        FROM all_cf_liabilities_calculation
                        WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = 'Flexi Term Loan ';
                    """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
                    initial_value = cursor.fetchone()

                    initial_value = float(initial_value[0]) if initial_value and initial_value[0] is not None else 0.0

                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = initial_value

                else:
                    previous_date = entry_date - pd.DateOffset(months=1)
                    last_day_previous_month = previous_date + pd.offsets.MonthEnd(0)
                    #print('last_day_previous_month',last_day_previous_month)

                    last_day_previous_month = last_day_previous_month.strftime('%Y-%m-%d')

                    previous_value = dynamic_liabilities_projections_df.loc[
                        (dynamic_liabilities_projections_df['entry_date'] == last_day_previous_month) & 
                        (dynamic_liabilities_projections_df['liabilities_name'] == 'Flexi Term Loan '), 
                        'liabilities_value'
                    ].values

                    #print('previous value',previous_value)

                    if len(previous_value) > 0:
                        previous_value = previous_value[0]
                    else:
                        previous_value = 0.0

                    # Update the current row with the new liabilities value
                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = previous_value          

        return dynamic_liabilities_projections_df
    
    def save_dynamic_pre_liabilities_projections_df_to_db(self, dynamic_liabilities_projections_df):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        dynamic_liabilities_projections_df.to_sql('dynamic_pre_liabilities_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_pre_liabilities_projections'")

    def load_dynamic_pre_liabilities_projections_df_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_pre_liabilities_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_pre_liabilities_projections' does not exist.")
            dynamic_liabilities_projections_df = pd.DataFrame()
        else:
            dynamic_liabilities_projections_df = pd.read_sql('dynamic_pre_liabilities_projections', engine)

        return dynamic_liabilities_projections_df    
    
    def reshape_dynamic_pre_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df


    def reshape_display_dynamic_pre_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)

        return reshaped_df    

    def run_dynamic_pre_liabilities_projections(self, user_code, dob, retirement_age, month_choice):
        dynamic_liabilities_projections_df = self.load_dynamic_pre_liabilities_projections_df_from_db()
        #st.write('1. data has been loaded')
        user_name = self.fetch_user_name(user_code)
        
        liabilities_with_categories = self.fetch_liabilities_for_liabilities_projections(user_code)
        #st.write('2. data has been fetched')
        if dynamic_liabilities_projections_df.empty:
            #st.write('in loop dynamic_liabilities_projections_df',dynamic_liabilities_projections_df)
            new_projections = self.create_pre_liabilities_projections_table(dob, retirement_age, liabilities_with_categories, user_id, user_name, month_choice)
            dynamic_liabilities_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_liabilities_projections_df['user_code'].unique():
                new_projections = self.create_pre_liabilities_projections_table(dob, retirement_age, liabilities_with_categories, user_id, user_name, month_choice)
                dynamic_liabilities_projections_df = pd.DataFrame(new_projections)
        #st.write('out loop dynamic_liabilities_projections_df',dynamic_liabilities_projections_df)
        #st.write('3. data has been created')
        # Reshape and display the existing liabilities projections for the user
        #reshaped_df = self.reshape_dynamic_pre_liabilities_projections(dynamic_liabilities_projections_df, user_id)
        #st.dataframe(reshaped_df)     
        # Ask if user wants to update the liabilities projection
        #if st.radio("Do you want to update the liabilities projection?", ["No", "Yes"], index=0, key='update the loan repayment table') == "Yes":
        dynamic_liabilities_projections_df = self.update_dynamic_pre_liabilities_projections(dynamic_liabilities_projections_df, user_code)
        #st.write('2. data has been updated')
        #st.success("Liabilities projections have been updated.")
         
        #dynamic_liabilities_projections_df = self.update_dynamic_pre_liabilities_projections_with_flexi_term_loan(dynamic_liabilities_projections_df, user_code)
        #st.write('2. flexi term data has been updated')
        # Display the updated investment projections for the user
        st.write("### User Liabilities Projections:")
       
        # Reshape and display the existing liabilities projections for the user
        reshaped_df = self.reshape_dynamic_pre_liabilities_projections(dynamic_liabilities_projections_df, user_id)
        st.dataframe(reshaped_df)  

        self.save_dynamic_pre_liabilities_projections_df_to_db(dynamic_liabilities_projections_df)   
        st.write('Pre goal planning liabilities table updated and saved to the database.')


    def create_pre_liabilities_outflows_projections_table(self, dob, retirement_age, liabilities_with_categories, user_id, user_name, month_choice):
    
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        liabilities_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)   

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)   

        return liabilities_projections    
    
    def update_dynamic_pre_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id, dob):
        # Convert entry_date in dynamic_liabilities_outflows_projections_df to datetime format
        category_142_exists = self.check_category_142_liability(user_id)
    
        # Check if the DataFrame is empty and create one with required columns if it is
        if dynamic_liabilities_outflows_projections_df.empty:
            st.warning(f"No liabilities available for user {user_id}. Creating an empty projection table.")
            
            # Define the required columns for the DataFrame
            columns = ['user_code', 'user_name', 'entry_date', 'age', 'category_id', 'liabilities_name', 'liabilities_value']
            dtypes = {
            'user_code': 'string',           # equivalent to text in PostgreSQL
            'user_name': 'string',           # equivalent to text in PostgreSQL
            'entry_date': 'string',          # storing as text
            'age': 'int64',                  # equivalent to bigint in PostgreSQL
            'category_id': 'int64',          # equivalent to bigint in PostgreSQL
            'liabilities_name': 'string',    # equivalent to text in PostgreSQL
            'liabilities_value': 'float64'   # equivalent to double precision in PostgreSQL
            }

            # Create an empty DataFrame with these columns and data types
            dynamic_liabilities_outflows_projections_df = pd.DataFrame(columns=columns).astype(dtypes)             
        
            
            # Save the empty DataFrame to the database as the initial structure
            self.save_dynamic_pre_liabilities_projections_df_to_db(dynamic_liabilities_outflows_projections_df)
            st.write(f"Empty liabilities projections table created for user {user_id}.")
            return dynamic_liabilities_outflows_projections_df

        for idx, projection in dynamic_liabilities_outflows_projections_df.iterrows():
            entry_date = projection['entry_date']
            #print('first entry_date',entry_date)
            category_id = projection['category_id']
            liabilities_name = projection['liabilities_name']
            cursor = self.connection.cursor()

            liabilities_total = 0  # Initialize liabilities total

            if not category_142_exists:
                # Fetch end_balance from all_cf_liabilities_calculation if category_id 142 is not present
                
                cursor.execute("""
                    SELECT emi 
                    FROM all_cf_liabilities_calculation
                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                """, (user_id, entry_date, category_id, liabilities_name))
                emi_value_1 = cursor.fetchone()
                emi_value_1 = float(emi_value_1[0]) if emi_value_1 and emi_value_1[0] is not None else 0.0
                liabilities_total +=  emi_value_1 
                #print('existing entry_date', entry_date)
                #print('existing liabilities total', liabilities_total)    

            # Update the DataFrame
            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = liabilities_total
                    
        #dynamic_liabilities_outflows_projections_df['entry_date'] = pd.to_datetime(dynamic_liabilities_outflows_projections_df['entry_date']).dt.dates

        return dynamic_liabilities_outflows_projections_df
    
    def save_dynamic_pre_liabilities_outflows_projections_df_to_db(self, dynamic_liabilities_outflows_projections_df):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table
        dynamic_liabilities_outflows_projections_df.to_sql('dynamic_pre_liabilities_outflows_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_pre_liabilities_outflows_projections'")
        
    
    def load_dynamic_pre_liabilities_outflows_projections_df_from_db(self):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_pre_liabilities_outflows_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_pre_liabilities_outflows_projections' does not exist.")
            dynamic_liabilities_outflows_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_liabilities_outflows_projections_df = pd.read_sql('dynamic_pre_liabilities_outflows_projections', engine)

        return dynamic_liabilities_outflows_projections_df

    def reshape_dynamic_pre_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df 
    
    def reshape_display_pre_dynamic_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)
        return reshaped_df 
    
    def user_exists_in_pre_liabilities_outflows_proj_db(self, user_id):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        inspector = inspect(engine)
        if not inspector.has_table('dynamic_pre_liabilities_outflows_projections'):
            print("Table 'dynamic_pre_liabilities_outflows_projections' does not exist.")
            return False

        query = f"SELECT 1 FROM dynamic_pre_liabilities_outflows_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None

    def clear_dynamic_pre_liabilities_outflows_projections(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_pre_liabilities_outflows_projections;")
            self.connection.commit()
            print("Cleared the dynamic_pre_liabilities_outflows_projections table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_pre_liabilities_outflows_projections table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()   
    
    def run_dynamic_pre_liabilities_outflows_projections(self, user_id, month_choice):

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('dynamic_pre_liabilities_outflows_projections'):
                # Only delete old records if the table exists
                print('data has been clear')
                self.clear_dynamic_pre_liabilities_outflows_projections()
        # Fetch required data
        liabilities_with_categories = self.fetch_liabilities_for_liabilities_outflows(user_id)
        user_name = self.fetch_user_name(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        dynamic_liabilities_outflows_projections_df = self.load_dynamic_pre_liabilities_outflows_projections_df_from_db()

        if not self.user_exists_in_pre_liabilities_outflows_proj_db(user_id):
            new_projections = self.create_pre_liabilities_outflows_projections_table(dob, retirement_age, liabilities_with_categories, user_id, user_name, month_choice)
            if dynamic_liabilities_outflows_projections_df.empty:
                dynamic_liabilities_outflows_projections_df = pd.DataFrame(new_projections)
            else:
                 dynamic_liabilities_outflows_projections_df = pd.concat([dynamic_liabilities_outflows_projections_df, pd.DataFrame(new_projections)], ignore_index=True)
            self.save_dynamic_pre_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df) 

        # Update the projections based on user input
        dynamic_liabilities_outflows_projections_df = self.update_dynamic_pre_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id, dob)  

        st.write("### User Liabilities Outflows Projection")
        # Reshape and display the existing liabilities projections for the user
        reshaped_df = self.reshape_dynamic_pre_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
        st.dataframe(reshaped_df)

        # Save the updated DataFrame to the PostgreSQL database
        self.save_dynamic_pre_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)
        st.write("Pre goal planning liabilities outflows table updated and saved to the database.")
    
    def save_pre_goal_dynamic_insurance_outflows_projections_df_to_db(self, dynamic_insurance_outflows_projections_df):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table
        dynamic_insurance_outflows_projections_df.to_sql('dynamic_pre_goal_insurance_outflows_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_pre_goal_insurance_outflows_projections'")
        

    def load_pre_goal_dynamic_insurance_outflows_projections_df_from_db(self):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_pre_goal_insurance_outflows_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_pre_goal_insurance_outflows_projections' does not exist.")
            dynamic_insurance_outflows_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_insurance_outflows_projections_df = pd.read_sql('dynamic_pre_goal_insurance_outflows_projections', engine)

        return dynamic_insurance_outflows_projections_df
    
    def clear_pre_goal_dynamic_insurance_outflows_projections(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_pre_goal_insurance_outflows_projections;")
            self.connection.commit()
            print("Cleared the dynamic_pre_goal_insurance_outflows_projections table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_pre_goal_insurance_outflows_projections table: {e}")
            self.connection.rollback()
        finally:
            cursor.close() 

    def run_pre_goal_dynamic_insurance_outflows_projections(self, user_id, month_choice):

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('dynamic_pre_goal_insurance_outflows_projections'):
                # Only delete old records if the table exists
                print('data has been clear')
                self.clear_pre_goal_dynamic_insurance_outflows_projections()
        # Fetch required data
        distinct_insurance_names = self.fetch_distinct_insurance_names(user_id)
        user_name = self.fetch_user_name(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)

        # Load existing data from the database
        dynamic_insurance_outflows_projections_df = self.load_pre_goal_dynamic_insurance_outflows_projections_df_from_db()

        if dynamic_insurance_outflows_projections_df.empty:
            new_projections = self.create_insurance_outflows_projections_table(dob, retirement_age, distinct_insurance_names, user_id, user_name, month_choice)
            dynamic_insurance_outflows_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_insurance_outflows_projections_df['user_code'].unique():
                new_projections = self.create_insurance_outflows_projections_table(dob, retirement_age, distinct_insurance_names, user_id, user_name, month_choice)
                dynamic_insurance_outflows_projections_df = pd.DataFrame(new_projections)


        # Reshape and display the existing liabilities projections for the user
        #reshaped_df = self.reshape_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
        #st.dataframe(reshaped_df)    

        # Update the projections based on user input
        dynamic_insurance_outflows_projections_df = self.update_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id, dob)  

        st.write("### User Insurance Projection")
        # Reshape and display the existing liabilities projections for the user
        reshaped_df = self.reshape_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
        st.dataframe(reshaped_df)   

        # Save the updated DataFrame to the PostgreSQL database
        self.save_pre_goal_dynamic_insurance_outflows_projections_df_to_db(dynamic_insurance_outflows_projections_df)
        st.write("Pre goal planning all insruance projection updated and save to the database")

    
    def fetch_milestones_liabilities(self, user_code):
        """Fetch milestones liabilities data from the database for the given user."""
        query = """
            SELECT purpose, milestone_year, amount, pdf_outstanding, loan_funded, interest_rate, pending_tenure, inflation, your_percent_share
            FROM milestones_liabilities
            WHERE user_code = %s;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            milestones_df = pd.DataFrame(data, columns=columns)

            if milestones_df.empty:
                st.warning("No milestones liabilities found for the given user.")
                return None
            
            # Process the DataFrame
            milestones_df = self.process_milestones_liabilities(milestones_df)
            
         
            return milestones_df

        except Exception as e:
            print(f"Error fetching milestones liabilities: {e}")
            return None

    def process_milestones_liabilities(self, milestones_df):

        """Process and format the milestones liabilities DataFrame."""
        # Rename columns
        milestones_df.rename(columns={
            "purpose": "Goal Name",
            "milestone_year": "Goal Year",
            "amount": "Desired Goal Amount",
            "pdf_outstanding": "Future Goal Amount",
            "loan_funded":"Loan Funded",
            "interest_rate":"Interest Rate",
            "pending_tenure": "Pending Tenure",
            "inflation": "Inflation",
            "your_percent_share": "Your Percent Share"
            ""
        }, inplace=True)

        # Set `pending_tenure` to 0 where `loan_funded` is "No"
        milestones_df["Pending Tenure"] = milestones_df.apply(lambda row: 0 if row["Loan Funded"] == "No" else row["Pending Tenure"], axis=1)

        # Set `interest_rate` to 0 where `loan_funded` is "No"
        milestones_df["Interest Rate"] = milestones_df.apply(lambda row: 0 if row["Loan Funded"] == "No" else row["Interest Rate"], axis=1)

        # Multiply `interest_rate`, `inflation`, and `your_percent_share` by 100
        milestones_df["Interest Rate"] = milestones_df["Interest Rate"] * 100
        milestones_df["Inflation"] = milestones_df["Inflation"] * 100
        milestones_df["Your Percent Share"] = milestones_df["Your Percent Share"] * 100

        # Convert `Goal Year` to datetime and sort by ascending order
        milestones_df["Goal Year"] = pd.to_datetime(milestones_df["Goal Year"], format="%Y-%m-%d")
        milestones_df.sort_values(by="Goal Year", ascending=True, inplace=True)

        # Convert back to string for display
        #milestones_df["Goal Year"] = milestones_df["Goal Year"].dt.strftime("%d-%m-%Y")

        # Add Serial Number Column
        #milestones_df.insert(0, "Sr. No.", range(1, len(milestones_df) + 1))

        milestones_df["Goal Year"] = milestones_df["Goal Year"].dt.strftime("%d-%m-%Y")

        milestones_df.set_index('Goal Name', inplace=True)
        
        return milestones_df   

    def display_milestones_liabilities(self, user_code):
        """Fetch and display the formatted milestones liabilities table."""
        milestones_df = self.fetch_milestones_liabilities(user_code)
        if milestones_df is not None:
            #st.write("### Milestones Liabilities Table")
            st.dataframe(milestones_df)

    def fetch_pre_liabilities(self, user_code):
        """Fetch milestones liabilities data from the database for the given user."""
        query = """
            SELECT  name, outstanding_amount, pending_tenure, monthly_installment, interest_rate , account_age
            FROM liabilities
            WHERE user_code = %s and is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            milestones_df = pd.DataFrame(data, columns=columns)

            if milestones_df.empty:
                st.warning("No milestones liabilities found for the given user.")
                return None

            # Process the DataFrame
            milestones_df = self.process_pre_liabilities(milestones_df)

            return milestones_df

        except Exception as e:
            print(f"Error fetching milestones liabilities: {e}")
            return None
        
    def fetch_pre_assets(self, user_code):
        """Fetch assets data from the database for the given user."""
        query = """
            SELECT name, current_amount, monthly_investment
            FROM assets
            WHERE user_code = %s and is_active = true;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            assets_df = pd.DataFrame(data, columns=columns)

            if assets_df.empty:
                st.warning("No assets found for the given user.")
                return None

            # Process the DataFrame
            assets_df = self.process_pre_assets(assets_df)

            return assets_df

        except Exception as e:
            print(f"Error fetching aseets: {e}")
            return None   


    def fetch_pre_insurance(self, user_code):
        """Fetch assets data from the database for the given user."""
        query = """
            SELECT name, start_date, last_date, maturity_date, coverage, annual_premium, pending_tenure, payment_frequency
            FROM insurance
            WHERE user_code = %s and is_active = true ;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            insurance_df = pd.DataFrame(data, columns=columns)

            if insurance_df.empty:
                st.warning("No assets found for the given user.")
                return None

            # Process the DataFrame
            insurance_df = self.process_pre_insurance(insurance_df)

            return insurance_df

        except Exception as e:
            print(f"Error fetching aseets: {e}")
            return None     

    def process_pre_liabilities(self, milestones_df):
        """Process and format the milestones liabilities DataFrame."""
        # Rename columns
        milestones_df.rename(columns={
            #"created_at": "Liability Year",
            "outstanding_amount": "Outstanding Amount",
            "pending_tenure": "Pending Tenure",
            "monthly_installment": "Monthly Installment",
            "interest_rate":"Interest Rate",
            "account_age":"Account Age"
            ""
        }, inplace=True)

        # Multiply `interest_rate`, `inflation`, and `your_percent_share` by 100
        milestones_df["Interest Rate"] = milestones_df["Interest Rate"] * 100

        # milestones_df["Liability Year"] = pd.to_datetime(milestones_df["Liability Year"], format="%d-%m-%Y")
        # milestones_df.sort_values(by="Liability Year", ascending=True, inplace=True)

        # # Convert back to string for display
        # milestones_df["Liability Year"] = milestones_df["Liability Year"].dt.strftime("%d-%m-%Y")
        milestones_df.set_index('name', inplace=True) 
        # Add Serial Number Column
        #milestones_df.insert(0, "Sr. No.", range(1, len(milestones_df) + 1))

        return milestones_df
    
    def process_pre_assets(self, assets_df):
        """Process and format the assets DataFrame."""
        # Rename columns
        assets_df.rename(columns={

            "current_amount": "Current Amount",
            "monthly_investment": "Monthly Investment"
            ""
        }, inplace=True)
        assets_df.set_index('name', inplace=True)
        # Add Serial Number Column
        #assets_df.insert(0, "Sr. No.", range(1, len(assets_df) + 1))

        return assets_df
    
    def process_pre_insurance(self, insurance_df):
        """Process and format the assets DataFrame."""
        # Rename columns
        insurance_df.rename(columns={

            "start_date": "Start Date",
            "last_date": "Last Date",
            "maturity_date": "Maturity Date",
            "annual_premium": "Annual Premium", 
            "pending_tenure" : "Pending Tenure", 
            "payment_frequency" : "Payment Frequency"
            ""
        }, inplace=True)
        insurance_df.set_index('name', inplace=True)
        # Add Serial Number Column
        #insurance_df.insert(0, "Sr. No.", range(1, len(insurance_df) + 1))

        return insurance_df

    def display_pre_liabilities(self, user_code):
        """Fetch and display the formatted milestones liabilities table."""
        milestones_df = self.fetch_pre_liabilities(user_code)
        if milestones_df is not None:
            #st.write("### User Liabilities")
            st.dataframe(milestones_df)


    def display_pre_assets(self, user_code):
        """Fetch and display the formatted assets table."""
        assets_df = self.fetch_pre_assets(user_code)
        if assets_df is not None:
            #st.write("### User Assets")
            st.dataframe(assets_df) 

    def display_pre_insurance(self, user_code):
        """Fetch and display the formatted assets table."""
        insurance_df = self.fetch_pre_insurance(user_code)
        if insurance_df is not None:
            #st.write("### User Insurance")
            st.dataframe(insurance_df)          

    def convert_to_annual_multiplication(self, df):
        """Convert data to annual format by multiplying March values by 12."""
        # Ensure entry_date is in datetime format
        df['entry_date'] = pd.to_datetime(df['entry_date'], format='%d-%m-%Y')

        # Select relevant columns
        required_columns = [
            "gross_income_amount",
            "post_income",
            "tax_projection_values",
            "net_income_post_tax",
            "household_lifestyle_expense_amount"
        ]

        df = df[['entry_date'] + ['age'] + required_columns]

        # Filter only March values
        df_march = df[df['entry_date'].dt.month == 3]

        # Multiply the values by 12
        for col in required_columns:
            df_march[col] = df_march[col] * 12

        return df_march[['entry_date'] + ['age'] + required_columns] 

    # Method to transpose the dynamic_income_projection data
    def transpose_pre_dynamic_income_projection_1(self, dynamic_income_projection_df):
        # Drop unnecessary columns
        # Drop unnecessary columns
        dynamic_income_projection_df = dynamic_income_projection_df.drop(columns=[
            'user_code', 'fin_year_entry', 'fin_year_in_words', 
            'est_income_growth_percentage', 'est_expense_growth_percentage', 'total_expense'
        ], errors='ignore')


        dynamic_income_projection_df.rename(columns={
            "gross_income_amount": "Gross Income",
            "post_income": "Post Income",
            "tax_projection_values": "Tax Expense",
            "net_income_post_tax": "Net Income",
            "household_lifestyle_expense_amount":"Household Expenses"
            ""
        }, inplace=True)
        # Ensure entry_date is in string format
        dynamic_income_projection_df['entry_date'] = pd.to_datetime(dynamic_income_projection_df['entry_date']).dt.date
        
        # Transpose the table
        df_transposed = dynamic_income_projection_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        #st.dataframe(df_transposed)

        return df_transposed      

    def fetch_cf_projections(self, user_code):
        """Fetch iter_total_assets data from cf_projections table for the given user."""
        query = """
            SELECT entry_date, iter_total_income, household_expenses, tax, emi, iter_surplus, iter_total_assets, iter_total_liabilities, iter_total_networth
            FROM cf_projections 
            WHERE user_code = %s
            ORDER BY entry_date ASC;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            # Convert to DataFrame
            cf_projections_df = pd.DataFrame(data, columns=columns)

            if cf_projections_df.empty:
                st.warning("No data found in cf_projections for the given user.")
                return None

            return cf_projections_df

        except Exception as e:
            print(f"Error fetching cf_projections: {e}")
            return None  
        

    def create_dynamic_pre_goal_cashflow(self, dob, retirement_age, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)  # Age limit year when user turns 80
        print('age_limit_year', age_limit_year)
        dynamic_pre_goal_cashflow_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            print('last_day_of_month', last_day_of_month)
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            dynamic_pre_goal_cashflow_data = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'iter_total_income': 0,
                'household_expenses':0,
                'tax':0,
                'emi': 0,
                'iter_surplus': 0,
                'iter_total_assets': 0,
                'iter_total_liabilities': 0,
                'iter_total_networth': 0
            }
            dynamic_pre_goal_cashflow_projections.append(dynamic_pre_goal_cashflow_data)

            # Move to the next month
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)
            print('start_date', start_date)

        return dynamic_pre_goal_cashflow_projections   


    def save_dynamic_pre_goal_cashflow_df_to_db(self, dynamic_pre_goal_cashflow_df, db_config):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
        # Create the engine
        engine = create_engine(connection_string)

        # Define the table schema with specific data types
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'iter_total_income': NUMERIC,
            'household_expenses': NUMERIC,
            'tax' : NUMERIC,
            'emi': NUMERIC,
            'iter_surplus': NUMERIC,
            'iter_total_assets': NUMERIC,
            'iter_total_liabilities': NUMERIC,
            'iter_total_networth': NUMERIC
        }

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_pre_goal_cashflow_df.to_sql(
            'pre_goal_cashflow',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'pre_goal_cashflow'")

    def load_dynamic_pre_goal_cashflow_df_from_db(self, db_config):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        
        # Create the engine
        engine = create_engine(connection_string)
        
        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'pre_goal_cashflow'
            );
        """)
        
        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'pre_goal_cashflow' does not exist.")
            dynamic_pre_goal_cashflow_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_pre_goal_cashflow_df = pd.read_sql('pre_goal_cashflow', engine)
        
        return dynamic_pre_goal_cashflow_df  

    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_pre_goal_cashflow_df(self, dynamic_pre_goal_cashflow_df):
        # Drop unnecessary columns
        dynamic_pre_goal_cashflow_df = dynamic_pre_goal_cashflow_df.drop(columns=['user_code', 'user_name'])
        
        # Transpose the table
        df_transposed = dynamic_pre_goal_cashflow_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)  

        return df_transposed 


    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_pre_goal_cashflow_df_1(self, dynamic_pre_goal_cashflow_df):
        # Drop unnecessary columns
        dynamic_pre_goal_cashflow_df = dynamic_pre_goal_cashflow_df.drop(columns=['user_code', 'user_name'])
        dynamic_pre_goal_cashflow_df['entry_date'] = pd.to_datetime(dynamic_pre_goal_cashflow_df['entry_date']).dt.date 
        # Transpose the table
        df_transposed = dynamic_pre_goal_cashflow_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_pre_goal_cashflow_df_2(self, dynamic_pre_goal_cashflow_df):
        
        dynamic_pre_goal_cashflow_df['entry_date'] = pd.to_datetime(dynamic_pre_goal_cashflow_df['entry_date']).dt.date

        # Transpose the table
        df_transposed = dynamic_pre_goal_cashflow_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 

    def update_dynamic_pre_goal_cashflow(self, pre_goal_cashflow_df, user_id):
        """Update iter_total_assets column by dividing yearly iter_total_assets by 12."""
        cf_projections_df = self.fetch_cf_projections(user_id)
        if cf_projections_df is None:
            return pre_goal_cashflow_df

        for idx, row in cf_projections_df.iterrows():
            financial_year_end_date = pd.to_datetime(row["entry_date"], format="%Y-%m-%d")

            # Calculate the monthly iter_total_assets value
            monthly_total_income_value = row["iter_total_income"] / 12
            monthly_total_household_expense_value = row['household_expenses']/12
            monthly_tax_value = row['tax']/12
            monthly_emi_value = row["emi"] / 12
            monthly_surplus_value = row["iter_surplus"] / 12
            monthly_assets_value = row['iter_total_assets']/12
            monthly_liabilities_value = row['iter_total_liabilities']/12
            monthly_networth_value =  row['iter_total_networth']/12

            # Apply this value to all months in the corresponding financial year
            pre_goal_cashflow_df.loc[
                (pre_goal_cashflow_df["entry_date"] >= f"{financial_year_end_date.year - 1}-04-01") &
                (pre_goal_cashflow_df["entry_date"] <= f"{financial_year_end_date.year}-03-31"),
                ["iter_total_income", "household_expenses", "tax", "emi", "iter_surplus", "iter_total_assets","iter_total_liabilities","iter_total_networth" ]
            ] = [monthly_total_income_value, monthly_total_household_expense_value, monthly_tax_value, monthly_emi_value, monthly_surplus_value, monthly_assets_value, monthly_liabilities_value, monthly_networth_value ]

        return pre_goal_cashflow_df   

    def convert_to_annual_multiplication_1(self, df):
        """Convert data to annual format by multiplying March values by 12."""
        # Ensure entry_date is in datetime format
        df['entry_date'] = pd.to_datetime(df['entry_date'], format='%d-%m-%Y')

        # Select relevant columns
        required_columns = [
              'iter_total_income','household_expenses','tax', 'emi', 'iter_surplus', 'iter_total_assets', 'iter_total_liabilities', 'iter_total_networth'
        ]

        df = df[['entry_date'] + ['age'] + required_columns]

        # Filter only March values
        df_march = df[df['entry_date'].dt.month == 3]

        # Multiply the values by 12
        for col in required_columns:
            df_march[col] = df_march[col] * 12

        return df_march[['entry_date'] + ['age'] + required_columns]
    
    def convert_to_annual_liabilities_multiplication(self, df):
        """
        Another annual version. 
        We'll keep it consistent with code #1, but only handle 'assets_value'.
        """
        df["entry_date"] = pd.to_datetime(df["entry_date"], format="%d-%m-%Y")
        # Filter only March
        df_march = df[df["entry_date"].dt.month == 3].copy()
        df_march["liabilities_value"] = df_march["liabilities_value"]
        return df_march
    
    def convert_to_annual_outflows_liabilities_multiplication(self, df):
        """
        Another annual version. 
        We'll keep it consistent with code #1, but only handle 'assets_value'.
        """
        df["entry_date"] = pd.to_datetime(df["entry_date"], format="%d-%m-%Y")
        # Filter only March
        df_march = df[df["entry_date"].dt.month == 3].copy()
        df_march["liabilities_value"] = df_march["liabilities_value"]
        return df_march
    
    def run_create_dynamic_pre_goal_cashflow(self, user_id, dob, retirement_age, month_choice):
        connection = self.connect_db()

        if connection is None:
            return

        # Load existing data
        dynamic_pre_goal_cashflow_df = self.load_dynamic_pre_goal_cashflow_df_from_db(self.db_config)

        # Fetch user name based on user_id
        user_name = self.fetch_user_name(user_id)


        if dynamic_pre_goal_cashflow_df.empty:
            new_projections = self.create_dynamic_pre_goal_cashflow(dob, retirement_age, user_id, user_name, month_choice)
            dynamic_pre_goal_cashflow_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_pre_goal_cashflow_df['user_code'].unique():
                new_projections = self.create_dynamic_pre_goal_cashflow(dob, retirement_age, user_id, user_name, month_choice)
                dynamic_pre_goal_cashflow_df = pd.DataFrame(new_projections)

        # Update iter_total_assets column
        dynamic_pre_goal_cashflow_df = self.update_dynamic_pre_goal_cashflow(dynamic_pre_goal_cashflow_df, user_id)    

        st.write('### User All Cashflow Projection')         
        
        transposed_df = self.transpose_dynamic_pre_goal_cashflow_df_1(dynamic_pre_goal_cashflow_df)
        st.dataframe(transposed_df)			

        # Save the updated DataFrame to the PostgreSQL database
        self.save_dynamic_pre_goal_cashflow_df_to_db(dynamic_pre_goal_cashflow_df, self.db_config)
        st.write('Pre goal planning all cashflow projection updated and save to the database')

        # Close the connection
        connection.close()
    
    def create_dynamic_pre_investment_cashflow(self, dob, retirement_age, user_id, user_name, month_choice):
        # -- Find all category_ids the user actually uses in cf_assets_projections
        cat_cursor = self.connection.cursor()
        cat_cursor.execute(
            """
            SELECT DISTINCT c.id, c.name
            FROM milestones_category c
            JOIN cf_assets_projections a ON a.category_id = c.id
            WHERE a.user_code = %s
            """,
            (user_id,)
        )
        cat_rows = cat_cursor.fetchall()
        cat_cursor.close()

        if not cat_rows:
            # If user doesn't have any categories in cf_assets_projections,
            # just return an empty list
            return []

        # Prepare a list of (category_id, category_name)
        categories = [(str(r[0]), r[1]) for r in cat_rows]

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        #age_limit_year = current_year + (80 - current_age)
        age_limit_year = current_year + (retirement_age - current_age +1 )
        print('age_limit_year',age_limit_year)
        dynamic_pre_goal_cashflow_projections = []

        # Generate a monthly date skeleton until user is 80 or month_choice
        while (start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice)):
            last_day_of_month = start_date.replace( day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # For each category, we create one row
            for cat_id, cat_name in categories:
                data_row = {
                    "user_code": user_id,
                    "user_name": user_name,
                    "entry_date": last_day_of_month.strftime("%Y-%m-%d"),
                    "age": iter_age,
                    # We'll keep category_id internally to match up in update function
                    "category_id": cat_id,
                    "assets_name": cat_name,
                    "assets_value": 0.0
                }
                dynamic_pre_goal_cashflow_projections.append(data_row)

            # Move to the next month
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return dynamic_pre_goal_cashflow_projections
    
    def fetch_pre_cf_investment_projections(self, user_code):
        query = """
            SELECT category_id, entry_date, monthly_installment
            FROM cf_assets_projections
            WHERE user_code = %s
            ORDER BY entry_date ASC;
        """
        try:
            cursor = self.connection.cursor()
            cursor.execute(query, (user_code,))
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            cursor.close()

            cf_proj_df = pd.DataFrame(data, columns=columns)
            if cf_proj_df.empty:
                st.warning("No data found in cf_assets_projections for the given user.")
                return None

            return cf_proj_df

        except Exception as e:
            print(f"Error fetching cf_assets_projections: {e}")
            return None
        
    def save_dynamic_pre_investment_cashflow_df_to_db(self, dynamic_pre_goal_investment_df, db_config):
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
        connection_string = (
            f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}"
            f"@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        )
        engine = create_engine(connection_string)

        table_schema = {
            "user_code": UUID(as_uuid=True),
            "user_name": TEXT,
            "entry_date": DATE,
            "age": BIGINT,
            "category_id": BIGINT,       # <--- or TEXT, if your category_id is a string in DB
            "assets_name": TEXT,
            "assets_value": NUMERIC
        }

        # Save the DataFrame to PostgreSQL table
        dynamic_pre_goal_investment_df.to_sql(
            "pre_goal_investment_cashflow",
            engine,
            if_exists="replace",
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'pre_goal_investment_cashflow'")

    def load_dynamic_pre_goal_investment_cashflow_df_from_db(self, db_config):
       
        connection_string = (f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}" f"@{db_config['host']}:{db_config['port']}/{db_config['database']}")
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'pre_goal_investment_cashflow');
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar()

        if not table_exists:
            print("Table 'pre_goal_investment_cashflow' does not exist.")
            dynamic_pre_goal_investment_df = pd.DataFrame()
        else:
            dynamic_pre_goal_investment_df = pd.read_sql("pre_goal_investment_cashflow", engine)

        return dynamic_pre_goal_investment_df

    def transpose_dynamic_pre_goal_investment_cashflow_df_1(self, dynamic_pre_goal_investment_df):
        """
        Similar to reshape_dynamic_pre_assets_projections, but specifically for 
        'transpose_dynamic_pre_goal_cashflow_df_1'. 
        Produces a pivoted table with index='assets_name', columns=['entry_date','age'].
        """
        # Work on a copy so we don't mutate the original DataFrame
        df = dynamic_pre_goal_investment_df.copy()

        # Sort by date
        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')

        # Convert date to string, for pivot columns
        df['entry_date'] = df['entry_date'].astype(str)

        # Create pivot
        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        ).reset_index()

        return reshaped_df

    def transpose_dynamic_pre_goal_investment_cashflow_df_2(self, dynamic_pre_goal_investment_df):
        df = dynamic_pre_goal_investment_df.copy()

        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')
        df['entry_date'] = df['entry_date'].astype(str)

        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        ).reset_index()

        return reshaped_df

    def update_dynamic_pre_goal_investment_cashflow(self, dynamic_pre_goal_investment_df, user_id):
        cf_assets_df = self.fetch_pre_cf_investment_projections(user_id)
        if cf_assets_df is None or cf_assets_df.empty:
            return dynamic_pre_goal_investment_df

        # Convert entry_date from dd-mm-yyyy
        cf_assets_df["entry_date"] = pd.to_datetime(cf_assets_df["entry_date"], format="%Y-%m-%d")

        for idx, row in cf_assets_df.iterrows():
            fy_end_date = row["entry_date"]  # e.g. 31-Mar-2025
            cat_id = str(row["category_id"])
            val = row["monthly_installment"] if row["monthly_installment"] else 0.0

            # If it's 31-Mar-Year => that covers 1-Apr-(Year-1) to 31-Mar-Year
            year_ending = fy_end_date.year

            monthly_val = val 

            start_fy = pd.to_datetime(f"{year_ending - 1}-04-01")
            end_fy   = pd.to_datetime(f"{year_ending}-03-31")

            # Update all skeleton rows matching category_id and date in [start_fy, end_fy]
            mask = (
                (dynamic_pre_goal_investment_df["category_id"] == cat_id) &
                (pd.to_datetime(dynamic_pre_goal_investment_df["entry_date"]) >= start_fy) &
                (pd.to_datetime(dynamic_pre_goal_investment_df["entry_date"]) <= end_fy)
            )
            dynamic_pre_goal_investment_df.loc[mask, "assets_value"] = monthly_val

        return dynamic_pre_goal_investment_df   

    def convert_to_annual_investment_multiplication(self, df):
        """
        Another annual version. 
        We'll keep it consistent with code #1, but only handle 'assets_value'.
        """
        df["entry_date"] = pd.to_datetime(df["entry_date"], format="%d-%m-%Y")
        # Filter only March
        df_march = df[df["entry_date"].dt.month == 3].copy()
        df_march["assets_value"] = df_march["assets_value"]
        return df_march    

    def run_create_dynamic_pre_goal_investment_cashflow(self, user_id, dob, retirement_age, month_choice):
        connection = self.connect_db()
        if connection is None:
            return

        # Load existing data from 'pre_goal_cashflow_1'
        dynamic_pre_goal_investment_df = self.load_dynamic_pre_goal_investment_cashflow_df_from_db(self.db_config)
        user_name = self.fetch_user_name(user_id)

        # If empty or user_id not present, create fresh skeleton
        if dynamic_pre_goal_investment_df.empty:
            investment_new_projections = self.create_dynamic_pre_investment_cashflow(dob, retirement_age, user_id, user_name, month_choice)
            dynamic_pre_goal_investment_df = pd.DataFrame(investment_new_projections)
        else:
            if user_id not in dynamic_pre_goal_investment_df["user_code"].unique():
                investment_new_projections = self.create_dynamic_pre_investment_cashflow(dob, retirement_age, user_id, user_name, month_choice)
                dynamic_pre_goal_investment_df = pd.DataFrame(investment_new_projections)

        # Update 'assets_value' using the distribution logic
        dynamic_pre_goal_investment_df = self.update_dynamic_pre_goal_investment_cashflow(dynamic_pre_goal_investment_df, user_id)

        st.write("### User Investment Projection")
        investment_df_transposed = self.transpose_dynamic_pre_goal_investment_cashflow_df_1(dynamic_pre_goal_investment_df)
        st.dataframe(investment_df_transposed)

        # Finally, save the updated DataFrame into 'pre_goal_cashflow'
        self.save_dynamic_pre_investment_cashflow_df_to_db(dynamic_pre_goal_investment_df, self.db_config)
        st.write("Pre goal planning Investment table updated and saved to the database.")

        # Close connection
        connection.close()    

    def reshape_dynamic_pre_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df
    
    def reshape_dynamic_pre_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df
    
    def transpose_display_pre_dynamic_income_projection_1(self, dynamic_income_projection_df):
        # Drop unnecessary columns
        # Drop unnecessary columns
        dynamic_income_projection_df = dynamic_income_projection_df.drop(columns=[
            'user_code', 'fin_year_entry', 'fin_year_in_words', 
            'est_income_growth_percentage', 'est_expense_growth_percentage', 'total_expense'
        ], errors='ignore')


        dynamic_income_projection_df.rename(columns={
            "gross_income_amount": "Gross Income",
            "post_income": "Post Income",
            "tax_projection_values": "Tax Expense",
            "net_income_post_tax": "Net Income",
            "household_lifestyle_expense_amount":"Household Expenses"
            ""
        }, inplace=True)
        # Ensure entry_date is in string format
        dynamic_income_projection_df['entry_date'] = pd.to_datetime(dynamic_income_projection_df['entry_date']).dt.date
        
        # Transpose the table
        df_transposed = dynamic_income_projection_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        df_transposed.set_index('entry_date', inplace=True)
        #st.dataframe(df_transposed)

        return df_transposed 
    
    def transpose_display_dynamic_pre_goal_cashflow_df_1(self, dynamic_pre_goal_cashflow_df):
        # Drop unnecessary columns
        dynamic_pre_goal_cashflow_df = dynamic_pre_goal_cashflow_df.drop(columns=['user_code', 'user_name'])

        # Transpose the table
        df_transposed = dynamic_pre_goal_cashflow_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)

        return df_transposed 
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_display_dynamic_pre_goal_cashflow_df_2(self, dynamic_pre_goal_cashflow_df):
        
        dynamic_pre_goal_cashflow_df['entry_date'] = pd.to_datetime(dynamic_pre_goal_cashflow_df['entry_date']).dt.date

        # Transpose the table
        df_transposed = dynamic_pre_goal_cashflow_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)

        return df_transposed

    
    def reshape_display_dynamic_pre_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)

        return reshaped_df
    
    def transpose_display_dynamic_pre_goal_asset_df_1(self, dynamic_pre_goal_asset_df):

        # Work on a copy so we don't mutate the original DataFrame
        df = dynamic_pre_goal_asset_df.copy()
        # Sort by date
        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')
        # Convert date to string, for pivot columns
        df['entry_date'] = df['entry_date'].astype(str)

        # Create pivot
        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        )
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('assets_name', inplace=True)

        return reshaped_df
    
    def transpose_display_dynamic_pre_goal_investment_cashflow_df_1(self, dynamic_pre_goal_investment_df):
        # Work on a copy so we don't mutate the original DataFrame
        df = dynamic_pre_goal_investment_df.copy()

        # Sort by date
        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')

        # Convert date to string, for pivot columns
        df['entry_date'] = df['entry_date'].astype(str)

        # Create pivot
        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        )
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('assets_name', inplace=True)

        return reshaped_df
    
    def transpose_display_dynamic_pre_goal_investment_cashflow_df_2(self, dynamic_pre_goal_investment_df):
        df = dynamic_pre_goal_investment_df.copy()

        df['entry_date'] = pd.to_datetime(df['entry_date'])
        df = df.sort_values(by='entry_date')
        df['entry_date'] = df['entry_date'].astype(str)

        reshaped_df = df.pivot_table(
            index='assets_name', 
            columns=['entry_date', 'age'], 
            values='assets_value', 
            aggfunc='sum', 
            fill_value=0
        )
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('assets_name', inplace=True)

        return reshaped_df
    
    def reshape_display_dynamic_pre_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)

        return reshaped_df   

    def convert_to_annual_insurance_outflows_liabilities_multiplication(self, df):
        """
        Another annual version. 
        We'll keep it consistent with code #1, but only handle 'insurance_value'.
        """
        df["entry_date"] = pd.to_datetime(df["entry_date"], format="%d-%m-%Y")
        # Filter only March
        df_march = df[df["entry_date"].dt.month == 3].copy()
        df_march["insurance_value"] = df_march["insurance_value"]
        return df_march 

    def run_all_pre_goal_planning_projections(self,user_id):

        self.run_create_dynamic_pre_goal_asset(user_id, dob, retirement_age, month_choice)
        self.run_dynamic_pre_liabilities_projections(user_id, dob, retirement_age, month_choice)
        self.run_dynamic_pre_liabilities_outflows_projections(user_id, month_choice)
        self.run_create_dynamic_pre_goal_cashflow(user_id, dob, retirement_age, month_choice)
        self.run_create_dynamic_pre_goal_investment_cashflow(user_id, dob, retirement_age, month_choice)
        self.run_pre_goal_dynamic_insurance_outflows_projections(user_id, month_choice)
        

    def run_all_pre_goal_planning_projections_1(self, user_id):
            connection = self.connect_db()

            if connection is None:
                return
            
            st.write("### User Milestones")
            projection_updater.display_milestones_liabilities(user_id)
            st.write("### User Assets")
            projection_updater.display_pre_assets(user_id)
            st.write("### User Liabilities")
            projection_updater.display_pre_liabilities(user_id)
            st.write("### User Insurance")
            projection_updater.display_pre_insurance(user_id)

            # Load existing data
            dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()  
            dynamic_pre_goal_cashflow_df = self.load_dynamic_pre_goal_cashflow_df_from_db(db_config) 
            dynamic_pre_goal_asset_df = self.load_dynamic_pre_goal_asset_df_from_db(self.db_config)
            dynamic_pre_goal_investment_df = self.load_dynamic_pre_goal_investment_cashflow_df_from_db(self.db_config)
            dynamic_pre_liabilities_projections_df = self.load_dynamic_pre_liabilities_projections_df_from_db()
            dynamic_pre_outflows_liabilities_projections_df = self.load_dynamic_pre_liabilities_outflows_projections_df_from_db()
            dynamic_pre_insurance_outflows_projections_df = self.load_pre_goal_dynamic_insurance_outflows_projections_df_from_db()

            # Selection for Monthly or Annually data representation
            view_option = st.radio( "Do you want to convert data to Monthly or Annually?", ["Monthly", "Annually"])

            st.write("### Select Date Range")
            start_date = st.date_input("Start Date", value=datetime.today())
            end_date = st.date_input("End Date", value=datetime.today()) 

            # Apply filtering by date range
            #filtered_df = self.filter_data_by_date_range(dynamic_pre_goal_cashflow_df, start_date, end_date) 
            dynamic_income_projection_df = self.filter_data_by_date_range(dynamic_income_projection_df, start_date, end_date)
            dynamic_pre_goal_cashflow_df = self.filter_data_by_date_range(dynamic_pre_goal_cashflow_df, start_date, end_date)   
            dynamic_pre_goal_asset_df = self.filter_data_by_date_range(dynamic_pre_goal_asset_df, start_date, end_date)
            dynamic_pre_goal_investment_df = self.filter_data_by_date_range(dynamic_pre_goal_investment_df, start_date, end_date)
            dynamic_pre_liabilities_projections_df = self.filter_data_by_date_range(dynamic_pre_liabilities_projections_df, start_date, end_date)
            dynamic_pre_outflows_liabilities_projections_df = self.filter_data_by_date_range(dynamic_pre_outflows_liabilities_projections_df, start_date, end_date)
            dynamic_pre_insurance_outflows_projections_df = self.filter_data_by_date_range(dynamic_pre_insurance_outflows_projections_df, start_date, end_date)
            # **Step 7: Handle Cases Where No Data Exists After Filtering**
            if dynamic_pre_goal_cashflow_df.empty:
                st.warning("No data available for the selected date range.")
                return    
  
            if dynamic_income_projection_df.empty:
                st.warning("No income data available for the selected date range.")
                return 
            
            if dynamic_pre_goal_asset_df.empty:
                st.warning("No asset data available for the selected date range.")
                return
            
            if dynamic_pre_goal_investment_df.empty:
                st.warning("No asset data available for the selected date range.")
                return
            
            if dynamic_pre_liabilities_projections_df.empty:
                st.warning("No asset data available for the selected date range.")
                return
            
            if dynamic_pre_outflows_liabilities_projections_df.empty:
                st.warning("No asset data available for the selected date range.")
                return
            
            if dynamic_pre_insurance_outflows_projections_df.empty:
                st.warning("No asset data available for the selected date range.")
                return

            if view_option == "Monthly":
                df_transposed = self.transpose_display_pre_dynamic_income_projection_1(dynamic_income_projection_df)
                cf_transposed_df = self.transpose_display_dynamic_pre_goal_cashflow_df_1(dynamic_pre_goal_cashflow_df) 
                asset_transposed_df = self.transpose_display_dynamic_pre_goal_asset_df_1(dynamic_pre_goal_asset_df)
                investment_transposed_df = self.transpose_display_dynamic_pre_goal_investment_cashflow_df_1(dynamic_pre_goal_investment_df)
                liabilities_reshaped_df = self.reshape_display_dynamic_pre_liabilities_projections(dynamic_pre_liabilities_projections_df, user_id)
                outflows_liabilities_reshaped_df = self.reshape_display_dynamic_pre_liabilities_outflows_projections(dynamic_pre_outflows_liabilities_projections_df, user_id)
                dynamic_pre_insurance_outflows_projections_df = self.reshape_display_dynamic_insurance_outflows_projections(dynamic_pre_insurance_outflows_projections_df, user_id)
                
                st.write("User Income Projection")
                st.dataframe(df_transposed)
                
                st.write("#User Pre Goal Planning Balance Sheet")
                st.write("User pre goal plannning all asset Projection")
                st.dataframe(asset_transposed_df)
                st.write("User pre goal plannning all liabilities Projection")
                st.dataframe(liabilities_reshaped_df)
                
                st.write("#User Pre Goal Planning Cash Flow Statement")
                st.write("User pre goal plannning all investment Projection")
                st.dataframe(investment_transposed_df)
                st.write("User pre goal plannning all liabilities Outflows Projection")
                st.dataframe(outflows_liabilities_reshaped_df)
                st.write("User pre goal plannning all insurance Outflows Projection")
                st.dataframe(dynamic_pre_insurance_outflows_projections_df)
                st.write("User pre goal plannning all cashflows Projection")
                st.dataframe(cf_transposed_df)
            elif view_option == "Annually":
                # Convert to annual format
                df_transposed = self.convert_to_annual_multiplication(dynamic_income_projection_df)
                df_transposed = self.filter_data_by_date_range(df_transposed, start_date, end_date)
                df_transposed = self.transpose_display_pre_dynamic_income_projection_1(df_transposed)

                cf_transposed_df = self.convert_to_annual_multiplication_1(dynamic_pre_goal_cashflow_df)
                cf_transposed_df = self.filter_data_by_date_range(cf_transposed_df, start_date, end_date)
                cf_transposed_df = self.transpose_display_dynamic_pre_goal_cashflow_df_2(cf_transposed_df)

                asset_transposed_df = self.convert_to_annual_asset_multiplication_1(dynamic_pre_goal_asset_df)
                asset_transposed_df = self.filter_data_by_date_range(asset_transposed_df, start_date, end_date)
                asset_transposed_df = self.transpose_display_dynamic_pre_goal_asset_df_1(asset_transposed_df)

                investment_transposed_df = self.convert_to_annual_investment_multiplication(dynamic_pre_goal_investment_df)
                investment_transposed_df = self.filter_data_by_date_range(investment_transposed_df, start_date, end_date)
                investment_transposed_df = self.transpose_display_dynamic_pre_goal_investment_cashflow_df_2(investment_transposed_df)

                liabilities_transposed_df = self.convert_to_annual_liabilities_multiplication(dynamic_pre_liabilities_projections_df)
                liabilities_transposed_df = self.filter_data_by_date_range(liabilities_transposed_df, start_date, end_date)
                liabilities_reshaped_df = self.reshape_display_dynamic_pre_liabilities_projections(liabilities_transposed_df, user_id)

                outflows_liabilities_transposed_df = self.convert_to_annual_outflows_liabilities_multiplication(dynamic_pre_outflows_liabilities_projections_df)
                outflows_liabilities_transposed_df = self.filter_data_by_date_range(outflows_liabilities_transposed_df, start_date, end_date)
                outflows_liabilities_transposed_df = self.reshape_display_dynamic_pre_liabilities_outflows_projections(outflows_liabilities_transposed_df, user_id)

                insurance_outflows_liabilities_transposed_df = self.convert_to_annual_insurance_outflows_liabilities_multiplication(dynamic_pre_insurance_outflows_projections_df)
                insurance_outflows_liabilities_transposed_df = self.filter_data_by_date_range(insurance_outflows_liabilities_transposed_df, start_date, end_date)
                insurance_outflows_liabilities_transposed_df = self.reshape_display_dynamic_insurance_outflows_projections(insurance_outflows_liabilities_transposed_df, user_id)

                

                st.write("## User Income Projection")
                st.dataframe(df_transposed)
                 
                st.write("### User Pre Goal Planning Balance Sheet")
                st.write("User pre goal plannning all asset Projection")
                st.dataframe(asset_transposed_df)   
                st.write("User pre goal plannning all liabilities Projection")
                st.dataframe(liabilities_reshaped_df) 

                st.write("### User Pre Goal Planning Cash Flow Statement")
                st.write("User pre goal plannning all investment Projection")
                st.dataframe(investment_transposed_df)  
                st.write("User pre goal plannning all liabilities Outflows Projection")
                st.dataframe(outflows_liabilities_transposed_df)
                st.write("User pre goal plannning all insurance Outflows Projection")
                st.dataframe(insurance_outflows_liabilities_transposed_df)
                st.write("User pre goal plannning all cashflows Projection")
                st.dataframe(cf_transposed_df) 
            

            # Save the updated DataFrame to the PostgreSQL database
            # self.save_dynamic_pre_goal_cashflow_df_to_db(dynamic_pre_goal_cashflow_df, self.db_config)
            # self.save_dynamic_pre_goal_asset_df_to_db(dynamic_pre_goal_asset_df, self.db_config)
            #st.write('Pre goal planning model updated and save to the database')
    
            # Close the connection
            connection.close()   


    #investment projections    
    def fetch_assets_with_categories(self, connection, user_id):
        cursor = connection.cursor()
        cursor.execute("""
            SELECT DISTINCT a.name AS asset_name, a.category_id
            FROM assets_milestones a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' AND a.is_active = true;
        """, (user_id,))

        assets_with_categories = cursor.fetchall()
        cursor.close()

        return assets_with_categories
    
    def fetch_purpose_for_investmentr_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None'
            AND loan_funded = 'Yes' and category_id IN (604,609);
        """, (user_id,))

        investment_relate_purpose = cursor.fetchall()
        cursor.close()

        return investment_relate_purpose
    
    def create_user_projection_table(self, dob, retirement_age, assets_with_categories, investment_relate_purpose, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for asset_name, category_id in assets_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': asset_name,
                    'asset_value': 0  # Initialize asset value to 0
                }
                projections.append(projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in investment_relate_purpose:
                investmentr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': purpose,  # Use purpose as liabilities_name
                    'asset_value': 0  # Initialize liability value to 0
                }
                projections.append(investmentr_projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return projections
    

    def create_user_projection_table_1(self, dob, retirement_age, assets_with_categories, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for asset_name, category_id in assets_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': asset_name,
                    'asset_value': 0  # Initialize asset value to 0
                }
                projections.append(projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return projections


    # def load_dynamic_milestone_income_projection_from_db(self, user_id):
    #     """Loads milestone income projections from DB only once per session."""

    #     key = f"dynamic_milestone_income_projection_df_{user_id}"

    #     if key not in st.session_state:
    #         # Create the database engine
    #         connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #         engine = create_engine(connection_string)

    #         # Check if the table exists
    #         inspector = inspect(engine)
    #         if not inspector.has_table("dynamic_milestone_income_projection"):
    #             st.session_state[key] = pd.DataFrame()
    #             return st.session_state[key]

    #         # Load data only for the given user_id
    #         query = """
    #             SELECT *
    #             FROM dynamic_milestone_income_projection
    #             WHERE user_code = %s
    #         """
    #         st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

    #     return st.session_state[key]


    def load_dynamic_milestone_income_projection_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_milestone_income_projection'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_milestone_income_projection' does not exist.")
            return pd.DataFrame()
        else:
            return pd.read_sql('dynamic_milestone_income_projection', engine)
  

    def save_investment_projections_to_db(self, investment_projections_df, user_id):
        import io
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Create table if it doesn't exist
        inspector = inspect(engine)
        if not inspector.has_table('investment_projections'):
            print("Table 'investment_projections' does not exist. Creating it.")
            investment_projections_df.head(0).to_sql(
                'investment_projections',
                engine,
                if_exists='replace',
                index=False
            )

        # Get only the user-specific rows
        user_rows = investment_projections_df[investment_projections_df["user_code"] == user_id]

        raw_conn = engine.raw_connection()
        try:
            cur = raw_conn.cursor()
            cur.execute("DELETE FROM investment_projections WHERE user_code = %s", (user_id,))

            buffer = io.StringIO()
            df_user = investment_projections_df[investment_projections_df["user_code"] == user_id]
            df_user.to_csv(buffer, index=False, header=False)
            buffer.seek(0)

            copy_sql = "COPY investment_projections FROM STDIN WITH CSV"
            cur.copy_expert(copy_sql, buffer)

            raw_conn.commit()
            print("ðŸš€ Data saved in under 1 second using COPY.")
        finally:
            cur.close()
            raw_conn.close()

        print("Investment projections saved using COPY (fast).")



    def add_additional_asset(self, investment_projections_df, investment_dict, assets_with_categories, user_id, dob, retirement_age, asset_name, month_choice):

        # Check if the asset_name already exists for the user
        user_specific_df = investment_projections_df[investment_projections_df['user_code'] == user_id]
        # Extract unique asset names from the user's specific data, then strip spaces and convert to lowercase
        unique_existing_assets = [asset.strip().lower() for asset in user_specific_df['asset_name'].unique()]
        stripped_asset_name = asset_name.strip().lower()

        # Temporarily strip spaces from the asset_name for comparison
        if stripped_asset_name in unique_existing_assets:
            #exact_matches = sum(1 for existing in unique_existing_assets if existing == stripped_asset_name)
            existing_count = sum(1 for existing in unique_existing_assets if existing.strip().lower().startswith(stripped_asset_name))
            print('exact_matches check', existing_count)
            new_asset_name = f"{asset_name.strip()} {existing_count + 1}"
            
            # Retrieve category_id from the DataFrame, handling extra spaces
            category_id = investment_projections_df.loc[
                investment_projections_df['asset_name'].str.strip().str.lower() == stripped_asset_name, 
                'category_id'
            ].values[0]
        else:
            new_asset_name = asset_name
            category_id = next((cat_id for cat_id, name in investment_dict.items() if name == asset_name), None)

        if category_id is not None:
            # Append new asset to the list with category
            assets_with_categories.append((new_asset_name, category_id))
            new_projections = self.create_user_projection_table_1(dob, retirement_age, [(new_asset_name, category_id)], user_id, self.fetch_user_name(user_id),month_choice)
            investment_projections_df = pd.concat([investment_projections_df, pd.DataFrame(new_projections)], ignore_index=True)
        else:
            st.write("Invalid asset name entered. No asset added.")

        return investment_projections_df, assets_with_categories

    def update_investment_projections(self, user_id, investment_projections_df, distinct_names, entry_type, growth_month=None, investment_growth=None, single_date=None, range_dates=None, increment_params=None):
        unique_asset_names = investment_projections_df[investment_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'growth_increment':
            # Divide growth percentages by 100 to convert them to decimal
            investment_growth_1 = investment_growth[0]
            investment_growth_2 = investment_growth[1]
            investment_growth_3 = investment_growth[2]
            investment_growth_4 = investment_growth[3]

            initial_investments = {}
            #print('initial_investments',initial_investments)
            last_investment_value = {}
            #print('last_investment_value', last_investment_value)

            # Fetch initial investments from database
            for idx, projection in investment_projections_df.iterrows():
                user_code = projection['user_code']
                asset_name = projection['asset_name']
                category_id = projection['category_id']

                if (user_code, asset_name) not in initial_investments:
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        SELECT monthly_investment 
                        FROM assets_milestones 
                        WHERE user_code = %s AND name = %s AND category_id = %s AND is_active = true;
                    """, (user_code, asset_name, category_id))
                    result = cursor.fetchone()
                    cursor.close()

                    if result:
                        initial_investments[(user_code, asset_name)] = result[0]
                        print('initial_investments',initial_investments)
                    else:
                        initial_investments[(user_code, asset_name)] = 0

            # Apply growth increment based on age
            for idx, projection in investment_projections_df.iterrows():
                entry_date = projection['entry_date']
                entry_year, entry_month = entry_date.split('-')[:2]
                age = projection['age']
                asset_name = projection['asset_name']
                user_code = projection['user_code']

                entry_dt = datetime.strptime(entry_date, "%Y-%m-%d")
                current_year = datetime.now().year
                current_month = datetime.now().month

                if age <= 35:
                    growth_percentage = investment_growth_1
                elif 36 <= age <= 45:
                    growth_percentage = investment_growth_2
                elif 46 <= age <= 55:
                    growth_percentage = investment_growth_3
                else:
                    growth_percentage = investment_growth_4    
                
                if (user_code, asset_name) not in last_investment_value:
                    last_investment_value[(user_code, asset_name)] = initial_investments[(user_code, asset_name)]

                if current_month == 4 and growth_month == '04':
                    april_this_year = datetime(current_year, 4, 1)
                    march_next_year = datetime(current_year + 1, 3, 31)

                    if april_this_year <= entry_dt <= march_next_year:
                        # First April to next March: no growth
                        last_investment_value[(user_code, asset_name)] = initial_investments[(user_code, asset_name)]
                    elif entry_month == growth_month:
                        # Apply growth from second April onwards
                        last_investment_value[(user_code, asset_name)] *= (1 + growth_percentage)
                else:
                    if entry_month == growth_month:
                        last_investment_value[(user_code, asset_name)] *= (1 + growth_percentage)

                investment_projections_df.at[idx, 'asset_value'] = -abs(last_investment_value[(user_code, asset_name)])


        elif entry_type == 'single':
            print('single_date', single_date)
            asset_name = increment_params.get('asset_name')  # Asset name passed from frontend
            print('asset_name',asset_name)
            amount = increment_params.get('amount')
            print('amount',amount)

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return investment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'") 

            #Apply the update for the matched asset name on the given single date
            #updated = False
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == single_date and projection['asset_name'] == matched_asset_name):
                    investment_projections_df.at[idx, 'asset_value'] = -abs(amount)
                    #updated = True
                    #print(f"Successfully updated asset: '{matched_asset_name}' for date: {single_date} with amount: {amount}")

            #if not updated:
                #print(f"No record updated for asset: {matched_asset_name} on date: {single_date}")        

        elif entry_type == 'range':
            asset_name = increment_params.get('asset_name')
            amount = increment_params.get('amount')

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return investment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")

            # Apply update for the range of dates
            start_date, end_date = range_dates
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and start_date <= projection['entry_date'] <= end_date and projection['asset_name'] == matched_asset_name):
                    investment_projections_df.at[idx, 'asset_value'] = -abs(amount)

        elif entry_type == 'increment':
            asset_name = increment_params.get('asset_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return investment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['asset_name'] == matched_asset_name):
                    previous_amount = float(projection.get('asset_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return investment_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['asset_name'] == matched_asset_name):
                    investment_projections_df.at[idx, 'asset_value'] = -abs(incremented_amount)

        return investment_projections_df
    
    def project_growth_for_new_asset(self, investment_projections_df, user_id, growth_month, investment_growth):
        """
        Project growth for newly added assets based on their initial value set via the 'single' option.
        """
        # Convert investment_growth percentages to decimals
        investment_growth = [growth for growth in investment_growth]

        # Find newly added assets
        new_assets = investment_projections_df[investment_projections_df['user_code'] == user_id].copy()
        new_assets = new_assets.groupby('asset_name').filter(lambda x: x['asset_value'].sum() != 0)

        if new_assets.empty:
            st.warning("No new assets with initial values found for projection.")
            return investment_projections_df

        # Dictionary to hold the last projected value for each new asset
        last_investment_value = {}

        # Iterate through each row in the DataFrame for the user
        for idx, projection in new_assets.iterrows():
            entry_date = projection['entry_date']
            entry_year, entry_month = entry_date.split('-')[:2]
            age = projection['age']
            asset_name = projection['asset_name']

            # Determine the growth percentage based on age
            if age <= 35:
                growth_percentage = investment_growth[0]
            elif 36 <= age <= 45:
                growth_percentage = investment_growth[1]
            elif 46 <= age <= 55:
                growth_percentage = investment_growth[2]
            else:
                growth_percentage = investment_growth[3]

            # Initialize the starting value for newly added assets
            if asset_name not in last_investment_value:
                last_investment_value[asset_name] = projection['asset_value']

            # Apply growth increment only during the specified growth month
            if entry_month == growth_month:
                last_investment_value[asset_name] *= (1 + growth_percentage)

            # Update the DataFrame with the projected value
            investment_projections_df.loc[idx, 'asset_value'] = -abs(last_investment_value[asset_name])

        st.success("Growth projection applied for newly added assets.")
        return investment_projections_df
    
    # Reshape the investment projections for the required format
    def reshape_investment_projections(self, investment_projections_df, user_id):
        # Filter data for the specified user
        user_df = investment_projections_df[investment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='asset_name', 
                                          columns=['entry_date', 'age'],
                                          values='asset_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df


    # Reshape the investment projections for the required format
    def reshape_display_investment_projections(self, investment_projections_df, user_id):
        # Filter data for the specified user
        user_df = investment_projections_df[investment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='asset_name', 
                                          columns=['entry_date', 'age'],
                                          values='asset_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('asset_name', inplace=True)  # Set asset_name as index
        return reshaped_df    
    
    # Function to delete records with entry_date less than the current date
    def delete_old_investment_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM investment_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")


    def fill_user_based_investment_values(self, user_id):
        if st.radio("Do you want to invest the amount by using the custom method in withdrawal table?", ['No', 'Yes'], key="custom_withdrawal_logic") == 'Yes':
            
            # Step 1: Entry date input
            entry_date_input = st.date_input("Select the entry date for custom investment",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="custom_entry_date")
            entry_date_str = entry_date_input.strftime('%Y-%m-%d')

            # Step 2: Input amount
            custom_amount = st.number_input("Enter the amount you want to invest:", min_value=0.0, key="custom_investment_amount")

            # Step 3: Fetch asset list
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            unique_assets = [asset_name for asset_name, _ in assets_with_categories]
            selected_asset = st.selectbox("Select the asset to invest in:", unique_assets, key="select_custom_asset")

            # Step 4: Enter percentage of surplus to invest
            percentage_to_invest = st.number_input("Enter percentage of surplus to invest:", min_value=0.0, max_value=100.0, key="custom_percentage_invest")
            end_total_surplus_difference = None

            if st.button("Display Acutal and Ideal value at selected entry date", key="display_actual_ideal_per"):

                # Step 6: Fetch surplus
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT end_total_surplus
                    FROM dynamic_yearly_cf_projections
                    WHERE user_code = %s AND entry_date = %s;
                """, (user_id, entry_date_input))
                result = cursor.fetchone()
                cursor.close()

                if result is None:
                    st.warning(f"No surplus data found for entry date {entry_date_str}")
                    return
                end_total_surplus_difference = result[0]
                st.write(f"End Total Surplus Difference on {entry_date_str}: â‚¹{end_total_surplus_difference:,.2f}")

                # Check if surplus is sufficient
                if end_total_surplus_difference < custom_amount:
                    st.warning("Entered amount exceeds available surplus.")
                    return
                
                # Step 9: Show projection values for decision making
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT equity, real_estate, passive_income_assets, debt, alternative_investments
                    FROM dynamic_ideal_projection_calculation
                    WHERE entry_date = %s;
                """, (entry_date_input,))
                ideal_values = cursor.fetchone()

                cursor.execute("""
                    SELECT equity, real_estate, passive_income, debt, alternate_investments
                    FROM actual_projections_with_milestones
                    WHERE entry_date = %s;
                """, (entry_date_input,))
                actual_values = cursor.fetchone()
                cursor.close()

                if ideal_values and actual_values:

                    # Multiply values by 100 to convert from decimal to percentage
                    ideal_values = [round(val * 100) for val in ideal_values]
                    actual_values = [round(val * 100) for val in actual_values]

                    col_names = ["Equity", "Real Estate", "Passive Income", "Debt", "Alternative Investments"]
                    df_compare = pd.DataFrame({
                        "Projection Type": ["Ideal", "Actual"],
                        **{name: [ideal, actual] for name, ideal, actual in zip(col_names, ideal_values, actual_values)}
                    })
                    df_compare.set_index("Projection Type", inplace=True)
                    st.write("### Comparison of Ideal vs Actual Projections")
                    st.dataframe(df_compare)
                else:
                    st.warning("Could not fetch ideal or actual values for comparison.")

            if st.button("Display the column end_total_surplus", key="show_surplus_column"):
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT entry_date, end_total_surplus
                    FROM dynamic_yearly_cf_projections
                    WHERE user_code = %s
                    ORDER BY entry_date;
                """, (user_id,))
                rows = cursor.fetchall()
                cursor.close()

                if rows:
                    df_surplus = pd.DataFrame(rows, columns=["Entry Date", "End Total Surplus Difference"])
                    df_surplus["Entry Date"] = pd.to_datetime(df_surplus["Entry Date"]).dt.strftime("%Y-%m-%d")
                    st.write("### Surplus Overview")
                    st.dataframe(df_surplus)
                else:
                    st.warning("No surplus data found for this user.")
        

            # Step 5: Action Button
            if st.button("Apply the custom investment method by using end total surplus difference", key="cust_investme_calculation"):

                if end_total_surplus_difference is None:
                    # Fetch again if not fetched yet
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        SELECT end_total_surplus_difference
                        FROM dynamic_yearly_cf_projections
                        WHERE user_code = %s AND entry_date = %s;
                    """, (user_id, entry_date_input))
                    result = cursor.fetchone()
                    cursor.close()
                    
                    if result is None:
                        st.warning(f"No surplus data found for entry date {entry_date_str}")
                        return
                    end_total_surplus_difference = result[0]
                    st.write(f"End Total Surplus Difference on {entry_date_str}: â‚¹{end_total_surplus_difference:,.2f}")

                    # Check if surplus is sufficient
                    if end_total_surplus_difference < custom_amount:
                        st.warning("Entered amount exceeds available surplus.")
                        return

                # Step 7: Calculate amount to invest
                invested_amount = round(end_total_surplus_difference * (percentage_to_invest / 100), 2)

                # Step 8: Update investment_projections table
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT asset_value
                    FROM investment_projections
                    WHERE user_code = %s AND asset_name = %s AND entry_date = %s;
                """, (user_id, selected_asset, entry_date_str))
                result = cursor.fetchone()

                if result:
                    updated_asset_value = float(result[0]) - invested_amount
                    cursor.execute("""
                        UPDATE investment_projections
                        SET asset_value = %s
                        WHERE user_code = %s AND asset_name = %s AND entry_date = %s;
                    """, (-abs(updated_asset_value), user_id, selected_asset, entry_date_str))
                    self.connection.commit()
                    st.success(f"â‚¹{invested_amount:,.2f} has been invested in {selected_asset} on {entry_date_str}.")
                else:
                    st.warning(f"No existing asset record found for '{selected_asset}' on {entry_date_str}. No update performed.")
                cursor.close()

                # Step 9: Load and return updated DataFrame
                investment_projections_df = self.load_investment_projections_from_db(user_id)
                st.session_state[f"investment_projections_df_{user_id}"] = investment_projections_df
                return investment_projections_df

            # Step 5: Action Button
            if st.button("Apply the custom investment method by using end total surplus", key="cust_end_total_surplus_investme_calculation"):

                if end_total_surplus_difference is None:
                    # Fetch again if not fetched yet
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        SELECT end_total_surplus
                        FROM dynamic_yearly_cf_projections
                        WHERE user_code = %s AND entry_date = %s;
                    """, (user_id, entry_date_input))
                    result = cursor.fetchone()
                    cursor.close()
                    
                    if result is None:
                        st.warning(f"No surplus data found for entry date {entry_date_str}")
                        return
                    end_total_surplus_difference = result[0]
                    st.write(f"End Total Surplus on {entry_date_str}: â‚¹{end_total_surplus_difference:,.2f}")

                    # Check if surplus is sufficient
                    if end_total_surplus_difference < custom_amount:
                        st.warning("Entered amount exceeds available surplus.")
                        return

                # Step 7: Calculate amount to invest
                invested_amount = round(end_total_surplus_difference * (percentage_to_invest / 100), 2)

                # Step 8: Update investment_projections table
                cursor = self.connection.cursor()
                cursor.execute("""
                    SELECT asset_value
                    FROM investment_projections
                    WHERE user_code = %s AND asset_name = %s AND entry_date = %s;
                """, (user_id, selected_asset, entry_date_str))
                result = cursor.fetchone()

                if result:
                    updated_asset_value = float(result[0]) - invested_amount
                    cursor.execute("""
                        UPDATE investment_projections
                        SET asset_value = %s
                        WHERE user_code = %s AND asset_name = %s AND entry_date = %s;
                    """, (-abs(updated_asset_value), user_id, selected_asset, entry_date_str))
                    self.connection.commit()
                    st.success(f"â‚¹{invested_amount:,.2f} has been invested in {selected_asset} on {entry_date_str}.")
                else:
                    st.warning(f"No existing asset record found for '{selected_asset}' on {entry_date_str}. No update performed.")
                cursor.close()

                # Step 9: Load and return updated DataFrame
                investment_projections_df = self.load_investment_projections_from_db(user_id)
                st.session_state[f"investment_projections_df_{user_id}"] = investment_projections_df
                return investment_projections_df      
    
        return None

    def load_investment_projections_from_db(self, user_id):
        """Loads investment projections from DB only once per session."""
        
        key = f"investment_projections_df_{user_id}"

        if key not in st.session_state:
            # Load only user_id rows for speed
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            # Safety: table may not exist on first run
            inspector = inspect(engine)
            if not inspector.has_table("investment_projections"):
                st.session_state[key] = pd.DataFrame()
                return st.session_state[key]


            query = """
                SELECT *
                FROM investment_projections
                WHERE user_code = %s
            """
            st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

        return st.session_state[key]
    

    def run_investment_projections(self, user_id, month_choice):

        self.delete_old_investment_records()

        key = f"investment_projections_df_{user_id}"

        # ------------------------------------------------------------------
        # Step 1: LOAD DATA (FAST â€” FROM CACHE)
        # ------------------------------------------------------------------
        investment_projections_df = self.load_investment_projections_from_db(user_id)

        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)


        assets_with_categories = self.fetch_assets_with_categories(self.connection, user_id)
        investment_relate_purpose = self.fetch_purpose_for_investmentr_projections(user_id)
        unique_assets = [asset_name for asset_name, _ in assets_with_categories]
    

        investment_dict = {
            631: "Rental Yielding (Residential) 2",
            627: "debt fund - swp",
            320: "Arbitrage Funds",
            18: "Public Stock (India)",
            19: "Equity Mutual Funds",
            21: "Unlisted Stocks",
            22: "Public Stocks (International)",
            23: "Equity ETFs",
            24: "International Funds",
            25: "Direct Bonds",
            26: "Liquid Debt Funds",
            27: "Debt Funds",
            28: "Hybrid Funds",
            29: "Rental Yielding (Residential)",
            30: "Rental Yielding (Commercial)",
            31: "Non-Yielding (Residential)",
            32: "Non-Yielding (Commercial)",
            33: "Occupied Home",
            34: "Physical Gold",
            35: "Gold ETFs",
            36: "Sovereign Gold Bonds",
            37: "Bank FD",
            38: "Corporate FD",
            39: "Post Office Monthly Income Scheme (POMIS)",
            40: "Senior Citizen Savings Scheme (SCSS)",
            41: "Sukanya Samriddhi Yojana (SSY)",
            42: "National Savings Certificate (NSC)",
            43: "EPF",
            44: "PPF",
            45: "Savings",
            46: "NPS Tier I",
            47: "NPS Tier II",
            48: "Pradhan Mantri Vaya Vandana Yojana (PMVVY)",
            49: "Atal Pension Yojana (APY)",
            50: "Direct Cryptos",
            51: "Coin Baskets",
            53: "Loans Given",
            54: "Free Debt Instruments",
            90: "Physical Silver",
            91: "Silver ETFs",
            120: "Free Debt Instruments",
            235: "ESOP",
            236: "REITs/InvITs",
            237: "Bank RD",
            238: "P2P Lending",
            634: "Passive income from occupied home",
            642: "Occupied Home 3"
        }

        # If first time for the user â€” create all projections
        if investment_projections_df.empty and not self.user_exists_in_investment_proj_db(user_id):
            new_df = self.create_user_projection_table(
                dob, retirement_age, assets_with_categories,
                investment_relate_purpose, user_id, user_name, month_choice
            )

            investment_projections_df = pd.DataFrame(new_df)

            # Save to DB
            self.save_investment_projections_to_db(investment_projections_df, user_id)

            # Update cache
            st.session_state[key] = investment_projections_df

            st.success("Initial projections created successfully!")    

        # Reshape and display the existing investment projections for the user
        #st.write("### Investment Projections")
        #reshaped_df = self.reshape_display_investment_projections(investment_projections_df, user_id)
        #st.dataframe(reshaped_df)

        

        # Dropdown to select an asset to add as a new asset
        additional_asset_name = st.selectbox("Select asset name to add:", list(investment_dict.values()), key="investment_add_asset")
        if st.button("Add Asset", key="investment_add_button"):
            assets_with_categories = self.fetch_assets_with_categories(self.connection, user_id)

            investment_projections_df, assets_with_categories = self.add_additional_asset(
                investment_projections_df, investment_dict, assets_with_categories,
                user_id, dob, retirement_age, additional_asset_name, month_choice
            )

            # Save to DB + Cache
            self.save_investment_projections_to_db(investment_projections_df, user_id)
            st.session_state[key] = investment_projections_df

            st.success(f"Added {additional_asset_name}.")

        # Fetch distinct asset names for the dropdowns
        unique_assets_investment_projections = investment_projections_df[investment_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()
        #print('unique_assets_investment_projections',unique_assets_investment_projections)

        # Update projections based on growth or other entry types
        entry_type = st.radio("Choose entry type:", ('growth_increment', 'growth_increment_from_middle', 'growth_increment_selected_assets', 'single', 'range', 'increment', 'project_new_asset_growth', 'stop'),key="investment_entry_type")
        
        if entry_type == 'growth_increment':
            growth_month = st.selectbox("Select Growth Month", [str(i).zfill(2) for i in range(1, 13)], key="investment_growth_month")
            # investment_growth_1 = st.number_input("Growth for age <35:", value=5.0, key="investment_growth_1")
            # investment_growth_2 = st.number_input("Growth for age 36-45:", value=4.0, key="investment_growth_2")
            # investment_growth_3 = st.number_input("Growth for age 46-55:", value=3.0, key="investment_growth_3")
            # investment_growth_4 = st.number_input("Growth for age >55:", value=2.0, key="investment_growth_4")

            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            query = """
                SELECT category_id, growth_rate
                FROM life_stage_growth_milestone
                WHERE user_code = %s AND category_id IN (239, 240, 241, 242)
                ORDER BY category_id;
            """

            df_growth = pd.read_sql(query, engine, params=(user_id,))

            # Extract growth values
            growth_map = df_growth.set_index('category_id')['growth_rate'].to_dict()

            # If a value is missing in DB, default to 0%
            investment_growth_1 = growth_map.get(239, 0)   # < 35 years
            investment_growth_2 = growth_map.get(240, 0)   # 36â€“45
            investment_growth_3 = growth_map.get(241, 0)   # 46â€“55
            investment_growth_4 = growth_map.get(242, 0)   # > 55

            if st.button("Apply Growth", key="apply_investment_growth"):
                investment_projections_df = self.update_investment_projections(user_id, investment_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, growth_month=growth_month, investment_growth=[investment_growth_1, investment_growth_2, investment_growth_3, investment_growth_4])
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.session_state[key] = investment_projections_df
                st.success("Growth applied and saved to the database.")


        elif entry_type == 'growth_increment_selected_assets':
            growth_month = st.selectbox("Select Growth Month", [str(i).zfill(2) for i in range(1, 13)], key="growth_month_selected")
            # investment_growth_1 = st.number_input("Growth for age <35:", value=5.0, key="growth_sel_1")
            # investment_growth_2 = st.number_input("Growth for age 36-45:", value=4.0, key="growth_sel_2")
            # investment_growth_3 = st.number_input("Growth for age 46-55:", value=3.0, key="growth_sel_3")
            # investment_growth_4 = st.number_input("Growth for age >55:", value=2.0, key="growth_sel_4")
        
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            query = """
                SELECT category_id, growth_rate
                FROM life_stage_growth_milestone
                WHERE user_code = %s AND category_id IN (239, 240, 241, 242)
                ORDER BY category_id;
            """

            df_growth = pd.read_sql(query, engine, params=(user_id,))

            # Extract growth values
            growth_map = df_growth.set_index('category_id')['growth_rate'].to_dict()

            # If a value is missing in DB, default to 0%
            investment_growth_1 = growth_map.get(239, 0)   # < 35 years
            investment_growth_2 = growth_map.get(240, 0)   # 36â€“45
            investment_growth_3 = growth_map.get(241, 0)   # 46â€“55
            investment_growth_4 = growth_map.get(242, 0)   # > 55  

            user_assets = investment_projections_df[investment_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()
            selected_assets_for_growth = st.multiselect("Select existing assets to apply growth:", user_assets, key="sel_asset_growth")
            if st.button("Apply Selected Growth", key="apply_selected_growth"):
                if not selected_assets_for_growth:
                    st.warning("Please select at least one asset.")
                else:
                    filtered_df = investment_projections_df[
                        (investment_projections_df['user_code'] == user_id) &
                        (investment_projections_df['asset_name'].isin(selected_assets_for_growth))
                    ].copy()
                    updated_df = projection_updater.update_investment_projections(
                        user_id,
                        filtered_df,
                        distinct_names=selected_assets_for_growth,
                        entry_type='growth_increment',
                        growth_month=growth_month,
                        investment_growth=[investment_growth_1, investment_growth_2, investment_growth_3, investment_growth_4]
                    )
                    investment_projections_df = investment_projections_df[~(
                        (investment_projections_df['user_code'] == user_id) &
                        (investment_projections_df['asset_name'].isin(selected_assets_for_growth))
                    )]
                    investment_projections_df = pd.concat([investment_projections_df, updated_df], ignore_index=True)
                    projection_updater.save_investment_projections_to_db(investment_projections_df, user_id)
                    st.session_state[key] = investment_projections_df
                    st.success("Selected growth applied and saved.")    


        # âœ… New: Apply growth_increment from the middle
        elif entry_type == 'growth_increment_from_middle':
            growth_month = st.selectbox("Select Growth Month", [str(i).zfill(2) for i in range(1, 13)], key="growth_month_middle")
            # investment_growth_1 = st.number_input("Growth for age <35:", value=5.0, key="growth_middle_1")
            # investment_growth_2 = st.number_input("Growth for age 36-45:", value=4.0, key="growth_middle_2")
            # investment_growth_3 = st.number_input("Growth for age 46-55:", value=3.0, key="growth_middle_3")
            # investment_growth_4 = st.number_input("Growth for age >55:", value=2.0, key="growth_middle_4")

            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            query = """
                SELECT category_id, growth_rate
                FROM life_stage_growth_milestone
                WHERE user_code = %s AND category_id IN (239, 240, 241, 242)
                ORDER BY category_id;
            """

            df_growth = pd.read_sql(query, engine, params=(user_id,))

            # Extract growth values
            growth_map = df_growth.set_index('category_id')['growth_rate'].to_dict()

            # If a value is missing in DB, default to 0%
            investment_growth_1 = growth_map.get(239, 0)   # < 35 years
            investment_growth_2 = growth_map.get(240, 0)   # 36â€“45
            investment_growth_3 = growth_map.get(241, 0)   # 46â€“55
            investment_growth_4 = growth_map.get(242, 0)   # > 55

            asset_name = st.selectbox("Select asset name to apply growth from middle:", unique_assets_investment_projections, key="growth_middle_asset")
            entry_date = st.date_input("Start Entry Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="growth_middle_entry").strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="growth_middle_end").strftime('%Y-%m-%d')

            if st.button("Apply Middle Growth", key="apply_middle_growth"):
                filtered_df = investment_projections_df[
                    (investment_projections_df['user_code'] == user_id) &
                    (investment_projections_df['asset_name'].str.strip().str.lower() == asset_name.strip().lower()) &
                    (investment_projections_df['entry_date'] >= entry_date) &
                    (investment_projections_df['entry_date'] <= end_date)
                ].copy()


                filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
                filtered_df = filtered_df.sort_values(by='entry_date')
                filtered_df['entry_date'] = filtered_df['entry_date'].dt.strftime('%Y-%m-%d')
                # st.write('filtered_df',filtered_df)

                if filtered_df.empty:
                    st.warning("No records found for the selected asset in the specified date range.")
                else:
                    # Grouped value tracking
                    last_value = None
                    cached_growth_value = None

                    for idx, row in filtered_df.iterrows():
                        age = row['age']
                        entry_dt = datetime.strptime(row['entry_date'], "%Y-%m-%d")
                        entry_month = entry_dt.strftime('%m')

                        # Determine growth rate by age group
                        if age <= 35:
                            growth_percentage = investment_growth_1
                        elif 36 <= age <= 45:
                            growth_percentage = investment_growth_2
                        elif 46 <= age <= 55:
                            growth_percentage = investment_growth_3
                        else:
                            growth_percentage = investment_growth_4

                        # Initialise last_value if still None
                        if last_value is None:
                            if row['asset_value'] is None:
                                last_value = 0  # Default to 0 if missing
                            else:
                                last_value = abs(row['asset_value'])

                        if entry_month == growth_month:
                            last_value *= (1 + growth_percentage)
                            cached_growth_value = last_value
                        elif cached_growth_value is not None:
                            last_value = cached_growth_value

                        filtered_df.at[idx, 'asset_value'] = -abs(last_value)

                    investment_projections_df = investment_projections_df[~(
                        (investment_projections_df['user_code'] == user_id) &
                        (investment_projections_df['asset_name'].str.strip().str.lower() == asset_name.strip().lower()) &
                        (investment_projections_df['entry_date'] >= entry_date) &
                        (investment_projections_df['entry_date'] <= end_date)
                    )]
                    investment_projections_df = pd.concat([investment_projections_df, filtered_df], ignore_index=True)
                    projection_updater.save_investment_projections_to_db(investment_projections_df, user_id)
                    st.session_state[key] = investment_projections_df
                    st.success("Growth from middle applied and saved.")        
                

        elif entry_type == 'single':
            single_date = st.date_input("Select date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="investment_single_date")
            # Convert single_date to a string for comparison or database use
            single_date_str = single_date.strftime('%Y-%m-%d')
            #print('single_date in run investment',single_date)
            #asset_name = st.text_input("Enter the asset name:")
           
            asset_name = st.selectbox("Select asset name:", unique_assets_investment_projections, key="investment_single_asset")
            print('asset_name in all run fun',asset_name)
            #amount = st.number_input("Enter amount:")
            amount = int(st.number_input("Enter amount:", value=0, key="investment_single_amount"))  # Convert amount to integer
            print('amount in all run fun',amount)
            if st.button("Apply Single Date Update", key="apply_investment_single_update"):
                # Update the investment projections
                investment_projections_df = self.update_investment_projections(
                    user_id,
                    investment_projections_df, 
                    distinct_names=[a for a, _ in assets_with_categories],  # Use the original names
                    entry_type=entry_type, 
                    single_date=single_date_str, 
                    increment_params={'amount': amount, 'asset_name': asset_name}  # Pass asset name without trimming
                )
                # Save the updated projections immediately after the update
                st.write("update the single value using update function")
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.session_state[key] = investment_projections_df
                st.success("Single date update applied and saved to the database.")

        elif entry_type == 'range':
            start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="investment_range_start")
            #start_date_str = start_date.strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="investment_range_end")
            #end_date_str = end_date.strftime('%Y-%m-%d')
            asset_name = st.selectbox("Select asset name for range:", unique_assets_investment_projections, key="investment_range_asset")
            amount = int(st.number_input("Enter amount for range:",value = 0, key="investment_range_amount"))
            if st.button("Apply Range Update", key="apply_investment_range_update"):
                investment_projections_df = self.update_investment_projections(user_id, investment_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, range_dates=[start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')], increment_params={'amount': amount, 'asset_name': asset_name})
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.session_state[key] = investment_projections_df
                st.success("Range date update applied and save to the database.")

        elif entry_type == 'increment':
            entry_date = st.date_input("Entry Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="investment_increment_entry")
            percentage = st.number_input("Increment percentage:", key="investment_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="investment_increment_end")
            asset_name = st.selectbox("Select asset name for increment:", unique_assets_investment_projections, key="investment_increment_asset")
            if st.button("Apply Increment Update", key="apply_investment_increment_update"):
                investment_projections_df = self.update_investment_projections(user_id, investment_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, increment_params={'entry_date': entry_date.strftime('%Y-%m-%d'), 'percentage': percentage, 'end_date': end_date_increment.strftime('%Y-%m-%d'), 'asset_name': asset_name})
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.session_state[key] = investment_projections_df
                st.success("Increment update applied and save to the database.")

        elif entry_type == 'project_new_asset_growth':
            growth_month = st.selectbox("Select Growth Month for New Asset", [str(i).zfill(2) for i in range(1, 13)], key="new_asset_growth_month")
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            query = """
                SELECT category_id, growth_rate
                FROM life_stage_growth_milestone
                WHERE user_code = %s AND category_id IN (239, 240, 241, 242)
                ORDER BY category_id;
            """

            df_growth = pd.read_sql(query, engine, params=(user_id,))

            # Extract growth values
            growth_map = df_growth.set_index('category_id')['growth_rate'].to_dict()

            # If a value is missing in DB, default to 0%
            investment_growth_1 = growth_map.get(239, 0)   # < 35 years
            investment_growth_2 = growth_map.get(240, 0)   # 36â€“45
            investment_growth_3 = growth_map.get(241, 0)   # 46â€“55
            investment_growth_4 = growth_map.get(242, 0)   # > 55 
            
            if st.button("Apply Growth for New Asset", key="apply_growth_new_asset"):
                investment_projections_df = self.project_growth_for_new_asset(
                    investment_projections_df,
                    user_id,
                    growth_month=growth_month,
                    investment_growth=[investment_growth_1, investment_growth_2, investment_growth_3, investment_growth_4]
                )
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.session_state[key] = investment_projections_df
                st.success("Growth projection for new assets applied and saved to the database.")        

        elif entry_type == 'stop':
            self.save_investment_projections_to_db(investment_projections_df, user_id)
            st.session_state[key] = investment_projections_df
            st.info("Stop function executed. No changes applied.")

        #self.save_investment_projections_to_db(investment_projections_df, user_id) 
        # Functionality to delete an asset category from asset_name column
        st.write("## Delete an Asset Category")
        
        # Dropdown for selecting an asset category to delete
        asset_to_delete = st.selectbox("Select asset category to delete from projections:", unique_assets_investment_projections, key="investment_delete_asset")
        
        # Confirm deletion
        if st.button("Delete Selected Asset Category", key="delete_investment_asset"):
            investment_projections_df = self.delete_asset_category_from_investment_projections(investment_projections_df, user_id, asset_to_delete)
            self.save_investment_projections_to_db(investment_projections_df, user_id)
            st.session_state[key] = investment_projections_df
            st.success(f"Asset category '{asset_to_delete}' has been deleted from projections for user_id {user_id}.") 

        updated_df = self.fill_user_based_investment_values(user_id)

        if updated_df is not None:
            investment_projections_df = updated_df

        reshaped_df = self.reshape_display_investment_projections(investment_projections_df, user_id)
        st.write("### Investment Projections after changes:")
        st.dataframe(reshaped_df)

    def delete_asset_category_from_investment_projections(self, investment_projections_df, user_id, asset_name):

        return investment_projections_df[~((investment_projections_df['user_code'] == user_id) &
                                                  (investment_projections_df['asset_name'] == asset_name))]     


    def user_exists_in_investment_proj_db(self, user_id):
        """Check if the user_id already exists in the PostgreSQL table."""
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('investment_projections', schema="public"):
            print("Table 'investment_projections' does not exist.")
            return False

        
        query = f"SELECT 1 FROM investment_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None
         
    
    #loan repayment code start from here
    def fetch_liabilities_for_loan_repayment(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT l.name AS liabilities_name, l.category_id
            FROM liabilities_milestone_table l
            JOIN milestones_category c ON l.category_id = c.id
            WHERE l.user_code = %s AND l.name IS NOT NULL AND l.name <> 'None' AND l.is_active = true;
        """, (user_id,))

        liabilities_with_categories = cursor.fetchall()
        cursor.close()
    
        return liabilities_with_categories 
    
    def fetch_distinct_liabilities_purpose(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None' and loan_funded = 'Yes';
        """, (user_id,))
        
        liabilities_purpose = cursor.fetchall()
        cursor.close()
        
        return liabilities_purpose    


    def create_loan_repayment_projection_table(self, dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice):
    
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        loan_repayment_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                lr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                loan_repayment_projections.append(lr_projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in liabilities_purpose:
                lr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': purpose,  # Use purpose as liabilities_name
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                loan_repayment_projections.append(lr_projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return loan_repayment_projections
    

    def load_dynamic_loan_repayment_projections_from_db(self, user_id):
        """Loads loan repayment projections from DB only once per session."""
        
        key = f"dynamic_loan_repayment_projections_df_{user_id}"

        if key not in st.session_state:
            # Load only user_id rows for speed
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            # Safety: table may not exist on first run
            inspector = inspect(engine)
            if not inspector.has_table("dynamic_loan_repayment_projections"):
                st.session_state[key] = pd.DataFrame()
                return st.session_state[key]


            query = """
                SELECT *
                FROM dynamic_loan_repayment_projections
                WHERE user_code = %s
            """
            st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

        return st.session_state[key]
    

    def save_dynamic_loan_repayment_projections_to_db(self, dynamic_loan_repayment_projections_df, user_id):
        import io
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Create table if it doesn't exist
        inspector = inspect(engine)
        if not inspector.has_table('dynamic_loan_repayment_projections'):
            print("Table 'dynamic_loan_repayment_projections' does not exist. Creating it.")
            dynamic_loan_repayment_projections_df.head(0).to_sql(
                'dynamic_loan_repayment_projections',
                engine,
                if_exists='replace',
                index=False
            )

        # Get only the user-specific rows
        #user_rows = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df["user_code"] == user_id]

        raw_conn = engine.raw_connection()
        try:
            cur = raw_conn.cursor()
            cur.execute("DELETE FROM dynamic_loan_repayment_projections WHERE user_code = %s", (user_id,))

            buffer = io.StringIO()
            df_user = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df["user_code"] == user_id]
            df_user.to_csv(buffer, index=False, header=False)
            buffer.seek(0)

            copy_sql = "COPY dynamic_loan_repayment_projections FROM STDIN WITH CSV"
            cur.copy_expert(copy_sql, buffer)

            raw_conn.commit()
            print("ðŸš€ Data saved in under 1 second using COPY.")
        finally:
            cur.close()
            raw_conn.close()

        print("Loan Repayment projections saved using COPY (fast).")

    def update_dynamic_loan_repayment_projections(self, user_id, dynamic_loan_repayment_projections_df, distinct_liabilities_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        #unique_liabilities_names = dynamic_loan_repayment_projections_df['liabilities_name'].unique()
        unique_liabilities_names = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'single':
            print('single_date', single_date)
            liability_name = increment_params.get('liability_name')  # liability name passed from frontend
            print('liability_name',liability_name)
            amount = increment_params.get('amount')
            print('amount',amount)

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'") 

            #Apply the update for the matched asset name on the given single date
            #updated = False
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == single_date and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_repayment_projections_df.at[idx, 'liabilities_value'] = -abs(amount)
                    #updated = True
                    #print(f"Successfully updated asset: '{matched_asset_name}' for date: {single_date} with amount: {amount}")

            #if not updated:
                #print(f"No record updated for asset: {matched_asset_name} on date: {single_date}")        

        elif entry_type == 'range':
            liability_name = increment_params.get('liability_name')
            amount = increment_params.get('amount')

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")

            # Apply update for the range of dates
            start_date, end_date = range_dates
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and start_date <= projection['entry_date'] <= end_date and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_repayment_projections_df.at[idx, 'liabilities_value'] = -abs(amount)

        elif entry_type == 'increment':
            liability_name = increment_params.get('liability_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['liabilities_name'] == matched_liability_name):
                    previous_amount = float(projection.get('liabilities_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return dynamic_loan_repayment_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_repayment_projections_df.at[idx, 'liabilities_value'] = -abs(incremented_amount)

        return dynamic_loan_repayment_projections_df
    
    # Reshape the investment projections for the required format
    def reshape_loan_repayment_projections(self, dynamic_loan_repayment_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df 
    
    # Reshape the investment projections for the required format
    def reshape_display_loan_repayment_projections(self, dynamic_loan_repayment_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)  # Set asset_name as index
        return reshaped_df
    
    # Function to delete records with entry_date less than the current date
    def delete_old_loan_repayments_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM dynamic_loan_repayment_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")

    def add_additional_loan_repayment(self, dynamic_loan_repayment_projections_df, liability_dict, repayment_loan_with_categories, user_id, dob, retirement_age, additional_liabilities_name, month_choice):
        # Check if the asset_name already exists for the user
        user_specific_df = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]
        # Extract unique liabilities names from the user's specific data, then strip spaces and convert to lowercase
        unique_existing_liabilities = [liability.strip().lower() for liability in user_specific_df['liabilities_name'].unique()]
        stripped_liabilities_name = additional_liabilities_name.strip().lower()

        # Temporarily strip spaces from the asset_name for comparison
        if stripped_liabilities_name in unique_existing_liabilities:
            #exact_matches = sum(1 for existing in unique_existing_liabilities if existing == stripped_liabilities_name)
            existing_count = sum(1 for existing in unique_existing_liabilities if existing.strip().lower().startswith(stripped_liabilities_name))
            print('exact_matches check', existing_count)
            new_liabilities_name = f"{additional_liabilities_name.strip()} {existing_count + 1}"
            
            # Retrieve category_id from the DataFrame, handling extra spaces
            category_id = dynamic_loan_repayment_projections_df.loc[
                dynamic_loan_repayment_projections_df['liabilities_name'].str.strip().str.lower() == stripped_liabilities_name, 
                'category_id'
            ].values[0]
        else:
            new_liabilities_name = additional_liabilities_name
            category_id = next((cat_id for cat_id, name in liability_dict.items() if name == additional_liabilities_name), None)

        if category_id is not None:
            # Append new asset to the list with category
            repayment_loan_with_categories.append((new_liabilities_name, category_id))
            new_loan_repyament_projections = self.create_user_loan_repayment_projection_table_1(dob, retirement_age, [(new_liabilities_name, category_id)], user_id, self.fetch_user_name(user_id),month_choice)
            dynamic_loan_repayment_projections_df = pd.concat([dynamic_loan_repayment_projections_df, pd.DataFrame(new_loan_repyament_projections)], ignore_index=True)
        else:
            st.write("Invalid liability name entered. No liability added.")

        return dynamic_loan_repayment_projections_df, repayment_loan_with_categories	
		
		

    def create_user_loan_repayment_projection_table_1(self, dob, retirement_age, repayment_loan_with_categories, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for liabilities_name, category_id in repayment_loan_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize asset value to 0
                }
                projections.append(projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return projections
         

    def run_loan_repayment_projections(self, user_id, month_choice):
   
        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        key = f"dynamic_loan_repayment_projections_df_{user_id}"
        
        if inspector.has_table('dynamic_loan_repayment_projections'):
            # Only delete old records if the table exists
            self.delete_old_loan_repayments_records()

        # Load the existing data from the investment_projections table
        dynamic_loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)


        # Fetch distinct liabilities with their categories
        liabilities_with_categories = self.fetch_liabilities_for_loan_repayment(user_id)
        print('liabilities_with_categories',liabilities_with_categories)
        liabilities_purpose = self.fetch_distinct_liabilities_purpose(user_id)
        print('liabilities_purpose',liabilities_purpose)
        # Update the projections based on user input
        distinct_liabilities_names = [liabilities for liabilities, _ in liabilities_with_categories] + [purpose for purpose, _ in liabilities_purpose]
        print('distinct_liabilities_names',distinct_liabilities_names)

        liability_dict = {
            15: "Loans",
            55: "Auto Loan",
            56: "Property Loan",
            57: "Housing Loan",
            58: "Car Loan",
            59: "Personal Loan",
            60: "Two-Wheeler Loan",
            61: "Consumer Loan",
            104: "Credit Card Loan",
            53: "Loans Given",
            175: "Education Loan",
            209: "Gold Loan",
            210: "Loan Against Property"
        }
        


        if not self.user_exists_in_loan_repyament_db(user_id):
            if dynamic_loan_repayment_projections_df.empty:
                new_projections = self.create_loan_repayment_projection_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_loan_repayment_projections_df = pd.DataFrame(new_projections)
            else:
                new_projections = self.create_loan_repayment_projection_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_loan_repayment_projections_df = pd.concat([dynamic_loan_repayment_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

            # Pass user_id as an argument
            self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_repayment_projections_df
        else:
            st.warning(f"User {user_id} already exists in the database. No new data will be appended.")
        

        # Reshape and display the existing investment projections for the user
        st.write("### loan repayment Projections")
        reshaped_df = self.reshape_display_loan_repayment_projections(dynamic_loan_repayment_projections_df, user_id)
        st.dataframe(reshaped_df)


        additional_liabilities_name = st.selectbox("Select asset name to add:", list(liability_dict.values()), key="loan_repayment_add_liability")
        if st.button("Add loan", key="loan_repayment_add_button"):
            #with st.spinner("Adding loan..."):
                repayment_loan_with_categories = self.fetch_liabilities_for_loan_repayment(user_id)
                dynamic_loan_repayment_projections_df, repayment_loan_with_categories = self.add_additional_loan_repayment(
                    dynamic_loan_repayment_projections_df, liability_dict, repayment_loan_with_categories,
                    user_id, dob, retirement_age, additional_liabilities_name, month_choice
                )
                self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_repayment_projections_df
                st.success(f"Added {additional_liabilities_name} to projections and saved to the database.")
                dynamic_loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)    


        # Update projections based on growth or other entry types
        entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'), key="loan_entry_type")
        
        
        if entry_type == 'single':
            single_date = st.date_input("Select date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))
            # Convert single_date to a string for comparison or database use
            single_date_str = single_date.strftime('%Y-%m-%d')
            #print('single_date in run investment',single_date)
            #asset_name = st.text_input("Enter the asset name:")
           
            liability_name = st.selectbox("Select liability name:", distinct_liabilities_names, key="loan_liability_name")
            #print('asset_name in all run fun',asset_name)
            #amount = st.number_input("Enter amount:")
            amount = st.number_input("Enter amount:", value=0.0, key="loan_amount")  # Convert amount to integer
            print('amount in all run fun',amount)
            if st.button("Apply Single Date Update", key="apply_loan_single_update"):
                # Update the investment projections
                dynamic_loan_repayment_projections_df = self.update_dynamic_loan_repayment_projections(
                    user_id, dynamic_loan_repayment_projections_df, 
                    distinct_liabilities_names,  # Use the original names
                    entry_type=entry_type, 
                    single_date=single_date_str, 
                    increment_params={'amount': amount, 'liability_name': liability_name}  # Pass asset name without trimming
                )
                # Save the updated projections immediately after the update
                self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_repayment_projections_df
                st.success("Single date update applied and saved to the database.")

        elif entry_type == 'range':
            start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="loan_start_date")
            #start_date_str = start_date.strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="loan_end_date")
            #end_date_str = end_date.strftime('%Y-%m-%d')
            liability_name = st.selectbox("Select asset name for range:", distinct_liabilities_names,key="loan_liability_range")
            amount = int(st.number_input("Enter amount for range:",value = 0,key="loan_range_amount"))
            if st.button("Apply Range Update",key="apply_loan_range_update"):
                dynamic_loan_repayment_projections_df = self.update_dynamic_loan_repayment_projections(user_id, dynamic_loan_repayment_projections_df, distinct_liabilities_names, entry_type=entry_type, range_dates=[start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')], increment_params={'amount': amount, 'liability_name': liability_name})
                self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_repayment_projections_df
                st.success("Range date update applied and save to the database.")

        elif entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="loan_increment_date")
            percentage = st.number_input("Increment percentage:", key="loan_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="loan_end_date_increment")
            liability_name = st.selectbox("Select asset name for increment:", distinct_liabilities_names, key="loan_increment_liability")
            if st.button("Apply Increment Update",key="apply_loan_increment_update"):
                dynamic_loan_repayment_projections_df = self.update_dynamic_loan_repayment_projections(user_id, dynamic_loan_repayment_projections_df, distinct_liabilities_names, entry_type=entry_type, increment_params={'entry_date': entry_date.strftime('%Y-%m-%d'), 'percentage': percentage, 'end_date': end_date_increment.strftime('%Y-%m-%d'), 'liability_name': liability_name})
                self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_repayment_projections_df
                st.success("Increment update applied and save to the database.")

        elif entry_type == 'stop':
            self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_repayment_projections_df
            st.write("Stop function executed. No changes applied.")
        
        #self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
        # Functionality to delete an asset category from asset_name column
        st.write("## Delete an Asset Category")

        # Fetch distinct asset names for the dropdowns
        unique_liabilities_loanr_projections = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()
        
        # Dropdown for selecting an asset category to delete
        liability_to_delete = st.selectbox("Select liability category to delete from projections:", unique_liabilities_loanr_projections, key="loan_delete_liability")
        
        # Confirm deletion
        if st.button("Delete Selected Liability Category", key="delete_loan_repayment_liability"):
            dynamic_loan_repayment_projections_df = self.delete_liability_category_from_loan_repayment_proj(dynamic_loan_repayment_projections_df, user_id, liability_to_delete)
            self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_repayment_projections_df
            st.success(f"Liability category '{liability_to_delete}' has been deleted from projections for user_id {user_id}.")

        # Display the updated investment projections for the user
        st.write("### loan repayment Projections after changes:")
       
        # Reshape and display the existing investment projections for the user
        reshaped_df = self.reshape_display_loan_repayment_projections(dynamic_loan_repayment_projections_df, user_id)
        st.dataframe(reshaped_df)



    def user_exists_in_loan_repyament_db(self, user_id):
        """Check if the user_id already exists in the PostgreSQL table."""
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('dynamic_loan_repayment_projections', schema = 'public'):
            print("Table 'dynamic_loan_repayment_projections' does not exist.")
            return False

        
        query = f"SELECT 1 FROM dynamic_loan_repayment_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None
        
    def delete_liability_category_from_loan_repayment_proj(self, dynamic_loan_repayment_projections_df, user_id, liability_name):
        
        return dynamic_loan_repayment_projections_df[~((dynamic_loan_repayment_projections_df['user_code'] == user_id) &
                                                  (dynamic_loan_repayment_projections_df['liabilities_name'] == liability_name))]     
    




    #new loan repayment table for surplus 
    def fetch_liabilities_for_loan_surplus_repayment(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT l.name AS liabilities_name, l.category_id
            FROM liabilities l
            JOIN milestones_category c ON l.category_id = c.id
            WHERE l.user_code = %s AND l.name IS NOT NULL AND l.name <> 'None';
        """, (user_id,))

        liabilities_with_categories = cursor.fetchall()
        cursor.close()
    
        return liabilities_with_categories 
    
    def fetch_distinct_liabilities_purpose(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None';
        """, (user_id,))
        
        liabilities_purpose = cursor.fetchall()
        cursor.close()
        
        return liabilities_purpose    


    def create_loan_surplus_repayment_projection_table(self, dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice):
    
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        loan_repayment_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                lr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                loan_repayment_projections.append(lr_projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in liabilities_purpose:
                lr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': purpose,  # Use purpose as liabilities_name
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                loan_repayment_projections.append(lr_projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return loan_repayment_projections
    

    def load_dynamic_loan_surplus_repayment_projections_from_db(self, user_id):
        """Loads loan surplus repayment projections from DB only once per session."""
        
        key = f"dynamic_loan_surplus_repayment_projections_df_{user_id}"

        if key not in st.session_state:
            # Load only user_id rows for speed
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            # Safety: table may not exist on first run
            inspector = inspect(engine)
            if not inspector.has_table("dynamic_loan_surplus_repayment_projections"):
                st.session_state[key] = pd.DataFrame()
                return st.session_state[key]


            query = """
                SELECT *
                FROM dynamic_loan_surplus_repayment_projections
                WHERE user_code = %s
            """
            st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

        return st.session_state[key]
    

    def save_dynamic_loan_surplus_repayment_projections_to_db(self, dynamic_loan_surplus_repayment_projections_df, user_id):
        import io
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Create table if it doesn't exist
        inspector = inspect(engine)
        if not inspector.has_table('dynamic_loan_surplus_repayment_projections'):
            print("Table 'dynamic_loan_surplus_repayment_projections' does not exist. Creating it.")
            dynamic_loan_surplus_repayment_projections_df.head(0).to_sql(
                'dynamic_loan_surplus_repayment_projections',
                engine,
                if_exists='replace',
                index=False
            )

        # Get only the user-specific rows
        #user_rows = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df["user_code"] == user_id]

        raw_conn = engine.raw_connection()
        try:
            cur = raw_conn.cursor()
            cur.execute("DELETE FROM dynamic_loan_surplus_repayment_projections WHERE user_code = %s", (user_id,))

            buffer = io.StringIO()
            df_user = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df["user_code"] == user_id]
            df_user.to_csv(buffer, index=False, header=False)
            buffer.seek(0)

            copy_sql = "COPY dynamic_loan_surplus_repayment_projections FROM STDIN WITH CSV"
            cur.copy_expert(copy_sql, buffer)

            raw_conn.commit()
            print("ðŸš€ Data saved in under 1 second using COPY.")
        finally:
            cur.close()
            raw_conn.close()

        print("Loan surplus Repayment projections saved using COPY (fast).")


    def update_dynamic_loan_surplus_repayment_projections(self, user_id, dynamic_loan_surplus_repayment_projections_df, distinct_liabilities_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        #unique_liabilities_names = dynamic_loan_surplus_repayment_projections_df['liabilities_name'].unique()
        unique_liabilities_names = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'single':
            print('single_date', single_date)
            liability_name = increment_params.get('liability_name')  # liability name passed from frontend
            print('liability_name',liability_name)
            amount = increment_params.get('amount')
            print('amount',amount)

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_surplus_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'") 

            #Apply the update for the matched asset name on the given single date
            #updated = False
            for idx, projection in dynamic_loan_surplus_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == single_date and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_surplus_repayment_projections_df.at[idx, 'liabilities_value'] = amount
                    #updated = True
                    #print(f"Successfully updated asset: '{matched_asset_name}' for date: {single_date} with amount: {amount}")

            #if not updated:
                #print(f"No record updated for asset: {matched_asset_name} on date: {single_date}")        

        elif entry_type == 'range':
            liability_name = increment_params.get('liability_name')
            amount = increment_params.get('amount')

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_surplus_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")

            # Apply update for the range of dates
            start_date, end_date = range_dates
            for idx, projection in dynamic_loan_surplus_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and start_date <= projection['entry_date'] <= end_date and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_surplus_repayment_projections_df.at[idx, 'liabilities_value'] = amount

        elif entry_type == 'increment':
            liability_name = increment_params.get('liability_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_surplus_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in dynamic_loan_surplus_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['liabilities_name'] == matched_liability_name):
                    previous_amount = float(projection.get('liabilities_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return dynamic_loan_surplus_repayment_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in dynamic_loan_surplus_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_surplus_repayment_projections_df.at[idx, 'liabilities_value'] = incremented_amount

        return dynamic_loan_surplus_repayment_projections_df
    
    # Reshape the investment projections for the required format
    def reshape_loan_surplus_repayment_projections(self, dynamic_loan_surplus_repayment_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)  # Set asset_name as index

        return reshaped_df 
    
    # Reshape the investment projections for the required format
    def reshape_display_loan_surplus_repayment_projections(self, dynamic_loan_surplus_repayment_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)  # Set asset_name as index
        return reshaped_df
    
    # Function to delete records with entry_date less than the current date
    def delete_old_loan_surplus_repayments_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM dynamic_loan_surplus_repayment_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")


    def add_additional_loan_surplus_repayment(self, dynamic_loan_surplus_repayment_projections_df, liability_dict, repayment_surplus_loan_with_categories, user_id, dob, retirement_age, additional_liabilities_name, month_choice):
        # Check if the asset_name already exists for the user
        user_specific_df = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id]
        # Extract unique liabilities names from the user's specific data, then strip spaces and convert to lowercase
        unique_existing_milestones = [liability.strip().lower() for liability in user_specific_df['liabilities_name'].unique()]
        stripped_liabilities_name = additional_liabilities_name.strip().lower()

        # Temporarily strip spaces from the asset_name for comparison
        if stripped_liabilities_name in unique_existing_milestones:
            #exact_matches = sum(1 for existing in unique_existing_milestones if existing == stripped_liabilities_name)
            existing_count = sum(1 for existing in unique_existing_milestones if existing.strip().lower().startswith(stripped_liabilities_name))
            print('exact_matches check', existing_count)
            new_liabilities_name = f"{additional_liabilities_name.strip()} {existing_count + 1}"
            
            # Retrieve category_id from the DataFrame, handling extra spaces
            category_id = dynamic_loan_surplus_repayment_projections_df.loc[
                dynamic_loan_surplus_repayment_projections_df['liabilities_name'].str.strip().str.lower() == stripped_liabilities_name, 
                'category_id'
            ].values[0]
        else:
            new_liabilities_name = additional_liabilities_name
            category_id = next((cat_id for cat_id, name in liability_dict.items() if name == additional_liabilities_name), None)

        if category_id is not None:
            # Append new asset to the list with category
            repayment_surplus_loan_with_categories.append((new_liabilities_name, category_id))
            new_loan_repyament_projections = self.create_user_loan_repayment_projection_table_1(dob, retirement_age, [(new_liabilities_name, category_id)], user_id, self.fetch_user_name(user_id),month_choice)
            dynamic_loan_surplus_repayment_projections_df = pd.concat([dynamic_loan_surplus_repayment_projections_df, pd.DataFrame(new_loan_repyament_projections)], ignore_index=True)
        else:
            st.write("Invalid liability name entered. No liability added.")

        return dynamic_loan_surplus_repayment_projections_df, repayment_surplus_loan_with_categories


    def run_loan_surplus_repayment_projections(self, user_id, month_choice):

        key = f"dynamic_loan_surplus_repayment_projections_df_{user_id}"
   
        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('dynamic_loan_surplus_repayment_projections'):
            # Only delete old records if the table exists
            self.delete_old_loan_surplus_repayments_records()

        # Load the existing data from the investment_projections table
        dynamic_loan_surplus_repayment_projections_df = self.load_dynamic_loan_surplus_repayment_projections_from_db(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)


        # Fetch distinct liabilities with their categories
        liabilities_with_categories = self.fetch_liabilities_for_loan_repayment(user_id)
        #print('liabilities_with_categories',liabilities_with_categories)
        liabilities_purpose = self.fetch_distinct_liabilities_purpose(user_id)
        print('liabilities_purpose',liabilities_purpose)
        # Update the projections based on user input
        distinct_liabilities_names = [liabilities for liabilities, _ in liabilities_with_categories] + [purpose for purpose, _ in liabilities_purpose]
        #print('distinct_liabilities_names',distinct_liabilities_names)

        if not self.user_exists_in_loan_surplus_repyament_db(user_id):
            if dynamic_loan_surplus_repayment_projections_df.empty:
                new_projections = self.create_loan_surplus_repayment_projection_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_loan_surplus_repayment_projections_df = pd.DataFrame(new_projections)
            else:
                new_projections = self.create_loan_surplus_repayment_projection_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_loan_surplus_repayment_projections_df = pd.concat([dynamic_loan_surplus_repayment_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

            # Pass user_id as an argument
            self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
        else:
            st.warning(f"User {user_id} already exists in the database. No new data will be appended.")
        

        # Reshape and display the existing investment projections for the user
        st.write("### loan repayment Projections")
        reshaped_df = self.reshape_loan_surplus_repayment_projections(dynamic_loan_surplus_repayment_projections_df, user_id)
        st.dataframe(reshaped_df)

        # Define milestone categories and purposes
        milestone_list = self.load_milestone_list()
 
        additional_liabilities_name = st.selectbox("Select asset name to add:", list(milestone_list.values()), key="loan_surplus_repayment_add_liability")
        if st.button("Add Milestone", key="loan_surplus_repayment_add_button"):
            #with st.spinner("Adding loan..."):
            repayment_surplus_loan_with_categories = self.fetch_liabilities_for_loan_repayment(user_id)
            dynamic_loan_surplus_repayment_projections_df, repayment_surplus_loan_with_categories = self.add_additional_loan_surplus_repayment(
                dynamic_loan_surplus_repayment_projections_df, milestone_list, repayment_surplus_loan_with_categories,
                user_id, dob, retirement_age, additional_liabilities_name, month_choice)
            
            self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
            st.success(f"Added {additional_liabilities_name} to projections and saved to the database.")
            dynamic_loan_surplus_repayment_projections_df = self.load_dynamic_loan_surplus_repayment_projections_from_db(user_id)

        # Update projections based on growth or other entry types
        entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'), key="loan_surplus_entry_type")
        
        
        if entry_type == 'single':
            single_date = st.date_input("Select date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))
            # Convert single_date to a string for comparison or database use
            single_date_str = single_date.strftime('%Y-%m-%d')
            #print('single_date in run investment',single_date)
            #asset_name = st.text_input("Enter the asset name:")
           
            liability_name = st.selectbox("Select liability name:", distinct_liabilities_names, key="loan_surplus_liability_name")
            #print('asset_name in all run fun',asset_name)
            #amount = st.number_input("Enter amount:")
            amount = st.number_input("Enter amount:", value=0.0, key="loan_surplus_amount")  # Convert amount to integer
            print('amount in all run fun',amount)
            if st.button("Apply Single Date Update", key="apply_loan_surplus_single_update"):
                # Update the investment projections
                dynamic_loan_surplus_repayment_projections_df = self.update_dynamic_loan_surplus_repayment_projections(
                    user_id, dynamic_loan_surplus_repayment_projections_df, 
                    distinct_liabilities_names,  # Use the original names
                    entry_type=entry_type, 
                    single_date=single_date_str, 
                    increment_params={'amount': amount, 'liability_name': liability_name}  # Pass asset name without trimming
                )
                # Save the updated projections immediately after the update
                self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
                st.success("Single date update applied and saved to the database.")

        elif entry_type == 'range':
            start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="loan_surplus_start_date")
            #start_date_str = start_date.strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="loan_surplus_end_date")
            #end_date_str = end_date.strftime('%Y-%m-%d')
            liability_name = st.selectbox("Select asset name for range:", distinct_liabilities_names,key="loan_surplus_liability_range")
            amount = int(st.number_input("Enter amount for range:",value = 0,key="loan_surplus_range_amount"))
            if st.button("Apply Range Update",key="apply_loan_surplus_range_update"):
                dynamic_loan_surplus_repayment_projections_df = self.update_dynamic_loan_surplus_repayment_projections(user_id, dynamic_loan_surplus_repayment_projections_df, distinct_liabilities_names, entry_type=entry_type, range_dates=[start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')], increment_params={'amount': amount, 'liability_name': liability_name})
                self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
                st.success("Range date update applied and save to the database.")

        elif entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="loan_surplus_increment_date")
            percentage = st.number_input("Increment percentage:", key="loan_surplus_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="loan_surplus_end_date_increment")
            liability_name = st.selectbox("Select asset name for increment:", distinct_liabilities_names, key="loan_surplus_increment_liability")
            if st.button("Apply Increment Update",key="apply_loan_surplus_increment_update"):
                dynamic_loan_surplus_repayment_projections_df = self.update_dynamic_loan_surplus_repayment_projections(user_id, dynamic_loan_surplus_repayment_projections_df, distinct_liabilities_names, entry_type=entry_type, increment_params={'entry_date': entry_date.strftime('%Y-%m-%d'), 'percentage': percentage, 'end_date': end_date_increment.strftime('%Y-%m-%d'), 'liability_name': liability_name})
                self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
                st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
                st.success("Increment update applied and save to the database.")

        elif entry_type == 'stop':
            self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
            st.write("Stop function executed. No changes applied.")
        
        #self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
        # Functionality to delete an asset category from asset_name column
        st.write("## Delete an Asset Category")

        # Fetch distinct asset names for the dropdowns
        unique_liabilities_loanr_projections = dynamic_loan_surplus_repayment_projections_df[dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()
        
        # Dropdown for selecting an asset category to delete
        liability_to_delete = st.selectbox("Select liability category to delete from projections:", unique_liabilities_loanr_projections, key="loan_delete_liability")
        
        # Confirm deletion
        if st.button("Delete Selected Liability Category", key="delete_loan_surplus_repayment_liability"):
            dynamic_loan_surplus_repayment_projections_df = self.delete_liability_category_from_loan_surplus_repayment_proj(dynamic_loan_surplus_repayment_projections_df, user_id, liability_to_delete)
            self.save_dynamic_loan_surplus_repayment_projections_to_db(dynamic_loan_surplus_repayment_projections_df, user_id)
            st.session_state[key] = dynamic_loan_surplus_repayment_projections_df
            st.success(f"Liability category '{liability_to_delete}' has been deleted from projections for user_id {user_id}.")

        # Display the updated investment projections for the user
        st.write("### loan repayment Projections after changes:")
       
        # Reshape and display the existing investment projections for the user
        reshaped_df = self.reshape_loan_surplus_repayment_projections(dynamic_loan_surplus_repayment_projections_df, user_id)
        st.dataframe(reshaped_df) 

    def user_exists_in_loan_surplus_repyament_db(self, user_id):
        """Check if the user_id already exists in the PostgreSQL table."""
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('dynamic_loan_surplus_repayment_projections',schema = 'public'):
            print("Table 'dynamic_loan_surplus_repayment_projections' does not exist.")
            return False

        
        query = f"SELECT 1 FROM dynamic_loan_surplus_repayment_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None
        
    def delete_liability_category_from_loan_surplus_repayment_proj(self, dynamic_loan_surplus_repayment_projections_df, user_id, liability_name):
        
        return dynamic_loan_surplus_repayment_projections_df[~((dynamic_loan_surplus_repayment_projections_df['user_code'] == user_id) &
                                                  (dynamic_loan_surplus_repayment_projections_df['liabilities_name'] == liability_name))]






    #liabilities_projections
    def fetch_liabilities_for_liabilities_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT l.name AS liabilities_name, l.category_id
            FROM liabilities_milestone_table l
            JOIN milestones_category c ON l.category_id = c.id
            WHERE l.user_code = %s AND l.name IS NOT NULL AND l.name <> 'None';
        """, (user_id,))

        liabilities_with_categories = cursor.fetchall()
        cursor.close()

        return liabilities_with_categories

    def fetch_purpose_for_liabilities_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None'
            AND loan_funded = 'Yes';
        """, (user_id,))

        liabilities_purpose = cursor.fetchall()
        cursor.close()

        return liabilities_purpose 
    
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    def create_liabilities_projections_table(self, dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice):

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        liabilities_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in liabilities_purpose:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': purpose,  # Use purpose as liabilities_name
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return liabilities_projections

    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()
    
    # This function checks if category_id 142 exists for the user
    def check_category_142_liability(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM liabilities_milestone_table 
                WHERE user_code = %s AND category_id = 142;
            """, (user_code,))
            category_142_exists = cursor.fetchone() is not None
            cursor.close()
            return category_142_exists
        except Exception as e:
            print(f"An error occurred while checking for category_id 142: {e}")
            return False
        

    def check_milestone_liabilities(self, user_code):
        """Check if the user has milestone liabilities with loan_funded = 'Yes'."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM milestones_liabilities 
                WHERE user_code = %s AND loan_funded = 'Yes';
            """, (user_code,))
            milestone_exists = cursor.fetchone() is not None
            cursor.close()
            return milestone_exists
        except Exception as e:
            print(f"An error occurred while checking for milestone liabilities: {e}")
            return False    
    
    
    
    def update_dynamic_liabilities_projections(self, dynamic_liabilities_projections_df, user_code):

        # ==============================================================
        # Your unchanged "DO NOT TOUCH" block
        # ==============================================================
        category_142_exists = self.check_category_142_liability(user_code)
        milestone_liabilities_exist = self.check_milestone_liabilities(user_code)

        if dynamic_liabilities_projections_df.empty:
            st.warning(f"No liabilities available for user {user_code}. Creating an empty projection table.")
            columns = ['user_code', 'user_name', 'entry_date', 'age', 'category_id', 
                    'liabilities_name','liabilities_value']

            dtypes = {'user_code':'string','user_name':'string','entry_date':'string','age':'int64',
                    'category_id':'int64','liabilities_name':'string','liabilities_value':'float64'}

            dynamic_liabilities_projections_df = pd.DataFrame(columns=columns).astype(dtypes)
            self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_projections_df)
            return dynamic_liabilities_projections_df
        # ==============================================================


        # Always required
        df_loan = pd.read_sql("""
            SELECT entry_date, category_id, liabilities_name, liabilities_value
            FROM dynamic_loan_repayment_projections
            WHERE user_code = %s
        """, self.connection, params=(user_code,))
        df_loan['key'] = (
            df_loan['entry_date'].astype(str) + "|" +
            df_loan['category_id'].astype(str) + "|" +
            df_loan['liabilities_name'].str.upper().str.strip()
        )
        loan_map = df_loan.set_index('key')['liabilities_value'].to_dict()


        # Load CF only if needed
        if not category_142_exists:
            df_cf = pd.read_sql("""
                SELECT entry_date, category_id, liability_name AS liabilities_name, principal_remaining
                FROM all_cf_liabilities_calculation
                WHERE user_code = %s
            """, self.connection, params=(user_code,))
            df_cf['key'] = (
                df_cf['entry_date'].astype(str) + "|" +
                df_cf['category_id'].astype(str) + "|" +
                df_cf['liabilities_name'].str.upper().str.strip()
            )
            cf_map = df_cf.set_index('key')['principal_remaining'].to_dict()
        else:
            cf_map = {}


        # Load milestones only if needed
        if milestone_liabilities_exist:
            df_ms = pd.read_sql("""
                SELECT entry_date, category_id, liability_name AS liabilities_name, principal_remaining
                FROM cf_milestone_loan_calculation
                WHERE user_code = %s
            """, self.connection, params=(user_code,))
            df_ms['key'] = (
                df_ms['entry_date'].astype(str) + "|" +
                df_ms['category_id'].astype(str) + "|" +
                df_ms['liabilities_name'].str.upper().str.strip()
            )
            ms_map = df_ms.set_index('key')['principal_remaining'].to_dict()
        else:
            ms_map = {}


        # ============================================================
        # 2ï¸âƒ£ NOW LOOP FAST WITH NO SQL CALLS
        # ============================================================
        for idx, row in dynamic_liabilities_projections_df.iterrows():

            key = f"{row['entry_date']}|{row['category_id']}|{row['liabilities_name'].strip().upper()}"

            # 1. ALWAYS start with loan repayment (same as your code)
            liabilities_total = loan_map.get(key, 0.0)

            # 2. If category_142 does NOT exist â†’ overwrite with CF value
            if not category_142_exists:
                if key in cf_map:
                    liabilities_total = cf_map[key]    # overwrite exactly like your code

            # 3. Add milestone values if available
            if milestone_liabilities_exist:
                liabilities_total += ms_map.get(key, 0.0)

            dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = liabilities_total


        # ==============================================================
        # 3ï¸âƒ£ Your ZEROâ€‘LOGIC (unchanged)
        # ==============================================================

        for name in dynamic_liabilities_projections_df['liabilities_name'].unique():
            for cid in dynamic_liabilities_projections_df['category_id'].unique():

                block = dynamic_liabilities_projections_df[
                    (dynamic_liabilities_projections_df['liabilities_name'] == name) &
                    (dynamic_liabilities_projections_df['category_id'] == cid)
                ]

                started = False
                drop_flag = False

                for idx, row in block.iterrows():
                    val = row['liabilities_value']

                    if not started and val > 0:
                        started = True

                    if started and val < 1 and not drop_flag:
                        drop_flag = True

                    if drop_flag:
                        dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = 0

        return dynamic_liabilities_projections_df



   

    def apply_repayment_logic(self, dynamic_liabilities_projections_df, user_code): 
        # New logic for repayment with tracking already updated liabilities
        #updated_liabilities = set()  # Track liabilities already updated during previous runs    

        # New pop-up logic for repayment
        #apply_repayment = st.radio("Do you want to apply the repayment logic?", ["No", "Yes"], index=0)

        #if apply_repayment == "Yes":
        # Input pop-ups
        selected_entry_date = st.date_input("Select the entry_date to apply repayment:").strftime('%Y-%m-%d')
        liabilities_names = dynamic_liabilities_projections_df['liabilities_name'].unique()
        selected_liabilities_name = st.selectbox("Select the liabilities_name for repayment logic:", liabilities_names)


        if st.button("run the carry forward existing loan repayment", key = 'all existing liabilities repayment'):
            # Fetch principal amount from all_cf_liabilities_calculation  (âœ” same table as original code 1)
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT entry_date, principal
                FROM all_cf_liabilities_calculation
                WHERE user_code = %s AND liability_name = %s;
            """, (user_code, selected_liabilities_name))

            principal_data = cursor.fetchall()
            principal_df = pd.DataFrame(principal_data, columns=['entry_date', 'principal'])
            principal_df['entry_date'] = principal_df['entry_date'].astype(str)

            # Fetch liabilities_value from dynamic_loan_repayment_projections
            cursor.execute("""
                SELECT entry_date, liabilities_value 
                FROM dynamic_loan_repayment_projections
                WHERE user_code = %s AND liabilities_name = %s;
            """, (user_code, selected_liabilities_name))

            loan_repayment_data = cursor.fetchall()
            loan_repayment_df = pd.DataFrame(loan_repayment_data, columns=['entry_date', 'liabilities_value'])
            loan_repayment_df['entry_date'] = loan_repayment_df['entry_date'].astype(str)

            # Find the index of the selected entry date
            matching_rows = dynamic_liabilities_projections_df[
                (dynamic_liabilities_projections_df['entry_date'] == selected_entry_date) &
                (dynamic_liabilities_projections_df['liabilities_name'] == selected_liabilities_name)
            ]

            if matching_rows.empty:
                st.error(f"No matching entry found for {selected_entry_date} and liability {selected_liabilities_name}")
                return dynamic_liabilities_projections_df

            start_index = matching_rows.index[0]

            # Iterate from the selected entry date onwards
            for idx in range(start_index, len(dynamic_liabilities_projections_df)):

                row = dynamic_liabilities_projections_df.iloc[idx]

                if row['liabilities_name'] == selected_liabilities_name:

                    # ---- Get previous liabilities_value ----
                    if idx == start_index:
                        prev_value = row['liabilities_value']
                    else:
                        previous_rows = dynamic_liabilities_projections_df.iloc[:idx]
                        previous_matching_rows = previous_rows[
                            previous_rows['liabilities_name'] == selected_liabilities_name
                        ]

                        if not previous_matching_rows.empty:
                            prev_row = previous_matching_rows.iloc[-1]
                            prev_value = prev_row['liabilities_value']
                        else:
                            prev_value = 0.0

                    # ---- Safe float conversion (prevents ValueError) ----
                    try:
                        prev_value_f = float(prev_value) if prev_value is not None else 0.0
                    except:
                        prev_value_f = 0.0

                    # Fetch principal for current date
                    matching_principal = principal_df[principal_df['entry_date'] == row['entry_date']]
                    principal_value = matching_principal['principal'].iloc[0] if not matching_principal.empty else 0.0

                    try:
                        principal_value_f = float(principal_value) if principal_value is not None else 0.0
                    except:
                        principal_value_f = 0.0

                    # Fetch loan repayment for current date
                    matching_loan = loan_repayment_df[loan_repayment_df['entry_date'] == row['entry_date']]
                    loan_repayment_value = matching_loan['liabilities_value'].iloc[0] if not matching_loan.empty else 0.0

                    try:
                        loan_repayment_value_f = float(loan_repayment_value) if loan_repayment_value is not None else 0.0
                    except:
                        loan_repayment_value_f = 0.0

                    # ---- Apply repayment logic safely ----
                    updated_value = prev_value_f - principal_value_f + loan_repayment_value_f
                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = updated_value


        if st.button("run the carry forward goal loan repayment", key = 'all milestones liabilities repayment'):
            # Fetch principal amount from all_cf_liabilities_calculation
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT entry_date, principal
                FROM cf_milestone_loan_calculation
                WHERE user_code = %s AND liability_name = %s;
            """, (user_code, selected_liabilities_name))
            principal_data = cursor.fetchall()
            principal_df = pd.DataFrame(principal_data, columns=['entry_date', 'principal'])
            principal_df['entry_date'] = principal_df['entry_date'].astype(str)

            # Fetch liabilities_value from dynamic_loan_repayment_projections
            cursor.execute("""
                SELECT entry_date, liabilities_value 
                FROM dynamic_loan_repayment_projections
                WHERE user_code = %s AND liabilities_name = %s;
            """, (user_code, selected_liabilities_name))
            loan_repayment_data = cursor.fetchall()
            loan_repayment_df = pd.DataFrame(loan_repayment_data, columns=['entry_date', 'liabilities_value'])
            loan_repayment_df['entry_date'] = loan_repayment_df['entry_date'].astype(str)

            # Apply logic to update liabilities_value
            # Find the index of the selected entry date
            matching_rows = dynamic_liabilities_projections_df[
                (dynamic_liabilities_projections_df['entry_date'] == selected_entry_date) &
                (dynamic_liabilities_projections_df['liabilities_name'] == selected_liabilities_name)
            ]
            
            if matching_rows.empty:
                st.error(f"No matching entry found for {selected_entry_date} and liability {selected_liabilities_name}")
                return dynamic_liabilities_projections_df
        
            start_index = matching_rows.index[0]
            #st.write('Start Index:', start_index)

            # Iterate from the selected entry date onwards
            for idx in range(start_index, len(dynamic_liabilities_projections_df)):  
                #st.write('Current index:', idx)
                row = dynamic_liabilities_projections_df.iloc[idx]

                if row['liabilities_name'] == selected_liabilities_name:
                    # Get previous row's liabilities_value for the same liabilities_name
                    if idx == start_index:
                        prev_value = row['liabilities_value']
                        #st.write('prev_value first loop:', prev_value)
                    else:
                        # Get all previous rows with the same liabilities_name
                        previous_rows = dynamic_liabilities_projections_df.iloc[:idx]
                        previous_matching_rows = previous_rows[previous_rows['liabilities_name'] == selected_liabilities_name]

                        if not previous_matching_rows.empty:
                            prev_row = previous_matching_rows.iloc[-1]
                            prev_value = prev_row['liabilities_value']
                            # st.write('prev_row:', prev_row)
                            # st.write('prev_value second loop:', prev_value)
                        else:
                            prev_value = 0.0
                            #st.write('No previous matching row found, using prev_value = 0.0')

                    #st.write('prev_value',prev_value)    

                    # Fetch principal for the current date
                    matching_principal = principal_df[principal_df['entry_date'] == row['entry_date']]
                    principal_value = matching_principal['principal'].iloc[0] if not matching_principal.empty else 0.0
                    #st.write('principal_value',principal_value)

                    # Fetch loan repayment for the current date
                    matching_loan = loan_repayment_df[loan_repayment_df['entry_date'] == row['entry_date']]
                    loan_repayment_value = matching_loan['liabilities_value'].iloc[0] if not matching_loan.empty else 0.0
                    #st.write('loan_repayment_value',loan_repayment_value)  

                    # ðŸ”‘ make sure all 3 are float before arithmetic
                    try:
                        prev_value_f = float(prev_value) if prev_value is not None else 0.0
                    except Exception:
                        prev_value_f = 0.0

                    try:
                        principal_value_f = float(principal_value) if principal_value is not None else 0.0
                    except Exception:
                        principal_value_f = 0.0

                    try:
                        loan_repayment_value_f = float(loan_repayment_value) if loan_repayment_value is not None else 0.0
                    except Exception:
                        loan_repayment_value_f = 0.0 


                    # Apply repayment logic
                    # repayment logic with normalized floats
                    updated_value = prev_value_f - principal_value_f + loan_repayment_value_f
                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = updated_value



        # New logic: if liabilities_value is less than 1 after projection starts, set it to 0 for that and subsequent entry dates
        for liabilities_name in dynamic_liabilities_projections_df['liabilities_name'].unique():
            for category_id in dynamic_liabilities_projections_df['category_id'].unique():
                category_data = dynamic_liabilities_projections_df[
                    (dynamic_liabilities_projections_df['liabilities_name'] == liabilities_name) &
                    (dynamic_liabilities_projections_df['category_id'] == category_id)
                ]

                projection_started = False
                value_below_1_found = False

                for idx, projection in category_data.iterrows():
                    current_value = projection['liabilities_value']

                    # Check if projection has started (i.e., first non-zero value)
                    if not projection_started and current_value > 0:
                        projection_started = True

                    # If projection has started and value is below 1, set subsequent values to 0
                    if projection_started:
                        if current_value < 1 and not value_below_1_found:
                            value_below_1_found = True

                        if value_below_1_found:
                            # Set liabilities_value to 0 for this and subsequent rows
                            dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = 0

        return dynamic_liabilities_projections_df
    

    def update_dynamic_liabilities_projections_with_flexi_term_loan(self, dynamic_liabilities_projections_df, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT 1
            FROM liabilities
            WHERE user_code = %s AND name = 'Flexi Term Loan ';
        """, (user_id,))

        flexi_term_loan_exists = cursor.fetchone() is not None

        if not flexi_term_loan_exists:
            return dynamic_liabilities_projections_df

        # Determine the first date for the Flexi Term Loan
        first_flexi_term_loan_date = dynamic_liabilities_projections_df.loc[
            dynamic_liabilities_projections_df['liabilities_name'] == 'Flexi Term Loan ', 'entry_date'
        ].min()

        if isinstance(first_flexi_term_loan_date, str):
            try:
                first_flexi_term_loan_date = datetime.strptime(first_flexi_term_loan_date, '%Y-%m-%d %H:%M:%S')
            except ValueError:
                first_flexi_term_loan_date = datetime.strptime(first_flexi_term_loan_date, '%Y-%m-%d')
        elif isinstance(entry_date, pd.Timestamp):
            first_flexi_term_loan_date = first_flexi_term_loan_date.to_pydatetime()
        #print(first_flexi_term_loan_date)

        # Iterate through the projections to update 'Flexi Term Loan'
        for idx, projection in dynamic_liabilities_projections_df.iterrows():
            if projection['liabilities_name'] == 'Flexi Term Loan ':
                entry_date = projection['entry_date']
                category_id = projection['category_id']

                        # Ensure entry_date is a datetime object
                if isinstance(entry_date, str):
                    try:
                        entry_date = datetime.strptime(entry_date, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        entry_date = datetime.strptime(entry_date, '%Y-%m-%d')
                elif isinstance(entry_date, pd.Timestamp):
                    entry_date = entry_date.to_pydatetime()

                # Convert entry_date to the text format used in dynamic_loan_repayment_projections
                entry_date_text = entry_date.strftime('%Y-%m-%d')

                # Check if the entry_date is the first date for 'Flexi Term Loan'
                if entry_date == first_flexi_term_loan_date:
                    # Fetch the value from all_cf_liabilities_calculation for the current month
                    cursor = self.connection.cursor()
                    cursor.execute("""
                        SELECT end_balance 
                        FROM all_cf_liabilities_calculation
                        WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = 'Flexi Term Loan ';
                    """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
                    initial_value = cursor.fetchone()

                    cursor.execute("""
                        SELECT liabilities_value 
                        FROM dynamic_loan_repayment_projections
                        WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liabilities_name = 'Flexi Term Loan '
                    """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
                    repayment_value_1 = cursor.fetchone()


                    initial_value = float(initial_value[0]) if initial_value and initial_value[0] is not None else 0.0
                    repayment_value_1 = float(repayment_value_1[0]) if repayment_value_1 and repayment_value_1[0] is not None else 0.0

                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = initial_value + repayment_value_1

                    #print('initial_value',initial_value)
                    #dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = initial_value
                else:
                    previous_date = entry_date - pd.DateOffset(months=1)
                    last_day_previous_month = previous_date + pd.offsets.MonthEnd(0)
                    print('last_day_previous_month',last_day_previous_month)

                    last_day_previous_month = last_day_previous_month.strftime('%Y-%m-%d')

                    print('last_day_previous_month',last_day_previous_month)
                    #print(dynamic_liabilities_projections_df['entry_date'])
                    # Retrieve the value for the last day of the previous month
                    previous_value = dynamic_liabilities_projections_df.loc[
                        (dynamic_liabilities_projections_df['entry_date'] == last_day_previous_month) & 
                        (dynamic_liabilities_projections_df['liabilities_name'] == 'Flexi Term Loan '), 
                        'liabilities_value'
                    ].values

                    #print('previous value',previous_value)

                    if len(previous_value) > 0:
                        previous_value = previous_value[0]
                    else:
                        previous_value = 0.0

                    # Fetch the current month's repayment value
                    cursor.execute("""
                        SELECT liabilities_value 
                        FROM dynamic_loan_repayment_projections
                        WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liabilities_name = 'Flexi Term Loan '
                    """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
                    repayment_value = cursor.fetchone()
                    repayment_value = float(repayment_value[0]) if repayment_value else 0.0
                    #print('repayment_value',repayment_value)

                    # Update the current row with the new liabilities value
                    dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = previous_value + repayment_value


        #New logic: if liabilities_value is less than 1 after projection starts, set it to 0 for that and subsequent entry dates
        for liabilities_name in dynamic_liabilities_projections_df['liabilities_name'].unique():
            if liabilities_name == 'Flexi Term Loan ':  # Only apply to 'Flexi Term Loan'
                for category_id in dynamic_liabilities_projections_df['category_id'].unique():
                    category_data = dynamic_liabilities_projections_df[
                        (dynamic_liabilities_projections_df['liabilities_name'] == liabilities_name) &
                        (dynamic_liabilities_projections_df['category_id'] == category_id)
                    ]

                    projection_started = False
                    value_below_1_found = False

                    for idx, projection in category_data.iterrows():
                        current_value = projection['liabilities_value']

                        # Check if projection has started (i.e., first non-zero value)
                        if not projection_started and current_value > 0:
                            projection_started = True

                        # If projection has started and value is below 1, set subsequent values to 0
                        if projection_started:
                            if current_value < 1 and not value_below_1_found:
                                value_below_1_found = True

                            if value_below_1_found:
                                # Set liabilities_value to 0 for this and subsequent rows
                                dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = 0            

        return dynamic_liabilities_projections_df

    def save_dynamic_liabilities_projections_df_to_db(self, dynamic_liabilities_projections_df):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        dynamic_liabilities_projections_df.to_sql('dynamic_liabilities_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_liabilities_projections'")

    def load_dynamic_liabilities_projections_df_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_liabilities_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_liabilities_projections' does not exist.")
            dynamic_liabilities_projections_df = pd.DataFrame()
        else:
            dynamic_liabilities_projections_df = pd.read_sql('dynamic_liabilities_projections', engine)

        return dynamic_liabilities_projections_df

    def reshape_dynamic_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df   


    def reshape_display_dynamic_liabilities_projections(self, dynamic_liabilities_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)

        return reshaped_df 
    
    def user_exists_in_liabilities_proj_db(self, user_id):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        inspector = inspect(engine)
        if not inspector.has_table('dynamic_liabilities_projections'):
            print("Table 'dynamic_liabilities_projections' does not exist.")
            return False

        query = f"SELECT 1 FROM dynamic_liabilities_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(query)
            return result.fetchone() is not None
    
    def clear_existing_liabilities_data_for_user(self, user_id):
        # Delete existing data for the user_id from the dynamic_assets_projections table
        cursor = self.connection.cursor()
        cursor.execute("TRUNCATE TABLE dynamic_liabilities_projections;")
        self.connection.commit()
        cursor.close()
        print(f"Existing data for user_id {user_id} has been cleared.")

    def run_dynamic_liabilities_projections(self, user_code, dob, retirement_age, month_choice):

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        drop_liability_table = st.radio("Do you want to drop the liability table?", ["No", "Yes"], index=0)

        if drop_liability_table == "Yes":
            if inspector.has_table('dynamic_liabilities_projections', schema='public'):
                with engine.connect() as connection:
                    connection.execute(text("DROP TABLE dynamic_liabilities_projections;"))
                    st.success("dynamic_liabilities_projections table has been dropped successfully.")
                    return
            else:
                st.warning("The dynamic_liabilities_projections table does not exist.")
        
        # if inspector.has_table('dynamic_liabilities_projections'):
        #     # Only delete old records if the table exists
        #     self.clear_existing_liabilities_data_for_user(user_id)

        liabilities_with_categories = self.fetch_liabilities_for_liabilities_projections(user_code)  
        liabilities_purpose = self.fetch_purpose_for_liabilities_projections(user_code)  
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_code)
        dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()

        # # âœ… If the DataFrame is empty, stop execution & display a message
        # if dynamic_liabilities_projections_df.empty:
        #     st.warning("No liabilities data available. Please check your input or add data before proceeding.")
        #     return  # Stop execution here
        
        if dynamic_liabilities_projections_df.empty:
            new_projections = self.create_liabilities_projections_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
            dynamic_liabilities_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_liabilities_projections_df['user_code'].unique():
                new_projections = self.create_liabilities_projections_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_liabilities_projections_df = pd.DataFrame(new_projections)

        if st.radio("Do you want to update the liabilities projection?", ["No", "Yes"], index=0, key='update the loan repayment table') == "Yes":
            dynamic_liabilities_projections_df = self.update_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_code)
            st.success("Liabilities projections have been updated.")

        # Ask if user wants to apply repayment logic
        if st.radio("Do you want to apply the repayment logic?", ["No", "Yes"], index=0, key ='update the loan repayment logic') == "Yes":
            dynamic_liabilities_projections_df = self.apply_repayment_logic(dynamic_liabilities_projections_df, user_code)
            st.success("Repayment logic applied to the selected liabilities.")

        #dynamic_liabilities_projections_df = self.update_dynamic_liabilities_projections_with_flexi_term_loan(dynamic_liabilities_projections_df, user_code)

        self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_projections_df)   
        st.write('liabilities projections updated') 

        # Display the updated investment projections for the user
        st.write("### Liabilities Projections after changes:")        
       
        # âœ… Ensure DataFrame is not empty before calling reshape function
        if not dynamic_liabilities_projections_df.empty:
            reshaped_df = self.reshape_display_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_code)
            st.dataframe(reshaped_df)
        else:
            st.warning("No data available for reshaping. Skipping projection display.")

           

    #liabilities outflows
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age  
    
    def fetch_liabilities_for_liabilities_outflows(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT l.name AS liabilities_name, l.category_id
            FROM liabilities_milestone_table l
            JOIN milestones_category c ON l.category_id = c.id
            WHERE l.user_code = %s AND l.name IS NOT NULL AND l.name <> 'None';
        """, (user_id,))

        liabilities_with_categories = cursor.fetchall()
        cursor.close()

        return liabilities_with_categories
    
    def fetch_purpose_for_liabilities_outflows(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None'
            AND loan_funded = 'Yes';
        """, (user_id,))

        liabilities_purpose = cursor.fetchall()
        cursor.close()

        return liabilities_purpose
    
    def create_liabilities_outflows_projections_table(self, dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice):
    
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        liabilities_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add liabilities from liabilities table
            for liabilities_name, category_id in liabilities_with_categories:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': liabilities_name,
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in liabilities_purpose:
                liabilities_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'liabilities_name': purpose,  # Use purpose as liabilities_name
                    'liabilities_value': 0  # Initialize liability value to 0
                }
                liabilities_projections.append(liabilities_projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)   

        return liabilities_projections

    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()
    
    # This function checks if category_id 142 exists for the user
    def check_category_142_liability(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM liabilities_milestone_table 
                WHERE user_code = %s AND category_id = 142;
            """, (user_code,))
            category_142_exists = cursor.fetchone() is not None
            cursor.close()
            return category_142_exists
        except Exception as e:
            print(f"An error occurred while checking for category_id 142: {e}")
            return False
        
    def check_milestone_liabilities(self, user_code):
        """Check if the user has milestone liabilities with loan_funded = 'Yes'."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM milestones_liabilities 
                WHERE user_code = %s AND loan_funded = 'Yes';
            """, (user_code,))
            milestone_exists = cursor.fetchone() is not None
            cursor.close()
            return milestone_exists
        except Exception as e:
            print(f"An error occurred while checking for milestone liabilities: {e}")
            return False     
    
    def update_dynamic_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id, dob):
        # Convert entry_date in dynamic_liabilities_outflows_projections_df to datetime format
        category_142_exists = self.check_category_142_liability(user_id)
        milestone_liabilities_exist = self.check_milestone_liabilities(user_id)

        # Check if the DataFrame is empty and create one with required columns if it is
        if dynamic_liabilities_outflows_projections_df.empty:
            st.warning(f"No liabilities available for user {user_id}. Creating an empty projection table.")
            
            # Define the required columns for the DataFrame
            columns = ['user_code', 'user_name', 'entry_date', 'age', 'category_id', 'liabilities_name', 'liabilities_value']
            dtypes = {
            'user_code': 'string',           # equivalent to text in PostgreSQL
            'user_name': 'string',           # equivalent to text in PostgreSQL
            'entry_date': 'string',          # storing as text
            'age': 'int64',                  # equivalent to bigint in PostgreSQL
            'category_id': 'int64',          # equivalent to bigint in PostgreSQL
            'liabilities_name': 'string',    # equivalent to text in PostgreSQL
            'liabilities_value': 'float64'   # equivalent to double precision in PostgreSQL
            }

            # Create an empty DataFrame with these columns and data types
            dynamic_liabilities_outflows_projections_df = pd.DataFrame(columns=columns).astype(dtypes)             
        
            
            # Save the empty DataFrame to the database as the initial structure
            self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_outflows_projections_df)
            st.write(f"Empty liabilities projections table created for user {user_id}.")
            return dynamic_liabilities_outflows_projections_df

        for idx, projection in dynamic_liabilities_outflows_projections_df.iterrows():
            entry_date = projection['entry_date']
            #print('first entry_date',entry_date)
            category_id = projection['category_id']
            liabilities_name = projection['liabilities_name']
            cursor = self.connection.cursor()

            liabilities_total = 0  # Initialize liabilities total

            if not category_142_exists:
                # Fetch end_balance from all_cf_liabilities_calculation if category_id 142 is not present
                
                cursor.execute("""
                    SELECT emi 
                    FROM all_cf_liabilities_calculation
                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                """, (user_id, entry_date, category_id, liabilities_name))
                emi_value_1 = cursor.fetchone()
                emi_value_1 = float(emi_value_1[0]) if emi_value_1 and emi_value_1[0] is not None else 0.0
                liabilities_total += -emi_value_1 
                #print('existing entry_date', entry_date)
                #print('existing liabilities total', liabilities_total)   

            if milestone_liabilities_exist:
                # Fetch end_balance from cf_milestone_loan_calculation (this should always run)
                cursor.execute("""
                    SELECT emi 
                    FROM cf_milestone_loan_calculation
                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                """, (user_id, entry_date, category_id, liabilities_name))
                emi_value_2 = cursor.fetchone()
                emi_value_2 = float(emi_value_2[0]) if emi_value_2 and emi_value_2[0] is not None else 0.0 
                liabilities_total += -emi_value_2    
                #print('existing milestone entry_date', entry_date)
                #print('entry_date, existing milestone liabilities total', entry_date,liabilities_total) 

            # Update the DataFrame
            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = liabilities_total

        # Fetch the liabilities data from dynamic_liabilities_projections table
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, category_id, liabilities_name, liabilities_value 
            FROM dynamic_liabilities_projections 
            WHERE user_code = %s;
        """, (user_id,))

        liabilities_data = cursor.fetchall()
        cursor.close()

        # Convert liabilities data into a DataFrame for easier processing
        liabilities_df = pd.DataFrame(liabilities_data, columns=['entry_date', 'category_id', 'liabilities_name','liabilities_value'])

        # Define category IDs that should NOT have the above logic applied
        excluded_category_ids = [604, 57]  # You can add more category IDs in the future

        # Ask user if they want to apply logic for excluded category IDs
        apply_logic_to_excluded = st.selectbox(
            "Do you want to apply the above logic to category ID(s) that start from the middle of the projection?",
            ["No", "Yes"],
            format_func=lambda x: "Yes (Apply logic)" if x == "Yes" else "No (Do not apply logic)"
        )

        # Precompute last non-zero entry_date per (category_id, liabilities_name)
        last_non_zero_dates = (
            liabilities_df[liabilities_df['liabilities_value'] > 0]
            .groupby(['category_id', 'liabilities_name'])['entry_date']
            .max()
            .reset_index()
            .rename(columns={'entry_date': 'last_non_zero_entry_date'})
        )

        for idx, projection in dynamic_liabilities_outflows_projections_df.iterrows():
            entry_date = projection['entry_date']
            category_id = projection['category_id']
            liabilities_name = projection['liabilities_name']

            if category_id in excluded_category_ids and not apply_logic_to_excluded:
                continue

            matching_db_row = liabilities_df[
                (liabilities_df['entry_date'] == entry_date) &
                (liabilities_df['category_id'] == category_id) &
                (liabilities_df['liabilities_name'] == liabilities_name)
            ]

            if not matching_db_row.empty:
                liabilities_value = matching_db_row.iloc[0]['liabilities_value']
                #st.write('liabilities_value here',liabilities_value)

                override_as_emi = False
                match_last_date_row = last_non_zero_dates[
                    (last_non_zero_dates['category_id'] == category_id) &
                    (last_non_zero_dates['liabilities_name'] == liabilities_name)
                ]

                if not match_last_date_row.empty:
                    last_non_zero_entry_date = match_last_date_row.iloc[0]['last_non_zero_entry_date']
                    last_non_zero_entry_date = pd.to_datetime(last_non_zero_entry_date)
                    # Add one month
                    one_month_later = last_non_zero_entry_date + relativedelta(months=1)
                    # Get last day of the new month
                    last_day = monthrange(one_month_later.year, one_month_later.month)[1]
                    # Construct final extended_date as last day of that month
                    extended_date = one_month_later.replace(day=last_day)
                    #st.write('extended_date',extended_date)

                    # âœ… Core fix: allow one extra EMI month beyond last non-zero date
                    if entry_date == extended_date.strftime('%Y-%m-%d') and category_id in excluded_category_ids:
                        override_as_emi = True

                if not matching_db_row.empty:
                    liabilities_value = matching_db_row.iloc[0]['liabilities_value']

                    if liabilities_value == 0:
                        if override_as_emi:
                            cursor = self.connection.cursor()
                            emi_val = 0.0

                            if not category_142_exists:
                                cursor.execute("""
                                    SELECT emi 
                                    FROM all_cf_liabilities_calculation
                                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                                """, (user_id, entry_date, category_id, liabilities_name))
                                result = cursor.fetchone()
                                if result and result[0] is not None:
                                    emi_val += -float(result[0])
                                    #st.write('emi_val 1', emi_val)

                            if milestone_liabilities_exist:
                                cursor.execute("""
                                    SELECT emi 
                                    FROM cf_milestone_loan_calculation
                                    WHERE user_code = %s AND entry_date = %s AND category_id = %s AND liability_name = %s
                                """, (user_id, entry_date, category_id, liabilities_name))
                                result = cursor.fetchone()
                                if result and result[0] is not None:
                                    emi_val += -float(result[0])
                                    #st.write('emi_val 2', emi_val)

                            cursor.close()
                            #st.write('emi_value',emi_val)
                            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = emi_val
                        else:
                            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = 0

        return dynamic_liabilities_outflows_projections_df
    
    
    def save_dynamic_liabilities_outflows_projections_df_to_db(self, dynamic_liabilities_outflows_projections_df):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table
        dynamic_liabilities_outflows_projections_df.to_sql('dynamic_liabilities_outflows_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_liabilities_outflows_projections'")
        
    
    def load_dynamic_liabilities_outflows_projections_df_from_db(self):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_liabilities_outflows_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_liabilities_outflows_projections' does not exist.")
            dynamic_liabilities_outflows_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_liabilities_outflows_projections_df = pd.read_sql('dynamic_liabilities_outflows_projections', engine)

        return dynamic_liabilities_outflows_projections_df

    def reshape_dynamic_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df 
    
    def reshape_display_dynamic_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('liabilities_name', inplace=True)
        return reshaped_df 
    
    def user_exists_in_liabilities_outflows_proj_db(self, user_id):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        inspector = inspect(engine)
        if not inspector.has_table('dynamic_liabilities_outflows_projections'):
            print("Table 'dynamic_liabilities_outflows_projections' does not exist.")
            return False

        query = f"SELECT 1 FROM dynamic_liabilities_outflows_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(query)
            return result.fetchone() is not None

    def clear_dynamic_liabilities_outflows_projections(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_liabilities_outflows_projections;")
            self.connection.commit()
            print("Cleared the dynamic_liabilities_outflows_projections table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_liabilities_outflows_projections table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()  

    def update_dynamic_liabilities_outflows_values(self, user_id, dynamic_liabilities_outflows_projections_df):
        st.markdown("### Optional Manual Update for Liabilities Outflows")
        add_updates = st.radio("Do you want to add values in the outflows table?", ('No', 'Yes'), key="update_outflows_toggle")

        if add_updates == 'Yes':
            distinct_liabilities_names = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()

            entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'), key="loan_entry_type")

            if entry_type == 'single':
                single_date = st.date_input("Select date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))
                single_date_str = single_date.strftime('%Y-%m-%d')
                liability_name = st.selectbox("Select liability name:", distinct_liabilities_names, key="loan_liability_name")
                amount = st.number_input("Enter amount:", value=0.0, key="loan_amount")

                if st.button("Apply Single Date Update", key="apply_loan_single_update"):
                    for idx, projection in dynamic_liabilities_outflows_projections_df.iterrows():
                        if (projection['user_code'] == user_id and projection['entry_date'] == single_date_str and projection['liabilities_name'].strip().lower() == liability_name.strip().lower()):
                            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = -abs(amount)
                    st.success("Single date update applied.")
                    self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)

            elif entry_type == 'range':
                start_date = st.date_input("Start Date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="loan_start_date")
                end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="loan_end_date")
                liability_name = st.selectbox("Select liability name for range:", distinct_liabilities_names, key="loan_liability_range")
                amount = st.number_input("Enter amount for range:", value=0.0, key="loan_range_amount")

                if st.button("Apply Range Update", key="apply_loan_range_update"):
                    for idx, projection in dynamic_liabilities_outflows_projections_df.iterrows():
                        if (projection['user_code'] == user_id and start_date.strftime('%Y-%m-%d') <= projection['entry_date'] <= end_date.strftime('%Y-%m-%d') and projection['liabilities_name'].strip().lower() == liability_name.strip().lower()):
                            dynamic_liabilities_outflows_projections_df.at[idx, 'liabilities_value'] = -abs(amount)
                    st.success("Range update applied.")
                    self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)

            elif entry_type == 'stop':
                st.info("No updates applied.")

        return dynamic_liabilities_outflows_projections_df


    def run_dynamic_liabilities_outflows_projections(self, user_id, month_choice):

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('dynamic_liabilities_outflows_projections'):
                # Only delete old records if the table exists
                print('data has been clear')
                self.clear_dynamic_liabilities_outflows_projections()
        # Fetch required data
        liabilities_with_categories = self.fetch_liabilities_for_liabilities_outflows(user_id)
        liabilities_purpose = self.fetch_purpose_for_liabilities_outflows(user_id)
        user_name = self.fetch_user_name(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()

        if dynamic_liabilities_outflows_projections_df.empty:
            new_projections = self.create_liabilities_outflows_projections_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
            dynamic_liabilities_outflows_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_liabilities_outflows_projections_df['user_code'].unique():
                new_projections = self.create_liabilities_outflows_projections_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
                dynamic_liabilities_outflows_projections_df = pd.DataFrame(new_projections)


        # # Reshape and display the existing liabilities projections for the user
        # reshaped_df = self.reshape_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
        # st.dataframe(reshaped_df)    

        # Update the projections based on user input
        dynamic_liabilities_outflows_projections_df = self.update_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id, dob)

        # Save the updated DataFrame to the PostgreSQL database
        self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)
        st.write("liabilities outflows projections updated")  

        # âœ… Ensure DataFrame is not empty before calling reshape function
        if not dynamic_liabilities_outflows_projections_df.empty:
            reshaped_df = self.reshape_display_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
            st.dataframe(reshaped_df)
        else:
            st.warning("No data available for reshaping. Skipping projection display.")  


    
    # def run_dynamic_liabilities_outflows_projections(self, user_id, month_choice):
    #     connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #     engine = create_engine(connection_string)
    #     inspector = inspect(engine)

    #     user_exists = self.user_exists_in_liabilities_outflows_proj_db(user_id)

    #     # âœ… Only clear table if table exists AND user does NOT already have data
    #     if inspector.has_table('dynamic_liabilities_outflows_projections') and not user_exists:
    #         self.clear_dynamic_liabilities_outflows_projections()

    #     # Fetch required data
    #     liabilities_with_categories = self.fetch_liabilities_for_liabilities_outflows(user_id)
    #     liabilities_purpose = self.fetch_purpose_for_liabilities_outflows(user_id)
    #     user_name = self.fetch_user_name(user_id)
    #     dob, retirement_age = self.fetch_user_data(user_id)

    #     # Load the table
    #     dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()

    #     # âœ… Only create new data if not already present for this user
    #     if not user_exists:
    #         new_projections = self.create_liabilities_outflows_projections_table(dob, retirement_age, liabilities_with_categories, liabilities_purpose, user_id, user_name, month_choice)
    #         if dynamic_liabilities_outflows_projections_df.empty:
    #             dynamic_liabilities_outflows_projections_df = pd.DataFrame(new_projections)
    #         else:
    #             dynamic_liabilities_outflows_projections_df = pd.concat([dynamic_liabilities_outflows_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

    #         # âœ… Run default projection logic ONLY on first setup
    #         dynamic_liabilities_outflows_projections_df = self.update_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id, dob)

    #         # âœ… Save after initial generation
    #         self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)

    #     # âœ… Load again after save or if user already exists
    #     dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()

    #     # âœ… Always allow user to add updates interactively (manual step)
    #     dynamic_liabilities_outflows_projections_df = self.update_dynamic_liabilities_outflows_values(user_id, dynamic_liabilities_outflows_projections_df)

    #     # âœ… Save final combined table with all updates
    #     self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)

    #     st.write("Liabilities outflows projections updated and saved.")

    #     # âœ… Display reshaped table
    #     if not dynamic_liabilities_outflows_projections_df.empty:
    #         reshaped_df = self.reshape_display_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
    #         st.dataframe(reshaped_df)
    #     else:
    #         st.warning("No data available for reshaping. Skipping projection display.")

    def update_dynamic_assets_values(self, user_id, dynamic_assets_projections_df):
        st.markdown("### Optional Manual Update for Assets Projections")
        add_updates = st.radio("Do you want to add values in the assets table?", ('No', 'Yes'), key="update_assets_values_toggle")

        if add_updates == 'Yes':
            distinct_asset_names = dynamic_assets_projections_df[dynamic_assets_projections_df['user_code'] == user_id]['assets_name'].unique().tolist()
            entry_type = st.radio("Choose entry type for assets: ", ('single', 'range', 'increment', 'stop'), key="asset_entry_type")

            if entry_type == 'single':
                single_date = st.date_input("Select date for asset update:", key="single_asset_date")
                single_date_str = single_date.strftime('%Y-%m-%d')
                asset_name = st.selectbox("Select asset name:", distinct_asset_names, key="single_asset_name")
                amount = st.number_input("Enter asset value:", value=0.0, key="single_asset_amount")

                if st.button("Apply Single Asset Update", key="apply_asset_single_update"):
                    for idx, row in dynamic_assets_projections_df.iterrows():
                        if (row['user_code'] == user_id and row['entry_date'] == single_date_str and row['assets_name'].strip().lower() == asset_name.strip().lower()):
                            dynamic_assets_projections_df.at[idx, 'assets_value'] = float(amount)
                    st.success("Single asset update applied.")
                    self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)

            elif entry_type == 'range':
                start_date = st.date_input("Start Date for asset:", key="asset_range_start")
                end_date = st.date_input("End Date for asset:", key="asset_range_end")
                asset_name = st.selectbox("Select asset name for range:", distinct_asset_names, key="range_asset_name")
                amount = st.number_input("Enter amount for asset range:", value=0.0, key="range_asset_amount")

                if st.button("Apply Range Asset Update", key="apply_asset_range_update"):
                    for idx, row in dynamic_assets_projections_df.iterrows():
                        if (row['user_code'] == user_id and start_date.strftime('%Y-%m-%d') <= row['entry_date'] <= end_date.strftime('%Y-%m-%d') and row['assets_name'].strip().lower() == asset_name.strip().lower()):
                            dynamic_assets_projections_df.at[idx, 'assets_value'] = float(amount)
                    st.success("Range asset update applied.")
                    self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)

            elif entry_type == 'stop':
                st.info("No updates applied.")

        return dynamic_assets_projections_df

    def update_dynamic_insurance_values(self, user_id, dynamic_insurance_outflows_projections_df):
        st.markdown("### Optional Manual Update for Insurance Outflows")
        add_updates = st.radio("Do you want to add values in the insurance table?", ('No', 'Yes'), key="update_insurance_values_toggle")

        if add_updates == 'Yes':
            distinct_insurance_names = dynamic_insurance_outflows_projections_df[dynamic_insurance_outflows_projections_df['user_code'] == user_id]['insurance_name'].unique().tolist()
            entry_type = st.radio("Choose entry type for insurance: ", ('single', 'range', 'increment', 'stop'), key="insurance_entry_type")

            if entry_type == 'single':
                single_date = st.date_input("Select date for insurance update:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="single_insurance_date")
                single_date_str = single_date.strftime('%Y-%m-%d')
                insurance_name = st.selectbox("Select insurance name:", distinct_insurance_names, key="single_insurance_name")
                amount = st.number_input("Enter insurance value:", value=0.0, key="single_insurance_amount")

                if st.button("Apply Single Insurance Update", key="apply_insurance_single_update"):
                    for idx, row in dynamic_insurance_outflows_projections_df.iterrows():
                        if (row['user_code'] == user_id and row['entry_date'] == single_date_str and row['insurance_name'].strip().lower() == insurance_name.strip().lower()):
                            dynamic_insurance_outflows_projections_df.at[idx, 'insurance_value'] = -abs(amount)
                    st.success("Single insurance update applied.")
                    self.save_dynamic_insurance_outflows_projections_df_to_db(dynamic_insurance_outflows_projections_df)

            elif entry_type == 'range':
                start_date = st.date_input("Start Date for insurance:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="insurance_range_start")
                end_date = st.date_input("End Date for insurance:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="insurance_range_end")
                insurance_name = st.selectbox("Select insurance name for range:", distinct_insurance_names, key="range_insurance_name")
                amount = st.number_input("Enter amount for insurance range:", value=0.0, key="range_insurance_amount")

                if st.button("Apply Range Insurance Update", key="apply_insurance_range_update"):
                    for idx, row in dynamic_insurance_outflows_projections_df.iterrows():
                        if (row['user_code'] == user_id and start_date.strftime('%Y-%m-%d') <= row['entry_date'] <= end_date.strftime('%Y-%m-%d') and row['insurance_name'].strip().lower() == insurance_name.strip().lower()):
                            dynamic_insurance_outflows_projections_df.at[idx, 'insurance_value'] = -abs(amount)
                    st.success("Range insurance update applied.")
                    self.save_dynamic_insurance_outflows_projections_df_to_db(dynamic_insurance_outflows_projections_df)

            elif entry_type == 'stop':
                st.info("No updates applied.")

        return dynamic_insurance_outflows_projections_df


    def update_dynamic_liabilities_values(self, user_id, dynamic_liabilities_projections_df):
        st.markdown("### Optional Manual Update for Liabilities Values")
        add_updates = st.radio("Do you want to add values in the outflows table?", ('No', 'Yes'), key="update_liabilities_toggle_1")

        if add_updates == 'Yes':
            distinct_liabilities_names = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]['liabilities_name'].unique().tolist()

            entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'), key="loan_entry_liability_type")

            if entry_type == 'single':
                single_date = st.date_input("Select date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))
                single_date_str = single_date.strftime('%Y-%m-%d')
                liability_name = st.selectbox("Select liability name:", distinct_liabilities_names, key="loan_liability_name_1")
                amount = st.number_input("Enter amount:", value=0.0, key="loan_amount_liability")

                if st.button("Apply Single Date Update", key="apply_loan_liability_single_update"):
                    for idx, projection in dynamic_liabilities_projections_df.iterrows():
                        if (projection['user_code'] == user_id and projection['entry_date'] == single_date_str and projection['liabilities_name'].strip().lower() == liability_name.strip().lower()):
                            dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = amount
                    st.success("Single date update applied.")
                    self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_projections_df) 

            elif entry_type == 'range':
                start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="loan_start_date")
                end_date = st.date_input("End Date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="loan_end_date")
                liability_name = st.selectbox("Select liability name for range:", distinct_liabilities_names, key="loan_liability_range")
                amount = st.number_input("Enter amount for range:", value=0.0, key="loan_range_amount_liability")

                if st.button("Apply Range Update", key="apply_loan_range_update_1"):
                    for idx, projection in dynamic_liabilities_projections_df.iterrows():
                        if (projection['user_code'] == user_id and start_date.strftime('%Y-%m-%d') <= projection['entry_date'] <= end_date.strftime('%Y-%m-%d') and projection['liabilities_name'].strip().lower() == liability_name.strip().lower()):
                            dynamic_liabilities_projections_df.at[idx, 'liabilities_value'] = amount
                    st.success("Range update applied.")
                    self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_projections_df) 

            elif entry_type == 'stop':
                st.info("No updates applied.")

        return dynamic_liabilities_projections_df    

    def update_dynamic_milestone_values(self, user_id, milestone_df):
        """
        UI to optionally update milestone_calculation_projections.milestone_value
        for the given user by single date or range, mirroring code number 1 behavior.
        """
        # st.markdown("### Optional Manual Update for Milestone Projections")
        # add_updates = st.radio(
        #     "Do you want to add values in the milestone table?",
        #     ('No', 'Yes'),
        #     key="update_milestone_values_toggle"
        # )

        #if add_updates == 'Yes':
        # Collect distinct goals for this user
        user_mask = milestone_df['user_code'].astype(str) == str(user_id)
        distinct_milestone_names = (
            milestone_df.loc[user_mask, 'milestone_name']
            .dropna()
            .astype(str)
            .unique()
            .tolist()
        )

        entry_type = st.radio(
            "Choose entry type for milestones:",
            ('single', 'range', 'stop'),
            key="milestone_entry_type"
        )

        # --- SINGLE date set ---
        if entry_type == 'single':
            single_date = st.date_input("Select date for milestone update:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="single_milestone_date")
            single_date_str = single_date.strftime('%Y-%m-%d')

            milestone_name = st.selectbox( "Select milestone name:", distinct_milestone_names, key="single_milestone_name")
            amount = st.number_input("Enter milestone value:", value=0.0, key="single_milestone_amount")

            if st.button("Apply Single Milestone Update", key="apply_milestone_single_update"):
                # Update matching rows
                mask = (
                    (milestone_df['user_code'].astype(str) == str(user_id)) &
                    (milestone_df['entry_date'].astype(str) == single_date_str) &
                    (milestone_df['milestone_name'].astype(str).str.strip().str.lower()
                        == str(milestone_name).strip().lower())
                )
                milestone_df.loc[mask, 'milestone_value'] = float(amount)
                st.success("Single milestone update applied.")
                self.save_milestone_calculation_projections_to_db(milestone_df)
                # fresh = self.load_milestone_calculation_projections_from_db()
                # st.dataframe(self.display_reshape_milestone_projections(fresh, user_id))

        # --- RANGE set ---
        elif entry_type == 'range':
            start_date = st.date_input("Start Date for milestone:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="milestone_range_start")
            end_date = st.date_input("End Date for milestone:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="milestone_range_end")

            milestone_name = st.selectbox(
                "Select milestone name for range:",
                distinct_milestone_names,
                key="range_milestone_name"
            )
            amount = st.number_input(
                "Enter milestone value for date range:",
                value=0.0,
                key="range_milestone_amount"
            )

            if st.button("Apply Range Milestone Update", key="apply_milestone_range_update"):
                start_str = start_date.strftime('%Y-%m-%d')
                end_str = end_date.strftime('%Y-%m-%d')

                mask = (
                    (milestone_df['user_code'].astype(str) == str(user_id)) &
                    (milestone_df['entry_date'].astype(str) >= start_str) &
                    (milestone_df['entry_date'].astype(str) <= end_str) &
                    (milestone_df['milestone_name'].astype(str).str.strip().str.lower()
                        == str(milestone_name).strip().lower())
                )
                milestone_df.loc[mask, 'milestone_value'] = float(amount)
                st.success("Range milestone update applied.")
                self.save_milestone_calculation_projections_to_db(milestone_df)
                # fresh = self.load_milestone_calculation_projections_from_db()
                # st.dataframe(self.display_reshape_milestone_projections(fresh, user_id))

        # --- STOP ---
        elif entry_type == 'stop':
            st.info("No updates applied.")

        return milestone_df    


    def update_assets_and_liabilities_projections(self, user_id):

        # âœ… Second pop-up: Assets Projections
        update_assets = st.radio("Do you want to update the assets projections table?", ('No', 'Yes'), key="update_assets_toggle")

        if update_assets == 'Yes':
            dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
            dynamic_assets_projections_df = self.update_dynamic_assets_values(user_id, dynamic_assets_projections_df)
            #self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)

            st.write("Assets projections updated and saved.")

            reshaped_df = self.display_reshape_dynamic_assets_projections(dynamic_assets_projections_df, user_id)
            st.dataframe(reshaped_df)
            #self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)


        # âœ… Second pop-up: liabilities Projections
        update_liabilities = st.radio("Do you want to update the liabilities projections table?", ('No', 'Yes'), key="update_liabilities_toggle_2")

        if update_liabilities == 'Yes':
            dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()
            dynamic_liabilities_projections_df = self.update_dynamic_liabilities_values(user_id, dynamic_liabilities_projections_df)
            #self.save_dynamic_liabilities_projections_df_to_db(dynamic_liabilities_projections_df)   

            st.write("liabilities projections updated and saved.")

            # âœ… Ensure DataFrame is not empty before calling reshape function
            if not dynamic_liabilities_projections_df.empty:
                reshaped_df = self.reshape_display_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_id)
                st.dataframe(reshaped_df)
            else:
                st.warning("No data available for reshaping. Skipping projection display.")    

        # âœ… First pop-up: Liabilities Outflows
        update_liabilities_outflows = st.radio("Do you want to update the liabilities outflows table?", ('No', 'Yes'), key="update_liabilities_outflows_toggle")

        if update_liabilities_outflows == 'Yes':
            dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()
            dynamic_liabilities_outflows_projections_df = self.update_dynamic_liabilities_outflows_values(user_id, dynamic_liabilities_outflows_projections_df)
            #self.save_dynamic_liabilities_outflows_projections_df_to_db(dynamic_liabilities_outflows_projections_df)

            st.write("Liabilities outflows projections updated and saved.")

            if not dynamic_liabilities_outflows_projections_df.empty:
                reshaped_df = self.reshape_display_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
                st.dataframe(reshaped_df)
            else:
                st.warning("No data available for reshaping. Skipping projection display.")


        # âœ… Third pop-up: Insurance Projections
        update_insurance = st.radio("Do you want to update the insurance outflows table?", ('No', 'Yes'), key="update_insurance_toggle")

        if update_insurance == 'Yes':
            dynamic_insurance_outflows_projections_df = self.load_dynamic_insurance_outflows_projections_df_from_db()
            dynamic_insurance_outflows_projections_df = self.update_dynamic_insurance_values(user_id, dynamic_insurance_outflows_projections_df)
            #self.save_dynamic_insurance_outflows_projections_df_to_db(dynamic_insurance_outflows_projections_df)

            st.write("Insurance outflows projections updated and saved.")

            reshaped_df = self.reshape_display_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
            st.dataframe(reshaped_df)


        # === Manual milestone updates (same UX as code number 1) ===
        update_milestones = st.radio("Do you want to update the milestone_calculation_projections table?", ('No', 'Yes'), key="update_milestones_toggle")

        if update_milestones == 'Yes':
            # Always pull fresh (so the user edits whatâ€™s actually stored)
            milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
            milestone_calculation_projections_df = self.update_dynamic_milestone_values(user_id, milestone_calculation_projections_df)
            st.write("Milestone projections updated and saved.")

            # Display the updated milestone projections in a table
            st.write("### Milestone Calculation Projections after changes:")
            milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
            reshaped_df = self.display_reshape_milestone_projections(milestone_calculation_projections_df, user_id)
            st.dataframe(reshaped_df)       
            
        

        

    #Insurance outflows
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age  
    
    def fetch_distinct_insurance_names(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT i.name AS insurance_name, i.category_id
            FROM insurance i
            WHERE user_code = %s AND name IS NOT NULL AND name <> 'None' AND is_active = true;
        """, (user_id,))

        distinct_insurance_names = cursor.fetchall()
        cursor.close()

        return distinct_insurance_names
    
    def create_insurance_outflows_projections_table(self, dob, retirement_age, distinct_insurance_names, user_id, user_name, month_choice):
    
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        insurances_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            # Add insurance from insurance table
            for insurance_name, category_id in distinct_insurance_names:
                insurance_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'insurance_name': insurance_name,  # Use insurance_name as liabilities_name
                    'insurance_value': 0  # Initialize liability value to 0
                }
                insurances_projections.append(insurance_projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)   

        return insurances_projections

    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()
    
    # This function checks if category_id 142 exists for the user
    def check_category_143_insurance(self, user_code):
        try:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT 1
                FROM insurance 
                WHERE user_code = %s AND category_id = 143;
            """, (user_code,))
            category_143_exists = cursor.fetchone() is not None
            cursor.close()
            return category_143_exists
        except Exception as e:
            print(f"An error occurred while checking for category_id 143: {e}")
            return False    
    
    def update_dynamic_insurance_outflows_projections(self, dynamic_insurance_outflows_projections_df, user_id, dob):
        # Convert entry_date in dynamic_liabilities_outflows_projections_df to datetime format
        category_143_exists = self.check_category_143_insurance(user_id)

        # Check if the DataFrame is empty and create one with required columns if it is
        if dynamic_insurance_outflows_projections_df.empty:
            st.warning(f"No insurance available for user {user_id}. Creating an empty projection table.")
            
            # Define the required columns for the DataFrame
            columns = ['user_code', 'user_name', 'entry_date', 'age', 'category_id', 'insurance_name', 'insurance_value']
            dtypes = {
            'user_code': 'string',           # equivalent to text in PostgreSQL
            'user_name': 'string',           # equivalent to text in PostgreSQL
            'entry_date': 'string',          # storing as text
            'age': 'int64',                  # equivalent to bigint in PostgreSQL
            'category_id': 'int64',          # equivalent to bigint in PostgreSQL
            'insurance_name': 'string',    # equivalent to text in PostgreSQL
            'insurance_value': 'float64'   # equivalent to double precision in PostgreSQL
            }

            # Create an empty DataFrame with these columns and data types
            dynamic_insurance_outflows_projections_df = pd.DataFrame(columns=columns).astype(dtypes)             
         
            # Save the empty DataFrame to the database as the initial structure
            #self.save_dynamic_insurance_projections_df_to_db(dynamic_insurance_outflows_projections_df)
            st.write(f"Empty insurance projections table created for user {user_id}.")
            return dynamic_insurance_outflows_projections_df

    

        if not category_143_exists:
    
            #dynamic_insurance_outflows_projections_df['entry_date'] = pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']).astype(str)
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT name, last_date, start_date, annual_premium, payment_frequency
                FROM insurance
                WHERE user_code = %s AND (category_id = 101 OR category_id = 102 OR category_id = 228 OR category_id = 231 OR category_id = 230) and is_active = TRUE;
            """, (user_id,))

            insurance_data = cursor.fetchall()
            #st.write('insurance_data',insurance_data)
            cursor.close()


            for insurance_name, last_date, start_date, annual_premium, payment_frequency in insurance_data:
                #st.write('insurance_name',insurance_name)
                #start_date = datetime.strptime(start_date, '%Y-%m-%d')
                #last_date = datetime.strptime(last_date, '%Y-%m-%d')
                # current_year = datetime.now().year
                # current_month = datetime.now().month
                # last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
                # start_date = last_day_of_current_month
                if start_date is None or last_date is None:
                # Skip processing if start_date or last_date is None
                    continue
                
                #print('last_date',last_date)
                last_date = pd.to_datetime(last_date)  # Ensure last_date is datetime64[ns]
                start_date = pd.to_datetime(start_date)  # Ensure start_date is datetime64[ns]
                last_date = last_date.replace(day=monthrange(last_date.year, last_date.month)[1])  # Ensure last_date is the last day of the month
                start_date = start_date.replace(day=monthrange(start_date.year, start_date.month)[1]) 
                #print('after last_date',last_date)
                #print('after start_date', start_date)
                while start_date <= last_date:
                    if payment_frequency == 1:
                        matching_rows = dynamic_insurance_outflows_projections_df[
                            (dynamic_insurance_outflows_projections_df['insurance_name'] == insurance_name) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']).dt.month == start_date.month) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']) >= start_date) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']) <= last_date)
                        ]
                        #st.write('display matching_rows',matching_rows)
                        # if not matching_rows.empty:
                        #     dynamic_liabilities_outflows_projections_df.loc[
                        #         (dynamic_liabilities_outflows_projections_df['liabilities_name'] == insurance_name) &
                        #         (pd.to_datetime(dynamic_liabilities_outflows_projections_df['entry_date']).dt.month == start_date.month),
                        #         'liabilities_value'
                        #     ] = -abs(annual_premium)   
                        if not matching_rows.empty:
                            dynamic_insurance_outflows_projections_df.loc[
                            matching_rows.index,
                            'insurance_value'
                        ] = -abs(annual_premium)    


                    # NEW: handle quarterly payments (payment_frequency == 4)
                    elif payment_frequency == 4:
                        matching_rows = dynamic_insurance_outflows_projections_df[
                            (dynamic_insurance_outflows_projections_df['insurance_name'] == insurance_name) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']).dt.month == start_date.month) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']) >= start_date) &
                            (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']) <= last_date)
                        ]
                        if not matching_rows.empty:
                            dynamic_insurance_outflows_projections_df.loc[
                                matching_rows.index,
                                'insurance_value'
                            ] = -abs(float(annual_premium)) / 4.0

                        # Move by one quarter and snap to month-end, then continue loop
                        start_date = start_date + pd.DateOffset(months=3)
                        start_date = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
                        continue

                    #print('start_date',start_date)
                    #start_date = (start_date + timedelta(days=32)).replace(day=1)  # Move to the next month  
                    #start_date = (start_date + timedelta(days=365)).replace(month=1, day=1)
                    start_date = start_date + pd.DateOffset(years=1)
                    start_date = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

                    #start_date = start_date + pd.offsets.MonthEnd(0)  
                    #start_date = start_date.date()
                    print('start_date',start_date)    


            # Check for category_id 64 (health insurance) in the insurance table
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT name, start_date, last_date, annual_premium, payment_frequency
                FROM insurance
                WHERE user_code = %s AND category_id = 64 AND is_active = TRUE;
            """, (user_id,))
            health_insurance_data = cursor.fetchall()
            #print('health_insurance_data',health_insurance_data)

            health_inflation = st.number_input("Enter the inflation rate:", value=5.0, key="health_inflation") / 100
            #print('in out of loop start date',start_date)
            for name, start_date, last_date, annual_premium, payment_frequency in health_insurance_data:
                #annual_premium = annual_premium
                if start_date == datetime(1, 1, 1).date():  # Check for the default date 0001-01-01
                    st.write(f"Start date for {name} is not set.")
                    start_date_input = st.date_input(f"Enter start date for {name}:")
                    start_date = pd.to_datetime(start_date_input)

                # Convert start_date to last day of its month
                start_date = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

                if last_date is None or pd.isna(last_date):
                    last_date = pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']).max()

                # Determine premium multiplier based on frequency
                if payment_frequency == 1:
                    multiplier = 1
                elif payment_frequency == 2:
                    multiplier = 0.5
                elif payment_frequency == 3:
                    multiplier = 2
                elif payment_frequency == 4:
                    multiplier = 0.25
                elif payment_frequency == 5:
                    multiplier = 3
                elif payment_frequency == 12:
                    multiplier = 1/12
                else:
                    multiplier = 1  # Default case    

                # Initialize insurance value (negative premium)
                current_liabilities_value = -abs(annual_premium * multiplier)
                
                # Start from the given start date (now last day of the month)
                start_date_1 = pd.to_datetime(start_date)

                while start_date_1 <= last_date:
                    # Filter rows matching the exact date (last day of month)
                    matching_rows = dynamic_insurance_outflows_projections_df[
                        (dynamic_insurance_outflows_projections_df['insurance_name'] == name) &
                        (pd.to_datetime(dynamic_insurance_outflows_projections_df['entry_date']) == start_date_1)
                    ]

                    if not matching_rows.empty:
                        dynamic_insurance_outflows_projections_df.loc[
                            matching_rows.index,
                            'insurance_value'
                        ] = current_liabilities_value

                    # Apply inflation to the next period
                    current_liabilities_value *= (1 + health_inflation)

                    # Move to next entry based on frequency
                    if payment_frequency == 1:
                        start_date_1 += pd.DateOffset(years=1)
                    elif payment_frequency == 2:
                        start_date_1 += pd.DateOffset(months=6)
                    elif payment_frequency == 3:
                        start_date_1 += pd.DateOffset(years=2)
                    elif payment_frequency == 4:
                        start_date_1 += pd.DateOffset(months=3)
                    elif payment_frequency == 5:
                        start_date_1 += pd.DateOffset(years=3)
                    elif payment_frequency == 12:
                        start_date_1 += pd.DateOffset(months=1)
                    else:
                        start_date_1 += pd.DateOffset(years=1)  # Default fallback

                    # Ensure the next start_date is the last day of the month
                    start_date_1 = start_date_1.replace(day=monthrange(start_date_1.year, start_date_1.month)[1]) 


                # print('name',name)
                # print('in loop start_date', start_date)
                # print('in loop last_date', last_date)
                # print('in loop annual_premium',annual_premium)
                # print('in loop payment_frequency',payment_frequency)          

            # Convert entry_date column to text datatype
            dynamic_insurance_outflows_projections_df['entry_date'] = dynamic_insurance_outflows_projections_df['entry_date'].astype(str)


        return dynamic_insurance_outflows_projections_df
    
    
    def save_dynamic_insurance_outflows_projections_df_to_db(self, dynamic_insurance_outflows_projections_df):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Save the DataFrame to PostgreSQL table
        dynamic_insurance_outflows_projections_df.to_sql('dynamic_insurance_outflows_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_insurance_outflows_projections'")
        
    
    def load_dynamic_insurance_outflows_projections_df_from_db(self):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_insurance_outflows_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_insurance_outflows_projections' does not exist.")
            dynamic_insurance_outflows_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_insurance_outflows_projections_df = pd.read_sql('dynamic_insurance_outflows_projections', engine)

        return dynamic_insurance_outflows_projections_df

    def reshape_dynamic_insurance_outflows_projections(self, dynamic_insurance_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_insurance_outflows_projections_df[dynamic_insurance_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='insurance_name', 
                                          columns=['entry_date', 'age'],
                                          values='insurance_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df 
    
    def reshape_display_dynamic_insurance_outflows_projections(self, dynamic_insurance_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_insurance_outflows_projections_df[dynamic_insurance_outflows_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='insurance_name', 
                                          columns=['entry_date', 'age'],
                                          values='insurance_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('insurance_name', inplace=True)
        return reshaped_df 

    def clear_dynamic_insurance_outflows_projections(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_insurance_outflows_projections;")
            self.connection.commit()
            print("Cleared the dynamic_insurance_outflows_projections table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_insurance_outflows_projections table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()   

    def reshape_display_insurance_outflows_projections(self, dynamic_insurance_outflows_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_insurance_outflows_projections_df[dynamic_insurance_outflows_projections_df['user_code'] == user_id]
        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='insurance_name', 
                                        columns=['entry_date', 'age'],
                                        values='insurance_value', 
                                        aggfunc='sum', 
                                        fill_value=0)

        # Reset the index to bring insurance_name as a column for better readability
        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('insurance_name', inplace=True)  # Set asset_name as index
        
        return reshaped_df        
    
    def run_dynamic_insurance_outflows_projections(self, user_id, month_choice):

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('dynamic_insurance_outflows_projections'):
                # Only delete old records if the table exists
                print('data has been clear')
                self.clear_dynamic_insurance_outflows_projections()
        # Fetch required data
        distinct_insurance_names = self.fetch_distinct_insurance_names(user_id)
        user_name = self.fetch_user_name(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)

        # Load existing data from the database
        dynamic_insurance_outflows_projections_df = self.load_dynamic_insurance_outflows_projections_df_from_db()

        if dynamic_insurance_outflows_projections_df.empty:
            new_projections = self.create_insurance_outflows_projections_table(dob, retirement_age, distinct_insurance_names, user_id, user_name, month_choice)
            dynamic_insurance_outflows_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_insurance_outflows_projections_df['user_code'].unique():
                new_projections = self.create_insurance_outflows_projections_table(dob, retirement_age, distinct_insurance_names, user_id, user_name, month_choice)
                dynamic_insurance_outflows_projections_df = pd.DataFrame(new_projections)


        # Reshape and display the existing liabilities projections for the user
        #reshaped_df = self.reshape_display_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
        #st.dataframe(reshaped_df)    

        # Update the projections based on user input
        dynamic_insurance_outflows_projections_df = self.update_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id, dob)

        # Save the updated DataFrame to the PostgreSQL database
        self.save_dynamic_insurance_outflows_projections_df_to_db(dynamic_insurance_outflows_projections_df)
        st.write("insurance outflows projections updated")  

        # Reshape and display the existing liabilities projections for the user
        reshaped_df = self.reshape_display_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
        st.dataframe(reshaped_df)      

    #surplus related withdrawal
    def fetch_assets_with_categories_1(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT a.name AS asset_name, a.category_id
            FROM assets_milestones a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
        """, (user_id,))

        assets_with_categories = cursor.fetchall()
        cursor.close()

        return assets_with_categories
    
    def fetch_purpose_for_surplusr_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None'
            AND loan_funded = 'Yes' and category_id IN (604,609);
        """, (user_id,))

        surplus_relate_purpose = cursor.fetchall()
        cursor.close()

        return surplus_relate_purpose
    

    def create_surplus_related_withdrawal_projection_table(self, dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        surplusr_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for asset_name, category_id in assets_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': asset_name,
                    #'asset': 0,         # Initialize asset to 0
                    #'liabilities': 0,    # Initialize liabilities to 0
                    'asset_value': 0,  # Initialize asset value to 0
                }
                surplusr_projections.append(projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in surplus_relate_purpose:
                surplusr_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': purpose,  # Use purpose as liabilities_name
                    'asset_value': 0  # Initialize liability value to 0
                }
                surplusr_projections.append(surplusr_projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return surplusr_projections
    
    def create_surplus_related_withdrawal_projection_table_1(self, dob, retirement_age, assets_with_categories, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        surplusr_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for asset_name, category_id in assets_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'asset_name': asset_name,
                    #'asset': 0,         # Initialize asset to 0
                    #'liabilities': 0,    # Initialize liabilities to 0
                    'asset_value': 0,  # Initialize asset value to 0
                }
                surplusr_projections.append(projection_data)    

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return surplusr_projections
    

    # def load_surplus_withdrawal_projections_from_db(self):
    #     connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #     engine = create_engine(connection_string)

    #     table_exists_query = text("""
    #         SELECT EXISTS (
    #             SELECT FROM information_schema.tables 
    #             WHERE table_name = 'surplus_withdrawal_projections'
    #         );
    #     """)

    #     with engine.connect() as connection:
    #         table_exists = connection.execute(table_exists_query).scalar_one()

    #     if not table_exists:
    #         print("Table 'surplus_withdrawal_projections' does not exist.")
    #         surplus_withdrawal_projections_df = pd.DataFrame()  # Return an empty DataFrame
    #     else:
    #         surplus_withdrawal_projections_df = pd.read_sql('surplus_withdrawal_projections', engine)

    #     return surplus_withdrawal_projections_df    


    def load_surplus_withdrawal_projections_from_db(self, user_id):
        """Loads investment projections from DB only once per session."""
        
        key = f"surplus_withdrawal_projections_df_{user_id}"

        if key not in st.session_state:
            # Load only user_id rows for speed
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            # Safety: table may not exist on first run
            inspector = inspect(engine)
            if not inspector.has_table("surplus_withdrawal_projections"):
                st.session_state[key] = pd.DataFrame()
                return st.session_state[key]


            query = """
                SELECT *
                FROM surplus_withdrawal_projections
                WHERE user_code = %s
            """
            st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

        return st.session_state[key]

    
    # def save_surplus_withdrawal_projections_to_db(self, surplus_withdrawal_projections_df, user_id):
    #     connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #     engine = create_engine(connection_string)

    #     # Use inspect to check if the table exists
    #     inspector = inspect(engine)
    #     if not inspector.has_table('surplus_withdrawal_projections'):
    #         print("Table 'surplus_withdrawal_projections' does not exist. Creating the table.")
    #         surplus_withdrawal_projections_df.head(0).to_sql(
    #             'surplus_withdrawal_projections',
    #             engine,
    #             if_exists='replace',  # Create table
    #             index=False
    #         )
    #     else:
    #         print(f"Table 'surplus_withdrawal_projections' already exists.")

    #     with engine.connect() as connection:
    #         existing_data = pd.read_sql('surplus_withdrawal_projections', connection)

    #     existing_data = existing_data[existing_data['user_code'] != user_id]
    #     updated_data = pd.concat([existing_data, surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]])
    #     updated_data = updated_data.drop_duplicates().reset_index(drop=True)

    #     updated_data.to_sql('surplus_withdrawal_projections', engine, if_exists='replace', index=False)
    #     print("surplus_withdrawal_projections saved to the PostgreSQL database.")


    # def save_surplus_withdrawal_projections_to_db(self, surplus_withdrawal_projections_df, user_id):
    #     # Fast & safe engine setup (no fast_executemany for psycopg2)
    #     connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #     engine = create_engine(connection_string, pool_pre_ping=True, pool_recycle=3600)

    #     inspector = inspect(engine)
    #     if not inspector.has_table('surplus_withdrawal_projections'):
    #         print("Table 'surplus_withdrawal_projections' does not exist. Creating table.")
    #         surplus_withdrawal_projections_df.head(0).to_sql(
    #             'surplus_withdrawal_projections',
    #             engine,
    #             if_exists='replace',
    #             index=False
    #         )

    #     # Parameterized delete for safety
    #     delete_sql = text("""
    #         DELETE FROM surplus_withdrawal_projections
    #         WHERE user_code = :uid;
    #     """)

    #     with engine.begin() as conn:
    #         conn.execute(delete_sql, {"uid": user_id})

    #     # Filter for current user's records
    #     user_rows = surplus_withdrawal_projections_df[
    #         surplus_withdrawal_projections_df["user_code"] == user_id
    #     ]

    #     # Write to DB in chunks (if data exists)
    #     if not user_rows.empty:
    #         user_rows.to_sql(
    #             "surplus_withdrawal_projections",
    #             engine,
    #             if_exists="append",
    #             index=False,
    #             method="multi",
    #             chunksize=10000  # Larger batch size improves speed
    #         )

    #     st.success("âœ… Surplus withdrawal projections saved successfully.")

    def save_surplus_withdrawal_projections_to_db(self, df, user_id):
        import psycopg2
        from io import StringIO

        # Build connection string for psycopg2
        dsn = f"dbname={self.db_config['database']} user={self.db_config['user']} password={self.db_config['password']} host={self.db_config['host']} port={self.db_config['port']}"

        # Filter only the user rows
        df_user = df[df["user_code"] == user_id].copy()

        # Convert DataFrame to CSV buffer for COPY
        buffer = StringIO()
        df_user.to_csv(buffer, index=False, header=False)
        buffer.seek(0)

        # Connect using psycopg2 for COPY
        conn = psycopg2.connect(dsn)
        cur = conn.cursor()

        # Delete existing user rows
        cur.execute("DELETE FROM surplus_withdrawal_projections WHERE user_code = %s", (user_id,))

        # COPY = ULTRA FAST BULK INSERT
        copy_sql = """
            COPY surplus_withdrawal_projections
            FROM STDIN WITH CSV;
        """
        cur.copy_expert(copy_sql, buffer)

        conn.commit()
        cur.close()
        conn.close()

        st.success("ðŸš€ Data saved in under 1 second using PostgreSQL COPY!")






    def add_additional_asset_for_surplus_withdrawal(self, surplus_withdrawal_projections_df, assets_dict, assets_with_categories, user_id, dob, retirement_age, asset_name, month_choice):

        # Check if the asset_name already exists for the user
        user_specific_df = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]
        # Extract unique asset names from the user's specific data, then strip spaces and convert to lowercase
        unique_existing_assets = [asset.strip().lower() for asset in user_specific_df['asset_name'].unique()]
        stripped_asset_name = asset_name.strip().lower()

        # Temporarily strip spaces from the asset_name for comparison
        if stripped_asset_name in unique_existing_assets:
            #exact_matches = sum(1 for existing in unique_existing_assets if existing == stripped_asset_name)
            existing_count = sum(1 for existing in unique_existing_assets if existing.strip().lower().startswith(stripped_asset_name))
            print('exact_matches check', existing_count)
            new_asset_name = f"{asset_name.strip()} {existing_count + 1}"
            
            # Retrieve category_id from the DataFrame, handling extra spaces
            category_id = surplus_withdrawal_projections_df.loc[
                surplus_withdrawal_projections_df['asset_name'].str.strip().str.lower() == stripped_asset_name, 
                'category_id'
            ].values[0]
        else:
            new_asset_name = asset_name
            category_id = next((cat_id for cat_id, name in assets_dict.items() if name == asset_name), None)

        if category_id is not None:
            # Append new asset to the list with category
            assets_with_categories.append((new_asset_name, category_id))
            new_projections = self.create_surplus_related_withdrawal_projection_table_1(dob, retirement_age, [(new_asset_name, category_id)], user_id, self.fetch_user_name(user_id),month_choice)
            surplus_withdrawal_projections_df = pd.concat([surplus_withdrawal_projections_df, pd.DataFrame(new_projections)], ignore_index=True)
        else:
            st.write("Invalid asset name entered. No asset added.")

        return surplus_withdrawal_projections_df, assets_with_categories    
    

    def update_surplus_related_withdrawal_projections(self, user_id, surplus_withdrawal_projections_df, distinct_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        unique_asset_names = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()
        #st.write("Current unique assets:", unique_asset_names)

        if entry_type == 'single':
            print('single_date', single_date)
            asset_name = increment_params.get('asset_name')  # Asset name passed from frontend
            print('asset_name',asset_name)
            amount = increment_params.get('amount')
            print('amount',amount)

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return surplus_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'") 

            #Apply the update for the matched asset name on the given single date
            #updated = False
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == single_date and projection['asset_name'] == matched_asset_name):
                    surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(amount)
                    #surplus_withdrawal_projections_df.at[idx, 'liabilities'] = 0  # Use your liabilities logic if needed
                    #updated = True
                    #print(f"Successfully updated asset: '{matched_asset_name}' for date: {single_date} with amount: {amount}")

                    # Calculate `asset_value` as the sum of `asset` and `liabilities`
                    #surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(
                        #surplus_withdrawal_projections_df.at[idx, 'asset'] + surplus_withdrawal_projections_df.at[idx, 'liabilities'])

            #if not updated:
                #print(f"No record updated for asset: {matched_asset_name} on date: {single_date}")        

        elif entry_type == 'range':
            asset_name = increment_params.get('asset_name')
            amount = increment_params.get('amount')

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return surplus_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")

            # Apply update for the range of dates
            start_date, end_date = range_dates
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and start_date <= projection['entry_date'] <= end_date and projection['asset_name'] == matched_asset_name):
                    surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(amount)
                    #surplus_withdrawal_projections_df.at[idx, 'liabilities'] = 0  # Use your liabilities logic if needed

                    # Calculate `asset_value` as the sum of `asset` and `liabilities`
                    #surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(
                        #surplus_withdrawal_projections_df.at[idx, 'asset'] + surplus_withdrawal_projections_df.at[idx, 'liabilities'])

        elif entry_type == 'increment':
            asset_name = increment_params.get('asset_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return surplus_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['asset_name'] == matched_asset_name):
                    previous_amount = float(projection.get('asset_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return surplus_withdrawal_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['asset_name'] == matched_asset_name):
                    surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(incremented_amount)
                    #surplus_withdrawal_projections_df.at[idx, 'liabilities'] = 0  # Use your liabilities logic if needed
                    # Calculate `asset_value` as the sum of `asset` and `liabilities`
                    #surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(
                            #surplus_withdrawal_projections_df.at[idx, 'asset'] + surplus_withdrawal_projections_df.at[idx, 'liabilities'])

        return surplus_withdrawal_projections_df
    

    # Reshape the investment projections for the required format
    def reshape_surplus_related_withdrawal_projections(self, surplus_withdrawal_projections_df, user_id):
        # Filter data for the specified user
        user_df = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='asset_name', 
                                          columns=['entry_date', 'age'],
                                          values='asset_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df
    
    def reshape_display_surplus_related_withdrawal_projections(self, surplus_withdrawal_projections_df, user_id):
        # Filter data for the specified user
        user_df = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]
        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='asset_name', 
                                          columns=['entry_date', 'age'],
                                          values='asset_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df.columns = [f"{date},{age}" for date, age in reshaped_df.columns]
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('asset_name', inplace=True)  # Set asset_name as index
        
        return reshaped_df
    
    # Unpivoting the reshaped DataFrame
    def unpivot_reshaped_data(self, reshaped_df):
        """
        Unpivot the reshaped DataFrame back to its original format.
        """
        reshaped_df = reshaped_df.reset_index()

        # Melt the reshaped DataFrame to long format
        melted_df = reshaped_df.melt(id_vars='asset_name', var_name='entry_date_and_age', value_name='asset_value')
        
        # Split the `entry_date_and_age` column into `entry_date` and `age`
        melted_df[['entry_date', 'age']] = melted_df['entry_date_and_age'].str.split(',', expand=True)
        
        # Clean up columns
        melted_df['entry_date'] = melted_df['entry_date'].str.strip()  # Ensure no extra spaces
        melted_df['age'] = melted_df['age'].astype(int)  # Convert age to integer
        melted_df = melted_df.drop(columns=['entry_date_and_age'])  # Drop combined column

        return melted_df

    # Update Main DataFrame with New Values
    def update_main_dataframe(self, original_df, updated_df):
        """
        Update the original DataFrame with the values from the updated DataFrame.
        """
        # Convert entry_date in both DataFrames to ensure proper matching
        updated_df['entry_date'] = pd.to_datetime(updated_df['entry_date'])
        original_df['entry_date'] = pd.to_datetime(original_df['entry_date'])

        # Merge updated values into the original DataFrame
        for index, row in updated_df.iterrows():
            original_df.loc[
                (original_df['user_code'] == user_id) &
                (original_df['asset_name'] == row['asset_name']) &
                (original_df['entry_date'] == row['entry_date']), 'asset_value'
            ] = row['asset_value']

        updated_df['entry_date'] = updated_df['entry_date'].astype(str)
        original_df['entry_date'] = original_df['entry_date'].astype(str)    

        return original_df
    
    # Unpivoting the reshaped DataFrame of liabilities
    def liabilities_unpivot_reshaped_data(self, reshaped_df):

        reshaped_df = reshaped_df.reset_index()

        # Melt the reshaped DataFrame to long format
        melted_df = reshaped_df.melt(id_vars='liabilities_name', var_name='entry_date_and_age', value_name='liabilities_value')
        
        # Split the `entry_date_and_age` column into `entry_date` and `age`
        melted_df[['entry_date', 'age']] = melted_df['entry_date_and_age'].str.split(',', expand=True)
        
        # Clean up columns
        melted_df['entry_date'] = melted_df['entry_date'].str.strip()  # Ensure no extra spaces
        melted_df['age'] = melted_df['age'].astype(int)  # Convert age to integer
        melted_df = melted_df.drop(columns=['entry_date_and_age'])  # Drop combined column

        return melted_df

    # Update Main DataFrame with New Values
    def liabilities_update_main_dataframe(self, original_df, updated_df):
    
        # Convert entry_date in both DataFrames to ensure proper matching
        updated_df['entry_date'] = pd.to_datetime(updated_df['entry_date'])
        original_df['entry_date'] = pd.to_datetime(original_df['entry_date'])

        # Merge updated values into the original DataFrame
        for index, row in updated_df.iterrows():
            original_df.loc[
                (original_df['user_code'] == user_id) &
                (original_df['liabilities_name'] == row['liabilities_name']) &
                (original_df['entry_date'] == row['entry_date']), 'liabilities_value'
            ] = row['liabilities_value']

        updated_df['entry_date'] = updated_df['entry_date'].astype(str)
        original_df['entry_date'] = original_df['entry_date'].astype(str)    

        return original_df

    
    # Function to delete records with entry_date less than the current date
    def delete_old_surplus_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM surplus_withdrawal_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        st.write(f"Records with entry_date less than {current_date} have been deleted.")

    def copy_withdrawal_values(self, user_id, surplus_withdrawal_projections_df, unique_assets_surplus_projections):
        if st.radio("Do you want to copy the amount directly into the withdrawal table?", ["No", "Yes"], key="copy_withdrawal_choice") == "Yes":

            table_choice = st.radio(
                "From which table do you want to copy the values into withdrawal table?",
                ("insurance", "expense category"),
                key="source_table_choice"
            )

            if table_choice == "insurance":
                    start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="insurance_copy_start")
                    end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="insurance_copy_end")
                    asset_name = st.selectbox("Select asset name for mapping:", unique_assets_surplus_projections, key="insurance_asset_mapping")
                    if st.button('Copy the Insurance value',key= 'Copy_insurance'):
                        insurance_df = self.load_dynamic_insurance_outflows_projections_df_from_db()
                        insurance_df['entry_date'] = pd.to_datetime(insurance_df['entry_date'])
                        insurance_df = insurance_df[
                            (insurance_df['user_code'] == user_id) &
                            (insurance_df['entry_date'] >= pd.to_datetime(start_date)) &
                            (insurance_df['entry_date'] <= pd.to_datetime(end_date))
                        ]
                        insurance_df_grouped = insurance_df.groupby('entry_date')['insurance_value'].sum().reset_index()
                        insurance_df_grouped['entry_date'] = insurance_df_grouped['entry_date'].dt.strftime('%Y-%m-%d')

                        for _, row in insurance_df_grouped.iterrows():
                            surplus_withdrawal_projections_df.loc[
                                (surplus_withdrawal_projections_df['user_code'] == user_id) &
                                (surplus_withdrawal_projections_df['entry_date'] == row['entry_date']) &
                                (surplus_withdrawal_projections_df['asset_name'] == asset_name),
                                'asset_value'
                            ] = row['insurance_value']

                        st.success("Insurance values copied to withdrawal table.")
                        self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

            elif table_choice == "expense category":
                
                    start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_copy_start")
                    end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_copy_end")

                    additional_income_expense_df = self.load_additional_income_expense_criteria_df_from_db()
                    filtered_df = additional_income_expense_df[additional_income_expense_df['user_code'] == user_id]

                    existing_categories = filtered_df['expense_category_name'].unique()
                    expense_category_name = st.selectbox("Select an existing expense category:", existing_categories, key="expense_category_selector")
            
                    asset_name = st.selectbox("Select asset name for mapping:", unique_assets_surplus_projections, key="expense_asset_mapping")

                    if st.button('Copy the Insurance value',key= 'Copy_insurance'):
                        filtered_df = filtered_df[
                            (filtered_df['expense_category_name'] == expense_category_name) &
                            (filtered_df['entry_date'] >= pd.to_datetime(start_date)) &
                            (filtered_df['entry_date'] <= pd.to_datetime(end_date))
                        ]
                        filtered_df['entry_date'] = filtered_df['entry_date'].dt.strftime('%Y-%m-%d')

                        for _, row in filtered_df.iterrows():
                            surplus_withdrawal_projections_df.loc[
                                (surplus_withdrawal_projections_df['user_code'] == user_id) &
                                (surplus_withdrawal_projections_df['entry_date'] == row['entry_date']) &
                                (surplus_withdrawal_projections_df['asset_name'] == asset_name),
                                'asset_value'
                            ] = row['amount']

                        st.success("Expense category values copied to withdrawal table.")
                        self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

        return surplus_withdrawal_projections_df   

    def fill_weight_avg_withdrawal_values(self, user_id, surplus_withdrawal_projections_df):
        if st.radio("Do you want to add the amount by using the weighted average method in withdrawal table?", ["No", "Yes"], key="weighted_avg_choice") == "Yes":

            # Step 1: Entry date selection
            entry_date = st.date_input("Select the entry date for applying weighted average:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="weighted_avg_entry_date").strftime('%Y-%m-%d')

            # Step 2: Select milestone goal
            milestone_df = self.load_milestone_calculation_projections_from_db()
            milestone_df = milestone_df[milestone_df['user_code'] == user_id]
            existing_goals = milestone_df['milestone_name'].unique()

            if len(existing_goals) == 0:
                st.warning("No milestone goals found for this user.")
                return surplus_withdrawal_projections_df
            
            milestone_name = st.selectbox("Select an existing goal category:", existing_goals, key="milestone_name_select")

            # Step 3: Asset selection (multi-select)
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            unique_assets = [asset_name for asset_name, _ in assets_with_categories]

            selected_assets = st.multiselect("Select assets to withdraw from:", unique_assets, key="weighted_avg_assets")   
    

            if st.button('Apply the Weighted Average calculation',key= 'wt_avg_calculation'):
            
                # Check if positive value exists at the entry_date for this milestone
                filtered_milestone = milestone_df[(milestone_df['entry_date'] == entry_date) & (milestone_df['milestone_name'] == milestone_name)]

                if filtered_milestone.empty or filtered_milestone['milestone_value'].values[0] <= 0:
                    st.warning("No milestone value > 0 found at the selected entry_date.")
                    return surplus_withdrawal_projections_df

                milestone_value = filtered_milestone['milestone_value'].values[0]

                if not selected_assets:
                    st.warning("No assets selected.")
                    return surplus_withdrawal_projections_df

                # Load dynamic asset projections
                asset_proj_df = self.load_dynamic_assets_projections_df_from_db(user_id)
                asset_proj_df = asset_proj_df[(asset_proj_df['user_code'] == user_id) & (asset_proj_df['entry_date'] == entry_date)]

                asset_values = {}
                total_value = 0
                for asset in selected_assets:
                    row = asset_proj_df[asset_proj_df['assets_name'] == asset]
                    if not row.empty:
                        val = row['assets_value'].values[0]
                        asset_values[asset] = val
                        total_value += val

                if total_value == 0:
                    st.warning("Total asset value is zero. Cannot calculate weighted average.")
                    return surplus_withdrawal_projections_df

                for asset, value in asset_values.items():
                    weight = value / total_value
                    withdrawal_amount = -abs(weight * milestone_value)

                    # Fetch actual asset value from dynamic asset projection
                    asset_row = asset_proj_df[asset_proj_df['assets_name'] == asset]
                    if not asset_row.empty:
                        actual_asset_value = asset_row['assets_value'].values[0]

                        # Get existing withdrawal value already in surplus table for this asset and date
                        existing_withdrawal = surplus_withdrawal_projections_df.loc[
                            (surplus_withdrawal_projections_df['user_code'] == user_id) &
                            (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                            (surplus_withdrawal_projections_df['asset_name'] == asset),
                            'asset_value'
                        ]

                        existing_withdrawal_value = existing_withdrawal.values[0] if not existing_withdrawal.empty else 0

                        total_withdrawal = existing_withdrawal_value + withdrawal_amount

                        if total_withdrawal > actual_asset_value:
                            st.warning(f"Total withdrawal amount for {asset} exceeds its available asset value. Skipping.")
                            continue

                        # Update the withdrawal projections by adding to existing value
                        surplus_withdrawal_projections_df.loc[
                            (surplus_withdrawal_projections_df['user_code'] == user_id) &
                            (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                            (surplus_withdrawal_projections_df['asset_name'] == asset),
                            'asset_value'
                        ] = total_withdrawal

                st.success("Weighted average values applied to surplus withdrawal projections.")
                self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

        return surplus_withdrawal_projections_df 
        

    def fill_user_based_withdrawal_values(self, user_id, surplus_withdrawal_projections_df):
        if st.radio("Do you want to add the amount using user-defined percentage for withdrawal?", ["No", "Yes"], key="user_based_choice") == "Yes":

            # Step 1: Entry date selection
            entry_date = st.date_input("Select the entry date for applying user-defined percentage:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="user_based_entry_date").strftime('%Y-%m-%d')

            # Step 2: Select milestone goal
            milestone_df = self.load_milestone_calculation_projections_from_db()
            milestone_df = milestone_df[milestone_df['user_code'] == user_id]
            existing_goals = milestone_df['milestone_name'].unique()

            if len(existing_goals) == 0:
                st.warning("No milestone goals found for this user.")
                return surplus_withdrawal_projections_df

            milestone_name = st.selectbox("Select an existing goal category:", existing_goals, key="user_based_milestone_select")

            # Step 3: Select a single asset
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            unique_assets = [asset_name for asset_name, _ in assets_with_categories]

            selected_asset = st.selectbox("Select the asset to withdraw from:", unique_assets, key="user_based_asset_select")

            # Step 4: Enter user-defined percentage
            percentage_input = st.number_input("Enter percentage to withdraw (e.g. 50 for 50%):", min_value=0.0, max_value=100.0, step=0.1, key="user_based_percentage")

            if st.button('Apply the User-defined Withdrawal', key='user_based_withdrawal_apply'):
                # Validate milestone value
                filtered_milestone = milestone_df[(milestone_df['entry_date'] == entry_date) & (milestone_df['milestone_name'] == milestone_name)]

                if filtered_milestone.empty or filtered_milestone['milestone_value'].values[0] <= 0:
                    st.warning("No milestone value > 0 found at the selected entry_date.")
                    return surplus_withdrawal_projections_df

                milestone_value = filtered_milestone['milestone_value'].values[0]
                withdrawal_amount = -abs((percentage_input / 100.0) * milestone_value)

                # Load dynamic asset projections to check value constraint
                asset_proj_df = self.load_dynamic_assets_projections_df_from_db(user_id)
                asset_proj_df = asset_proj_df[(asset_proj_df['user_code'] == user_id) & (asset_proj_df['entry_date'] == entry_date)]

                asset_row = asset_proj_df[asset_proj_df['assets_name'] == selected_asset]
                if not asset_row.empty:
                    actual_asset_value = asset_row['assets_value'].values[0]

                    existing_withdrawal = surplus_withdrawal_projections_df.loc[
                        (surplus_withdrawal_projections_df['user_code'] == user_id) &
                        (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                        (surplus_withdrawal_projections_df['asset_name'] == selected_asset),
                        'asset_value'
                    ]

                    existing_value = existing_withdrawal.values[0] if not existing_withdrawal.empty else 0
                    total_withdrawal = existing_value + withdrawal_amount

                    if total_withdrawal > actual_asset_value:
                        st.warning(f"Total withdrawal exceeds available asset value for {selected_asset}. Skipping update.")
                        return surplus_withdrawal_projections_df

                    # Update projection
                    surplus_withdrawal_projections_df.loc[
                        (surplus_withdrawal_projections_df['user_code'] == user_id) &
                        (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                        (surplus_withdrawal_projections_df['asset_name'] == selected_asset),
                        'asset_value'
                    ] = total_withdrawal

                    self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                    st.success("User-defined withdrawal value applied successfully.")

        return surplus_withdrawal_projections_df
    

    def fill_expense_category_weight_avg_withdrawal_values(self, user_id, surplus_withdrawal_projections_df):
        if st.radio("Do you want to add the amount by using the weighted average method in withdrawal table for expense_category?", ["No", "Yes"], key="expense_category_weighted_avg_choice") == "Yes":

            # Step 1: Entry date selection
            entry_date = st.date_input("Select the entry date for applying weighted average:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_category_weighted_avg_entry_date").strftime('%Y-%m-%d')

            additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
            additional_income_expense_criteria_df['entry_date'] = pd.to_datetime(additional_income_expense_criteria_df['entry_date']).dt.strftime('%Y-%m-%d')
            additional_income_expense_criteria_df = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_id]
            existing_expense_categories = additional_income_expense_criteria_df['expense_category_name'].unique()

            if len(existing_expense_categories) == 0:
                st.warning("No expense category found for this user.")
                return surplus_withdrawal_projections_df
            
            expense_category_name = st.selectbox("Select an existing expense category:", existing_expense_categories, key="expense_category_name_select")

            # Step 3: Asset selection (multi-select)
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            unique_assets = [asset_name for asset_name, _ in assets_with_categories]

            selected_assets = st.multiselect("Select assets to withdraw from:", unique_assets, key="expense_category_weighted_avg_assets")   
    

            if st.button('Apply the Weighted Average calculation',key= 'expense_category_wt_avg_calculation'):
            
                # Check if positive value exists at the entry_date for this milestone
                filtered_expense_category = additional_income_expense_criteria_df[(additional_income_expense_criteria_df['entry_date'] == entry_date) & (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name)]

                if filtered_expense_category.empty or filtered_expense_category['amount'].values[0] >= 0:
                    st.warning("No expense category amount > 0 found at the selected entry_date.")
                    return surplus_withdrawal_projections_df

                expnese_category_amount = filtered_expense_category['amount'].values[0]

                if not selected_assets:
                    st.warning("No assets selected.")
                    return surplus_withdrawal_projections_df

                # Load dynamic asset projections
                asset_proj_df = self.load_dynamic_assets_projections_df_from_db(user_id)
                asset_proj_df = asset_proj_df[(asset_proj_df['user_code'] == user_id) & (asset_proj_df['entry_date'] == entry_date)]

                asset_values = {}
                total_value = 0
                for asset in selected_assets:
                    row = asset_proj_df[asset_proj_df['assets_name'] == asset]
                    if not row.empty:
                        val = row['assets_value'].values[0]
                        asset_values[asset] = val
                        total_value += val

                if total_value == 0:
                    st.warning("Total asset value is zero. Cannot calculate weighted average.")
                    return surplus_withdrawal_projections_df

                for asset, value in asset_values.items():
                    weight = value / total_value
                    withdrawal_amount = -abs(weight * expnese_category_amount)

                    # Fetch actual asset value from dynamic asset projection
                    asset_row = asset_proj_df[asset_proj_df['assets_name'] == asset]
                    if not asset_row.empty:
                        actual_asset_value = asset_row['assets_value'].values[0]

                        # Get existing withdrawal value already in surplus table for this asset and date
                        existing_withdrawal = surplus_withdrawal_projections_df.loc[
                            (surplus_withdrawal_projections_df['user_code'] == user_id) &
                            (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                            (surplus_withdrawal_projections_df['asset_name'] == asset),
                            'asset_value'
                        ]

                        existing_withdrawal_value = existing_withdrawal.values[0] if not existing_withdrawal.empty else 0

                        total_withdrawal = existing_withdrawal_value + withdrawal_amount

                        if total_withdrawal > actual_asset_value:
                            st.warning(f"Total withdrawal amount for {asset} exceeds its available asset value. Skipping.")
                            continue

                        # Update the withdrawal projections by adding to existing value
                        surplus_withdrawal_projections_df.loc[
                            (surplus_withdrawal_projections_df['user_code'] == user_id) &
                            (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                            (surplus_withdrawal_projections_df['asset_name'] == asset),
                            'asset_value'
                        ] = total_withdrawal

                st.success("Weighted average values applied to surplus withdrawal projections.")
                self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

        return surplus_withdrawal_projections_df


    def fill_expense_category_user_based_withdrawal_values(self, user_id, surplus_withdrawal_projections_df):
        if st.radio("Do you want to add the amount using user-defined percentage for withdrawal of expense category?", ["No", "Yes"], key="expense_category_user_based_choice") == "Yes":

            # Step 1: Entry date selection
            entry_date = st.date_input("Select the entry date for applying user-defined percentage:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_category_user_based_entry_date").strftime('%Y-%m-%d')

            # Step 2: Select milestone goal
            additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
            additional_income_expense_criteria_df['entry_date'] = pd.to_datetime(additional_income_expense_criteria_df['entry_date']).dt.strftime('%Y-%m-%d')
            additional_income_expense_criteria_df = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_id]
            existing_expense_categories = additional_income_expense_criteria_df['expense_category_name'].unique()

            if len(existing_expense_categories) == 0:
                st.warning("No expense category found for this user.")
                return surplus_withdrawal_projections_df

            expense_category_name = st.selectbox("Select an existing expense category:", existing_expense_categories, key="user_based_expense_category_select")

            # Step 3: Select a single asset
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            unique_assets = [asset_name for asset_name, _ in assets_with_categories]

            selected_asset = st.selectbox("Select the asset to withdraw from:", unique_assets, key="expense_cateogory_user_based_asset_select")

            # Step 4: Enter user-defined percentage
            percentage_input = st.number_input("Enter percentage to withdraw (e.g. 50 for 50%):", min_value=0.0, max_value=100.0, step=0.1, key="expense_cateogory_user_based_percentage")

            if st.button('Apply the User-defined Withdrawal', key='expense_cateogory_user_based_withdrawal_apply'):
                # Validate milestone value
                filtered_expense_category = additional_income_expense_criteria_df[(additional_income_expense_criteria_df['entry_date'] == entry_date) & (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name)]
                st.write('filtered_expense_category',filtered_expense_category)
                if filtered_expense_category.empty or filtered_expense_category['amount'].values[0] >= 0:
                    st.warning("No expense category amount > 0 found at the selected entry_date.")
                    return surplus_withdrawal_projections_df

                expnese_category_amount = filtered_expense_category['amount'].values[0]
                withdrawal_amount = -abs((percentage_input / 100.0) * expnese_category_amount)

                # Load dynamic asset projections to check value constraint
                asset_proj_df = self.load_dynamic_assets_projections_df_from_db(user_id)
                asset_proj_df = asset_proj_df[(asset_proj_df['user_code'] == user_id) & (asset_proj_df['entry_date'] == entry_date)]

                asset_row = asset_proj_df[asset_proj_df['assets_name'] == selected_asset]
                if not asset_row.empty:
                    actual_asset_value = asset_row['assets_value'].values[0]

                    existing_withdrawal = surplus_withdrawal_projections_df.loc[
                        (surplus_withdrawal_projections_df['user_code'] == user_id) &
                        (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                        (surplus_withdrawal_projections_df['asset_name'] == selected_asset),
                        'asset_value'
                    ]

                    existing_value = existing_withdrawal.values[0] if not existing_withdrawal.empty else 0
                    total_withdrawal = existing_value + withdrawal_amount

                    if total_withdrawal > actual_asset_value:
                        st.warning(f"Total withdrawal exceeds available asset value for {selected_asset}. Skipping update.")
                        return surplus_withdrawal_projections_df

                    # Update projection
                    surplus_withdrawal_projections_df.loc[
                        (surplus_withdrawal_projections_df['user_code'] == user_id) &
                        (surplus_withdrawal_projections_df['entry_date'] == entry_date) &
                        (surplus_withdrawal_projections_df['asset_name'] == selected_asset),
                        'asset_value'
                    ] = total_withdrawal

                    self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                    st.success("User-defined withdrawal value applied successfully.")

        return surplus_withdrawal_projections_df    
    
    

    def run_surplus_withdrawal_projections(self, user_id, month_choice):

        key = f"surplus_withdrawal_projections_df_{user_id}"

        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('surplus_withdrawal_projections'):
            # Only delete old records if the table exists
            self.delete_old_surplus_records()

        # Load the existing data from the investment_projections table
        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)


        assets_with_categories = self.fetch_assets_with_categories_1(user_id)
        surplus_relate_purpose = self.fetch_purpose_for_surplusr_projections(user_id)
        unique_assets = [asset_name for asset_name, _ in assets_with_categories]
        


        # Display unique asset names and their respective category_ids
        #st.write("Users current Assets")
        #for asset_name in assets_with_categories:
            #st.write(f"Asset: {asset_name}")

        assets_dict = {
            631: "Rental Yielding (Residential) 2",
            627: "debt fund - swp",
            320: "Arbitrage Funds",
            18: "Public Stock (India)",
            19: "Equity Mutual Funds",
            21: "Unlisted Stocks",
            22: "Public Stocks (International)",
            23: "Equity ETFs",
            24: "International Funds",
            25: "Direct Bonds",
            26: "Liquid Debt Funds",
            27: "Debt Funds",
            28: "Hybrid Funds",
            29: "Rental Yielding (Residential)",
            30: "Rental Yielding (Commercial)",
            31: "Non-Yielding (Residential)",
            32: "Non-Yielding (Commercial)",
            33: "Occupied Home",
            34: "Physical Gold",
            35: "Gold ETFs",
            36: "Sovereign Gold Bonds",
            37: "Bank FD",
            38: "Corporate FD",
            39: "Post Office Monthly Income Scheme (POMIS)",
            40: "Senior Citizen Savings Scheme (SCSS)",
            41: "Sukanya Samriddhi Yojana (SSY)",
            42: "National Savings Certificate (NSC)",
            43: "EPF",
            44: "PPF",
            45: "Savings",
            46: "NPS Tier I",
            47: "NPS Tier II",
            48: "Pradhan Mantri Vaya Vandana Yojana (PMVVY)",
            49: "Atal Pension Yojana (APY)",
            50: "Direct Cryptos",
            51: "Coin Baskets",
            53: "Loans Given",
            54: "Free Debt Instruments",
            90: "Physical Silver",
            91: "Silver ETFs",
            120: "Free Debt Instruments",
            235: "ESOP",
            236: "REITs/InvITs",
            237: "Bank RD",
            238: "P2P Lending",
            634: "Passive income from occupied home"
        }


        if surplus_withdrawal_projections_df.empty and not self.user_exists_in_surplus_withdrawal_proj_db(user_id):
            new_df = self.create_surplus_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name, month_choice)

            surplus_withdrawal_projections_df = pd.DataFrame(new_df)

            # Save to DB
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

            # Update cache
            st.session_state[key] = surplus_withdrawal_projections_df

            st.success("Initial projections created successfully!")        
 

        # Check if the DataFrame is empty and create initial projections if needed
        # if not self.user_exists_in_surplus_withdrawal_proj_db(user_id):
        #     if surplus_withdrawal_projections_df.empty:
        #         new_projections = self.create_surplus_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name, month_choice)
        #         surplus_withdrawal_projections_df = pd.DataFrame(new_projections)
        #     else:
        #         new_projections = self.create_surplus_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name, month_choice)
        #         surplus_withdrawal_projections_df = pd.concat([surplus_withdrawal_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

        #     self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)    
        #     st.session_state[key] = surplus_withdrawal_projections_df

        # Reshape and display the existing investment projections for the user
        st.write("### Surplus Projections")
        reshaped_df = self.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        st.dataframe(reshaped_df)

        

        # Dropdown to select an asset to add as a new asset
        additional_asset_name = st.selectbox("Select asset name to add:", list(assets_dict.values()), key="surplus_add_asset")
        if st.button("Add Asset", key="surplus_add_button"):
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            surplus_withdrawal_projections_df, assets_with_categories = self.add_additional_asset_for_surplus_withdrawal(surplus_withdrawal_projections_df, assets_dict, assets_with_categories, user_id, dob, retirement_age, additional_asset_name, month_choice)
            #print('surplus_withdrawal_projections_df check', surplus_withdrawal_projections_df)
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.session_state[key] = surplus_withdrawal_projections_df
            st.success(f"Added {additional_asset_name} to projections and saved to the database.")

        # Fetch distinct asset names for the dropdowns
        unique_assets_surplus_projections = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()
        #print('unique_assets_investment_projections',unique_assets_investment_projections)

        # Update projections based on growth or other entry types
        entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'),key="surplus_entry_type")
                

        if entry_type == 'single':
            single_date = st.date_input("Select date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="surplus_single_date")
            # Convert single_date to a string for comparison or database use
            single_date_str = single_date.strftime('%Y-%m-%d')
            #print('single_date in run investment',single_date)
            #asset_name = st.text_input("Enter the asset name:")
           
            asset_name = st.selectbox("Select asset name:", unique_assets_surplus_projections, key="surplus_single_asset")
            print('asset_name in all run fun',asset_name)
            #amount = st.number_input("Enter amount:")
            amount = st.number_input("Enter amount:", value=0.0, key="surplus_single_amount") # Convert amount to integer
            print('amount in all run fun',amount)
            if st.button("Apply Single Date Update", key="apply_surplus_single_update"):
                # Update the investment projections
                surplus_withdrawal_projections_df = self.update_surplus_related_withdrawal_projections(
                    user_id,
                    surplus_withdrawal_projections_df, 
                    distinct_names=[a for a, _ in assets_with_categories],  # Use the original names
                    entry_type=entry_type, 
                    single_date=single_date_str, 
                    increment_params={'amount': amount, 'asset_name': asset_name}  # Pass asset name without trimming
                )
                # Save the updated projections immediately after the update
                self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                st.session_state[key] = surplus_withdrawal_projections_df
                st.success("Single date update applied and saved to the database.")

        elif entry_type == 'range':
            start_date = st.date_input("Start Date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="surplus_range_start")
            #start_date_str = start_date.strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="surplus_range_end")
            #end_date_str = end_date.strftime('%Y-%m-%d')
            asset_name = st.selectbox("Select asset name for range:", unique_assets_surplus_projections, key="surplus_range_asset")
            amount = int(st.number_input("Enter amount for range:",value = 0, key="surplus_range_amount"))
            if st.button("Apply Range Update", key="apply_surplus_range_update"):
                surplus_withdrawal_projections_df = self.update_surplus_related_withdrawal_projections(user_id, surplus_withdrawal_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, range_dates=[start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')], increment_params={'amount': amount, 'asset_name': asset_name})
                self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                st.session_state[key] = surplus_withdrawal_projections_df
                st.success("Range date update applied and save to the database.")

        elif entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="surplus_increment_entry")
            percentage = st.number_input("Increment percentage:", key="surplus_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="surplus_increment_end")
            asset_name = st.selectbox("Select asset name for increment:", unique_assets_surplus_projections, key="surplus_increment_asset")
            if st.button("Apply Increment Update", key="apply_surplus_increment_update"):
                surplus_withdrawal_projections_df = self.update_surplus_related_withdrawal_projections(user_id, surplus_withdrawal_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, increment_params={'entry_date': entry_date.strftime('%Y-%m-%d'), 'percentage': percentage, 'end_date': end_date_increment.strftime('%Y-%m-%d'), 'asset_name': asset_name})
                self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                st.session_state[key] = surplus_withdrawal_projections_df
                st.success("Increment update applied and save to the database.")

        elif entry_type == 'stop':
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.session_state[key] = surplus_withdrawal_projections_df
            st.write("Stop function executed. No changes applied.")

        #self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)    

        # Functionality to delete an asset category from asset_name column
        st.write("### Delete an Asset Category")
        
        # Dropdown for selecting an asset category to delete
        asset_to_delete = st.selectbox("Select asset category to delete from projections:", unique_assets_surplus_projections, key="surplus_delete_asset")
        
        # Confirm deletion
        if st.button("Delete Selected Asset Category", key="delete_surplus_asset"):
            surplus_withdrawal_projections_df = self.delete_asset_category_from_projections(surplus_withdrawal_projections_df, user_id, asset_to_delete)
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.session_state[key] = surplus_withdrawal_projections_df
            st.success(f"Asset category '{asset_to_delete}' has been deleted from projections for user_id {user_id}.")

        surplus_withdrawal_projections_df = self.copy_withdrawal_values(user_id, surplus_withdrawal_projections_df, unique_assets_surplus_projections)

        surplus_withdrawal_projections_df = self.fill_weight_avg_withdrawal_values(user_id, surplus_withdrawal_projections_df)

        surplus_withdrawal_projections_df = self.fill_user_based_withdrawal_values(user_id, surplus_withdrawal_projections_df)

        surplus_withdrawal_projections_df = self.fill_expense_category_user_based_withdrawal_values(user_id, surplus_withdrawal_projections_df)

        surplus_withdrawal_projections_df = self.fill_expense_category_weight_avg_withdrawal_values(user_id, surplus_withdrawal_projections_df)

        st.session_state[key] = surplus_withdrawal_projections_df

        # Display the updated investment projections for the user
        st.write("### surplus Projections after changes:")
        #st.dataframe(investment_projections_df[investment_projections_df['user_code'] == user_id].transpose())    
        # Reshape and display the existing investment projections for the user
        reshaped_df = self.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        st.dataframe(reshaped_df)


    def delete_asset_category_from_projections(self, surplus_withdrawal_projections_df, user_id, asset_name):
        """
        Deletes the specified asset category from the asset_name column for the provided user_id.

        Args:
            surplus_withdrawal_projections_df (pd.DataFrame): DataFrame containing projections.
            user_id (str): The user code for the projections.
            asset_name (str): The asset category to delete.

        Returns:
            pd.DataFrame: Updated DataFrame with the asset category removed for the user.
        """
        return surplus_withdrawal_projections_df[~((surplus_withdrawal_projections_df['user_code'] == user_id) &
                                                  (surplus_withdrawal_projections_df['asset_name'] == asset_name))]    

    def user_exists_in_surplus_withdrawal_proj_db(self, user_id):
        """Check if the user_id already exists in the PostgreSQL table."""
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('surplus_withdrawal_projections', schema = 'public'):
            print("Table 'surplus_withdrawal_projections' does not exist.")
            return False

        
        query = f"SELECT 1 FROM surplus_withdrawal_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None 


    #assets projection
    def fetch_assets_for_assets_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT a.name AS assets_name, a.category_id
            FROM assets_milestones a
            JOIN milestones_category c ON a.category_id = c.id
            WHERE a.user_code = %s AND a.name IS NOT NULL AND a.name <> 'None' and a.is_active = true;
        """, (user_id,))
        assets_with_categories = cursor.fetchall()
        cursor.close()
        return assets_with_categories
    
    def fetch_purpose_for_asset_projections(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT purpose AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND name <> 'None'
            AND loan_funded = 'Yes' or loan_funded = 'No' and category_id IN (604,609,628);
        """, (user_id,))

        asset_purpose = cursor.fetchall()
        cursor.close()

        return asset_purpose

    def create_assets_projections_table(self, dob, retirement_age, assets_with_categories, asset_purpose, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)
        assets_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            for assets_name, category_id in assets_with_categories:
                assets_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'assets_name': assets_name,
                    'assets_value': 0  # Initialize assets value to 0
                }
                assets_projections.append(assets_projection_data)

            # Add purposes from milestones_liabilities table
            for purpose, category_id in asset_purpose:
                assets_projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'assets_name': purpose,  # Use purpose as liabilities_name
                    'assets_value': 0  # Initialize liability value to 0
                }
                assets_projections.append(assets_projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return assets_projections
    

    # def load_dynamic_assets_projections_df_from_db(self):
    #     connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
    #     engine = create_engine(connection_string)

    #     table_exists_query = text("""
    #         SELECT EXISTS (
    #             SELECT FROM information_schema.tables 
    #             WHERE table_name = 'dynamic_assets_projections'
    #         );
    #     """)

    #     with engine.connect() as connection:
    #         table_exists = connection.execute(table_exists_query).scalar_one()

    #     if not table_exists:
    #         print("Table 'dynamic_assets_projections' does not exist.")
    #         return pd.DataFrame()  # Return an empty DataFrame
    #     else:
    #         return pd.read_sql('dynamic_assets_projections', engine)

    def load_dynamic_assets_projections_df_from_db(self, user_id):
        """Loads dynamic projections from DB only once per session."""
        
        key = f"dynamic_assets_projections_df_{user_id}"

        if key not in st.session_state:
            # Load only user_id rows for speed
            connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            engine = create_engine(connection_string)

            # Safety: table may not exist on first run
            inspector = inspect(engine)
            if not inspector.has_table("dynamic_assets_projections"):
                st.session_state[key] = pd.DataFrame()
                return st.session_state[key]


            query = """
                SELECT *
                FROM dynamic_assets_projections
                WHERE user_code = %s
            """
            st.session_state[key] = pd.read_sql(query, engine, params=(user_id,))

        return st.session_state[key]
  



    def save_dynamic_assets_projections_df_to_db(self, dynamic_assets_projections_df):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        dynamic_assets_projections_df.to_sql('dynamic_assets_projections', engine, if_exists='replace', index=False)
        print("dynamic_assets_projections saved to the PostgreSQL database.")

    def update_dynamic_assets_projections(self, dynamic_assets_projections_df, user_id):
        cursor = self.connection.cursor()

        # Cache all investment and withdrawal values for the user into dictionaries
        cursor.execute("""
            SELECT entry_date, category_id, asset_name, asset_value
            FROM investment_projections
            WHERE user_code = %s
        """, (user_id,))
        investment_data = cursor.fetchall()
        investment_map = {
            (row[0], row[1], row[2]): float(row[3]) if row[3] is not None else 0.0
            for row in investment_data
        }

        cursor.execute("""
            SELECT entry_date, category_id, asset_name, asset_value
            FROM surplus_withdrawal_projections
            WHERE user_code = %s
        """, (user_id,))
        withdrawal_data = cursor.fetchall()
        withdrawal_map = {
            (row[0], row[1], row[2]): float(row[3]) if row[3] is not None else 0.0
            for row in withdrawal_data
        }

        cursor.execute("""
            SELECT category_id, name, current_amount
            FROM assets_milestones
            WHERE user_code = %s AND name IS NOT NULL AND name <> 'None' AND is_active = true
        """, (user_id,))
        initial_assets = cursor.fetchall()
        initial_value_map = {
            (row[1], row[0]): float(row[2]) if row[2] is not None else 0.0
            for row in initial_assets
        }

        cursor.execute("""
            SELECT id, weightage
            FROM milestones_category
        """)
        weightage_data = cursor.fetchall()
        weightage_map = {
            row[0]: float(row[1]) if row[1] is not None else 0.0
            for row in weightage_data
        }

        for assets_name, category_id in dynamic_assets_projections_df[['assets_name', 'category_id']].drop_duplicates().values:
            filtered_df = dynamic_assets_projections_df[
                (dynamic_assets_projections_df['assets_name'] == assets_name) &
                (dynamic_assets_projections_df['category_id'] == category_id)
            ].copy()

            if filtered_df.empty:
                continue

            first_idx = filtered_df.index.min()
            first_entry_date = dynamic_assets_projections_df.at[first_idx, 'entry_date']
            initial_value = initial_value_map.get((assets_name, category_id), 0.0)
            investment_value = investment_map.get((first_entry_date, category_id, assets_name), 0.0)
            withdrawal_value = withdrawal_map.get((first_entry_date, category_id, assets_name), 0.0)

            assets_value = initial_value - investment_value + withdrawal_value
            dynamic_assets_projections_df.at[first_idx, 'assets_value'] = assets_value

            weightage_value = weightage_map.get(category_id, 0.0)

            previous_date = datetime.strptime(first_entry_date, '%Y-%m-%d')

            for idx in range(first_idx + 1, len(dynamic_assets_projections_df)):
                row = dynamic_assets_projections_df.loc[idx]
                if row['assets_name'] == assets_name and row['category_id'] == category_id:
                    previous_date = (previous_date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1)
                    previous_idx = dynamic_assets_projections_df[
                        (dynamic_assets_projections_df['entry_date'] == previous_date.strftime('%Y-%m-%d')) &
                        (dynamic_assets_projections_df['assets_name'] == assets_name) &
                        (dynamic_assets_projections_df['category_id'] == category_id)
                    ].index

                    previous_value = dynamic_assets_projections_df.at[previous_idx[0], 'assets_value'] if not previous_idx.empty else 0.0
                    current_entry_date = row['entry_date']

                    investment_value = investment_map.get((current_entry_date, category_id, assets_name), 0.0)
                    withdrawal_value = withdrawal_map.get((current_entry_date, category_id, assets_name), 0.0)

                    current_assets_value = previous_value * (1 + weightage_value / 12.0) - investment_value + withdrawal_value
                    dynamic_assets_projections_df.at[idx, 'assets_value'] = current_assets_value

                    previous_date = datetime.strptime(current_entry_date, '%Y-%m-%d')

        return dynamic_assets_projections_df


    
    def calculate_assets_value_for_category_604(self, user_id, dynamic_assets_projections_df):
        category_id = 604

        # Filter only relevant rows
        category_df = dynamic_assets_projections_df[
            (dynamic_assets_projections_df['user_code'] == user_id) &
            (dynamic_assets_projections_df['category_id'] == category_id)
        ]
        if category_df.empty:
            return dynamic_assets_projections_df

        cursor = self.connection.cursor()

        # 1. Fetch weightage once
        cursor.execute("SELECT weightage FROM milestones_category WHERE id = %s", (category_id,))
        weightage_value = float(cursor.fetchone()[0]) if cursor.rowcount > 0 else 0.0

        # 2. Fetch milestone years
        cursor.execute("""
            SELECT milestone_year
            FROM milestones_liabilities
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))
        milestone_years = {row[0] for row in cursor.fetchall()}

        # 3. Fetch all milestone values
        cursor.execute("""
            SELECT entry_date, milestone_value
            FROM milestone_calculation_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        milestone_values = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            # Convert safely
            if isinstance(date_raw, str):
                date_key = date_raw
            else:
                date_key = date_raw.strftime('%Y-%m-%d')

            milestone_values[date_key] = float(row[1]) if row[1] is not None else 0.0


        # 4. Fetch all investment values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM investment_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        investment_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            investment_map[date_key] = float(row[1]) if row[1] is not None else 0.0


        # 5. Fetch all withdrawal values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM surplus_withdrawal_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        withdrawal_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            withdrawal_map[date_key] = float(row[1]) if row[1] is not None else 0.0


        # 6. Loop through and update values
        for idx, row in dynamic_assets_projections_df.iterrows():
            if row['category_id'] != category_id or row['user_code'] != user_id:
                continue

            entry_date = row['entry_date']
            previous_idx = dynamic_assets_projections_df[
                (dynamic_assets_projections_df['entry_date'] < entry_date) &
                (dynamic_assets_projections_df['category_id'] == category_id) &
                (dynamic_assets_projections_df['user_code'] == user_id)
            ].index.max()
            previous_value = dynamic_assets_projections_df.at[previous_idx, 'assets_value'] if pd.notna(previous_idx) else 0.0

            milestone_value = milestone_values.get(entry_date, 0.0)
            investment_value = investment_map.get(entry_date, 0.0)
            withdrawal_value = withdrawal_map.get(entry_date, 0.0)

            if datetime.strptime(entry_date, '%Y-%m-%d').date() in milestone_years:
                # Milestone year calculation
                calculated_value = milestone_value + previous_value * (1 + weightage_value / 12)
            else:
                # Normal compounding logic
                calculated_value = previous_value * (1 + weightage_value / 12)

            final_value = calculated_value - investment_value + withdrawal_value
            dynamic_assets_projections_df.at[idx, 'assets_value'] = final_value

        return dynamic_assets_projections_df

    
    def calculate_assets_value_for_category_628(self, user_id, dynamic_assets_projections_df):
        category_id = 628

        # Filter only relevant rows
        category_df = dynamic_assets_projections_df[
            (dynamic_assets_projections_df['user_code'] == user_id) &
            (dynamic_assets_projections_df['category_id'] == category_id)
        ]
        if category_df.empty:
            return dynamic_assets_projections_df

        cursor = self.connection.cursor()

        # 1. Fetch weightage once
        cursor.execute("SELECT weightage FROM milestones_category WHERE id = %s", (category_id,))
        weightage_value = float(cursor.fetchone()[0]) if cursor.rowcount > 0 else 0.0

        # 2. Fetch milestone years
        cursor.execute("""
            SELECT milestone_year
            FROM milestones_liabilities
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))
        milestone_years = {row[0] for row in cursor.fetchall()}

        # 3. Fetch all milestone values
        cursor.execute("""
            SELECT entry_date, milestone_value
            FROM milestone_calculation_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        milestone_values = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            milestone_values[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 4. Fetch all investment values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM investment_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        investment_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            investment_map[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 5. Fetch all withdrawal values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM surplus_withdrawal_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        withdrawal_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            withdrawal_map[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 6. Loop through and update values
        for idx, row in dynamic_assets_projections_df.iterrows():
            if row['category_id'] != category_id or row['user_code'] != user_id:
                continue

            entry_date = row['entry_date']
            previous_idx = dynamic_assets_projections_df[
                (dynamic_assets_projections_df['entry_date'] < entry_date) &
                (dynamic_assets_projections_df['category_id'] == category_id) &
                (dynamic_assets_projections_df['user_code'] == user_id)
            ].index.max()

            previous_value = dynamic_assets_projections_df.at[previous_idx, 'assets_value'] if pd.notna(previous_idx) else 0.0

            milestone_value = milestone_values.get(entry_date, 0.0)
            investment_value = investment_map.get(entry_date, 0.0)
            withdrawal_value = withdrawal_map.get(entry_date, 0.0)

            if datetime.strptime(entry_date, '%Y-%m-%d').date() in milestone_years:
                # Milestone year calculation
                calculated_value = milestone_value + previous_value * (1 + weightage_value / 12)
            else:
                # Normal compounding logic
                calculated_value = previous_value * (1 + weightage_value / 12)

            final_value = calculated_value - investment_value + withdrawal_value
            dynamic_assets_projections_df.at[idx, 'assets_value'] = final_value

        return dynamic_assets_projections_df


    def calculate_assets_value_for_category_627(self, user_id, dynamic_assets_projections_df):
        category_id = 627

        # Filter only relevant rows
        category_df = dynamic_assets_projections_df[
            (dynamic_assets_projections_df['user_code'] == user_id) &
            (dynamic_assets_projections_df['category_id'] == category_id)
        ]
        if category_df.empty:
            return dynamic_assets_projections_df

        cursor = self.connection.cursor()

        # 1. Fetch weightage once
        cursor.execute("SELECT weightage FROM milestones_category WHERE id = %s", (category_id,))
        weightage_value = float(cursor.fetchone()[0]) if cursor.rowcount > 0 else 0.0

        # 2. Fetch milestone years
        cursor.execute("""
            SELECT milestone_year
            FROM milestones_liabilities
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))
        milestone_years = {row[0] for row in cursor.fetchall()}

        # 3. Fetch all milestone values
        cursor.execute("""
            SELECT entry_date, milestone_value
            FROM milestone_calculation_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        milestone_values = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            milestone_values[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 4. Fetch all investment values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM investment_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        investment_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            investment_map[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 5. Fetch all withdrawal values
        cursor.execute("""
            SELECT entry_date, asset_value
            FROM surplus_withdrawal_projections
            WHERE user_code = %s AND category_id = %s
        """, (user_id, category_id))

        withdrawal_map = {}
        for row in cursor.fetchall():
            date_raw = row[0]
            date_key = date_raw if isinstance(date_raw, str) else date_raw.strftime('%Y-%m-%d')
            withdrawal_map[date_key] = float(row[1]) if row[1] is not None else 0.0

        # 6. Loop through and update values
        for idx, row in dynamic_assets_projections_df.iterrows():
            if row['category_id'] != category_id or row['user_code'] != user_id:
                continue

            entry_date = row['entry_date']
            previous_idx = dynamic_assets_projections_df[
                (dynamic_assets_projections_df['entry_date'] < entry_date) &
                (dynamic_assets_projections_df['category_id'] == category_id) &
                (dynamic_assets_projections_df['user_code'] == user_id)
            ].index.max()

            previous_value = dynamic_assets_projections_df.at[previous_idx, 'assets_value'] if pd.notna(previous_idx) else 0.0

            milestone_value = milestone_values.get(entry_date, 0.0)
            investment_value = investment_map.get(entry_date, 0.0)
            withdrawal_value = withdrawal_map.get(entry_date, 0.0)

            if datetime.strptime(entry_date, '%Y-%m-%d').date() in milestone_years:
                calculated_value = milestone_value + previous_value * (1 + weightage_value / 12)
            else:
                calculated_value = previous_value * (1 + weightage_value / 12)

            final_value = calculated_value - investment_value + withdrawal_value
            dynamic_assets_projections_df.at[idx, 'assets_value'] = final_value

        return dynamic_assets_projections_df   
    
    def fetch_investment_value(self, user_id, entry_date, category_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT asset_value 
            FROM investment_projections 
            WHERE user_code = %s AND entry_date = %s AND category_id = %s
        """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
        investment_value = cursor.fetchone()
        investment_value = float(investment_value[0]) if investment_value and investment_value[0] is not None else 0.0
        return investment_value
    
    def fetch_withdrawal_value(self, user_id, entry_date, category_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT asset_value 
            FROM surplus_withdrawal_projections 
            WHERE user_code = %s AND entry_date = %s AND category_id = %s
        """, (user_id, entry_date.strftime('%Y-%m-%d'), category_id))
        withdrawal_value = cursor.fetchone()
        withdrawal_value = float(withdrawal_value[0]) if withdrawal_value and withdrawal_value[0] is not None else 0.0
        return withdrawal_value
    

    def user_exists_in_assets_proj_db(self, user_id):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        inspector = inspect(engine)
        if not inspector.has_table('dynamic_assets_projections', schema = 'public'):
            print("Table 'dynamic_assets_projections' does not exist.")
            return False

        query = f"SELECT 1 FROM dynamic_assets_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(text(query))
            return result.fetchone() is not None  
        
    def reshape_dynamic_assets_projections(self, dynamic_assets_projections_df, user_id):
        user_df = dynamic_assets_projections_df[dynamic_assets_projections_df['user_code'] == user_id]
        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        user_df['entry_date'] = user_df['entry_date'].astype(str)
        reshaped_df = user_df.pivot_table(index='assets_name',
                                          columns=['entry_date', 'age'],
                                          values='assets_value',
                                          aggfunc='sum',
                                          fill_value=0).reset_index()
        return reshaped_df    
    
    def display_reshape_dynamic_assets_projections(self, dynamic_assets_projections_df, user_id):
        user_df = dynamic_assets_projections_df[dynamic_assets_projections_df['user_code'] == user_id]
        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        user_df['entry_date'] = user_df['entry_date'].astype(str)
        reshaped_df = user_df.pivot_table(index='assets_name',
                                          columns=['entry_date', 'age'],
                                          values='assets_value',
                                          aggfunc='sum',
                                          fill_value=0).reset_index()
        reshaped_df.set_index('assets_name', inplace=True)  # Set asset_name as index
        return reshaped_df
    
    def clear_existing_asset_data_for_user(self, user_id):
        # Delete existing data for the user_id from the dynamic_assets_projections table
        cursor = self.connection.cursor()
        cursor.execute("TRUNCATE TABLE dynamic_assets_projections;")
        self.connection.commit()
        cursor.close()
        print(f"Existing data for user_id {user_id} has been cleared.")

    def update_negative_assets_projections(self, user_code, dynamic_assets_projections_df):
    
		# New logic: if assets_value is less than 1 after projection starts, set it to 0 for that and subsequent entry dates
        for assets_name in dynamic_assets_projections_df['assets_name'].unique():
            for category_id in dynamic_assets_projections_df['category_id'].unique():
                category_data = dynamic_assets_projections_df[
                    (dynamic_assets_projections_df['assets_name'] == assets_name) &
                    (dynamic_assets_projections_df['category_id'] == category_id)
                ]

                projection_started = False
                value_below_1_found = False

                for idx, projection in category_data.iterrows():
                    current_value = projection['assets_value']

                    # Check if projection has started (i.e., first non-zero value)
                    if not projection_started and current_value > 0:
                        projection_started = True

                    # If projection has started and value is below 1, set subsequent values to 0
                    if projection_started:
                        if current_value < 1 and not value_below_1_found:
                            value_below_1_found = True

                        if value_below_1_found:
                            # Set assets_value to 0 for this and subsequent rows
                            dynamic_assets_projections_df.at[idx, 'assets_value'] = 0

        return dynamic_assets_projections_df        

    def run_dynamic_assets_projections(self, user_id, month_choice):
        
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('dynamic_assets_projections'):
            # Only delete old records if the table exists
            self.clear_existing_asset_data_for_user(user_id)
        

        # Fetch user and asset data
        assets_with_categories = self.fetch_assets_for_assets_projections(user_id)
        st.write(assets_with_categories)
        asset_purpose = self.fetch_purpose_for_asset_projections(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)

        # Load the existing data
        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
        st.write('after loading the data')

        # Create new projections if the user_id is not in the database
        if not self.user_exists_in_assets_proj_db(user_id):
            new_projections = self.create_assets_projections_table(dob, retirement_age, assets_with_categories, asset_purpose, user_id, user_name, month_choice)
            if dynamic_assets_projections_df.empty:
                dynamic_assets_projections_df = pd.DataFrame(new_projections)
            else:
                dynamic_assets_projections_df = pd.concat([dynamic_assets_projections_df, pd.DataFrame(new_projections)], ignore_index=True)
            self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)
        st.write('after creating the data')    
         
        dynamic_assets_projections_df = self.update_dynamic_assets_projections(dynamic_assets_projections_df, user_id) 
        st.write('after updating the data')


        #if st.button("Update Good Liability Asset Category", key="update_Good_liability_asset_asset"): 
        dynamic_assets_projections_df = self.calculate_assets_value_for_category_604(user_id, dynamic_assets_projections_df)
        dynamic_assets_projections_df = self.calculate_assets_value_for_category_627(user_id, dynamic_assets_projections_df)
        dynamic_assets_projections_df = self.calculate_assets_value_for_category_628(user_id, dynamic_assets_projections_df)
        dynamic_assets_projections_df = self.update_negative_assets_projections(user_id, dynamic_assets_projections_df)
        
        reshaped_df = self.display_reshape_dynamic_assets_projections(dynamic_assets_projections_df, user_id)
        st.dataframe(reshaped_df)
        self.save_dynamic_assets_projections_df_to_db(dynamic_assets_projections_df)


    #for calculating the outstanding amount after downpayment
    # New Functionality for Milestones Liabilities
    def manage_downpayment_outstanding_amount(self):  
        
        # Handle Down Payment Option
        st.subheader("Do you want to pay the down payment?")
        down_payment_option = st.selectbox("Select an Option", ["No", "Yes"], key="down_payment_option")
        user_id = st.text_input("Enter User ID for sum Records")
        if down_payment_option == "Yes":
            # Validate user input for user_code
            if not user_id:
                st.error("User ID is required to proceed.")
                return  # Exit the function if user_id is empty

            try:
                # Fetch valid purposes and asset categories from the database
                with self.connection.cursor() as cursor:
                    # Fetch purposes available for the given user_id
                    cursor.execute("""
                        SELECT DISTINCT purpose 
                        FROM milestones_liabilities 
                        WHERE user_code = %s;
                    """, (user_id,))
                    valid_purposes = [row[0] for row in cursor.fetchall()]

                    if not valid_purposes:
                        st.error(f"No purposes found for user '{user_id}'. Please check the data.")
                        return

                    # Fetch unique asset categories from surplus_withdrawal_projections
                    cursor.execute("""
                        SELECT DISTINCT asset_name 
                        FROM surplus_withdrawal_projections
                        WHERE user_code = %s;
                    """,(user_id,))
                    asset_categories = [row[0] for row in cursor.fetchall()]

                # Dropdown for purposes (filtered for the user)
                selected_milestone_category = st.selectbox("Select a Milestone Category", valid_purposes, key="milestone_category_dropdown")

                # Multiselect for asset categories
                selected_asset_categories = st.multiselect("Select Asset Categories", asset_categories, key="asset_category_dropdown")

                if st.button("Calculate and Update Outstanding Amount"):
                    try:
                        with self.connection.cursor() as cursor:
                            # Fetch milestone year for the selected purpose
                            cursor.execute("""
                                SELECT milestone_year::text 
                                FROM milestones_liabilities 
                                WHERE user_code = %s AND purpose = %s;
                            """, (user_id, selected_milestone_category))
                            milestone_year_entry = cursor.fetchone()

                            if milestone_year_entry is None:
                                st.error(f"Milestone year not found for the selected purpose '{selected_milestone_category}' and user '{user_id}'.")
                                return

                            milestone_year_entry = milestone_year_entry[0]

                            # Calculate sum of milestone_value for the selected milestone category
                            cursor.execute("""
                                SELECT SUM(milestone_value) 
                                FROM milestone_calculation_projections 
                                WHERE milestone_name = %s AND entry_date = %s;
                            """, (selected_milestone_category, milestone_year_entry))
                            milestone_sum = cursor.fetchone()[0] or 0
                            st.write('milestone_sum',milestone_sum)

                            # Calculate sum of asset_value for the selected asset categories
                            cursor.execute("""
                                SELECT SUM(asset_value) 
                                FROM surplus_withdrawal_projections 
                                WHERE asset_name = ANY(%s) AND entry_date = %s;
                            """, (selected_asset_categories, milestone_year_entry))
                            asset_sum = cursor.fetchone()[0] or 0
                            asset_sum = float(asset_sum)  # Convert to float
                            st.write('asset_sum',asset_sum)

                            # Calculate the total sum
                            total_sum = milestone_sum + asset_sum

                            # Update the outstanding amount in the milestones_liabilities table
                            cursor.execute("""
                                UPDATE milestones_liabilities 
                                SET outstanding_amount = %s, last_updated_at = NOW()
                                WHERE user_code = %s AND purpose = %s;
                            """, (total_sum, user_id, selected_milestone_category))
                            self.connection.commit()

                            st.success(f"Outstanding amount updated successfully! Total sum: {total_sum}")
                    except Exception as e:
                        st.error(f"Error during calculation or update: {e}")

            except Exception as e:
                st.error(f"Error fetching purposes or categories: {e}")        

    #for milestone income projection  

    # Additional logic to handle active income updates

    def fetch_passive_rental_data(self, user_code):
        """
        Fetch data from dynamic_assets_projections for passive rental income (category_id = 33).
        """
        query = """
            SELECT TO_DATE(entry_date, 'YYYY-MM-DD') AS entry_date, assets_value
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id in (634)
            ORDER BY entry_date
        """
        passive_rental_data = pd.read_sql(query, self.connection, params=[user_code])
        return passive_rental_data  
    
    def fetch_passive_swp_data(self, user_code):
        """
        Fetch data from dynamic_assets_projections for passive rental income (category_id = 33).
        """
        query = """
            SELECT TO_DATE(entry_date, 'YYYY-MM-DD') AS entry_date, assets_value
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id in (627)
            ORDER BY entry_date
        """
        passive_swp_data = pd.read_sql(query, self.connection, params=[user_code])
        return passive_swp_data

    def update_passive_swp_income(self, dynamic_milestone_income_projection, passive_swp_data, growth_percentage, start_date, end_date):
        """
        Update passive rental income projection based on user input start_date and end_date.
        """
        if passive_swp_data.empty:
            st.warning("No passive rental data found.")
            return dynamic_milestone_income_projection 
        
        # Convert 'entry_date' from TEXT to DATETIME
        passive_swp_data['entry_date'] = pd.to_datetime(passive_swp_data['entry_date'], format='%Y-%m-%d', errors='coerce')

        # Filter data based on start_date and end_date
        passive_swp_data = passive_swp_data[(passive_swp_data['entry_date'] >= start_date) & (passive_swp_data['entry_date'] <= end_date)]


        # Iterate over the projection period
        projection_start = start_date
        while projection_start <= end_date:
            # Match the asset value for the start of the projection year
            matching_row = passive_swp_data[passive_swp_data['entry_date'] == projection_start]
            if not matching_row.empty:
                asset_value = matching_row['assets_value'].values[0]
                # st.write('asset_value',asset_value)
                rental_income = (asset_value * growth_percentage)/12
            else:
                rental_income = 0      

            # Assign this rental income for the next 12 months
            for i in range(12):
                #st.write('rental_income',rental_income)
                
                # Ensure each projected date is the last day of the month
                projection_date = projection_start + pd.DateOffset(months=i)
                projection_date = projection_date.replace(day=monthrange(projection_date.year, projection_date.month)[1])  # Set to last day of the month

                
                if projection_date <= end_date:
                    # st.write('Projection Start in the loop:', projection_start, 'Projection Date:', projection_date)
                    # st.write('rental_income',rental_income)
                    # st.write('dynamic_milestone_income_projection',dynamic_milestone_income_projection['entry_date'])
                    dynamic_milestone_income_projection.loc[
                        dynamic_milestone_income_projection['entry_date'] == projection_date.date(), 
                        'passive_income_2'
                    ] = rental_income

            # Move to the next year
            # Move to the next year and set it to the last day of the month
            
            projection_start = projection_start.replace(year=projection_start.year + 1, day=1)  # Move to 1st of next year
            projection_start = projection_start.replace(day=monthrange(projection_start.year, projection_start.month)[1])  # Set to last day of the month  
        
        
        # self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)           

        return dynamic_milestone_income_projection
    

    def update_passive_rental_income(self, dynamic_milestone_income_projection, passive_rental_data, growth_percentage, start_date, end_date):
        """
        Update passive rental income projection based on user input start_date and end_date.
        """
        if passive_rental_data.empty:
            st.warning("No passive rental data found.")
            st.write('income data is empty')
            return dynamic_milestone_income_projection 
        
        # Convert 'entry_date' from TEXT to DATETIME
        passive_rental_data['entry_date'] = pd.to_datetime(passive_rental_data['entry_date'], format='%Y-%m-%d', errors='coerce')

        # Filter data based on start_date and end_date
        passive_rental_data = passive_rental_data[(passive_rental_data['entry_date'] >= start_date) & (passive_rental_data['entry_date'] <= end_date)]


        # Iterate over the projection period
        projection_start = start_date
        while projection_start <= end_date:
            # Match the asset value for the start of the projection year
            matching_row = passive_rental_data[passive_rental_data['entry_date'] == projection_start]
            if not matching_row.empty:
                asset_value = matching_row['assets_value'].values[0]
                # st.write('asset_value',asset_value)
                rental_income = (asset_value * growth_percentage)/12
            else:
                rental_income = 0

            # Assign this rental income for the next 12 months
            for i in range(12):
                #st.write('rental_income',rental_income)
                
                # Ensure each projected date is the last day of the month
                projection_date = projection_start + pd.DateOffset(months=i)
                projection_date = projection_date.replace(day=monthrange(projection_date.year, projection_date.month)[1])  # Set to last day of the month

                
                if projection_date <= end_date:
                    # st.write('Projection Start in the loop:', projection_start, 'Projection Date:', projection_date)
                    # st.write('rental_income',rental_income)
                    # st.write('dynamic_milestone_income_projection',dynamic_milestone_income_projection['entry_date'])
                    dynamic_milestone_income_projection.loc[
                        dynamic_milestone_income_projection['entry_date'] == projection_date.date(), 
                        'passive_income_3'
                    ] = rental_income

            # Move to the next year
            # Move to the next year and set it to the last day of the month
            
            projection_start = projection_start.replace(year=projection_start.year + 1, day=1)  # Move to 1st of next year
            projection_start = projection_start.replace(day=monthrange(projection_start.year, projection_start.month)[1])  # Set to last day of the month    

        # self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)           

        return dynamic_milestone_income_projection

    
    def process_passive_swp_income(self, user_code, dynamic_milestone_income_projection):

        # Ask the user if they want to earn passive income from rental properties
        include_passive_rental = st.radio("Do you want to earn passive income by SWP?", ("No", "Yes"))

        if include_passive_rental == "Yes":
            passive_swp_data = self.fetch_passive_swp_data(user_code)

            if not passive_swp_data.empty:
                real_estate_growth_percentage = self.get_real_estate_growth_percentage()
                start_date = st.date_input("Enter the start date for passive rental income (YYYY-MM-DD):")
                end_date = st.date_input("Enter the end date for passive rental income (YYYY-MM-DD):")

                start_date = pd.to_datetime(start_date)
                end_date = pd.to_datetime(end_date)

                if st.button('Update SWP Passive Income',key = 'swp_passive_income'):

                    dynamic_milestone_income_projection = self.update_passive_swp_income(
                        dynamic_milestone_income_projection, passive_swp_data, real_estate_growth_percentage, start_date, end_date
                    )

                    # Save and display the updated projection
                    self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)
                    st.dataframe(dynamic_milestone_income_projection)

        return dynamic_milestone_income_projection
    
    
    def process_passive_rental_income(self, user_code, dynamic_milestone_income_projection):

        # Ask the user if they want to earn passive income from rental properties
        include_passive_rental = st.radio("Do you want to earn passive income on existing property?", ("No", "Yes"))

        if include_passive_rental == "Yes":
            passive_rental_data = self.fetch_passive_rental_data(user_code)

            if not passive_rental_data.empty:
                real_estate_growth_percentage = self.get_real_estate_growth_percentage_1()
                start_date = st.date_input("Enter the start date for passive rental income (YYYY-MM-DD):",key = 'rental_start_date')
                end_date = st.date_input("Enter the end date for passive rental income (YYYY-MM-DD):", key = 'rental_end_date')

                start_date = pd.to_datetime(start_date)
                end_date = pd.to_datetime(end_date)

                if st.button('Update Rental Passive Income',key = 'rental_passive_income'):

                    dynamic_milestone_income_projection = self.update_passive_rental_income(
                        dynamic_milestone_income_projection, passive_rental_data, real_estate_growth_percentage, start_date, end_date
                    )

                    # Save and display the updated projection
                    self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)
                    st.dataframe(dynamic_milestone_income_projection)

        return dynamic_milestone_income_projection


    
    def update_gross_income_in_db(self, dynamic_milestone_income_projection, user_code):
        cursor = self.connection.cursor()
        for index, row in dynamic_milestone_income_projection.iterrows():
            cursor.execute("""
                UPDATE dynamic_milestone_income_projection
                SET gross_income = %s, net_income_post_tax = %s
                WHERE user_code = %s AND entry_date = %s;
            """, (row['gross_income'], row['net_income_post_tax'], user_code, row['entry_date']))
        
        self.connection.commit()
        cursor.close()
        print("Gross income updated successfully in PostgreSQL.")

    def alter_income_column_types(self):
        try:
            cursor = self.connection.cursor()
            alter_query = """
                ALTER TABLE dynamic_milestone_income_projection 
                ALTER COLUMN passive_income TYPE NUMERIC,
                ALTER COLUMN gross_income TYPE NUMERIC;
            """
            cursor.execute(alter_query)
            self.connection.commit()
            print("Column datatypes updated to NUMERIC successfully.")
        except Exception as e:
            print(f"Error occurred while altering column datatypes: {e}")
            self.connection.rollback()
        finally:
            cursor.close()    


    def update_active_income(self, dynamic_milestone_income_projection):
        add_active_income = st.radio("Do you want to add an amount in passive income, taxes, total expenses and household lifestyle expenses?", ("No", "Yes"))
        
        if add_active_income == "Yes":
                
                st.write("### Update Passive Income and Total Expense")

                update_option = st.radio("Choose entry type for update:", ('single', 'range', 'increment','growth_increment_from_middle'), key="update_income_option")

                #user_code = dynamic_milestone_income_projection['user_code'].iloc[0]
                #dynamic_milestone_income_projection['entry_date'] = pd.to_datetime(dynamic_milestone_income_projection['entry_date'])

                if update_option == 'single':
                    selected_date = st.date_input("Select entry date:", key="single_income_date")
                    selected_column = st.selectbox("Select column to update:", ['passive_income', 'taxes','total_expense','household_lifestyle_expense_amount'], key="single_income_column")
                    amount = st.number_input("Enter amount:", value=0.0, key="single_income_amount")

                    if st.button("Apply Single Update", key="apply_single_income"):
                        if selected_column == 'total_expense':
                            amount = -abs(amount)

                        dynamic_milestone_income_projection.loc[
                            dynamic_milestone_income_projection['entry_date'] == selected_date,
                            selected_column
                        ] = amount
                        st.success(f"{selected_column} updated successfully for {selected_date}.")

                elif update_option == 'range':
                    start_date = st.date_input("Start date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="range_start_date")
                    end_date = st.date_input("End date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="range_end_date")
                    selected_column = st.selectbox("Select column to update:", ['passive_income', 'taxes', 'total_expense','household_lifestyle_expense_amount'], key="range_income_column")
                    amount = st.number_input("Enter amount:", value=0.0, key="range_income_amount")

                    if st.button("Apply Range Update", key="apply_range_income"):
                        if selected_column == 'total_expense':
                            amount = -abs(amount)

                        mask = (pd.to_datetime(dynamic_milestone_income_projection['entry_date']) >= pd.to_datetime(start_date)) & \
                            (pd.to_datetime(dynamic_milestone_income_projection['entry_date']) <= pd.to_datetime(end_date))
                        dynamic_milestone_income_projection.loc[mask, selected_column] = amount
                        st.success(f"{selected_column} updated for date range {start_date} to {end_date}.")

                elif update_option == 'increment':
                    selected_column = st.selectbox("Select column to increment:", ['passive_income', 'taxes','total_expense','household_lifestyle_expense_amount'], key="increment_income_column")
                    start_date = st.date_input("Start increment from date:", key="increment_start_date")
                    end_date = st.date_input("End increment at date:", key="increment_end_date")
                    increment_pct = st.number_input("Enter increment %:", value=5.0, key="increment_income_pct") / 100

                    if st.button("Apply Increment Update", key="apply_increment_income"):
                        df = dynamic_milestone_income_projection
                        mask = (pd.to_datetime(df['entry_date']) >= pd.to_datetime(start_date)) & (pd.to_datetime(df['entry_date']) <= pd.to_datetime(end_date))
                        rows = df.loc[mask, ['entry_date', selected_column]].sort_values('entry_date')

                        if rows.empty:
                            st.warning("No matching rows found for the increment range.")
                        else:
                            prev_value = float(rows[selected_column].iloc[0] or 0)
                            for i, (idx, row) in enumerate(rows.iterrows()):
                                if i > 0:
                                    prev_value *= (1 + increment_pct)
                                if selected_column == 'total_expense':
                                    prev_value = -abs(prev_value)
                                dynamic_milestone_income_projection.loc[dynamic_milestone_income_projection['entry_date'] == row['entry_date'], selected_column] = prev_value
                            st.success(f"{selected_column} incrementally updated from {start_date} to {end_date}.")

                elif update_option == 'growth_increment_from_middle':
                    growth_month = st.selectbox("Select Growth Month", [str(i).zfill(2) for i in range(1, 13)], key="growth_month_middle")
                    growth_rate = st.number_input("Enter flat growth percentage:", value=5.0, key="flat_growth_rate") / 100
                    column_to_update = st.selectbox("Select column to apply growth:", ['passive_income', 'taxes','total_expense','household_lifestyle_expense_amount'], key="growth_column_select")
                    start_date = st.date_input("Start Entry Date:", key="growth_start_date")
                    end_date = st.date_input("End Entry Date:", key="growth_end_date")

                    if st.button("Apply Middle Growth", key="apply_middle_growth"):
                        df = dynamic_milestone_income_projection
                        mask = (pd.to_datetime(df['entry_date']) >= pd.to_datetime(start_date)) & (pd.to_datetime(df['entry_date']) <= pd.to_datetime(end_date))
                        rows = df.loc[mask, ['entry_date', column_to_update]].sort_values('entry_date')

                        if rows.empty:
                            st.warning("No records found for the selected user and date range.")
                        else:
                            last_value = None
                            cached_growth_value = None

                            for i, (idx, row) in enumerate(rows.iterrows()):
                                entry_month = row['entry_date'].strftime('%m')
                                if last_value is None:
                                    last_value = float(row[column_to_update] or 0)

                                if entry_month == growth_month:
                                    last_value *= (1 + growth_rate)
                                    cached_growth_value = last_value
                                elif cached_growth_value is not None:
                                    last_value = cached_growth_value

                                if column_to_update == 'total_expense':
                                    last_value = -abs(last_value)

                                if column_to_update == 'taxes':
                                    last_value = -abs(last_value)    

                                dynamic_milestone_income_projection.loc[dynamic_milestone_income_projection['entry_date'] == row['entry_date'], column_to_update] = last_value

                            st.success(f"{column_to_update} updated using middle-month growth logic.")

                # # Collect inputs for procedure
                # appraisal_end_date = st.selectbox("Select the appraisal end date (MM-DD):", ['03-31', '12-31'], key="passive_tax_appraisal_end_date")
                # tax_regime = st.selectbox("Select tax regime:", ["old", "new"], key="passive_tax_regime")            

                # # Call tax procedure
                # if st.button("Run Tax Projection for passive income"):
                #     try:
                #         with self.connection.cursor() as cursor:
                #             cursor.execute("""
                #                 CALL calculate_passive_income_tax_projection(%s, %s, %s)
                #             """, (user_id, tax_regime, appraisal_end_date))
                #         self.connection.commit()
                #         st.success("Tax projection generated and updated in the database.")

                #         # âœ… Reload updated data after procedure call
                #         dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
                #         st.dataframe(dynamic_milestone_income_projection)

                #     except Exception as e:
                #         st.error(f"Failed to execute tax projection: {e}")

                self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection) 
        
        return dynamic_milestone_income_projection

    def fetch_passive_income_from_income(self, user_code):
        """
        Fetch the sum of yearly_amount from the income table for specific category_ids
        related to passive income (307, 308, 309, 310).
        """
        query = """
            SELECT SUM(yearly_amount) AS total_passive_income
            FROM income
            WHERE user_code = %s AND category_id IN (307, 308, 309, 310)
        """
        cursor = self.connection.cursor()
        cursor.execute(query, (user_code,))
        result = cursor.fetchone()[0]  # Fetch the sum of yearly_amount
        cursor.close()
        return result if result else 0  # Return 0 if the result is None 

    def get_real_estate_growth_percentage(self):
        while True:
            try:
               percentage = st.number_input("Enter the annual real estate growth percentage (in %):", key="Locations")
               return percentage / 100  # Convert percentage to decimal
            except ValueError:
                print("Please enter a valid number.")

    def get_real_estate_growth_percentage_1(self):
        while True:
            try:
               percentage = st.number_input("Enter the annual real estate growth percentage (in %):", key="Locations_1")
               return percentage / 100  # Convert percentage to decimal
            except ValueError:
                print("Please enter a valid number.")            

    def fetch_real_estate_data(self, user_code):
        query = """
            SELECT TO_DATE(entry_date, 'YYYY-MM-DD') AS entry_date, assets_value
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (29, 30,631)   
            ORDER BY entry_date
        """
        real_estate_data = pd.read_sql(query, self.connection, params=[user_code]) 

        return real_estate_data

    def update_passive_income(self, dynamic_milestone_income_projection, real_estate_data, real_estate_growth_percentage, start_date, income_month):
        april_value = 0

        for index, row in dynamic_milestone_income_projection.iterrows():
            entry_date = row['entry_date']
            # Start projections from start_date onwards
            if entry_date >= start_date:
                entry_month = entry_date.month

                if entry_month == income_month:
                    matching_row = real_estate_data[real_estate_data['entry_date'] == entry_date]
                    if not matching_row.empty:
                        april_value = (matching_row['assets_value'].sum() * real_estate_growth_percentage)/12
                    else:
                        april_value = 0

                # Combine passive income from real estate (April) and the yearly passive income
                combined_passive_income =  april_value

                dynamic_milestone_income_projection.at[index, 'passive_income'] = combined_passive_income   
            
        return dynamic_milestone_income_projection  

    def alter_income_column_types_1(self):
        try:
            cursor = self.connection.cursor()
            alter_query = """
                ALTER TABLE dynamic_milestone_income_projection 
                    ALTER COLUMN entry_date TYPE DATE USING entry_date::date;
            """
            cursor.execute(alter_query)
            self.connection.commit()
            print("Column datatypes updated successfully.")
        except Exception as e:
            print(f"Error occurred while altering column datatypes: {e}")
            self.connection.rollback()
        finally:
            cursor.close() 


    def alter_goal_income_column_types(self):
        try:
            cursor = self.connection.cursor()
            alter_query = """
                ALTER TABLE dynamic_milestone_income_projection 
                ALTER COLUMN entry_date TYPE DATE USING entry_date::date,
                ALTER COLUMN age TYPE BIGINT USING age::bigint,
                ALTER COLUMN active_income TYPE NUMERIC USING active_income::numeric,
                ALTER COLUMN passive_income TYPE NUMERIC USING passive_income::numeric,
                ALTER COLUMN gross_income TYPE NUMERIC USING gross_income::numeric,
                ALTER COLUMN post_deduction_income TYPE NUMERIC USING post_deduction_income::numeric,
                ALTER COLUMN net_income_post_tax TYPE NUMERIC USING net_income_post_tax::numeric,
                ALTER COLUMN taxes TYPE NUMERIC USING taxes::numeric,
                ALTER COLUMN household_lifestyle_expense_amount TYPE NUMERIC USING household_lifestyle_expense_amount::numeric,
                ALTER COLUMN total_expense TYPE NUMERIC USING total_expense::numeric,
                ALTER COLUMN passive_income_2 TYPE NUMERIC USING passive_income_2::numeric,
                ALTER COLUMN passive_income_3 TYPE NUMERIC USING passive_income_3::numeric,
                ALTER COLUMN total_passive_income TYPE NUMERIC USING total_passive_income::numeric;
            """
            cursor.execute(alter_query)
            self.connection.commit()
            print("Column datatypes updated successfully.")
        except Exception as e:
            print(f"Error occurred while altering column datatypes: {e}")
            self.connection.rollback()
        finally:
            cursor.close()        

    def copy_temp_to_dynamic_milestone_income_projection(self, user_code):
        
        self.clear_dynamic_milestone_income_projection_table()

        query = """
            SELECT
                user_code AS user_code,
                entry_date AS entry_date,
                fin_year_entry AS fin_year_entry,
                fin_year_in_words AS fin_year_in_words,
                age AS age,
                active_income_2 AS active_income,
                passive_income_2 AS passive_income,
                gross_income_amount AS gross_income,
                post_income AS post_deduction_income,
                net_income_post_tax AS net_income_post_tax,
                -tax_projection_values AS taxes,
                -household_lifestyle_expense_amount AS household_lifestyle_expense_amount,
                -total_expense AS total_expense
            FROM dynamic_income_projection
            WHERE user_code = %s
            ORDER BY entry_date
        """
        new_user_data = pd.read_sql(query, self.connection, params=[user_code])

        new_user_data['passive_income_2'] = 0
        new_user_data['passive_income_3'] = 0
        new_user_data['bonus_income'] = 0
        new_user_data['total_passive_income'] = 0
        #new_user_data['gross_income'] = 0

        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()

        if dynamic_milestone_income_projection.empty:
            dynamic_milestone_income_projection = new_user_data
        #else:
            #dynamic_milestone_income_projection = self.update_dynamic_milestone_income_projection(dynamic_milestone_income_projection, new_user_data, user_code)

        self.alter_goal_income_column_types()    

        self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)
        st.write("data added successfully and save to database")

    def copy_combine_temp_to_dynamic_milestone_income_projection(self, user_code):
        
        self.clear_dynamic_milestone_income_projection_table()

        query = """
            SELECT
                user_code AS user_code,
                entry_date AS entry_date,
                fin_year_entry AS fin_year_entry,
                fin_year_in_words AS fin_year_in_words,
                age AS age,
                active_income_2 AS active_income,
                passive_income_2 AS passive_income,
                gross_income_amount AS gross_income,
                post_income AS post_deduction_income,
                net_income_post_tax AS net_income_post_tax,
                -tax_projection_values AS taxes,
                -household_lifestyle_expense_amount AS household_lifestyle_expense_amount,
                -total_expense AS total_expense
            FROM dynamic_combine_income_projection
            WHERE user_code = %s
            ORDER BY entry_date
        """
        new_user_data = pd.read_sql(query, self.connection, params=[user_code])

        new_user_data['passive_income_2'] = 0
        new_user_data['passive_income_3'] = 0
        new_user_data['bonus_income'] = 0
        new_user_data['total_passive_income'] = 0
        #new_user_data['gross_income'] = 0

        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()

        if dynamic_milestone_income_projection.empty:
            dynamic_milestone_income_projection = new_user_data
        #else:
            #dynamic_milestone_income_projection = self.update_dynamic_milestone_income_projection(dynamic_milestone_income_projection, new_user_data, user_code)

        self.alter_goal_income_column_types()    

        self.save_dynamic_milestone_income_projection_to_db(dynamic_milestone_income_projection)
        st.write("data added successfully and save to database")      

    def clear_dynamic_milestone_income_projection_table(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_milestone_income_projection")
            self.connection.commit()
            print("Cleared the dynamic_milestone_income_projection table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_income_projection table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()    


    def save_dynamic_milestone_income_projection_to_db(self, dynamic_milestone_income_projection):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        dynamic_milestone_income_projection.to_sql(
            'dynamic_milestone_income_projection',
            engine,
            if_exists='replace',
            index=False
        )
        print("Data saved to PostgreSQL table 'dynamic_milestone_income_projection'")


    def transpose_dynamic_milestone_income_projection_1(self, dynamic_milestone_income_projection):
        # Drop unnecessary columns
        dynamic_milestone_income_projection = dynamic_milestone_income_projection.drop(columns=['user_code', 'fin_year_entry', 'fin_year_in_words'])

        # Ensure entry_date is in string format
        #dynamic_milestone_income_projection['entry_date'] = dynamic_milestone_income_projection['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_milestone_income_projection.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        st.write(df_transposed)

        return df_transposed
    
    
    def apply_bonus_to_gross_income(self, user_code, df):
        """
        Compute an annually paid, age-banded, month-triggered bonus and write it to
        the `bonus_income` column (NOT to gross_income). Bonus is only applied for
        rows with entry_date between start_date and end_date (inclusive).
        """
        import pandas as pd
        from datetime import date, datetime
        from decimal import Decimal

        st.subheader("Bonus â†’ Bonus Income (not Gross)")

        do_bonus = st.radio(
            "Do you want to add the bonus income?",
            ["No", "Yes"],
            index=0,
            key="add_bonus_income_radio",
        )
        if do_bonus != "Yes":
            return df

        # Inputs (month trigger, age-banded growth, base amount, date window)
        bonus_month = st.selectbox(
            "Select Bonus Month (paid)",
            [str(i).zfill(2) for i in range(1, 13)],
            key="bonus_income_growth_month",
        )
        bonus_growth_1 = st.number_input("Annual Bonus Growth for age â‰¤ 35 (%)", value=5.0, key="bonus_income_growth_1")
        bonus_growth_2 = st.number_input("Annual Bonus Growth for age 36â€“45 (%)", value=4.0, key="bonus_income_growth_2")
        bonus_growth_3 = st.number_input("Annual Bonus Growth for age 46â€“55 (%)", value=3.0, key="bonus_income_growth_3")
        bonus_growth_4 = st.number_input("Annual Bonus Growth for age â‰¥ 56 (%)", value=2.0, key="bonus_income_growth_4")
        base_bonus    = st.number_input("What is your annual bonus amount?", min_value=0.0, step=1000.0, key="bonus_income_base_amount")

        start_date = st.date_input("Enter the start date for bonus income (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="bonus_income_start")
        end_date   = st.date_input("Enter the end date for bonus income (YYYY-MM-DD):", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),  key="bonus_income_end")

        if not st.button("Apply Bonus (write to bonus_income)", key="apply_bonus_income_btn"):
            return df

        if base_bonus <= 0:
            st.warning("Bonus amount must be greater than 0.")
            return df
        if end_date < start_date:
            st.error("End date must be on/after start date.")
            return df

        # Defensive filter for this user and dtype cleanup
        df_local = df.copy()
        if 'user_code' in df_local.columns:
            df_local = df_local[df_local['user_code'].astype(str) == str(user_code)]

        if df_local.empty:
            st.warning("No rows found for this user to apply bonus.")
            return df

        df_local['entry_date'] = pd.to_datetime(df_local['entry_date']).dt.date
        df_local['age'] = pd.to_numeric(df_local['age'], errors='coerce').fillna(0).astype(int)

        # Ensure bonus_income column exists in the DB/table (safe-guard)
        try:
            with self.connection.cursor() as cur:
                cur.execute("""
                    DO $$
                    BEGIN
                        IF NOT EXISTS (
                            SELECT 1
                            FROM information_schema.columns
                            WHERE table_name = 'dynamic_milestone_income_projection'
                            AND column_name = 'bonus_income'
                        ) THEN
                            ALTER TABLE dynamic_milestone_income_projection
                            ADD COLUMN bonus_income NUMERIC;
                        END IF;
                    END$$;
                """)
            self.connection.commit()
        except Exception as e:
            self.connection.rollback()
            st.error(f"Failed ensuring bonus_income column exists: {e}")
            return df

        # If column missing in the in-memory df, add it
        if 'bonus_income' not in df_local.columns:
            df_local['bonus_income'] = 0.0
        else:
            df_local['bonus_income'] = pd.to_numeric(df_local['bonus_income'], errors='coerce').fillna(0.0)

        # Age-banded growth rates â†’ decimals
        g1 = float(bonus_growth_1) / 100.0
        g2 = float(bonus_growth_2) / 100.0
        g3 = float(bonus_growth_3) / 100.0
        g4 = float(bonus_growth_4) / 100.0

        current_year  = datetime.now().year
        current_month = datetime.now().month
        bonus_value   = float(base_bonus)  # starting bonus amount

        # We iterate by date; apply growth at *each* bonus month row (same as your earlier logic),
        # but only write bonus to rows within [start_date, end_date].
        df_sorted = df_local.sort_values('entry_date')
        added_bonus = pd.Series(0.0, index=df_sorted.index)

        for idx, row in df_sorted.iterrows():
            entry_date_row = row['entry_date']
            entry_month    = f"{entry_date_row.month:02d}"
            age            = int(row['age'])

            # Choose growth % by age band
            if age <= 35:
                gp = g1
            elif 36 <= age <= 45:
                gp = g2
            elif 46 <= age <= 55:
                gp = g3
            else:
                gp = g4

            # April fiscal-year special-case (same behavior you had before)
            if bonus_month == "04" and current_month == 4:
                april_this_year  = date(current_year, 4, 1)
                march_next_year  = date(current_year + 1, 3, 31)
                if not (april_this_year <= entry_date_row <= march_next_year):
                    if entry_month == bonus_month:
                        bonus_value *= (1.0 + gp)
            else:
                if entry_month == bonus_month:
                    bonus_value *= (1.0 + gp)

            # Only assign a bonus to rows inside the requested window AND at the bonus month
            if (start_date <= entry_date_row <= end_date) and (entry_month == bonus_month):
                added_bonus.at[idx] = bonus_value

        # Write into the in-memory dataframe's bonus_income (overwrite for affected rows)
        affected_idx = added_bonus[added_bonus != 0.0].index
        if len(affected_idx) == 0:
            st.info("No rows fell within the date range and bonus month. Nothing to update.")
            return df

        df_sorted.loc[affected_idx, 'bonus_income'] = added_bonus.loc[affected_idx]

        # Persist to DB with batch UPDATE (only affected rows)
        update_rows = []
        for idx in affected_idx:
            bi = Decimal(str(df_sorted.at[idx, 'bonus_income'])) if pd.notnull(df_sorted.at[idx, 'bonus_income']) else Decimal('0')
            update_rows.append((bi, str(user_code), df_sorted.at[idx, 'entry_date']))

        try:
            with self.connection.cursor() as cur:
                cur.executemany(
                    """
                    UPDATE dynamic_milestone_income_projection
                    SET bonus_income = %s
                    WHERE user_code   = %s
                    AND entry_date  = %s
                    """,
                    update_rows,
                )
            self.connection.commit()
            st.success(f"bonus_income updated for {len(update_rows)} row(s).")
        except Exception as e:
            self.connection.rollback()
            st.error(f"Failed to save bonus_income to DB: {e}")
            return df
        
        # # Reload fresh data for this user and return it
        # df_after = self.load_dynamic_milestone_income_projection_from_db()
        # if not df_after.empty and 'user_code' in df_after.columns:
        #     df_after = df_after[df_after['user_code'].astype(str) == str(user_code)]
        # st.dataframe(df_after)
        # return df_after


    def run_dynamic_milestone_income_projection(self, user_id):
        if st.button("Copy the income projection into another table"):
            self.copy_temp_to_dynamic_milestone_income_projection(user_id) 

        # Load the dynamic_milestone_income_projection table and transpose it
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        query_milestone_income = """
            SELECT * FROM dynamic_milestone_income_projection WHERE user_code = %s order by entry_date;
        """
        try:
            dynamic_milestone_income_projection = pd.read_sql(query_milestone_income, engine, params=(user_id,))
        except Exception as e:
            st.warning("dynamic_milestone_income_projection table not found. Creating it...")
            self.copy_temp_to_dynamic_milestone_income_projection(user_id)
            dynamic_milestone_income_projection = pd.read_sql(query_milestone_income, engine, params=(user_id,))

        # Update active_income if user opts in
        dynamic_milestone_income_projection = self.update_active_income(dynamic_milestone_income_projection)

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.process_passive_swp_income(user_id, dynamic_milestone_income_projection)  

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.process_passive_rental_income(user_id, dynamic_milestone_income_projection)  

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.apply_bonus_to_gross_income(user_id, dynamic_milestone_income_projection)
        self.alter_goal_income_column_types()

 
        # Collect inputs for procedure
        appraisal_end_date = st.selectbox("Select the appraisal end date (MM-DD):", ['03-31', '02-28','12-31','10-31'], key="passive_tax_appraisal_end_date")
        tax_regime = st.selectbox("Select tax regime:", ["old", "new"], key="passive_tax_regime")            

        # Call tax procedure
        if st.button("Run Tax Projection for passive income"):
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        CALL calculate_passive_income_tax_projection(%s, %s, %s)
                    """, (user_id, tax_regime, appraisal_end_date))
                self.connection.commit()
                st.success("Tax projection generated and updated in the database.")

                # âœ… Reload updated data after procedure call
                dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
                #st.dataframe(dynamic_milestone_income_projection)

            except Exception as e:
                st.error(f"Failed to execute tax projection: {e}") 
        # Add Streamlit inputs for generate_tax_projection procedure
        st.subheader("Run Tax Projection Procedure")
        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        # # Step 4: Process passive rental income
        
        transposed_df = self.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
        st.dataframe(transposed_df)


    def run_dynamic_combine_milestone_income_projection(self, user_id):
        if st.button("Copy the income projection into another table"):
            self.copy_combine_temp_to_dynamic_milestone_income_projection(user_id) 

        # Load the dynamic_milestone_income_projection table and transpose it
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        query_milestone_income = """
            SELECT * FROM dynamic_milestone_income_projection WHERE user_code = %s order by entry_date;
        """
        try:
            dynamic_milestone_income_projection = pd.read_sql(query_milestone_income, engine, params=(user_id,))
        except Exception as e:
            st.warning("dynamic_milestone_income_projection table not found. Creating it...")
            self.copy_combine_temp_to_dynamic_milestone_income_projection(user_id)
            dynamic_milestone_income_projection = pd.read_sql(query_milestone_income, engine, params=(user_id,))

        # Update active_income if user opts in
        dynamic_milestone_income_projection = self.update_active_income(dynamic_milestone_income_projection)

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.process_passive_swp_income(user_id, dynamic_milestone_income_projection)  

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.process_passive_rental_income(user_id, dynamic_milestone_income_projection)  

        self.alter_goal_income_column_types()

        dynamic_milestone_income_projection = self.apply_bonus_to_gross_income(user_id, dynamic_milestone_income_projection)
        self.alter_goal_income_column_types()

 
        # Collect inputs for procedure
        appraisal_end_date = st.selectbox("Select the appraisal end date (MM-DD):", ['03-31', '12-31','10-31'], key="passive_tax_appraisal_end_date")
        tax_regime = st.selectbox("Select tax regime:", ["old", "new"], key="passive_tax_regime")            

        # Call tax procedure
        if st.button("Run Tax Projection for passive income"):
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("""
                        CALL calculate_passive_income_tax_projection(%s, %s, %s)
                    """, (user_id, tax_regime, appraisal_end_date))
                self.connection.commit()
                st.success("Tax projection generated and updated in the database.")

                # âœ… Reload updated data after procedure call
                dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
                #st.dataframe(dynamic_milestone_income_projection)

            except Exception as e:
                st.error(f"Failed to execute tax projection: {e}") 
        # Add Streamlit inputs for generate_tax_projection procedure
        st.subheader("Run Tax Projection Procedure")
        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        # # Step 4: Process passive rental income
        
        transposed_df = self.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
        st.dataframe(transposed_df)    


    def create_additional_income_expense_criteria(self, dob, retirement_age, user_code, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            projection_data = {
                'user_code': user_code,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'expense_category_name': '',
                'amount': 0  # Initialize amount to 0
            }
            projections.append(projection_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return pd.DataFrame(projections)

    def update_additional_income_expense_criteria(self, user_code, month_choice):
        dob, retirement_age = self.fetch_user_data(user_code)
        user_name = self.fetch_user_name(user_code)

        # Load existing data or create new data if none exists
        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()

        if additional_income_expense_criteria_df.empty:
            additional_income_expense_criteria_df = self.create_additional_income_expense_criteria(dob, retirement_age, user_code, user_name, month_choice)

        # Add functionality to delete an existing category
        delete_expense_category = st.radio("Do you want to delete an existing expense category?", ('no', 'yes'), key="delete_expense_key")

        if delete_expense_category == 'yes':
            # Fetch unique existing expense categories for the user
            existing_categories = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_code]['expense_category_name'].unique()

            if len(existing_categories) == 0:
                st.error("No expense categories found to delete.")
            else:
                expense_category_to_delete = st.selectbox(
                    "Select an expense category to delete:", 
                    existing_categories, 
                    key="delete_expense_category_dropdown"
                )

                if st.button("Delete Selected Expense Category", key="delete_expense_button"):
                    try:
                        # Delete the selected category from the database
                        delete_query = """
                            DELETE FROM additional_income_expense_criteria 
                            WHERE user_code = %s AND expense_category_name = %s;
                        """
                        cursor = self.connection.cursor()
                        cursor.execute(delete_query, (user_code, expense_category_to_delete))
                        self.connection.commit()
                        cursor.close()

                        # Update the in-memory DataFrame
                        additional_income_expense_criteria_df = additional_income_expense_criteria_df[
                            additional_income_expense_criteria_df['expense_category_name'] != expense_category_to_delete
                        ]

                        st.success(f"Expense category '{expense_category_to_delete}' has been deleted successfully.")
                    except Exception as error:
                        st.error(f"An error occurred while deleting the expense category: {error}")
                        self.connection.rollback()
                    return additional_income_expense_criteria_df  # Return updated DataFrame after deletion


        category_option = st.radio("Would you like to add a new expense category or use an existing one?",
                                ('Add new expense category', 'Use existing expense category'), key="expense_time_category")

        if category_option == 'Add new expense category':
            expense_category_name = st.text_input("Enter the name of the expense category:")

            if not expense_category_name.strip():
                st.error("Expense category name cannot be empty. Please enter a valid name.")
                return additional_income_expense_criteria_df  # Exit early if the name is invalid

            # Ensure we only append one row per unique entry_date
            unique_entry_dates = additional_income_expense_criteria_df['entry_date'].unique()

            # Create new rows for the new expense category with 0 amount for each unique entry_date
            new_category_data = [{
                'user_code': user_code,
                'user_name': user_name,
                'entry_date': entry_date,
                'age': self.calculate_age_on_date(dob, pd.to_datetime(entry_date)),
                'expense_category_name': expense_category_name,
                'amount': 0
            } for entry_date in unique_entry_dates]

            new_category_df = pd.DataFrame(new_category_data)

            # Append the new category only once for each entry_date
            self.save_additional_income_expense_criteria_df_to_db(new_category_df, append=True)

        else:
            # Fetch existing categories for the user
            filtered_df = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_code]
            existing_categories = filtered_df['expense_category_name'].unique()
            expense_category_name = st.selectbox("Select an existing expense category:", existing_categories, key="expense_single_asset")

            entry_type = st.radio("Choose entry type:", ('1 year interval','single', 'range', 'increment','incremental_rent','stop'), key="expense_entry_type")

            if entry_type == '1 year interval':
                start_date = st.date_input("Enter the start date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="expense_one_year_interval_start_date")
                initial_amount = st.number_input("Enter the amount:", key="expense_one_year_interval_initial_amount")
                income_growth_percentage = st.number_input("Enter the income growth percentage (%):", min_value=0.0, key="expense_one_year_income_growth_percent") / 100
                end_date = st.date_input("Enter the end date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_one_year_interval_end_date")

                current_date = pd.to_datetime(start_date)
                current_amount = initial_amount

                if st.button("Apply 1 year increment option Changes and Save", key="one_year_increment_button"): 
                    while current_date <= pd.to_datetime(end_date):
                        # Update the existing values for this category
                        additional_income_expense_criteria_df.loc[
                            (additional_income_expense_criteria_df['entry_date'] == current_date) &
                            (additional_income_expense_criteria_df['user_code'] == user_code) &
                            (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name), 
                            'amount'
                        ] =  -abs(current_amount)
                        
                        st.write('current_amount',current_amount)
                        st.write('current_date',current_date)
                        next_year_date = current_date + pd.DateOffset(years=1)
                        current_date = next_year_date + pd.offsets.MonthEnd(0)
                        current_amount = current_amount * (1 + income_growth_percentage)
                        

                    # Replace the existing rows in the database
                    self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df, append=False)
                    st.success("Data saved successfully.")

            elif entry_type == 'single':
                single_date = st.date_input("Enter the entry date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = "expense_single_date")
                amount = st.number_input("Enter the amount:",key = "expense_single_amount")
                if st.button("Apply single option Changes and Save",key = "expense_single_button"):
                    # Replace existing value for the selected entry date and expense category
                    additional_income_expense_criteria_df.loc[
                        (additional_income_expense_criteria_df['entry_date'] == single_date.strftime('%Y-%m-%d')) &
                        (additional_income_expense_criteria_df['user_code'] == user_code) &
                        (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name),
                        'amount'
                    ] = -abs(amount)

                    # Replace the existing rows in the database
                    self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df, append=False)
                    st.success("Data saved successfully.")

            elif entry_type == 'range':
                start_date = st.date_input("Enter the start date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key= "expense_range_start_date")
                end_date = st.date_input("Enter the end date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key= "expense_range_end_date")
                amount = st.number_input("Enter the amount:",key= "expense_range_amount")
                if st.button("Apply range option Changes and Save",key ='expense_range_button'):
                    additional_income_expense_criteria_df.loc[
                        (additional_income_expense_criteria_df['entry_date'] >= start_date.strftime('%Y-%m-%d')) &
                        (additional_income_expense_criteria_df['entry_date'] <= end_date.strftime('%Y-%m-%d')) &
                        (additional_income_expense_criteria_df['user_code'] == user_code) &
                        (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name),
                        'amount'
                    ] = -abs(amount)

                    # Replace the existing rows in the database
                    self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df, append=False)
                    st.success("Data saved successfully.")

            elif entry_type == 'increment':
                increment_percentage = st.number_input("Enter the increment percentage (%):",key="expense_increment_percent") / 100
                start_date = st.date_input("Enter the entry date where the increment will start (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_increment_start_date")
                end_date_increment = st.date_input("Enter the end date up to which the incremented value should be projected (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="expense_increment_end_date")
                if st.button("Apply increment option Changes and Save", key="expense_increment_button"): 
                    current_date = pd.to_datetime(start_date)

                    previous_date = (current_date - pd.DateOffset(months=1)).strftime('%Y-%m-%d')
                    previous_date = pd.to_datetime(previous_date) + pd.offsets.MonthEnd(0)
                    previous_value = additional_income_expense_criteria_df.loc[
                        (additional_income_expense_criteria_df['entry_date'] == previous_date.strftime('%Y-%m-%d')) &
                        (additional_income_expense_criteria_df['user_code'] == user_code) &
                        (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name),
                        'amount'
                    ].values

                    if len(previous_value) > 0:
                        new_value = previous_value[0] * (1 + increment_percentage)
                        while current_date <= pd.to_datetime(end_date_increment):
                            additional_income_expense_criteria_df.loc[
                                (additional_income_expense_criteria_df['entry_date'] == current_date.strftime('%Y-%m-%d')) &
                                (additional_income_expense_criteria_df['user_code'] == user_code) &
                                (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name),
                                'amount'
                            ] = -abs(new_value)

                            current_date = current_date + pd.offsets.MonthEnd(1) 
                    # Replace the existing rows in the database
                    self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df, append=False)
                    st.success("Total expense column has been updated and saved to the database.")

            # ðŸ”¹ NEW INCREMENTAL RENT LOGIC
            elif entry_type == 'incremental_rent':
                start_date = st.date_input("Enter the start date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31),key="expense_incremental_rent_start_date")
                initial_first_amount = st.number_input("Enter the amount:", key="expense_incremental_rent_initial_amount")
                expense_growth_percentage = st.number_input("Enter the income growth percentage (%):", min_value=0.0, key="expense_incremental_rent_growth_percent") / 100
                end_date = st.date_input("Enter the end date (YYYY-MM-DD):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="expense_incremental_rent_end_date")

                start_date = pd.to_datetime(start_date)
                end_date = pd.to_datetime(end_date)

                if st.button("Apply incremental rent option Changes and Save", key="incremental_rent_button"):
                    current_date = start_date
                    current_amount = initial_first_amount

                    while current_date <= end_date:
                        last_day_of_month = current_date + pd.offsets.MonthEnd(0)  # Ensure last day of the month
                        
                        # Assign the amount for the next 12 months
                        for i in range(12):
                            projection_date = last_day_of_month + pd.DateOffset(months=i)
                            
                            if projection_date <= end_date:
                                st.write('projection_date',projection_date)
                                st.write('current_amount',current_amount)
                                additional_income_expense_criteria_df.loc[
                                    (additional_income_expense_criteria_df['entry_date'] == projection_date.strftime('%Y-%m-%d')) &
                                    (additional_income_expense_criteria_df['user_code'] == user_code) &
                                    (additional_income_expense_criteria_df['expense_category_name'] == expense_category_name),
                                    'amount'
                                ] = -abs(current_amount)

                        # Move to the next year and apply growth percentage
                        current_amount *= (1 + expense_growth_percentage)
                        #st.write('current_amount',current_amount)
                        current_date = last_day_of_month + pd.DateOffset(years=1)  # Move to the last day of the next year

                    # Replace the existing rows in the database
                    self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df, append=False)
                    st.success("Incremental rent data saved successfully.")         

            elif entry_type == 'stop':
                self.save_additional_income_expense_criteria_df_to_db(additional_income_expense_criteria_df)
                st.write("Stop function executed. No changes applied.")        

        return additional_income_expense_criteria_df
    
    def create_table_if_not_exists(self):
        """Create the table if it doesn't exist."""
        cursor = self.connection.cursor()
        create_table_query = """
        CREATE TABLE IF NOT EXISTS additional_income_expense_criteria (
            user_code VARCHAR(255),
            user_name VARCHAR(255),
            entry_date DATE,
            age INT,
            expense_category_name VARCHAR(255),
            amount DECIMAL
        );
        """
        cursor.execute(create_table_query)
        self.connection.commit()
        cursor.close()
        print("Table 'additional_income_expense_criteria' created or exists already.")

    def save_additional_income_expense_criteria_df_to_db(self, additional_income_expense_criteria_df, append=True):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        if append:
            additional_income_expense_criteria_df.to_sql('additional_income_expense_criteria', engine, if_exists='append', index=False)
        else:
            additional_income_expense_criteria_df.to_sql('additional_income_expense_criteria', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'additional_income_expense_criteria'")

    def load_additional_income_expense_criteria_df_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'additional_income_expense_criteria'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'additional_income_expense_criteria' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('additional_income_expense_criteria', engine)

    def update_total_expense(self, user_code):
        try:
            import io
            from sqlalchemy import text

            engine = create_engine(f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}")

            # 1. Load required dataframes
            query_projection = """
                SELECT entry_date, household_lifestyle_expense_amount 
                FROM dynamic_milestone_income_projection 
                WHERE user_code = %s;
            """
            df_main = pd.read_sql(query_projection, engine, params=(user_code,))
            df_main['entry_date'] = pd.to_datetime(df_main['entry_date']).dt.date

            query_expense = """
                SELECT entry_date, SUM(amount) AS additional_expense
                FROM additional_income_expense_criteria 
                WHERE user_code = %s
                GROUP BY entry_date;
            """
            df_extra = pd.read_sql(query_expense, engine, params=(user_code,))
            df_extra['entry_date'] = pd.to_datetime(df_extra['entry_date']).dt.date

            # 2. Merge and calculate total_expense
            merged_df = pd.merge(df_main, df_extra, on='entry_date', how='left')
            merged_df['additional_expense'].fillna(0, inplace=True)
            merged_df['total_expense'] = merged_df['household_lifestyle_expense_amount'] + merged_df['additional_expense']
            merged_df['user_code'] = user_code

            # 3. Bulk update using temporary table + SQL
            with engine.begin() as conn:
                temp_table = "temp_expense_update"
                merged_df[['entry_date', 'total_expense', 'user_code']].to_sql(temp_table, conn, if_exists='replace', index=False)

                update_query = text(f"""
                    UPDATE dynamic_milestone_income_projection AS main
                    SET total_expense = temp.total_expense
                    FROM {temp_table} AS temp
                    WHERE main.user_code = temp.user_code AND main.entry_date = temp.entry_date
                """)
                conn.execute(update_query)

            #st.success("âœ… Total expense column updated successfully (fast method).")

        except Exception as error:
            st.error(f"An error occurred: {error}")
            self.connection.rollback()


    def transpose_dynamic_milestone_income_projection_1(self, dynamic_milestone_income_projection):
        # Drop unnecessary columns
        dynamic_milestone_income_projection = dynamic_milestone_income_projection.drop(columns=['user_code', 'fin_year_entry', 'fin_year_in_words'])

        # Ensure entry_date is in string format
        #dynamic_milestone_income_projection['entry_date'] = dynamic_milestone_income_projection['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_milestone_income_projection.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        st.write(df_transposed)

        return df_transposed   
    
    def transpose_display_dynamic_milestone_income_projection_1(self, dynamic_milestone_income_projection):
        # Drop unnecessary columns
        dynamic_milestone_income_projection = dynamic_milestone_income_projection.drop(
            columns=['user_code', 'fin_year_entry', 'fin_year_in_words'],
            errors='ignore'  # in case any column is missing
        )

        # âœ… Ensure entry_date is datetime and sorted before transpose
        dynamic_milestone_income_projection['entry_date'] = pd.to_datetime(
            dynamic_milestone_income_projection['entry_date'], errors='coerce'
        )
        dynamic_milestone_income_projection = dynamic_milestone_income_projection.sort_values(
            'entry_date', ignore_index=True
        )

        # Transpose the table
        df_transposed = dynamic_milestone_income_projection.set_index('entry_date').T

        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)  # Set asset_name as index
        return df_transposed  



    def transpose_dynamic_milestone_income_projection(self, dynamic_milestone_income_projection):
        dynamic_milestone_income_projection = self.transpose_and_sort_dates(dynamic_milestone_income_projection)
        # Drop unnecessary columns
        dynamic_milestone_income_projection = dynamic_milestone_income_projection.drop(columns=['user_code', 'fin_year_entry', 'fin_year_in_words'])

        # Ensure entry_date is in string format
        #dynamic_milestone_income_projection['entry_date'] = dynamic_milestone_income_projection['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_milestone_income_projection.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)


        return df_transposed 
    

    # Reshape the additional_income_expense_criteria for display
    def reshape_additional_income_expense_criteria(self, additional_income_expense_criteria_df, user_id):
        # Filter data for the specified user
        user_df = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get expense_category_name as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='expense_category_name', 
                                          columns=['entry_date', 'age'],
                                          values='amount', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring expense_category_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df
    
    # Reshape the additional_income_expense_criteria for display
    def reshape_display_additional_income_expense_criteria(self, additional_income_expense_criteria_df, user_id):
        # Filter data for the specified user
        user_df = additional_income_expense_criteria_df[additional_income_expense_criteria_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get expense_category_name as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='expense_category_name', 
                                          columns=['entry_date', 'age'],
                                          values='amount', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring expense_category_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        reshaped_df.set_index('expense_category_name', inplace=True)  # Set asset_name as index

        return reshaped_df
    
    
    # Function to delete records with entry_date less than the current date
    def delete_old_additional_income_expense_criteria_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM additional_income_expense_criteria 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")      

    def run_additional_income_expense_criteria(self, user_code, month_choice ):
        self.create_table_if_not_exists()

        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('additional_income_expense_criteria'):
            # Only delete old records if the table exists
            self.delete_old_additional_income_expense_criteria_records()

        add_expense = st.radio("Do you want to add an additional expense?", ('no', 'yes'), key="add_expense_key")
        
        if add_expense == 'yes':
            self.update_additional_income_expense_criteria(user_code, month_choice)

        self.update_total_expense(user_code)  

        # Load the dynamic_milestone_income_projection table and transpose it
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        query_milestone_income = """
            SELECT * FROM dynamic_milestone_income_projection WHERE user_code = %s order by entry_date;
        """
        dynamic_milestone_income_projection = pd.read_sql(query_milestone_income, engine, params=(user_code,))
        
        transposed_df = self.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
        st.dataframe(transposed_df)

        # Load the additional_income_expense_criteria table and reshape it
        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        
        reshaped_df = self.reshape_display_additional_income_expense_criteria(additional_income_expense_criteria_df, user_code)
        st.dataframe(reshaped_df)
        

    #milestone related withdrawal
    def fetch_assets_with_categories_2(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT TRIM(purpose) AS purpose, category_id
            FROM milestones_liabilities
            WHERE user_code = %s 
            AND purpose IS NOT NULL 
            AND purpose <> 'None';
        """, (user_id,))
        
        assets_with_categories = cursor.fetchall()
        cursor.close()
        
        return assets_with_categories

    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    def create_milestone_related_withdrawal_projection_table(self, dob, retirement_age, assets_with_categories, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)
        
        projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)
            
            for milestone_name, category_id in assets_with_categories:
                projection_data = {
                    'user_code': user_id,
                    'user_name': user_name,
                    'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                    'age': iter_age,
                    'category_id': category_id,
                    'milestone_name': milestone_name,
                    'milestone_value': 0  # Initialize milestone value to 0
                }
                projections.append(projection_data)
            
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return projections


    def save_milestone_withdrawal_projections_to_db(self, milestone_withdrawal_projections_df, user_id):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"

        # Create the engine
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('milestone_withdrawal_projections'):
            print("Table 'milestone_withdrawal_projections' does not exist. Creating the table.")
            milestone_withdrawal_projections_df.head(0).to_sql(
                'milestone_withdrawal_projections',
                engine,
                if_exists='replace',  # Create table
                index=False
            )
        else:
            print(f"Table 'milestone_withdrawal_projections' already exists.")

        with engine.connect() as connection:
            existing_data = pd.read_sql('milestone_withdrawal_projections', connection)

        existing_data = existing_data[existing_data['user_code'] != user_id]
        updated_data = pd.concat([existing_data, milestone_withdrawal_projections_df[milestone_withdrawal_projections_df['user_code'] == user_id]])
        updated_data = updated_data.drop_duplicates().reset_index(drop=True)

        updated_data.to_sql('milestone_withdrawal_projections', engine, if_exists='replace', index=False)
        print("milestone_withdrawal_projections saved to the PostgreSQL database.")

    def load_milestone_withdrawal_projections_from_db(self):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        
        # Create the engine
        engine = create_engine(connection_string)
        
        # Check if the table exists before trying to load
        table_exists_query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'milestone_withdrawal_projections'
            );
        """
        
        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar()

        if not table_exists:
            print("Table 'milestone_withdrawal_projections' does not exist.")
            milestone_withdrawal_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            milestone_withdrawal_projections_df = pd.read_sql('milestone_withdrawal_projections', engine)
        
        return milestone_withdrawal_projections_df


    def add_additional_asset_for_milestone_withdrawal(self, milestone_withdrawal_projections_df, assets_dict, assets_with_categories, user_id, dob, retirement_age, asset_name, month_choice):
        # Check if the asset_name already exists for the user
        user_specific_df = milestone_withdrawal_projections_df[milestone_withdrawal_projections_df['user_code'] == user_id]
        # Extract unique asset names from the user's specific data, then strip spaces and convert to lowercase
        unique_existing_assets = [asset.strip().lower() for asset in user_specific_df['milestone_name'].unique()]
        stripped_asset_name = asset_name.strip().lower()

        # Temporarily strip spaces from the asset_name for comparison
        if stripped_asset_name in unique_existing_assets:
            #exact_matches = sum(1 for existing in unique_existing_assets if existing == stripped_asset_name)
            existing_count = sum(1 for existing in unique_existing_assets if existing.strip().lower().startswith(stripped_asset_name))
            print('exact_matches check', existing_count)
            new_asset_name = f"{asset_name.strip()} {existing_count + 1}"
            
            # Retrieve category_id from the DataFrame, handling extra spaces
            category_id = milestone_withdrawal_projections_df.loc[
                milestone_withdrawal_projections_df['milestone_name'].str.strip().str.lower() == stripped_asset_name, 
                'category_id'
            ].values[0]
        else:
            new_asset_name = asset_name
            category_id = next((cat_id for cat_id, name in assets_dict.items() if name == asset_name), None)

        if category_id is not None:
            # Append new asset to the list with category
            assets_with_categories.append((new_asset_name, category_id))
            new_projections = self.create_milestone_related_withdrawal_projection_table(dob, retirement_age, [(new_asset_name, category_id)], user_id, self.fetch_user_name(user_id), month_choice)
            milestone_withdrawal_projections_df = pd.concat([milestone_withdrawal_projections_df, pd.DataFrame(new_projections)], ignore_index=True)
        else:
            st.write("Invalid asset name entered. No asset added.")

        return milestone_withdrawal_projections_df, assets_with_categories    
    

    def update_milestone_related_withdrawal_projections(self, user_id, milestone_withdrawal_projections_df, distinct_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        unique_asset_names = milestone_withdrawal_projections_df['milestone_name'].unique()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'single':
            print('single_date', single_date)
            asset_name = increment_params.get('asset_name')  # Asset name passed from frontend
            print('asset_name',asset_name)
            amount = increment_params.get('amount')
            print('amount',amount)

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return milestone_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'") 

            #Apply the update for the matched asset name on the given single date
            #updated = False
            for idx, projection in milestone_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == single_date and projection['milestone_name'] == matched_asset_name):
                    milestone_withdrawal_projections_df.at[idx, 'milestone_value'] = -abs(amount)
                    
                    #updated = True


            #if not updated:
                #print(f"No record updated for asset: {matched_asset_name} on date: {single_date}")        

        elif entry_type == 'range':
            asset_name = increment_params.get('asset_name')
            amount = increment_params.get('amount')

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return milestone_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")

            # Apply update for the range of dates
            start_date, end_date = range_dates
            for idx, projection in milestone_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and start_date <= projection['entry_date'] <= end_date and projection['milestone_name'] == matched_asset_name):
                    milestone_withdrawal_projections_df.at[idx, 'milestone_value'] = -abs(amount)
        

        elif entry_type == 'increment':
            asset_name = increment_params.get('asset_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return milestone_withdrawal_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in milestone_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['milestone_name'] == matched_asset_name):
                    previous_amount = float(projection.get('milestone_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return milestone_withdrawal_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in milestone_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['milestone_name'] == matched_asset_name):
                    milestone_withdrawal_projections_df.at[idx, 'milestone_value'] = -abs(incremented_amount)
                   
        return milestone_withdrawal_projections_df
    

    # Reshape the investment projections for the required format
    def reshape_milestone_related_withdrawal_projections(self, milestone_withdrawal_projections_df, user_id):
        # Filter data for the specified user
        user_df = milestone_withdrawal_projections_df[milestone_withdrawal_projections_df['user_code'] == user_id]

        # Convert entry_date to string format to avoid frontend issues
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='milestone_name', 
                                          columns=['entry_date', 'age'],
                                          values='milestone_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df  
    
    # Function to delete records with entry_date less than the current date
    def delete_old_milestone_withdrawal_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM milestone_withdrawal_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")

    def run_milestone_withdrawal_projections(self, user_id, month_choice):

        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('milestone_withdrawal_projections'):
            # Only delete old records if the table exists
            self.delete_old_milestone_withdrawal_records()

        # Load the existing data from the investment_projections table
        milestone_withdrawal_projections_df = self.load_milestone_withdrawal_projections_from_db()
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)


        assets_with_categories = self.fetch_assets_with_categories_2(user_id)
        unique_assets = [asset_name for asset_name, _ in assets_with_categories]
        

        assets_dict = {
            604: "Home Purchase",
            605: "Kids Abroad Education",
            606: "Parent Support",
            607: "Sister Marriage",
            608: "Purchase Car",
            609: "Vacation Home",
            610: "Kids Graduation",
            611: "Kids Higher Education",
            612: "Comfortable Retirement",
            613: "Kids Marriage",
            614: "Own Marriage",
            615: "Own Higher Education",
            616: "Land Purchase"
        }

        # Check if the DataFrame is empty and create initial projections if needed
        if not self.user_exists_in_milestone_withdrawal_proj_db(user_id):
            if milestone_withdrawal_projections_df.empty:
                new_projections = self.create_milestone_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, user_id, user_name, month_choice)
                milestone_withdrawal_projections_df = pd.DataFrame(new_projections)
            else:
                new_projections = self.create_milestone_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, user_id, user_name, month_choice)
                milestone_withdrawal_projections_df = pd.concat([milestone_withdrawal_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

            # Pass user_id as an argument
            self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
        else:
            st.warning(f"User {user_id} already exists in the database. No new data will be appended.")     

        # Reshape and display the existing investment projections for the user
        st.write("### Milestone Withdrawal Projections")
        reshaped_df = self.reshape_milestone_related_withdrawal_projections(milestone_withdrawal_projections_df, user_id)
        st.dataframe(reshaped_df)

        

        # Dropdown to select an asset to add as a new asset
        additional_asset_name = st.selectbox("Select milestone name to add:", list(assets_dict.values()), key="milestone_add_asset")
        if st.button("Add Milestone", key="milestone_add_button"):
            assets_with_categories = self.fetch_assets_with_categories(self.connection, user_id)
            milestone_withdrawal_projections_df, assets_with_categories = self.add_additional_asset_for_milestone_withdrawal(milestone_withdrawal_projections_df, assets_dict, assets_with_categories, user_id, dob, retirement_age, additional_asset_name, month_choice)
            #print('milestone_withdrawal_projections_df check', milestone_withdrawal_projections_df)
            self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
            st.success(f"Added {additional_asset_name} to projections and saved to the database.")

        # Fetch distinct asset names for the dropdowns
        unique_milestone_surplus_projections = milestone_withdrawal_projections_df[milestone_withdrawal_projections_df['user_code'] == user_id]['milestone_name'].unique().tolist()
        #print('unique_assets_investment_projections',unique_assets_investment_projections)

        # Update projections based on growth or other entry types
        entry_type = st.radio("Choose entry type:", ('single', 'range', 'increment', 'stop'),key="milestone_entry_type")
                

        if entry_type == 'single':
            single_date = st.date_input("Select date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="milestone_single_date")
            # Convert single_date to a string for comparison or database use
            single_date_str = single_date.strftime('%Y-%m-%d')
            #print('single_date in run investment',single_date)
            #asset_name = st.text_input("Enter the asset name:")
           
            asset_name = st.selectbox("Select milestone name:", unique_milestone_surplus_projections, key="milestone_single_asset")
            print('asset_name in all run fun',asset_name)
            #amount = st.number_input("Enter amount:")
            amount = int(st.number_input("Enter amount:", value=0, key="milestone_single_amount"))  # Convert amount to integer
            #print('amount in all run fun',amount)
            if st.button("Apply Single Date Update", key="apply_milestone_single_update"):
                # Update the investment projections
                milestone_withdrawal_projections_df = self.update_milestone_related_withdrawal_projections(
                    user_id,
                    milestone_withdrawal_projections_df, 
                    distinct_names=[a for a, _ in assets_with_categories],  # Use the original names
                    entry_type=entry_type, 
                    single_date=single_date_str, 
                    increment_params={'amount': amount, 'asset_name': asset_name}  # Pass asset name without trimming
                )
                # Save the updated projections immediately after the update
                self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
                st.success("Single date update applied and saved to the database.")

        elif entry_type == 'range':
            start_date = st.date_input("Start Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="milestone_range_start")
            #start_date_str = start_date.strftime('%Y-%m-%d')
            end_date = st.date_input("End Date:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key="milestone_range_end")
            #end_date_str = end_date.strftime('%Y-%m-%d')
            asset_name = st.selectbox("Select milestone name for range:", unique_milestone_surplus_projections, key="milestone_range_asset")
            amount = int(st.number_input("Enter amount for range:",value = 0, key="milestone_range_amount"))
            if st.button("Apply Range Update", key="apply_milestone_range_update"):
                milestone_withdrawal_projections_df = self.update_milestone_related_withdrawal_projections(user_id, milestone_withdrawal_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, range_dates=[start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')], increment_params={'amount': amount, 'asset_name': asset_name})
                self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
                st.success("Range date update applied and save to the database.")

        elif entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="milestone_increment_entry")
            percentage = st.number_input("Increment percentage:", key="milestone_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:",key="milestone_increment_end")
            asset_name = st.selectbox("Select milestone name for increment:", unique_milestone_surplus_projections, key="milestone_increment_asset")
            if st.button("Apply Increment Update", key="apply_milestone_increment_update"):
                milestone_withdrawal_projections_df = self.update_milestone_related_withdrawal_projections(user_id, milestone_withdrawal_projections_df, distinct_names=[a for a, _ in assets_with_categories], entry_type=entry_type, increment_params={'entry_date': entry_date.strftime('%Y-%m-%d'), 'percentage': percentage, 'end_date': end_date_increment.strftime('%Y-%m-%d'), 'asset_name': asset_name})
                self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
                st.success("Increment update applied and save to the database.")

        elif entry_type == 'stop':
            self.save_milestone_withdrawal_projections_to_db(milestone_withdrawal_projections_df, user_id)
            st.write("Stop function executed. No changes applied.")

        # Display the updated investment projections for the user
        st.write("### milestone Projections after changes:")
        reshaped_df = self.reshape_milestone_related_withdrawal_projections(milestone_withdrawal_projections_df, user_id)
        st.dataframe(reshaped_df)

    def user_exists_in_milestone_withdrawal_proj_db(self, user_id):
        """Check if the user_id already exists in the PostgreSQL table."""
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        # Use inspect to check if the table exists
        inspector = inspect(engine)
        if not inspector.has_table('milestone_withdrawal_projections'):
            print("Table 'milestone_withdrawal_projections' does not exist.")
            return False

        
        query = f"SELECT 1 FROM milestone_withdrawal_projections WHERE user_code = '{user_id}' LIMIT 1"
        with engine.connect() as connection:
            result = connection.execute(query)
            return result.fetchone() is not None    



    #calculate total surplus projections
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    def create_yearly_cf_projections_table_v1(self, dob, retirement_age, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        yearly_cf_projections_v1 = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            yearly_cf_projections_data_v1 = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'gross_income': 0,
                'total_expense': 0,
                'total_tax': 0,
                'total_investment': 0,
                'total_emi': 0,
                'total_surplus': 0,
                'milestone_withdrawal': 0,
                'positive_surplus': 0,
                'total_withdrawal': 0
            }
            yearly_cf_projections_v1.append(yearly_cf_projections_data_v1)
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return yearly_cf_projections_v1

    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()

    def update_dynamic_yearly_cf_projections_v1(self, connection, dynamic_yearly_cf_projections_df_v1, user_id):
        dynamic_yearly_cf_projections_df_v1['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df_v1['entry_date'])
        
        # Convert necessary columns to numeric (float) to avoid concatenation issues
        dynamic_yearly_cf_projections_df_v1['gross_income'] = pd.to_numeric(dynamic_yearly_cf_projections_df_v1['gross_income'], errors='coerce')
        dynamic_yearly_cf_projections_df_v1['total_expense'] = pd.to_numeric(dynamic_yearly_cf_projections_df_v1['total_expense'], errors='coerce')
        dynamic_yearly_cf_projections_df_v1['total_tax'] = pd.to_numeric(dynamic_yearly_cf_projections_df_v1['total_tax'], errors='coerce')
        dynamic_yearly_cf_projections_df_v1['total_investment'] = pd.to_numeric(dynamic_yearly_cf_projections_df_v1['total_investment'], errors='coerce')
        dynamic_yearly_cf_projections_df_v1['total_emi'] = pd.to_numeric(dynamic_yearly_cf_projections_df_v1['total_emi'], errors='coerce')

        # Fetch yearly cash flow data
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, gross_income, taxes, total_expense
            FROM dynamic_milestone_income_projection
            WHERE user_code = %s;
        """, (user_id,))

        yearly_cf_data = cursor.fetchall()
        cursor.close()

        yearly_cf_df = pd.DataFrame(yearly_cf_data, columns=['entry_date', 'gross_income', 'taxes', 'total_expense'])
        yearly_cf_df['entry_date'] = pd.to_datetime(yearly_cf_df['entry_date']).dt.tz_localize(None)

        # Fetch total investment data
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(asset_value::double precision) AS total_investment
            FROM investment_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        investment_data = cursor.fetchall()
        cursor.close()

        investment_df = pd.DataFrame(investment_data, columns=['entry_date', 'total_investment'])
        investment_df['entry_date'] = pd.to_datetime(investment_df['entry_date']).dt.tz_localize(None)

        # Fetch total EMI data
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_emi
            FROM dynamic_liabilities_outflows_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        emi_data = cursor.fetchall()
        cursor.close()

        emi_df = pd.DataFrame(emi_data, columns=['entry_date', 'total_emi'])
        emi_df['entry_date'] = pd.to_datetime(emi_df['entry_date']).dt.tz_localize(None)

        # Fetch total milestone withdrawal data
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(milestone_value::double precision) AS milestone_withdrawal
            FROM milestone_withdrawal_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        milestone_withdrawal_data = cursor.fetchall()
        cursor.close()

        milestone_withdrawal_df = pd.DataFrame(milestone_withdrawal_data, columns=['entry_date', 'milestone_withdrawal'])
        milestone_withdrawal_df['entry_date'] = pd.to_datetime(milestone_withdrawal_df['entry_date']).dt.tz_localize(None)
        

        # Update projections
        for idx, projection in dynamic_yearly_cf_projections_df_v1.iterrows():
            matching_row = yearly_cf_df[(yearly_cf_df['entry_date'] == projection['entry_date'])]

            if not matching_row.empty:
                dynamic_yearly_cf_projections_df_v1.at[idx, 'gross_income'] = matching_row['gross_income'].values[0]
                dynamic_yearly_cf_projections_df_v1.at[idx, 'total_tax'] = matching_row['taxes'].values[0]
                dynamic_yearly_cf_projections_df_v1.at[idx, 'total_expense'] = matching_row['total_expense'].values[0]

            matching_investment_row = investment_df[(investment_df['entry_date'] == projection['entry_date'])]

            if not matching_investment_row.empty:
                dynamic_yearly_cf_projections_df_v1.at[idx, 'total_investment'] = matching_investment_row['total_investment'].values[0]

            matching_emi_row = emi_df[(emi_df['entry_date'] == projection['entry_date'])]

            if not matching_emi_row.empty:
                dynamic_yearly_cf_projections_df_v1.at[idx, 'total_emi'] = matching_emi_row['total_emi'].values[0]

            matching_milestone_withdrawal_row = milestone_withdrawal_df[(milestone_withdrawal_df['entry_date'] == projection['entry_date'])]

            if not matching_milestone_withdrawal_row.empty:
                dynamic_yearly_cf_projections_df_v1.at[idx, 'milestone_withdrawal'] = matching_milestone_withdrawal_row['milestone_withdrawal'].values[0]

            gross_income = dynamic_yearly_cf_projections_df_v1.at[idx, 'gross_income']
            total_expense = dynamic_yearly_cf_projections_df_v1.at[idx, 'total_expense']
            total_tax = dynamic_yearly_cf_projections_df_v1.at[idx, 'total_tax']
            total_investment = dynamic_yearly_cf_projections_df_v1.at[idx, 'total_investment']
            total_emi = dynamic_yearly_cf_projections_df_v1.at[idx, 'total_emi']

            total_surplus = gross_income + total_expense + total_tax + total_investment + total_emi
            #total_surplus = (Decimal(gross_income) + Decimal(total_expense) + Decimal(total_tax) + Decimal(total_investment) + Decimal(total_emi))
            dynamic_yearly_cf_projections_df_v1.at[idx, 'total_surplus'] = total_surplus

        for idx, projection in dynamic_yearly_cf_projections_df_v1.iterrows():
            total_surplus = projection['total_surplus']
            if total_surplus >= 0:
                positive_surplus = 0
            else:
                positive_surplus = abs(total_surplus)

            dynamic_yearly_cf_projections_df_v1.at[idx, 'positive_surplus'] = positive_surplus

            milestone_withdrawal = projection['milestone_withdrawal']
            total_withdrawal = milestone_withdrawal + positive_surplus

            dynamic_yearly_cf_projections_df_v1.at[idx, 'total_withdrawal'] = total_withdrawal

        return dynamic_yearly_cf_projections_df_v1

    def save_dynamic_yearly_cf_projections_df_v1_to_db(self, dynamic_yearly_cf_projections_df_v1):
        # Convert all numpy types to native Python types
        dynamic_yearly_cf_projections_df_v1 = dynamic_yearly_cf_projections_df_v1.astype({
            'gross_income': 'float',  # Change this to 'int' if the column should be integer
            'total_expense': 'float',
            'total_tax': 'float',
            'total_investment': 'float',
            'total_emi': 'float',
            'total_surplus': 'float',
            'milestone_withdrawal': 'float',
            'positive_surplus': 'float',
            'total_withdrawal': 'float',
        })
        
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        dynamic_yearly_cf_projections_df_v1.to_sql('dynamic_yearly_cf_projections_v1', engine, if_exists='replace', index=False)
        print("Data saved to PostgreSQL table 'dynamic_yearly_cf_projections_v1'")

    def load_dynamic_yearly_cf_projections_df_v1_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_yearly_cf_projections_v1'
            );
        """

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar()

        if not table_exists:
            print("Table 'dynamic_yearly_cf_projections_v1' does not exist.")
            return pd.DataFrame()
        else:
            return pd.read_sql('dynamic_yearly_cf_projections_v1', engine)
        
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_yearly_cf_projections_v1_1(self, dynamic_yearly_cf_projections_v1):
        # Drop unnecessary columns
        dynamic_yearly_cf_projections_v1 = dynamic_yearly_cf_projections_v1.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_yearly_cf_projections_v1['entry_date'] = dynamic_yearly_cf_projections_v1['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_yearly_cf_projections_v1.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed   
    
    def transpose_dynamic_yearly_cf_projections_v1(self, dynamic_yearly_cf_projections_v1):
        # Drop unnecessary columns
        dynamic_yearly_cf_projections_v1 = dynamic_yearly_cf_projections_v1.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_yearly_cf_projections_v1['entry_date'] = dynamic_yearly_cf_projections_v1['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_yearly_cf_projections_v1.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed
     

    def run_dynamic_yearly_cf_projections_v1(self, user_id, month_choice):
        # Fetch user details
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)

        # Load existing projections from the database
        dynamic_yearly_cf_projections_df_v1 = self.load_dynamic_yearly_cf_projections_df_v1_from_db()

        if dynamic_yearly_cf_projections_df_v1.empty:
            new_projections = self.create_yearly_cf_projections_table_v1(dob, retirement_age, user_id, user_name, month_choice)
            dynamic_yearly_cf_projections_df_v1 = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_yearly_cf_projections_df_v1['user_code'].unique():
                new_projections = self.create_yearly_cf_projections_table_v1(dob, retirement_age, user_id, user_name, month_choice)
                dynamic_yearly_cf_projections_df_v1 = pd.DataFrame(new_projections)

        dynamic_yearly_cf_projections_df_v1 = self.update_dynamic_yearly_cf_projections_v1(self.connection, dynamic_yearly_cf_projections_df_v1, user_id)

        self.save_dynamic_yearly_cf_projections_df_v1_to_db(dynamic_yearly_cf_projections_df_v1)
        # Transpose the data for the desired format
        transposed_df = self.transpose_dynamic_yearly_cf_projections_v1_1(dynamic_yearly_cf_projections_df_v1)
        st.write("Reshaped total surplus Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit
        st.success("calculate total surplus and save to the database.")


    #calculate total networth, surplus projections
    def calculate_age_on_date(self,dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age
    
    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))
        
        user_name = cursor.fetchone()[0]
        cursor.close()
        
        return user_name.strip()
    
    

    def create_yearly_cf_projections_table(self, dob, retirement_age, user_id, user_name, month_choice):

        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        yearly_cf_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            yearly_cf_projections_data = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'gross_income': 0,
                'total_expense': 0,
                'total_tax':0,
                'total_investment':0,
                'total_liabilities_outflows':0,
                'total_insurance_outflows':0,
                'total_emi':0,
                'total_repayment':0,
                'total_surplus_repayment':0,
                'total_stp_investment':0,
                'total_surplus':0,
                'beg_total_surplus':0,
                'total_end_surplus':0,
                'total_liabilities':0,
                'total_assets':0,
                'total_networth':0,
                'total_milestone_withdrawal':0,
                'milestone_out_amt':0,
                'end_total_surplus':0,
                'end_total_surplus_difference':0
            }
            yearly_cf_projections.append(yearly_cf_projections_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return yearly_cf_projections

    def update_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df, user_id):

        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        # Convert necessary columns to numeric (float) to avoid concatenation issues
        dynamic_yearly_cf_projections_df['gross_income'] = pd.to_numeric(dynamic_yearly_cf_projections_df['gross_income'], errors='coerce')
        dynamic_yearly_cf_projections_df['total_expense'] = pd.to_numeric(dynamic_yearly_cf_projections_df['total_expense'], errors='coerce')
        dynamic_yearly_cf_projections_df['total_tax'] = pd.to_numeric(dynamic_yearly_cf_projections_df['total_tax'], errors='coerce')
        dynamic_yearly_cf_projections_df['total_investment'] = pd.to_numeric(dynamic_yearly_cf_projections_df['total_investment'], errors='coerce')
        dynamic_yearly_cf_projections_df['total_emi'] = pd.to_numeric(dynamic_yearly_cf_projections_df['total_emi'], errors='coerce')
        

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, gross_income, taxes, total_expense
            FROM dynamic_milestone_income_projection
            WHERE user_code = %s;
        """, (user_id,))

        yearly_cf_data = cursor.fetchall()
        cursor.close()

        yearly_cf_df = pd.DataFrame(yearly_cf_data, columns=['entry_date', 'gross_income', 'taxes', 'total_expense'])
        yearly_cf_df['entry_date'] = pd.to_datetime(yearly_cf_df['entry_date']).dt.tz_localize(None)
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(asset_value::double precision) AS total_investment
            FROM investment_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        investment_data = cursor.fetchall()
        cursor.close()

        investment_df = pd.DataFrame(investment_data, columns=['entry_date', 'total_investment'])
        investment_df['entry_date'] = pd.to_datetime(investment_df['entry_date']).dt.tz_localize(None)

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value) AS total_liabilities
            FROM dynamic_liabilities_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        liabilities_data = cursor.fetchall()
        cursor.close()

        liabilities_df = pd.DataFrame(liabilities_data, columns=['entry_date', 'total_liabilities'])
        liabilities_df['entry_date'] = pd.to_datetime(liabilities_df['entry_date']).dt.tz_localize(None)

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value) AS total_assets
            FROM dynamic_assets_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        assets_data = cursor.fetchall()
        cursor.close()

        assets_df = pd.DataFrame(assets_data, columns=['entry_date', 'total_assets'])
        assets_df['entry_date'] = pd.to_datetime(assets_df['entry_date']).dt.tz_localize(None)

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_liabilities_outflows
            FROM dynamic_liabilities_outflows_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        liabilities_outflows_data = cursor.fetchall()
        cursor.close()

        liabilities_outflows_df = pd.DataFrame(liabilities_outflows_data, columns=['entry_date', 'total_liabilities_outflows'])
        liabilities_outflows_df['entry_date'] = pd.to_datetime(liabilities_outflows_df['entry_date']).dt.tz_localize(None)

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(insurance_value::double precision) AS total_insurance_outflows
            FROM dynamic_insurance_outflows_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        insurance_outflows_data = cursor.fetchall()
        cursor.close()

        insurance_outflows_df = pd.DataFrame(insurance_outflows_data, columns=['entry_date', 'total_insurance_outflows'])
        insurance_outflows_df['entry_date'] = pd.to_datetime(insurance_outflows_df['entry_date']).dt.tz_localize(None)


        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_repayment
            FROM dynamic_loan_repayment_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        repayment_data = cursor.fetchall()
        cursor.close()

        repayment_df = pd.DataFrame(repayment_data, columns=['entry_date', 'total_repayment'])
        repayment_df['entry_date'] = pd.to_datetime(repayment_df['entry_date']).dt.tz_localize(None) 

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_surplus_repayment
            FROM dynamic_loan_surplus_repayment_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        surplus_repayment_data = cursor.fetchall()
        cursor.close()

        surplus_repayment_df = pd.DataFrame(surplus_repayment_data, columns=['entry_date', 'total_surplus_repayment'])
        surplus_repayment_df['entry_date'] = pd.to_datetime(surplus_repayment_df['entry_date']).dt.tz_localize(None) 

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(asset_value::double precision) AS total_stp_investment
            FROM dynamic_investment_surplus_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        stp_investment_data = cursor.fetchall()
        cursor.close()

        stp_investment_df = pd.DataFrame(stp_investment_data, columns=['entry_date', 'total_stp_investment'])
        stp_investment_df['entry_date'] = pd.to_datetime(stp_investment_df['entry_date']).dt.tz_localize(None)

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(asset_value::double precision) AS total_milestone_withdrawal
            FROM surplus_withdrawal_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        milestone_withdrawal_data = cursor.fetchall()
        cursor.close()

        milestone_withdrawal_df = pd.DataFrame(milestone_withdrawal_data, columns=['entry_date', 'total_milestone_withdrawal'])
        milestone_withdrawal_df['entry_date'] = pd.to_datetime(milestone_withdrawal_df['entry_date']).dt.tz_localize(None) 

        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(milestone_value::double precision) AS milestone_out_amt
            FROM milestone_calculation_projections
            WHERE user_code = %s
            GROUP BY entry_date;
        """, (user_id,))

        milestone_out_amt_data = cursor.fetchall()
        cursor.close()

        milestone_out_amt_df = pd.DataFrame(milestone_out_amt_data, columns=['entry_date', 'milestone_out_amt'])
        milestone_out_amt_df['entry_date'] = pd.to_datetime(milestone_out_amt_df['entry_date']).dt.tz_localize(None) 

        
        for idx, projection in dynamic_yearly_cf_projections_df.iterrows():
            matching_row = yearly_cf_df[(yearly_cf_df['entry_date'] == projection['entry_date'])]
            #print('matching_row',matching_row)
            if not matching_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'gross_income'] = matching_row['gross_income'].values[0]
                dynamic_yearly_cf_projections_df.at[idx, 'total_tax'] = matching_row['taxes'].values[0]
                dynamic_yearly_cf_projections_df.at[idx, 'total_expense'] = matching_row['total_expense'].values[0]

            matching_investment_row = investment_df[(investment_df['entry_date'] == projection['entry_date'])]

            if not matching_investment_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_investment'] = matching_investment_row['total_investment'].values[0]

            matching_liabilities_row = liabilities_df[(liabilities_df['entry_date'] == projection['entry_date'])]

            if not matching_liabilities_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_liabilities'] = matching_liabilities_row['total_liabilities'].values[0]

            matching_assets_row = assets_df[(assets_df['entry_date'] == projection['entry_date'])]

            if not matching_assets_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_assets'] = matching_assets_row['total_assets'].values[0]

            matching_liabilities_outflows_row = liabilities_outflows_df[(liabilities_outflows_df['entry_date'] == projection['entry_date'])]

            if not matching_liabilities_outflows_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_liabilities_outflows'] = matching_liabilities_outflows_row['total_liabilities_outflows'].values[0]

            matching_insurance_outflows_row = insurance_outflows_df[(insurance_outflows_df['entry_date'] == projection['entry_date'])]

            if not matching_insurance_outflows_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_insurance_outflows'] = matching_insurance_outflows_row['total_insurance_outflows'].values[0]


            matching_repayment_row = repayment_df[(repayment_df['entry_date'] == projection['entry_date'])]

            if not matching_repayment_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_repayment'] = matching_repayment_row['total_repayment'].values[0] 


            matching_surplus_repayment_row = surplus_repayment_df[(surplus_repayment_df['entry_date'] == projection['entry_date'])]

            if not matching_surplus_repayment_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_surplus_repayment'] = matching_surplus_repayment_row['total_surplus_repayment'].values[0]


            matching_stp_investment_row = stp_investment_df[(stp_investment_df['entry_date'] == projection['entry_date'])]

            if not matching_stp_investment_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_stp_investment'] = matching_stp_investment_row['total_stp_investment'].values[0]         


            matching_milestone_withdrawal_row = milestone_withdrawal_df[(milestone_withdrawal_df['entry_date'] == projection['entry_date'])]

            if not matching_repayment_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'total_milestone_withdrawal'] = matching_milestone_withdrawal_row['total_milestone_withdrawal'].values[0] 


            matching_milestone_out_amt_row = milestone_out_amt_df[(milestone_out_amt_df['entry_date'] == projection['entry_date'])]

            if not matching_milestone_out_amt_row.empty:
                dynamic_yearly_cf_projections_df.at[idx, 'milestone_out_amt'] = matching_milestone_out_amt_row['milestone_out_amt'].values[0]     



            gross_income = float(dynamic_yearly_cf_projections_df.at[idx, 'gross_income'] or 0)
            total_expense = float(dynamic_yearly_cf_projections_df.at[idx, 'total_expense'] or 0)
            total_tax = float(dynamic_yearly_cf_projections_df.at[idx, 'total_tax'] or 0)
            total_investment = float(dynamic_yearly_cf_projections_df.at[idx, 'total_investment'] or 0)
            total_liabilities_outflows = float(dynamic_yearly_cf_projections_df.at[idx, 'total_liabilities_outflows'] or 0)
            total_insurance_outflows = float(dynamic_yearly_cf_projections_df.at[idx, 'total_insurance_outflows'] or 0)
            total_repayment = float(dynamic_yearly_cf_projections_df.at[idx, 'total_repayment'] or 0)
            total_surplus_repayment = float(dynamic_yearly_cf_projections_df.at[idx, 'total_surplus_repayment'] or 0)
            total_stp_investment = float(dynamic_yearly_cf_projections_df.at[idx, 'total_stp_investment'] or 0)
            total_milestone_withdrawal = float(dynamic_yearly_cf_projections_df.at[idx, 'total_milestone_withdrawal'] or 0)
            total_milestone_out_amt = float(dynamic_yearly_cf_projections_df.at[idx, 'milestone_out_amt'] or 0)
            

            total_emi = total_liabilities_outflows + total_insurance_outflows 
            dynamic_yearly_cf_projections_df.at[idx, 'total_emi'] = total_emi

            total_surplus = gross_income + total_expense + total_tax + total_investment + total_emi
            dynamic_yearly_cf_projections_df.at[idx, 'total_surplus'] = total_surplus

            if idx == 0:
                beg_total_surplus = total_surplus
            else:
                #st.write('previous end_total_surplus', dynamic_yearly_cf_projections_df.at[idx - 1, 'end_total_surplus'] )
                #st.write('in loop current total surplus',total_surplus)
                beg_total_surplus = (dynamic_yearly_cf_projections_df.at[idx - 1, 'end_total_surplus'] + total_surplus)

            end_total_surplus = beg_total_surplus + total_repayment + total_surplus_repayment  - total_milestone_withdrawal - total_milestone_out_amt

            # st.write('idx',idx)
            # st.write('total_surplus',total_surplus)
            # st.write('beg_total_surplus',beg_total_surplus)
            # st.write('end_total_surplus',end_total_surplus)
            # st.write('----------------------------------------------------------------')

            dynamic_yearly_cf_projections_df.at[idx, 'beg_total_surplus'] = beg_total_surplus
            dynamic_yearly_cf_projections_df.at[idx, 'end_total_surplus'] = end_total_surplus

            total_liabilities = dynamic_yearly_cf_projections_df.at[idx, 'total_liabilities']
            total_assets = dynamic_yearly_cf_projections_df.at[idx, 'total_assets']

            total_networth = total_assets - total_liabilities
            dynamic_yearly_cf_projections_df.at[idx, 'total_networth'] = total_networth

            # Calculate end_total_surplus_difference and store it at the next entry_date
            dynamic_yearly_cf_projections_df['end_total_surplus_difference'] = None  # Initialize the column

            for i in range(1, len(dynamic_yearly_cf_projections_df)):
                prev_surplus = dynamic_yearly_cf_projections_df.at[i - 1, 'end_total_surplus']
                current_surplus = dynamic_yearly_cf_projections_df.at[i, 'end_total_surplus']
                surplus_diff = current_surplus - prev_surplus

                # Store the difference at the current index (i)
                dynamic_yearly_cf_projections_df.at[i, 'end_total_surplus_difference'] = surplus_diff

        return dynamic_yearly_cf_projections_df

    def save_dynamic_yearly_cf_projections_df_to_db(self, dynamic_yearly_cf_projections_df):
        # Ensure all integer types are converted to Python's built-in int
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.astype({
            'age': 'int',  # You can also convert other columns if needed
            'total_surplus': 'float',
            'gross_income': 'float',
            'total_expense': 'float',
            'total_tax': 'float',
            'total_investment': 'float',
            'total_liabilities_outflows':'float',
            'total_insurance_outflows':'float',
            'total_emi': 'float',
            'total_repayment':'float',
            'total_surplus_repayment':'float',
            'total_stp_investment':'float',
            'total_surplus':'float',
            'beg_total_surplus':'float',
            'total_end_surplus':'float',
            'total_liabilities': 'float',
            'total_assets': 'float',
            'total_networth': 'float',
            'total_milestone_withdrawal': 'float',
            'milestone_out_amt': 'float',
            'end_total_surplus': 'float',
            'end_total_surplus_difference': 'float'
        })
        
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        dynamic_yearly_cf_projections_df.to_sql('dynamic_yearly_cf_projections', engine, if_exists='replace', index=False)

        print("Data saved to PostgreSQL table 'dynamic_yearly_cf_projections'")

    def load_dynamic_yearly_cf_projections_df_from_db(self):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_yearly_cf_projections'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_yearly_cf_projections' does not exist.")
            dynamic_yearly_cf_projections_df = pd.DataFrame()
        else:
            dynamic_yearly_cf_projections_df = pd.read_sql('dynamic_yearly_cf_projections', engine)

        return dynamic_yearly_cf_projections_df
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_yearly_cf_projections_1(self, dynamic_yearly_cf_projections_df):
        # Drop unnecessary columns
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_yearly_cf_projections_df['entry_date'] = dynamic_yearly_cf_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_yearly_cf_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_display_dynamic_yearly_cf_projections_1(self, dynamic_yearly_cf_projections_df):
        # Drop unnecessary columns
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_yearly_cf_projections_df['entry_date'] = dynamic_yearly_cf_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_yearly_cf_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)  # Set asset_name as index
        return df_transposed


    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df):
        dynamic_yearly_cf_projections_df = self.transpose_and_sort_dates(dynamic_yearly_cf_projections_df)
        # Drop unnecessary columns
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.drop(columns=['user_code', 'age', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_yearly_cf_projections_df['entry_date'] = dynamic_yearly_cf_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_yearly_cf_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed   

    # Function to delete records with entry_date less than the current date
    def delete_old_yearly_cf_projections_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM dynamic_yearly_cf_projections 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.") 


    def run_dynamic_yearly_cf_projections(self, user_code, dob, retirement_age, month_choice):

       # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('dynamic_yearly_cf_projections'):
            # Only delete old records if the table exists
            self.delete_old_yearly_cf_projections_records()

        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()

        user_name = self.fetch_user_name(user_code)

        if dynamic_yearly_cf_projections_df.empty:
            new_projections = self.create_yearly_cf_projections_table(dob, retirement_age, user_code, user_name, month_choice)
            dynamic_yearly_cf_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_yearly_cf_projections_df['user_code'].unique():
                new_projections = self.create_yearly_cf_projections_table(dob, retirement_age, user_code, user_name, month_choice)
                dynamic_yearly_cf_projections_df = pd.DataFrame(new_projections)


        dynamic_yearly_cf_projections_df = self.update_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df, user_code)

        self.save_dynamic_yearly_cf_projections_df_to_db(dynamic_yearly_cf_projections_df)  
        
        # Transpose the data for the desired format
        transposed_df = self.transpose_display_dynamic_yearly_cf_projections_1(dynamic_yearly_cf_projections_df)
        st.write("Reshaped Cashflow Networth Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit
        st.success("Income projections generated, transposed, and saved to the database.") 


    #actual projection   
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    def create_dynamic_actual_projections_table(self, dob, retirement_age, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        dynamic_actual_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])

            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            dynamic_actual_projections_data = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'equity': 0,
                'real_estate': 0,
                'passive_income': 0,
                'debt': 0,
                'alternate_investments': 0,
                'good_liabilities_to_total_assets': 0,
                'bad_liabilities_to_total_assets': 0,
                'expense_to_income': 0,
                'good_liability_linked_emi_to_income': 0,
                'bad_liability_linked_emi_to_income': 0,
                'investment_to_income': 0,
                'emergency_funds': 0,
                'health_insurance': 0,
                'life_insurance': 0
            }
            dynamic_actual_projections.append(dynamic_actual_projections_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return dynamic_actual_projections

    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))

        user_name = cursor.fetchone()[0]
        cursor.close()

        return user_name.strip()

    def update_dynamic_actual_projections(self, connection, dynamic_actual_projections_df, user_id):

        #health_life_data = st.radio("Do you want to change the insurance data?",('no', 'yes'), key = "actual_health_life_question")

        #if health_life_data == 'yes':
            # Prompt user for health insurance and life insurance amounts
            #health_insurance_amount = st.number_input("Enter the health insurance amount:",key = "acutal_health_question")
            #life_insurance_amount = st.number_input("Enter the life insurance amount: ", key = "acutal_life_question")

            # Update health and life insurance in the DataFrame
            #for idx, projection in dynamic_actual_projections_df.iterrows():
                #dynamic_actual_projections_df.at[idx, 'health_insurance'] = health_insurance_amount
                #dynamic_actual_projections_df.at[idx, 'life_insurance'] = life_insurance_amount
        #else:
            # Fetch health insurance coverage for all entry_date
        cursor = connection.cursor()
        cursor.execute("""
            SELECT SUM(coverage) AS total_health_insurance
            FROM insurance
            WHERE user_code = %s AND category_id = 64 AND is_active = true;
        """, (user_id,))
        total_health_insurance = cursor.fetchone()[0]

        # Fetch life insurance coverage for all entry_date
        cursor.execute("""
            SELECT sum(coverage) AS total_life_insurance
            FROM insurance
            WHERE user_code = %s AND  (category_id = 101 or category_id = 102 or category_id = 228 or category_id = 231 ) AND is_active = true;
        """, (user_id,))
        total_life_insurance = cursor.fetchone()[0]
        #st.write('total_life_insurance',total_life_insurance)
        cursor.close()

        # Handle null or None for total_life_insurance and total_health_insurance
        total_health_insurance = total_health_insurance if total_health_insurance is not None else 0
        total_life_insurance = total_life_insurance if total_life_insurance is not None else 0

        # Apply the fetched total_health_insurance and total_life_insurance to all rows
        dynamic_actual_projections_df['health_insurance'] = total_health_insurance
        dynamic_actual_projections_df['life_insurance'] = total_life_insurance


        # Convert the entry_date column to timestamp without time zone
        dynamic_actual_projections_df['entry_date'] = pd.to_datetime(dynamic_actual_projections_df['entry_date'])

        # Ensure numeric columns are of the correct type
        numeric_columns = [
            'equity', 'real_estate', 'passive_income', 'debt', 'alternate_investments',
            'good_liabilities_to_total_assets', 'bad_liabilities_to_total_assets', 'expense_to_income',
            'good_liability_linked_emi_to_income', 'bad_liability_linked_emi_to_income', 'investment_to_income',
            'emergency_funds', 'health_insurance', 'life_insurance'
        ]

        for column in numeric_columns:
            dynamic_actual_projections_df[column] = dynamic_actual_projections_df[column].astype(float)

        # Fetch good liabilities from dynamic_liabilities_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_good_liabilities
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (56, 57, 175, 208, 604, 605, 609, 610, 611, 615, 616,628)
            GROUP BY entry_date;
        """, (user_id,))

        good_liabilities_data = cursor.fetchall()
        cursor.close()

        good_liabilities_df = pd.DataFrame(good_liabilities_data, columns=['entry_date', 'total_good_liabilities'])
        good_liabilities_df['entry_date'] = pd.to_datetime(good_liabilities_df['entry_date']).dt.tz_localize(None)

        # Fetch good liabilities from dynamic_liabilities_projections table (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_good_liabilities_1
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (56, 57, 175, 208, 604, 605, 609, 610, 611, 615, 616,628)
            GROUP BY entry_date;
        """, (user_id,))

        good_liabilities_data_1 = cursor.fetchall()
        cursor.close()

        good_liabilities_df_1 = pd.DataFrame(good_liabilities_data_1, columns=['entry_date', 'total_good_liabilities_1'])

        # Sort the DataFrame by 'entry_date'
        good_liabilities_df_1 = good_liabilities_df_1.sort_values(by='entry_date')
        st.write('good_liabilities_df_1',good_liabilities_df_1)
        

        #print('good_liabilities_df_1',good_liabilities_df_1)
        good_liabilities_df_1['entry_date'] = pd.to_datetime(good_liabilities_df_1['entry_date']).dt.tz_localize(None)

        # Fetch bad liabilities from dynamic_liabilities_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_bad_liabilities
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (55, 58, 59, 60, 61, 104, 607, 608, 613, 614) or liabilities_name = 'Flexi Term Loan '
            GROUP BY entry_date;
        """, (user_id,))

        bad_liabilities_data = cursor.fetchall()
        cursor.close()

        bad_liabilities_df = pd.DataFrame(bad_liabilities_data, columns=['entry_date', 'total_bad_liabilities'])
        bad_liabilities_df = bad_liabilities_df.sort_values(by='entry_date')
        st.write('bad_liabilities_df',bad_liabilities_df)

        bad_liabilities_df['entry_date'] = pd.to_datetime(bad_liabilities_df['entry_date']).dt.tz_localize(None)

        # Fetch total assets from dynamic_yearly_cf_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, total_assets, total_investment
            FROM dynamic_yearly_cf_projections
            WHERE user_code = %s;
        """, (user_id,))

        assets_data = cursor.fetchall()
        cursor.close()

        assets_df = pd.DataFrame(assets_data, columns=['entry_date', 'total_assets', 'total_investment'])    

        assets_df = assets_df.sort_values(by='entry_date')
        st.write('assets_df',assets_df)

        #print('asset_df',assets_df)
        assets_df['entry_date'] = pd.to_datetime(assets_df['entry_date']).dt.tz_localize(None)

        # Fetch gross income, taxes, and total expense from dynamic_milestone_income_projection table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, gross_income, taxes, household_lifestyle_expense_amount
            FROM dynamic_milestone_income_projection
            WHERE user_code = %s
            ORDER BY entry_date;
        """, (user_id,))

        income_data = cursor.fetchall()
        cursor.close()

        income_df = pd.DataFrame(income_data, columns=['entry_date', 'gross_income', 'taxes', 'total_expense'])
        income_df[['gross_income', 'taxes', 'total_expense']] = income_df[['gross_income', 'taxes', 'total_expense']].astype(float)
        income_df = income_df.sort_values(by='entry_date')
        st.write('income_df',income_df)
        income_df['entry_date'] = pd.to_datetime(income_df['entry_date']).dt.tz_localize(None)

        # Fetch good liability linked EMIs from dynamic_liabilities_outflows_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_good_liability_emi
            FROM dynamic_liabilities_outflows_projections
            WHERE user_code = %s AND category_id IN (56, 57, 175, 208, 604, 605, 609, 610, 611, 615, 616, 628) 
            GROUP BY entry_date;
        """, (user_id,))

        good_liability_emi_data = cursor.fetchall()
        cursor.close()

        good_liability_emi_df = pd.DataFrame(good_liability_emi_data, columns=['entry_date', 'total_good_liability_emi'])
        good_liability_emi_df['entry_date'] = pd.to_datetime(good_liability_emi_df['entry_date']).dt.tz_localize(None)

        # Fetch bad liability linked EMIs from dynamic_liabilities_outflows_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_bad_liability_emi
            FROM dynamic_liabilities_outflows_projections
            WHERE user_code = %s AND category_id IN (55, 58, 59, 60, 61, 104, 607, 608, 613, 614) or liabilities_name = 'Flexi Term Loan '
            GROUP BY entry_date;
        """, (user_id,))

        bad_liability_emi_data = cursor.fetchall()
        cursor.close()

        bad_liability_emi_df = pd.DataFrame(bad_liability_emi_data, columns=['entry_date', 'total_bad_liability_emi'])
        bad_liability_emi_df = bad_liability_emi_df.sort_values(by='entry_date')
        st.write('bad_liability_emi_df',bad_liability_emi_df)

        bad_liability_emi_df['entry_date'] = pd.to_datetime(bad_liability_emi_df['entry_date']).dt.tz_localize(None)

        # Fetch assets related to equity from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_equity_1
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (18,19,20,21,22,23,24,179,235)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_1 = cursor.fetchall()
        cursor.close()

        equity_df_1 = pd.DataFrame(equity_data_1, columns=['entry_date', 'total_equity_1'])

        # Sort the DataFrame by 'entry_date'
        equity_df_1 = equity_df_1.sort_values(by='entry_date')
        st.write('equity_df_1',equity_df_1)
        equity_df_1['entry_date'] = pd.to_datetime(equity_df_1['entry_date']).dt.tz_localize(None)

        # Fetch assets related to equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)/2 AS total_equity_2
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (28, 321, 322, 325,328)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_2 = cursor.fetchall()
        cursor.close()

        equity_df_2 = pd.DataFrame(equity_data_2, columns=['entry_date', 'total_equity_2'])

        equity_df_2 = equity_df_2.sort_values(by='entry_date')
        st.write('equity_df_2',equity_df_2)
        equity_df_2['entry_date'] = pd.to_datetime(equity_df_2['entry_date']).dt.tz_localize(None)

        # Fetch assets related to liabilities from dynamic_liabilities_projections table (category 209)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_equity_3
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (209)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_3 = cursor.fetchall()
        cursor.close()

        equity_df_3 = pd.DataFrame(equity_data_3, columns=['entry_date', 'total_equity_3'])
        equity_df_3 = equity_df_3.sort_values(by='entry_date')
        #print('equity_df_3',equity_df_3)

        equity_df_3['entry_date'] = pd.to_datetime(equity_df_3['entry_date']).dt.tz_localize(None)


        # Fetch assets related to Capital Protection Funds in equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.20 AS total_equity_4
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (323)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_4 = cursor.fetchall()
        cursor.close()

        equity_df_4 = pd.DataFrame(equity_data_4, columns=['entry_date', 'total_equity_4'])

        equity_df_4 = equity_df_4.sort_values(by='entry_date')
        st.write('equity_df_4',equity_df_4)
        equity_df_4['entry_date'] = pd.to_datetime(equity_df_4['entry_date']).dt.tz_localize(None)


        # Fetch assets related to Conservative Hybrid Funds in equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.30 AS total_equity_5
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (324)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_5 = cursor.fetchall()
        cursor.close()

        equity_df_5 = pd.DataFrame(equity_data_5, columns=['entry_date', 'total_equity_5'])

        equity_df_5 = equity_df_5.sort_values(by='entry_date')
        st.write('equity_df_5',equity_df_5)
        equity_df_5['entry_date'] = pd.to_datetime(equity_df_5['entry_date']).dt.tz_localize(None)

        # Fetch assets related to Equity Savings in equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.30 AS total_equity_6
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (326)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_6 = cursor.fetchall()
        cursor.close()

        equity_df_6 = pd.DataFrame(equity_data_6, columns=['entry_date', 'total_equity_6'])

        equity_df_6 = equity_df_6.sort_values(by='entry_date')
        st.write('equity_df_6',equity_df_6)
        equity_df_6['entry_date'] = pd.to_datetime(equity_df_6['entry_date']).dt.tz_localize(None)


        # Fetch assets related to Multi Asset Allocation in equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.70 AS total_equity_7
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (327)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_7 = cursor.fetchall()
        cursor.close()

        equity_df_7 = pd.DataFrame(equity_data_7, columns=['entry_date', 'total_equity_7'])

        equity_df_7 = equity_df_7.sort_values(by='entry_date')
        st.write('equity_df_7',equity_df_7)
        equity_df_7['entry_date'] = pd.to_datetime(equity_df_7['entry_date']).dt.tz_localize(None)


        # Fetch assets related to Aggressive Funds in equity (alternate categories)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.80 AS total_equity_8
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (319)
            GROUP BY entry_date;
        """, (user_id,))

        equity_data_8 = cursor.fetchall()
        cursor.close()

        equity_df_8 = pd.DataFrame(equity_data_8, columns=['entry_date', 'total_equity_8'])

        equity_df_8 = equity_df_8.sort_values(by='entry_date')
        st.write('equity_df_8',equity_df_8)
        equity_df_8['entry_date'] = pd.to_datetime(equity_df_8['entry_date']).dt.tz_localize(None) 


        # Fetch assets related to real estate from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_real_estate_1
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (31, 32, 57,609,616, 628,604,33,642) 
            GROUP BY entry_date;
        """, (user_id,))

        real_estate_data_1 = cursor.fetchall()
        cursor.close()

        real_estate_df_1 = pd.DataFrame(real_estate_data_1, columns=['entry_date', 'total_real_estate_1'])
        real_estate_df_1 = real_estate_df_1.sort_values(by='entry_date')
        st.write('real_estate_df_1',real_estate_df_1)
        real_estate_df_1['entry_date'] = pd.to_datetime(real_estate_df_1['entry_date']).dt.tz_localize(None)

        # Fetch assets related to liabilities from dynamic_liabilities_projections table (categories 56, 604)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_real_estate_2
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (56,57,604,609,616, 628)
            GROUP BY entry_date;
        """, (user_id,))

        real_estate_data_2 = cursor.fetchall()
        cursor.close()

        real_estate_df_2 = pd.DataFrame(real_estate_data_2, columns=['entry_date', 'total_real_estate_2'])
        real_estate_df_2 = real_estate_df_2.sort_values(by='entry_date')
        st.write('real_estate_df_2',real_estate_df_2)
        real_estate_df_2['entry_date'] = pd.to_datetime(real_estate_df_2['entry_date']).dt.tz_localize(None)

        # Fetch assets related to passive income from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_passive_income_1
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (29,30,236,627,631,634)
            GROUP BY entry_date;
        """, (user_id,))

        passive_income_data_1 = cursor.fetchall()
        cursor.close()

        passive_income_df_1 = pd.DataFrame(passive_income_data_1, columns=['entry_date', 'total_passive_income_1'])
        passive_income_df_1 = passive_income_df_1.sort_values(by='entry_date')
        st.write('passive_income_df_1',passive_income_df_1)
        passive_income_df_1['entry_date'] = pd.to_datetime(passive_income_df_1['entry_date']).dt.tz_localize(None)

        # Fetch assets related to liabilities from dynamic_liabilities_projections table (category 609)
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(liabilities_value::double precision) AS total_passive_income_2
            FROM dynamic_liabilities_projections
            WHERE user_code = %s AND category_id IN (609)
            GROUP BY entry_date;
        """, (user_id,))

        passive_income_data_2 = cursor.fetchall()
        cursor.close()

        passive_income_df_2 = pd.DataFrame(passive_income_data_2, columns=['entry_date', 'total_passive_income_2'])
        passive_income_df_2['entry_date'] = pd.to_datetime(passive_income_df_2['entry_date']).dt.tz_localize(None)

        # Fetch assets related to debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_debt
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (27, 54, 45, 25, 37, 26, 38, 39, 40, 41, 42, 43, 44, 48, 49, 237,320)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data = cursor.fetchall()
        cursor.close()

        debt_df = pd.DataFrame(debt_data, columns=['entry_date', 'total_debt'])
        debt_df = debt_df.sort_values(by='entry_date')
        st.write('debt_df',debt_df)
        debt_df['entry_date'] = pd.to_datetime(debt_df['entry_date']).dt.tz_localize(None)

        # Fetch assets related to Capital Protection Funds in debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.80 AS total_debt_2
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (323)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data_2 = cursor.fetchall()
        cursor.close()

        debt_df_2 = pd.DataFrame(debt_data_2, columns=['entry_date', 'total_debt_2'])
        debt_df_2 = debt_df_2.sort_values(by='entry_date')
        st.write('debt_df_2',debt_df_2)
        debt_df_2['entry_date'] = pd.to_datetime(debt_df_2['entry_date']).dt.tz_localize(None)

        

        # Fetch assets related to Conservative Hybrid Funds in debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.70 AS total_debt_3
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (324)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data_3 = cursor.fetchall()
        cursor.close()

        debt_df_3 = pd.DataFrame(debt_data_3, columns=['entry_date', 'total_debt_3'])
        debt_df_3 = debt_df_3.sort_values(by='entry_date')
        st.write('debt_df_2',debt_df_3)
        debt_df_3['entry_date'] = pd.to_datetime(debt_df_3['entry_date']).dt.tz_localize(None)

        # Fetch assets related to Equity Savings in debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.70 AS total_debt_4
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (326)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data_4 = cursor.fetchall()
        cursor.close()

        debt_df_4 = pd.DataFrame(debt_data_4, columns=['entry_date', 'total_debt_4'])
        debt_df_4 = debt_df_4.sort_values(by='entry_date')
        st.write('debt_df_4',debt_df_4)
        debt_df_4['entry_date'] = pd.to_datetime(debt_df_4['entry_date']).dt.tz_localize(None)

        # Fetch assets related to Multi Asset Allocation in debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.30 AS total_debt_5
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (327)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data_5 = cursor.fetchall()
        cursor.close()

        debt_df_5 = pd.DataFrame(debt_data_5, columns=['entry_date', 'total_debt_5'])
        debt_df_5 = debt_df_5.sort_values(by='entry_date')
        st.write('debt_df_4',debt_df_5)
        debt_df_5['entry_date'] = pd.to_datetime(debt_df_5['entry_date']).dt.tz_localize(None)

        # Fetch assets related to Aggressive Funds in debt from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision)*0.20 AS total_debt_6
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (319)
            GROUP BY entry_date;
        """, (user_id,))

        debt_data_6 = cursor.fetchall()
        cursor.close()

        debt_df_6 = pd.DataFrame(debt_data_6, columns=['entry_date', 'total_debt_6'])
        debt_df_6 = debt_df_6.sort_values(by='entry_date')
        st.write('debt_df_6',debt_df_6)
        debt_df_6['entry_date'] = pd.to_datetime(debt_df_6['entry_date']).dt.tz_localize(None)


        # Fetch assets related to alternate investments from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_alternate_investments
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (25, 34, 35, 36, 50, 51, 53, 90, 91, 238, 329, 337)
            GROUP BY entry_date;
        """, (user_id,))

        alternate_investments_data = cursor.fetchall()
        cursor.close()

        alternate_investments_df = pd.DataFrame(alternate_investments_data, columns=['entry_date', 'total_alternate_investments'])
        alternate_investments_df = alternate_investments_df.sort_values(by='entry_date')
        st.write('alternate_investments_df',alternate_investments_df)
        alternate_investments_df['entry_date'] = pd.to_datetime(alternate_investments_df['entry_date']).dt.tz_localize(None)


        # Fetch dynamic NPS percent breakup
        cursor = connection.cursor()
        cursor.execute("""
            SELECT category_id, value, description
            FROM nps_percent_breakup
            WHERE customer_code = %s 
            AND category_id IN (374, 375, 376, 378, 379, 380, 381, 382)
            AND is_active = true;
        """, (user_id,))
        nps_rows = cursor.fetchall()
        cursor.close()

        nps_percent_df = pd.DataFrame(nps_rows, columns=['category_id', 'value', 'description'])

        # Calculate individual percentages
        equity_9_percent = nps_percent_df.query("category_id == 374 and description.str.contains('Tier I')")['value'].sum() / 100
        debt_7_percent = nps_percent_df.query("category_id == 375 and description.str.contains('Tier I')")['value'].sum() / 100
        debt_8_percent = nps_percent_df.query("category_id == 376 and description.str.contains('Tier I')")['value'].sum() / 100
        alt_1_percent  = nps_percent_df.query("category_id == 378 and description.str.contains('Tier I')")['value'].sum() / 100

        equity_10_percent = nps_percent_df.query("category_id == 379 and description.str.contains('Tier II')")['value'].sum() / 100
        debt_9_percent = nps_percent_df.query("category_id == 380 and description.str.contains('Tier II')")['value'].sum() / 100
        debt_10_percent = nps_percent_df.query("category_id == 381 and description.str.contains('Tier II')")['value'].sum() / 100
        alt_2_percent   = nps_percent_df.query("category_id == 382 and description.str.contains('Tier II')")['value'].sum() / 100


        # Fetch assets related to NPS Tier I from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_nps_tier_I
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (46)
            GROUP BY entry_date;
        """, (user_id,))

        nps_tier_I_data = cursor.fetchall()
        cursor.close()

        nps_tier_I_df = pd.DataFrame(nps_tier_I_data, columns=['entry_date', 'total_nps_tier_I'])
        nps_tier_I_df = nps_tier_I_df.sort_values(by='entry_date')
        st.write('nps_tier_I_df',nps_tier_I_df)
        nps_tier_I_df['entry_date'] = pd.to_datetime(nps_tier_I_df['entry_date']).dt.tz_localize(None)

        
        # Fetch assets related to NPS Tier II from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_nps_tier_2
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (47)
            GROUP BY entry_date;
        """, (user_id,))

        nps_tier_2_data = cursor.fetchall()
        cursor.close()

        nps_tier_2_df = pd.DataFrame(nps_tier_2_data, columns=['entry_date', 'total_nps_tier_2'])
        nps_tier_2_df = nps_tier_2_df.sort_values(by='entry_date')
        st.write('nps_tier_2_df',nps_tier_2_df)
        nps_tier_2_df['entry_date'] = pd.to_datetime(nps_tier_2_df['entry_date']).dt.tz_localize(None) 

        
        # Fetch assets related to emergency fund from dynamic_assets_projections table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(assets_value::double precision) AS total_emergency_fund
            FROM dynamic_assets_projections
            WHERE user_code = %s AND category_id IN (11, 26, 45, 54, 237, 320)
            GROUP BY entry_date;
        """, (user_id,))

        emergency_fund_data = cursor.fetchall()
        cursor.close()

        emergency_fund_df = pd.DataFrame(emergency_fund_data, columns=['entry_date', 'total_emergency_fund'])
        emergency_fund_df['entry_date'] = pd.to_datetime(emergency_fund_df['entry_date']).dt.tz_localize(None)



        # Iterate over the projections DataFrame and calculate the metrics
        for idx, projection in dynamic_actual_projections_df.iterrows():
            # Assign user-entered values to health_insurance and life_insurance for each entry_date
            #dynamic_actual_projections_df.at[idx, 'health_insurance'] = health_insurance_amount
            #dynamic_actual_projections_df.at[idx, 'life_insurance'] = life_insurance_amount

            current_entry_date = projection['entry_date']
            #st.write('current_entry_date',current_entry_date)
            # Good and Bad liabilities calculations
            matching_good_liabilities_row = good_liabilities_df[good_liabilities_df['entry_date'] == current_entry_date]
            matching_good_liabilities_row_1 = good_liabilities_df_1[good_liabilities_df_1['entry_date'] == current_entry_date]
            matching_bad_liabilities_row = bad_liabilities_df[bad_liabilities_df['entry_date'] == current_entry_date]
            matching_assets_row = assets_df[assets_df['entry_date'] == current_entry_date]


            total_good_liabilities = matching_good_liabilities_row['total_good_liabilities'].values[0] if not matching_good_liabilities_row.empty else 0
            total_good_liabilities_1 = matching_good_liabilities_row_1['total_good_liabilities_1'].values[0] if not matching_good_liabilities_row_1.empty else 0
            total_assets = matching_assets_row['total_assets'].values[0] if not matching_assets_row.empty else 0
            total_bad_liabilities = matching_bad_liabilities_row['total_bad_liabilities'].values[0] if not matching_bad_liabilities_row.empty else 0 
            if total_assets > 0:    
                bad_liabilities_to_total_assets = total_bad_liabilities / total_assets
                good_liabilities_to_total_assets = total_good_liabilities / total_assets
            else:
                bad_liabilities_to_total_assets = 0
                good_liabilities_to_total_assets = 0


            dynamic_actual_projections_df.at[idx, 'good_liabilities_to_total_assets'] = good_liabilities_to_total_assets    
            dynamic_actual_projections_df.at[idx, 'bad_liabilities_to_total_assets'] = bad_liabilities_to_total_assets

            # Expense to income ratio
            matching_income_rows = income_df[(income_df['entry_date'] >= current_entry_date) & 
                                             (income_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]
            # Set default values for total_gross_income and total_taxes_and_expenses
            total_gross_income = matching_income_rows['gross_income'].sum() if not matching_income_rows.empty else 0
            total_taxes_and_expenses = (matching_income_rows['taxes'].sum() + matching_income_rows['total_expense'].sum()) if not matching_income_rows.empty else 0

            if total_gross_income > 0:
                expense_to_income = -float(total_taxes_and_expenses) / float(total_gross_income)
            else:
                expense_to_income = 0

            dynamic_actual_projections_df.at[idx, 'expense_to_income'] = expense_to_income  

            
            # matching_income_row = income_df[income_df['entry_date'] == current_entry_date]

            # total_taxes = matching_income_row['taxes'].values[0] if not matching_income_row.empty else 0
            # total_expensess = matching_income_row['total_expense'].values[0] if not matching_income_row.empty else 0
            # gross_income = matching_income_row['gross_income'].values[0] if not matching_income_row.empty else 0 
            # total_taxes_and_expenses = total_taxes + total_expensess
            # if gross_income > 0:
            #     expense_to_income = -total_taxes_and_expenses / float(gross_income)
            # else:
            #     expense_to_income = 0

            # dynamic_actual_projections_df.at[idx, 'expense_to_income'] = expense_to_income 


            # Good liability EMI to income ratio
            #matching_good_liability_emi_row = good_liability_emi_df[good_liability_emi_df['entry_date'] == current_entry_date]
            matching_income_rows = income_df[(income_df['entry_date'] >= current_entry_date) & 
                                             (income_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]

            matching_good_liability_emi_row = good_liability_emi_df[(good_liability_emi_df['entry_date'] >= current_entry_date) & 
                                             (good_liability_emi_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]
            #matching_income_row = income_df[income_df['entry_date'] == current_entry_date]
            total_gross_income = matching_income_rows['gross_income'].sum() if not matching_income_rows.empty else 0

            total_good_liability_emi = matching_good_liability_emi_row['total_good_liability_emi'].sum() if not matching_good_liability_emi_row.empty else 0

            if total_gross_income > 0:
                good_liability_linked_emi_to_income = -total_good_liability_emi / float(total_gross_income)
            else:
                good_liability_linked_emi_to_income = 0

            dynamic_actual_projections_df.at[idx, 'good_liability_linked_emi_to_income'] = good_liability_linked_emi_to_income

            # Bad liability EMI to income ratio
            #matching_bad_liability_emi_row = bad_liability_emi_df[bad_liability_emi_df['entry_date'] == current_entry_date]
            matching_income_rows = income_df[(income_df['entry_date'] >= current_entry_date) & 
                                             (income_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]

            matching_bad_liability_emi_row = bad_liability_emi_df[(bad_liability_emi_df['entry_date'] >= current_entry_date) & 
                                             (bad_liability_emi_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]
 
            total_gross_income = matching_income_rows['gross_income'].sum() if not matching_income_rows.empty else 0
            total_bad_liability_emi = matching_bad_liability_emi_row['total_bad_liability_emi'].sum() if not matching_bad_liability_emi_row.empty else 0
            
            if total_gross_income > 0:
                bad_liability_linked_emi_to_income = -total_bad_liability_emi / float(total_gross_income)
            else:
                bad_liability_linked_emi_to_income = 0

            dynamic_actual_projections_df.at[idx, 'bad_liability_linked_emi_to_income'] = bad_liability_linked_emi_to_income 

            # Investment to income ratio

            matching_income_rows = income_df[(income_df['entry_date'] >= current_entry_date) & 
                                             (income_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]
            matching_investment_rows = assets_df[(assets_df['entry_date'] >= current_entry_date) & 
                                                        (assets_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))]											 
                                                        
                                                        
            # Set default values for total_gross_income and total_taxes_and_expenses
            total_gross_income = matching_income_rows['gross_income'].sum() if not matching_income_rows.empty else 0

            total_twelve_month_investment = matching_investment_rows['total_investment'].sum() if not matching_investment_rows.empty else 0	

            if total_gross_income > 0:
                 investment_to_income = -total_twelve_month_investment / float(total_gross_income)
            else:
                investment_to_income = 0

            dynamic_actual_projections_df.at[idx, 'investment_to_income'] = investment_to_income 


            # matching_income_row = income_df[income_df['entry_date'] == current_entry_date]

            # total_investment = matching_assets_row['total_investment'].values[0] if not matching_assets_row.empty else 0
            # gross_income = matching_income_row['gross_income'].values[0] if not matching_income_row.empty else 0 
            # if gross_income > 0:
            #     investment_to_income =  -float(total_investment) / float(gross_income)
            # else:
            #     investment_to_income = 0

            # dynamic_actual_projections_df.at[idx, 'investment_to_income'] = investment_to_income

            # Equity calculation
            matching_equity_row_1 = equity_df_1[equity_df_1['entry_date'] == current_entry_date]
            matching_equity_row_2 = equity_df_2[equity_df_2['entry_date'] == current_entry_date]
            matching_equity_row_3 = equity_df_3[equity_df_3['entry_date'] == current_entry_date]
            matching_equity_row_4 = equity_df_4[equity_df_4['entry_date'] == current_entry_date]
            matching_equity_row_5 = equity_df_5[equity_df_5['entry_date'] == current_entry_date]
            matching_equity_row_6 = equity_df_6[equity_df_6['entry_date'] == current_entry_date]
            matching_equity_row_7 = equity_df_7[equity_df_7['entry_date'] == current_entry_date]
            matching_equity_row_8 = equity_df_8[equity_df_8['entry_date'] == current_entry_date]
            #print('matching_equity_row_1',matching_equity_row_1)
            #print('matching_equity_row_1',matching_equity_row_2)
            #print('matching_equity_row_3',matching_equity_row_3)
            # Handle cases where the rows might be empty by using a default value of 0
            total_equity_1 = matching_equity_row_1['total_equity_1'].values[0] if not matching_equity_row_1.empty else 0
            total_equity_2 = matching_equity_row_2['total_equity_2'].values[0] if not matching_equity_row_2.empty else 0
            total_equity_3 = matching_equity_row_3['total_equity_3'].values[0] if not matching_equity_row_3.empty else 0
            total_equity_4 = matching_equity_row_4['total_equity_4'].values[0] if not matching_equity_row_4.empty else 0
            total_equity_5 = matching_equity_row_5['total_equity_5'].values[0] if not matching_equity_row_5.empty else 0
            total_equity_6 = matching_equity_row_6['total_equity_6'].values[0] if not matching_equity_row_6.empty else 0
            total_equity_7 = matching_equity_row_7['total_equity_7'].values[0] if not matching_equity_row_7.empty else 0
            total_equity_8 = matching_equity_row_8['total_equity_8'].values[0] if not matching_equity_row_8.empty else 0

            matching_nps_I_row = nps_tier_I_df[nps_tier_I_df['entry_date'] == current_entry_date]
            nps_I_assets_value = matching_nps_I_row['total_nps_tier_I'].values[0] if not matching_nps_I_row.empty else 0

            matching_nps_2_row = nps_tier_2_df[nps_tier_2_df['entry_date'] == current_entry_date]
            nps_2_assets_value = matching_nps_2_row['total_nps_tier_2'].values[0] if not matching_nps_2_row.empty else 0

            # Equity addition (from NPS)
            total_equity_9 = equity_9_percent * nps_I_assets_value
            total_equity_10 = equity_10_percent * nps_2_assets_value
            #st.write('total_equity_9',total_equity_9)
            #st.write('total_equity_10',total_equity_10)

            # Debt addition (from NPS)
            total_debt_7 = debt_7_percent * nps_I_assets_value
            # st.write('total_debt_7',total_debt_7)
            total_debt_8 = debt_8_percent * nps_I_assets_value
            # st.write('total_debt_8',total_debt_8)
            total_debt_9 = debt_9_percent * nps_2_assets_value
            total_debt_10 = debt_10_percent * nps_2_assets_value

            # Alternate investment addition (from NPS)
            total_alt_invst_1 = alt_1_percent * nps_I_assets_value
            total_alt_invst_2 = alt_2_percent * nps_2_assets_value

            if total_assets > 0:
                equity = (total_equity_1 + total_equity_2 + total_equity_4 + total_equity_5 + total_equity_6 + total_equity_7 + total_equity_8 + total_equity_9 + total_equity_10 ) / (total_assets - total_good_liabilities_1)
                #equity = (total_equity_1) / (total_assets - total_good_liabilities_1)
            else:
                equity = 0

            dynamic_actual_projections_df.at[idx, 'equity'] = equity

            # Real estate calculation
            matching_real_estate_row_1 = real_estate_df_1[real_estate_df_1['entry_date'] == current_entry_date]
            matching_real_estate_row_2 = real_estate_df_2[real_estate_df_2['entry_date'] == current_entry_date]

            total_real_estate_1 = matching_real_estate_row_1['total_real_estate_1'].values[0] if not matching_real_estate_row_1.empty else 0
            #print('total_real_estate_1',total_real_estate_1)
            total_real_estate_2 = matching_real_estate_row_2['total_real_estate_2'].values[0] if not matching_real_estate_row_2.empty else 0
            #print('total_real_estate_2',total_real_estate_2)
            #print('total_assets',total_assets)
            if total_assets > 0:
                real_estate = (total_real_estate_1 - total_real_estate_2) / (total_assets - total_good_liabilities_1)
            else:
                real_estate = 0

            dynamic_actual_projections_df.at[idx, 'real_estate'] = real_estate

            # Passive income calculation
            matching_passive_income_row_1 = passive_income_df_1[passive_income_df_1['entry_date'] == current_entry_date]
            matching_passive_income_row_2 = passive_income_df_2[passive_income_df_2['entry_date'] == current_entry_date]

            total_passive_income_1 = matching_passive_income_row_1['total_passive_income_1'].values[0] if not matching_passive_income_row_1.empty else 0
            total_passive_income_2 = matching_passive_income_row_2['total_passive_income_2'].values[0] if not matching_passive_income_row_2.empty else 0
            if total_assets > 0:
                passive_income = (total_passive_income_1 - total_passive_income_2) / (total_assets - total_good_liabilities_1)
            else:
                passive_income = 0

            dynamic_actual_projections_df.at[idx, 'passive_income'] = passive_income    

            # Debt calculation
            matching_debt_row = debt_df[debt_df['entry_date'] == current_entry_date]
            matching_debt_row_2 = debt_df_2[debt_df_2['entry_date'] == current_entry_date]
            matching_debt_row_3 = debt_df_3[debt_df_3['entry_date'] == current_entry_date]
            matching_debt_row_4 = debt_df_4[debt_df_4['entry_date'] == current_entry_date]
            matching_debt_row_5 = debt_df_5[debt_df_5['entry_date'] == current_entry_date]
            matching_debt_row_6 = debt_df_6[debt_df_6['entry_date'] == current_entry_date]
            

            total_debt = matching_debt_row['total_debt'].values[0] if not matching_debt_row.empty else 0
            total_equity_2 = matching_equity_row_2['total_equity_2'].values[0] if not matching_equity_row_2.empty else 0
            total_debt_2 = matching_debt_row_2['total_debt_2'].values[0] if not matching_debt_row_2.empty else 0
            total_debt_3 = matching_debt_row_3['total_debt_3'].values[0] if not matching_debt_row_3.empty else 0
            total_debt_4 = matching_debt_row_4['total_debt_4'].values[0] if not matching_debt_row_4.empty else 0
            total_debt_5 = matching_debt_row_5['total_debt_5'].values[0] if not matching_debt_row_5.empty else 0
            total_debt_6 = matching_debt_row_6['total_debt_6'].values[0] if not matching_debt_row_6.empty else 0
            
            if total_assets > 0:
                debt = (total_debt + total_equity_2 + total_debt_2 + total_debt_3 + total_debt_4 + total_debt_5 + total_debt_6  + total_debt_7 + total_debt_8 + total_debt_9 + total_debt_10) / (total_assets - total_good_liabilities_1)
            else:
                debt = 0

            dynamic_actual_projections_df.at[idx, 'debt'] = debt  

            # Alternate investments calculation
            matching_alternate_investments_row = alternate_investments_df[alternate_investments_df['entry_date'] == current_entry_date]


            total_alternate_investments = matching_alternate_investments_row['total_alternate_investments'].values[0] if not matching_alternate_investments_row.empty else 0

            if total_assets > 0:
                alternate_investments = (total_alternate_investments + total_alt_invst_1 + total_alt_invst_2) / (total_assets - total_good_liabilities_1)
            else:
                alternate_investments = 0

            dynamic_actual_projections_df.at[idx, 'alternate_investments'] = alternate_investments        

            # Emergency fund calculation
            matching_emergency_fund_row = emergency_fund_df[emergency_fund_df['entry_date'] == current_entry_date]


            total_emergency_fund = matching_emergency_fund_row['total_emergency_fund'].values[0] if not matching_emergency_fund_row.empty else 0

            emergency_funds = total_emergency_fund

            dynamic_actual_projections_df.at[idx, 'emergency_funds'] = emergency_funds

        return dynamic_actual_projections_df

    def save_dynamic_actual_projections_df_to_db(self, dynamic_actual_projections_df, db_config):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
        # Create the engine
        engine = create_engine(connection_string)

        # Define the table schema with specific data types
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'equity': NUMERIC,
            'real_estate': NUMERIC,
            'passive_income': NUMERIC,
            'debt': NUMERIC,
            'alternate_investments': NUMERIC,
            'good_liabilities_to_total_assets': NUMERIC,
            'bad_liabilities_to_total_assets': NUMERIC,
            'expense_to_income': NUMERIC,
            'good_liability_linked_emi_to_income': NUMERIC,
            'bad_liability_linked_emi_to_income': NUMERIC,
            'investment_to_income': NUMERIC,
            'emergency_funds': NUMERIC,
            'health_insurance': NUMERIC,
            'life_insurance': NUMERIC
        }

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_actual_projections_df.to_sql(
            'actual_projections_with_milestones',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'actual_projections_with_milestones'")

    def load_dynamic_actual_projections_df_from_db(self, db_config):
        # Create the connection string using the db_config dictionary
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        
        # Create the engine
        engine = create_engine(connection_string)
        
        # Check if the table exists before trying to load
        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'actual_projections_with_milestones'
            );
        """)
        
        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'actual_projections_with_milestones' does not exist.")
            dynamic_actual_projections_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_actual_projections_df = pd.read_sql('actual_projections_with_milestones', engine)
        
        return dynamic_actual_projections_df


    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_actual_projections_df(self, dynamic_actual_projections_df):
        dynamic_actual_projections_df = self.transpose_and_sort_dates(dynamic_actual_projections_df)
        # Drop unnecessary columns
        dynamic_actual_projections_df = dynamic_actual_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_actual_projections_df['entry_date'] = dynamic_actual_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_actual_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)  

        return df_transposed 


    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_dynamic_actual_projections_df_1(self, dynamic_actual_projections_df):
        # Drop unnecessary columns
        dynamic_actual_projections_df = dynamic_actual_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_actual_projections_df['entry_date'] = dynamic_actual_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_actual_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 
    
    # Method to transpose the dynamic_yearly_cf_projections_df data
    def transpose_display_dynamic_actual_projections_df_1(self, dynamic_actual_projections_df):
        # Drop unnecessary columns
        dynamic_actual_projections_df = dynamic_actual_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        dynamic_actual_projections_df['entry_date'] = dynamic_actual_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_actual_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)  # Set asset_name as index 
        return df_transposed
        

    def delete_old_actual_projections_with_milestones_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM actual_projections_with_milestones 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")     

    def run_actual_projections_with_milestones(self, user_id, dob, retirement_age, month_choice):
        # connection = self.connect_db()

        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)	

        if inspector.has_table('actual_projections_with_milestones'):
            # Only delete old records if the table exists
            self.delete_old_actual_projections_with_milestones_records()    

        # Load existing data
        dynamic_actual_projections_df = self.load_dynamic_actual_projections_df_from_db(self.db_config)

        # Fetch user name based on user_id
        user_name = self.fetch_user_name(user_id)


        if dynamic_actual_projections_df.empty:
            new_projections = self.create_dynamic_actual_projections_table(dob, retirement_age, user_id, user_name, month_choice)
            dynamic_actual_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_actual_projections_df['user_code'].unique():
                new_projections = self.create_dynamic_actual_projections_table(dob, retirement_age, user_id, user_name, month_choice)
                dynamic_actual_projections_df = pd.DataFrame(new_projections)

        # Update projections based on user input
        dynamic_actual_projections_df = self.update_dynamic_actual_projections(self.connection, dynamic_actual_projections_df, user_id)

        # Transpose the data for the desired format
        transposed_df = self.transpose_display_dynamic_actual_projections_df_1(dynamic_actual_projections_df)
        st.write("Reshaped Milestone Actual Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit
        st.success("Actual projection changed, and saved to the database.") 

        # Save the updated DataFrame to the PostgreSQL database
        self.save_dynamic_actual_projections_df_to_db(dynamic_actual_projections_df, self.db_config)
        st.write('actual projections updated and save to the database')


    #ideal per projections    
    def run_pgsql_function(self, connection, liabilities_flag, user_code, effective_tax_rate, appraisal_end_date):
        try:
            # Create a cursor object to interact with the database
            cursor = connection.cursor()

            # Call the PostgreSQL function
            cursor.execute("""
                SELECT generate_dynamic_4_ideal_cashflow_networth_projection(%s, %s, %s, %s)
            """, (liabilities_flag, user_code, effective_tax_rate, appraisal_end_date))

            # Fetch result if needed
            result = cursor.fetchone()

            # Commit the transaction if the function makes changes in the database
            connection.commit()

            # Check the result (if applicable)
            if result:
                print("Function Output:", result)

        except Exception as e:
            print(f"An error occurred: {e}")
            connection.rollback()  # Rollback the transaction if there's an error

        finally:
            cursor.close()    
        
        
    def copy_temp_to_dynamic_ideal_projection(self, db_config, user_code):
        connection = self.connect_db()
        if connection is None:
            return
        
        self.clear_dynamic_ideal_projection_calculation()

        # Query to copy data from temp_ideal_per_projections
        query = "SELECT * FROM temp_ideal_per_projections ORDER BY entry_date"
        new_user_data = pd.read_sql(query, connection)

        # Load the existing data from dynamic_ideal_projection_calculation
        dynamic_ideal_projection_calculation = self.load_dynamic_ideal_projection_calculation_from_db(db_config)

        # If the table is empty, initialize it with new data
        if dynamic_ideal_projection_calculation.empty:
            dynamic_ideal_projection_calculation = new_user_data
        #else:
            #dynamic_ideal_projection_calculation = self.update_dynamic_ideal_projection_calculation(dynamic_ideal_projection_calculation, new_user_data, user_code)

        # Transpose the data for the desired format
        transposed_df = self.transpose_display_dynamic_ideal_projection_calculation_1(dynamic_ideal_projection_calculation)
        st.write("Reshaped Ideal Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit

        # Save the updated DataFrame back to the database
        self.save_dynamic_ideal_projection_calculation_to_db(dynamic_ideal_projection_calculation, db_config)

        # Close the connection
        connection.close() 

    def clear_dynamic_ideal_projection_calculation(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE dynamic_ideal_projection_calculation")
            self.connection.commit()
            print("Cleared the dynamic_ideal_projection_calculation table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the dynamic_ideal_projection_calculation table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()    

        
    def load_dynamic_ideal_projection_calculation_from_db(self, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'dynamic_ideal_projection_calculation'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'dynamic_ideal_projection_calculation' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('dynamic_ideal_projection_calculation', engine)   
        
    
    def save_dynamic_ideal_projection_calculation_to_db(self, dynamic_ideal_projection_calculation, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
    
        # Define the table schema with specific data types
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'equity': NUMERIC,
            'real_estate': NUMERIC,
            'passive_income_assets': NUMERIC,
            'debt': NUMERIC,
            'alternative_investments': NUMERIC,
            'good_liabilities_to_total_assets': NUMERIC,
            'bad_liabilities_to_total_assets': NUMERIC,
            'expense_to_income': NUMERIC,
            'good_liability_linked_emi_to_income': NUMERIC,
            'bad_liability_linked_emi_to_income': NUMERIC,
            'investment_to_income': NUMERIC,
            'emergency_funds': NUMERIC ,
            'health_insurance': NUMERIC ,
            'life_insurance': NUMERIC
        }

        # Save the DataFrame to PostgreSQL table with specific data types
        dynamic_ideal_projection_calculation.to_sql(
            'dynamic_ideal_projection_calculation',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )
        print("Data saved to PostgreSQL table 'dynamic_ideal_projection_calculation'")


    # Method to transpose the dynamic_ideal_projection_calculation data
    def transpose_dynamic_ideal_projection_calculation(self, dynamic_ideal_projection_calculation):
        dynamic_ideal_projection_calculation = self.transpose_and_sort_dates(dynamic_ideal_projection_calculation)
        # Drop unnecessary columns
        dynamic_ideal_projection_calculation = dynamic_ideal_projection_calculation.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #dynamic_ideal_projection_calculation['entry_date'] = dynamic_ideal_projection_calculation['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_ideal_projection_calculation.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed   

    # Method to transpose the dynamic_ideal_projection_calculation data
    def transpose_dynamic_ideal_projection_calculation_1(self, dynamic_ideal_projection_calculation):
        # Drop unnecessary columns
        dynamic_ideal_projection_calculation = dynamic_ideal_projection_calculation.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #dynamic_ideal_projection_calculation['entry_date'] = dynamic_ideal_projection_calculation['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_ideal_projection_calculation.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed
    
    # Method to transpose the dynamic_ideal_projection_calculation data
    def transpose_display_dynamic_ideal_projection_calculation_1(self, dynamic_ideal_projection_calculation):
        # Drop unnecessary columns
        dynamic_ideal_projection_calculation = dynamic_ideal_projection_calculation.drop(columns=['user_code'])
        # Transpose the table
        df_transposed = dynamic_ideal_projection_calculation.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)  # Set asset_name as index
        return df_transposed

        
    def run_dynamic_ideal_projection_calculation(self, user_code, effective_tax_rate=None, appraisal_end_date=None):
        connection = self.connect_db()

        if connection is None:
            return

        # Run the PostgreSQL function to generate the ideal projections
        liabilities_flag = 1  # Set this as needed
        #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'],key="ideal_appraisal_end_date")
        month_end_dates = [f"{str(month).zfill(2)}-{str(monthrange(2024, month)[1]).zfill(2)}" for month in range(1, 13)]

        # Selectbox to choose appraisal end date
        appraisal_end_date = st.selectbox( "Enter the appraisal end date (MM-DD):", month_end_dates, key="ideal_appraisal_end_date")
        #appraisal_end_date = st.selectbox("Enter the appraisal end date (MM-DD)", ['03-31', '12-31'],key="ideal_appraisal_end_date")

        #if st.button("Run User Ideal Projection", key="Update_ideal_projection"):
        if st.button("Update the User Ideal projection", key = 'User_ideal_projections_1'):
            self.run_pgsql_function(connection, liabilities_flag, user_code, effective_tax_rate, appraisal_end_date)

        # Copy data from temp_ideal_per_projections to dynamic_ideal_projection_calculation
        self.copy_temp_to_dynamic_ideal_projection(self.db_config, user_code)
        st.write('ideal projection updated and save to the database')

        self.copy_temp_to_ideal_max_milestone_metric(self.db_config, user_code)

        self.copy_temp_to_ideal_min_milestone_metric(self.db_config, user_code)

        # Close the connection
        connection.close()  
    

    def copy_temp_to_ideal_max_milestone_metric(self, db_config, user_code):
        connection = self.connect_db()
        if connection is None:
            return
        
        self.clear_ideal_max_milestone_metric()

        # Query to copy data from ideal_max_milestone_metric
        query = "SELECT * FROM fbs_metric_max ORDER BY entry_date"  # Assuming temp data is still in fbs_metric_max
        new_user_data = pd.read_sql(query, connection)

        # Load the existing data from ideal_max_milestone_metric
        ideal_max_milestone_metric_df = self.load_ideal_max_milestone_metric_from_db(db_config)

        # If the table is empty, initialize it with new data
        if ideal_max_milestone_metric_df.empty:
            ideal_max_milestone_metric_df = new_user_data
        #else:
            #ideal_max_milestone_metric_df = self.update_ideal_max_milestone_metric(ideal_max_milestone_metric_df, new_user_data, user_code)

        # Transpose the data for the desired format
        transposed_df = self.transpose_display_ideal_max_milestone_metric_1(ideal_max_milestone_metric_df)
        st.write("Reshaped Ideal Max Milestone Metric")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit

        # Save the updated DataFrame back to the database
        self.save_ideal_max_milestone_metric_to_db(ideal_max_milestone_metric_df, db_config)

        # Close the connection
        connection.close() 

    def clear_ideal_max_milestone_metric(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE ideal_max_milestone_metric")
            self.connection.commit()
            print("Cleared the ideal_max_milestone_metric table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the ideal_max_milestone_metric table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()

    
    def load_ideal_max_milestone_metric_from_db(self, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'ideal_max_milestone_metric'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'ideal_max_milestone_metric' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('ideal_max_milestone_metric', engine)   
    
    def save_ideal_max_milestone_metric_to_db(self, ideal_max_milestone_metric_df, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
    
        # Define the table schema with specific data types
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'equity': NUMERIC,
            'real_estate': NUMERIC,
            'passive_income_assets': NUMERIC,
            'debt': NUMERIC,
            'alternative_investments': NUMERIC,
            'good_liabilities_to_total_assets': NUMERIC,
            'bad_liabilities_to_total_assets': NUMERIC,
            'expense_to_income': NUMERIC,
            'good_liability_linked_emi_to_income': NUMERIC,
            'bad_liability_linked_emi_to_income': NUMERIC,
            'investment_to_income': NUMERIC,
            'emergency_funds': NUMERIC,
            'health_insurance': NUMERIC,
            'life_insurance': NUMERIC
        }

        # Save the DataFrame to PostgreSQL table with specific data types
        ideal_max_milestone_metric_df.to_sql(
            'ideal_max_milestone_metric',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )
        print("Data saved to PostgreSQL table 'ideal_max_milestone_metric'")

    # Method to transpose the ideal_max_milestone_metric data
    def transpose_ideal_max_milestone_metric_1(self, ideal_max_milestone_metric_df):
        # Drop unnecessary columns
        ideal_max_milestone_metric_df = ideal_max_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_max_milestone_metric_df['entry_date'] = ideal_max_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_max_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 

    # Method to transpose the ideal_max_milestone_metric data
    def transpose_display_ideal_max_milestone_metric_1(self, ideal_max_milestone_metric_df):
        # Drop unnecessary columns
        ideal_max_milestone_metric_df = ideal_max_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_max_milestone_metric_df['entry_date'] = ideal_max_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_max_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace = True)
        return df_transposed 
    

    # Method to transpose the ideal_max_milestone_metric data
    def transpose_ideal_max_milestone_metric(self, ideal_max_milestone_metric_df):
        ideal_max_milestone_metric_df = self.transpose_and_sort_dates(ideal_max_milestone_metric_df)
        # Drop unnecessary columns
        ideal_max_milestone_metric_df = ideal_max_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_max_milestone_metric_df['entry_date'] = ideal_max_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_max_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed


    def copy_temp_to_ideal_min_milestone_metric(self, db_config, user_code):
        connection = self.connect_db()
        if connection is None:
            return
        
        self.clear_ideal_min_milestone_metric()

        # Query to copy data from ideal_min_milestone_metric
        query = "SELECT * FROM fbs_metric_min ORDER BY entry_date"  # Fetching from fbs_metric_min
        new_user_data = pd.read_sql(query, connection)

        # Load the existing data from ideal_min_milestone_metric
        ideal_min_milestone_metric_df = self.load_ideal_min_milestone_metric_from_db(db_config)

        # If the table is empty, initialize it with new data
        if ideal_min_milestone_metric_df.empty:
            ideal_min_milestone_metric_df = new_user_data
        #else:
            #ideal_min_milestone_metric_df = self.update_ideal_min_milestone_metric(ideal_min_milestone_metric_df, new_user_data, user_code)

        # Transpose the data for the desired format
        transposed_df = self.transpose_display_ideal_min_milestone_metric_1(ideal_min_milestone_metric_df)
        st.write("Reshaped Ideal Min Milestone Metric")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit

        # Save the updated DataFrame back to the database
        self.save_ideal_min_milestone_metric_to_db(ideal_min_milestone_metric_df, db_config)

        # Close the connection
        connection.close() 

    def clear_ideal_min_milestone_metric(self):
        # Clear the existing dynamic_income_projection table for any user
        try:
            cursor = self.connection.cursor()
            cursor.execute("TRUNCATE TABLE ideal_min_milestone_metric")
            self.connection.commit()
            print("Cleared the ideal_min_milestone_metric table successfully.")
        except Exception as e:
            print(f"Error occurred while clearing the ideal_min_milestone_metric table: {e}")
            self.connection.rollback()
        finally:
            cursor.close()    
       
    
    def load_ideal_min_milestone_metric_from_db(self, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'ideal_min_milestone_metric'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'ideal_min_milestone_metric' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('ideal_min_milestone_metric', engine)   
    
    def save_ideal_min_milestone_metric_to_db(self, ideal_min_milestone_metric_df, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
    
        # Define the table schema with specific data types
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'equity': NUMERIC,
            'real_estate': NUMERIC,
            'passive_income_assets': NUMERIC,
            'debt': NUMERIC,
            'alternative_investments': NUMERIC,
            'good_liabilities_to_total_assets': NUMERIC,
            'bad_liabilities_to_total_assets': NUMERIC,
            'expense_to_income': NUMERIC,
            'good_liability_linked_emi_to_income': NUMERIC,
            'bad_liability_linked_emi_to_income': NUMERIC,
            'investment_to_income': NUMERIC,
            'emergency_funds': NUMERIC,
            'health_insurance': NUMERIC,
            'life_insurance': NUMERIC
        }

        # Save the DataFrame to PostgreSQL table with specific data types
        ideal_min_milestone_metric_df.to_sql(
            'ideal_min_milestone_metric',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )
        print("Data saved to PostgreSQL table 'ideal_min_milestone_metric'")

    # Method to transpose the ideal_min_milestone_metric data
    def transpose_ideal_min_milestone_metric_1(self, ideal_min_milestone_metric_df):
        # Drop unnecessary columns
        ideal_min_milestone_metric_df = ideal_min_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_min_milestone_metric_df['entry_date'] = ideal_min_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_min_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 
    
    # Method to transpose the ideal_min_milestone_metric data
    def transpose_display_ideal_min_milestone_metric_1(self, ideal_min_milestone_metric_df):
        # Drop unnecessary columns
        ideal_min_milestone_metric_df = ideal_min_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_min_milestone_metric_df['entry_date'] = ideal_min_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_min_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date',inplace = True)
        return df_transposed


    # Method to transpose the ideal_min_milestone_metric data
    def transpose_ideal_min_milestone_metric(self, ideal_min_milestone_metric_df):
        ideal_min_milestone_metric_df = self.transpose_and_sort_dates(ideal_min_milestone_metric_df)
        # Drop unnecessary columns
        ideal_min_milestone_metric_df = ideal_min_milestone_metric_df.drop(columns=['user_code'])

        # Ensure entry_date is in string format
        #ideal_min_milestone_metric_df['entry_date'] = ideal_min_milestone_metric_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = ideal_min_milestone_metric_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed     
    

    # calculate ideal emergency planning projections
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    # Function to create dynamic ideal projections for emergency planning
    def create_dynamic_ideal_projections_emergency_planning_table(self, dob, retirement_age, user_id, user_name,month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        dynamic_ideal_projections_emergency_planning = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            dynamic_ideal_projections_emergency_planning_data = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'emergency_funds': 0,
                'health_insurance': 0, 
                'life_insurance': 0
            }
            dynamic_ideal_projections_emergency_planning.append(dynamic_ideal_projections_emergency_planning_data)

            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return dynamic_ideal_projections_emergency_planning
    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM milestone_customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))
        
        user_name = cursor.fetchone()[0]
        cursor.close()
        
        return user_name.strip()

    # Function to update the emergency planning projections
    def update_dynamic_ideal_projections_emergency_planning_table(self, connection, dynamic_ideal_projections_emergency_planning_df, user_id):
        # Prompt user for health insurance and life insurance amounts

        #health_life_data = st.radio("Do you want to change the insurance data?",('no', 'yes'), key = "ideal_health_life_question")

        #if health_life_data == 'yes':
            # Prompt user for health insurance and life insurance amounts
            #health_insurance_amount = st.number_input("Enter the health insurance amount:",key = "ideal_health_question")
            #life_insurance_amount = st.number_input("Enter the life insurance amount: ", key = "ideal_life_question")

            
            # Update health and life insurance in the DataFrame
            #for idx, projection in dynamic_ideal_projections_emergency_planning_df.iterrows():
                #dynamic_ideal_projections_emergency_planning_df.at[idx, 'health_insurance'] = health_insurance_amount
                #dynamic_ideal_projections_emergency_planning_df.at[idx, 'life_insurance'] = life_insurance_amount
        #else:
            # Fetch health insurance coverage for all entry_date
        cursor = connection.cursor()
        cursor.execute("""
            SELECT SUM(cover) AS total_health_insurance
            FROM pmwell_response
            WHERE user_code = %s AND category_id = 165 AND is_active = True;
        """, (user_id,))
        total_health_insurance = cursor.fetchone()[0]

        # Fetch life insurance coverage for all entry_date
        cursor.execute("""
            SELECT SUM(cover) AS total_life_insurance
            FROM pmwell_response
            WHERE user_code = %s AND category_id = 166 AND is_active = True;
        """, (user_id,))
        total_life_insurance = cursor.fetchone()[0]

        cursor.close()

        # Handle null or None for total_life_insurance and total_health_insurance
        total_health_insurance = total_health_insurance if total_health_insurance is not None else 0
        total_life_insurance = total_life_insurance if total_life_insurance is not None else 0

        if total_life_insurance > 50000000:
            total_life_insurance = 50000000

        # Apply the fetched total_health_insurance and total_life_insurance to all rows
        dynamic_ideal_projections_emergency_planning_df['health_insurance'] = total_health_insurance
        dynamic_ideal_projections_emergency_planning_df['life_insurance'] = total_life_insurance

        numeric_columns = ['emergency_funds', 'health_insurance', 'life_insurance']    
            
            
        for column in numeric_columns:
            dynamic_ideal_projections_emergency_planning_df[column] = dynamic_ideal_projections_emergency_planning_df[column].astype(float)

        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, gross_income, taxes, household_lifestyle_expense_amount
            FROM dynamic_milestone_income_projection
            WHERE user_code = %s
            ORDER BY entry_date;
        """, (user_id,))

        income_data = cursor.fetchall()
        cursor.close()
        income_df = pd.DataFrame(income_data, columns=['entry_date', 'gross_income', 'taxes', 'household_lifestyle_expense_amount'])
        income_df['entry_date'] = pd.to_datetime(income_df['entry_date']).dt.tz_localize(None)

        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, total_emi
            FROM dynamic_yearly_cf_projections
            WHERE user_code = %s;
        """, (user_id,))

        emi_data = cursor.fetchall()
        cursor.close()
        emi_df = pd.DataFrame(emi_data, columns=['entry_date', 'total_emi'])
        emi_df['entry_date'] = pd.to_datetime(emi_df['entry_date']).dt.tz_localize(None)

        for idx, projection in dynamic_ideal_projections_emergency_planning_df.iterrows():
            #dynamic_ideal_projections_emergency_planning_df.at[idx, 'health_insurance'] = health_insurance_amount
            #dynamic_ideal_projections_emergency_planning_df.at[idx, 'life_insurance'] = life_insurance_amount

            # Ensure 'entry_date' is a datetime object
            current_entry_date = pd.to_datetime(projection['entry_date'])
            matching_income_rows = income_df[
                (income_df['entry_date'] >= current_entry_date) & 
                (income_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))
            ]

            matching_emi_rows = emi_df[
                (emi_df['entry_date'] >= current_entry_date) & 
                (emi_df['entry_date'] < current_entry_date + pd.DateOffset(months=12))
            ]

            total_expenses = matching_income_rows['household_lifestyle_expense_amount'].sum() if not matching_income_rows.empty else 0
            total_emi = matching_emi_rows['total_emi'].sum() if not matching_emi_rows.empty else 0
            emergency_funds = -(float(total_expenses) + float(total_emi)) / 2
            dynamic_ideal_projections_emergency_planning_df.at[idx, 'emergency_funds'] = emergency_funds

        return dynamic_ideal_projections_emergency_planning_df

    # Function to save the emergency planning projections to the database
    def save_dynamic_ideal_projections_emergency_planning_table_df_to_db(self, dynamic_ideal_projections_emergency_planning_df, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC 
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'emergency_funds': NUMERIC,
            'health_insurance': NUMERIC,
            'life_insurance': NUMERIC
        }

        dynamic_ideal_projections_emergency_planning_df.to_sql(
            'ideal_projections_emergency_fund_with_milestones',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'ideal_projections_emergency_fund_with_milestones'")

    # Function to load the emergency planning projections from the database
    def load_dynamic_ideal_projections_emergency_planning_table_df_from_db(self, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'ideal_projections_emergency_fund_with_milestones'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'ideal_projections_emergency_fund_with_milestones' does not exist.")
            dynamic_ideal_projections_emergency_planning_df = pd.DataFrame()  # Return an empty DataFrame
        else:
            dynamic_ideal_projections_emergency_planning_df = pd.read_sql('ideal_projections_emergency_fund_with_milestones', engine)

        return dynamic_ideal_projections_emergency_planning_df
    

    # Method to transpose the dynamic_ideal_projections_emergency_planning_df data
    def transpose_dynamic_ideal_projections_emergency_planning_1(self, dynamic_ideal_projections_emergency_planning_df):
        # Drop unnecessary columns
        dynamic_ideal_projections_emergency_planning_df = dynamic_ideal_projections_emergency_planning_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_ideal_projections_emergency_planning_df['entry_date'] = dynamic_ideal_projections_emergency_planning_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_ideal_projections_emergency_planning_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed


    # Method to transpose the dynamic_ideal_projections_emergency_planning_df data
    def transpose_display_dynamic_ideal_projections_emergency_planning_1(self, dynamic_ideal_projections_emergency_planning_df):
        # Drop unnecessary columns
        dynamic_ideal_projections_emergency_planning_df = dynamic_ideal_projections_emergency_planning_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_ideal_projections_emergency_planning_df['entry_date'] = dynamic_ideal_projections_emergency_planning_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_ideal_projections_emergency_planning_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date', inplace=True)
        return df_transposed    
    

    # Method to transpose the dynamic_ideal_projections_emergency_planning_df data
    def transpose_dynamic_ideal_projections_emergency_planning(self, dynamic_ideal_projections_emergency_planning_df):
        dynamic_ideal_projections_emergency_planning_df = self.transpose_and_sort_dates(dynamic_ideal_projections_emergency_planning_df)
        # Drop unnecessary columns
        dynamic_ideal_projections_emergency_planning_df = dynamic_ideal_projections_emergency_planning_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_ideal_projections_emergency_planning_df['entry_date'] = dynamic_ideal_projections_emergency_planning_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_ideal_projections_emergency_planning_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed
    
    def delete_old_ideal_projections_emergency_fund_with_milestones_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM ideal_projections_emergency_fund_with_milestones 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.") 


    # Function to run the emergency planning projections process
    def run_ideal_projections_emergency_fund_with_milestones(self, user_code, dob, retirement_age, month_choice):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('ideal_projections_emergency_fund_with_milestones'):
            # Only delete old records if the table exists
            self.delete_old_ideal_projections_emergency_fund_with_milestones_records()

        dynamic_ideal_projections_emergency_planning_df = self.load_dynamic_ideal_projections_emergency_planning_table_df_from_db(self.db_config)
        user_name = self.fetch_user_name(user_code)

        if dynamic_ideal_projections_emergency_planning_df.empty:
            new_projections = self.create_dynamic_ideal_projections_emergency_planning_table(dob, retirement_age, user_code, user_name, month_choice)
            dynamic_ideal_projections_emergency_planning_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_ideal_projections_emergency_planning_df['user_code'].unique():
                new_projections = self.create_dynamic_ideal_projections_emergency_planning_table(dob, retirement_age, user_code, user_name, month_choice)
                dynamic_ideal_projections_emergency_planning_df = pd.DataFrame(new_projections)

        dynamic_ideal_projections_emergency_planning_df = self.update_dynamic_ideal_projections_emergency_planning_table(self.connection, dynamic_ideal_projections_emergency_planning_df, user_code)

       # Transpose the data for the desired format
        transposed_df = self.transpose_display_dynamic_ideal_projections_emergency_planning_1(dynamic_ideal_projections_emergency_planning_df)
        st.write("Reshaped Ideal Emergency Planning Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit
        st.success("Ideal Emergency Planning  updated, and saved to the database.") 

        self.save_dynamic_ideal_projections_emergency_planning_table_df_to_db(dynamic_ideal_projections_emergency_planning_df, self.db_config)
        st.write("ideal emergency planning projections updated and save to the database")
        

    # calculate fbs projections
    def calculate_age_on_date(self, dob, date):
        age = date.year - dob.year
        if (date.month, date.day) < (dob.month, dob.day):
            age -= 1
        return age

    # Function to create dynamic FBS projections
    def create_dynamic_fbs_projections_table(self, dob, retirement_age, user_id, user_name, month_choice):
        current_year = datetime.now().year
        current_month = datetime.now().month
        last_day_of_current_month = datetime(current_year, current_month, monthrange(current_year, current_month)[1])
        start_date = last_day_of_current_month
        current_age = current_year - dob.year
        age_limit_year = current_year + (80 - current_age)

        dynamic_fbs_projections = []

        while start_date.year < age_limit_year or (start_date.year == age_limit_year and start_date.month <= month_choice):
            last_day_of_month = start_date.replace(day=monthrange(start_date.year, start_date.month)[1])
            iter_age = self.calculate_age_on_date(dob, last_day_of_month)

            dynamic_fbs_projections_data = {
                'user_code': user_id,
                'user_name': user_name,
                'entry_date': last_day_of_month.strftime('%Y-%m-%d'),
                'age': iter_age,
                'equity': 0,
                'real_estate': 0,
                'passive_income': 0,
                'debt': 0,
                'alternate_investments': 0,
                'good_liabilities_to_total_assets': 0,
                'bad_liabilities_to_total_assets': 0,
                'expense_to_income': 0,
                'good_liability_linked_emi_to_income': 0,
                'bad_liability_linked_emi_to_income': 0,
                'investment_to_income': 0,
                'emergency_funds': 0,
                'health_insurance': 0,
                'life_insurance': 0,
                'fbs': 0
            }
            dynamic_fbs_projections.append(dynamic_fbs_projections_data)
            start_date = (last_day_of_month + timedelta(days=1)).replace(day=1)

        return dynamic_fbs_projections
    
    def fetch_user_name(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT CONCAT(COALESCE(p.first_name,''), ' ', COALESCE(p.last_name,'')) AS Name 
            FROM milestone_customer_profile p 
            WHERE p.user_code = %s;
        """, (user_id,))
        
        user_name = cursor.fetchone()[0]
        cursor.close()
        
        return user_name.strip()
    

    # Function to update the FBS projections based on the actual and ideal projections
    def update_dynamic_fbs_projections(self, connection, dynamic_fbs_projections_df, user_id):
        # Fetch data from actual_projections_with_milestones table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, good_liabilities_to_total_assets, bad_liabilities_to_total_assets, expense_to_income,
                   good_liability_linked_emi_to_income, bad_liability_linked_emi_to_income, investment_to_income,
                   equity, real_estate, passive_income, debt, alternate_investments, emergency_funds, health_insurance, life_insurance
            FROM actual_projections_with_milestones
            WHERE user_code = %s;
        """, (user_id,))

        actual_data = cursor.fetchall()
        cursor.close()

        # Convert fetched data into a DataFrame
        actual_df = pd.DataFrame(actual_data, columns=['entry_date', 'actual_good_liabilities_to_total_assets', 'actual_bad_liabilities_to_total_assets', 
                                                       'actual_expense_to_income', 'actual_good_liability_linked_emi_to_income', 
                                                       'actual_bad_liability_linked_emi_to_income', 'actual_investment_to_income',
                                                       'actual_equity', 'actual_real_estate', 'actual_passive_income', 'actual_debt',
                                                       'actual_alternate_investments', 'actual_emergency_funds', 'actual_health_insurance', 'actual_life_insurance'])
        actual_df['entry_date'] = pd.to_datetime(actual_df['entry_date']).dt.tz_localize(None)
        
        # Convert decimal.Decimal values to float
        for col in actual_df.columns[1:]:
            actual_df[col] = actual_df[col].astype(float)

        # Fetch data from dynamic_ideal_projection_calculation table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, good_liabilities_to_total_assets, bad_liabilities_to_total_assets, expense_to_income,
                   good_liability_linked_emi_to_income, bad_liability_linked_emi_to_income, investment_to_income,
                   equity, real_estate, passive_income_assets, debt, alternative_investments
            FROM dynamic_ideal_projection_calculation
            WHERE user_code = %s;
        """, (user_id,))

        ideal_data = cursor.fetchall()
        cursor.close()

        # Convert fetched data into a DataFrame
        ideal_df = pd.DataFrame(ideal_data, columns=['entry_date', 'ideal_good_liabilities_to_total_assets', 'ideal_bad_liabilities_to_total_assets',
                                                     'ideal_expense_to_income', 'ideal_good_liability_linked_emi_to_income', 
                                                     'ideal_bad_liability_linked_emi_to_income', 'ideal_investment_to_income',
                                                     'ideal_equity', 'ideal_real_estate', 'ideal_passive_income_assets', 
                                                     'ideal_debt', 'ideal_alternative_investments'])
        ideal_df['entry_date'] = pd.to_datetime(ideal_df['entry_date']).dt.tz_localize(None)
        
        # Convert decimal.Decimal values to float
        for col in ideal_df.columns[1:]:
            ideal_df[col] = ideal_df[col].astype(float)

        # Fetch data from ideal_projections_emergency_fund_with_milestones table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT entry_date, emergency_funds, health_insurance, life_insurance
            FROM ideal_projections_emergency_fund_with_milestones
            WHERE user_code = %s;
        """, (user_id,))

        ideal_emergency_data = cursor.fetchall()
        cursor.close()

        # Convert fetched data into a DataFrame
        ideal_emergency_planning_df = pd.DataFrame(ideal_emergency_data, columns=['entry_date', 'ideal_emergency_funds', 'ideal_health_insurance', 'ideal_life_insurance'])
        ideal_emergency_planning_df['entry_date'] = pd.to_datetime(ideal_emergency_planning_df['entry_date']).dt.tz_localize(None)

        # Convert decimal.Decimal values to float
        for col in ideal_emergency_planning_df.columns[1:]:
            ideal_emergency_planning_df[col] = ideal_emergency_planning_df[col].astype(float)
        
        # Fetch user generation from the customer_details table
        cursor = connection.cursor()
        cursor.execute("""
            SELECT CASE
                        WHEN value = 'Generation 1' THEN 'Gen 1'
                        WHEN value = 'Generation 2' THEN 'Gen 2'
                        WHEN value = 'Generation 3' THEN 'Gen 3'
                    END AS user_gen
            FROM customer_details WHERE user_code = %s AND is_active = true AND category_id = 183;
        """, (user_id,))

        user_gen_result = cursor.fetchone()
        cursor.close()

        ideal_weightage_a = ideal_weightage_b = ideal_weightage_c = None

        if user_gen_result:
            user_gen = user_gen_result[0]
            if user_gen == 'Gen 1':
                ideal_weightage_a = 0.33
                ideal_weightage_b = 0.33
                ideal_weightage_c = 0.33
            elif user_gen == 'Gen 2':
                ideal_weightage_a = 0.40
                ideal_weightage_b = 0.40
                ideal_weightage_c = 0.20
            elif user_gen == 'Gen 3':
                ideal_weightage_a = 0.40
                ideal_weightage_b = 0.50
                ideal_weightage_c = 0.10

        # Iterate over the projections DataFrame and calculate FBS
        for idx, projection in dynamic_fbs_projections_df.iterrows():
            current_entry_date = projection['entry_date']

            matching_actual_row = actual_df[actual_df['entry_date'] == current_entry_date]
            matching_ideal_row = ideal_df[ideal_df['entry_date'] == current_entry_date]
            matching_ideal_emergency_plan_row = ideal_emergency_planning_df[ideal_emergency_planning_df['entry_date'] == current_entry_date]

            if not matching_actual_row.empty and not matching_ideal_row.empty:
                #good liabilities to total asset calculation                                     
                actual_value = matching_actual_row['actual_good_liabilities_to_total_assets'].values[0]
                ideal_value = matching_ideal_row['ideal_good_liabilities_to_total_assets'].values[0]

                if actual_value <= ideal_value:
                    good_liabilities_to_total_assets = 100 - ((100 - 50) / (ideal_value - 0) / 100) * (ideal_value - actual_value) * 100
                else:
                    good_liabilities_to_total_assets = 100 - 2 * ((100 - 50) / (ideal_value - 0) / 100) * (actual_value - ideal_value) * 100

                # Ensure that the value is not negative
                good_liabilities_to_total_assets = max(good_liabilities_to_total_assets, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'good_liabilities_to_total_assets'] = round(good_liabilities_to_total_assets,0)

                # Bad liabilities to total asset calculation
                actual_bad_value = matching_actual_row['actual_bad_liabilities_to_total_assets'].values[0]
                ideal_bad_value = matching_ideal_row['ideal_bad_liabilities_to_total_assets'].values[0]

                if actual_bad_value <= ideal_bad_value:
                    bad_liabilities_to_total_assets = 100 - ((100 - 75) / (ideal_bad_value - 0) / 100) * (actual_bad_value - 0) * 100
                else:
                    bad_liabilities_to_total_assets = 75 - 3 * ((100 - 75) / (ideal_bad_value - 0) / 100) * (actual_bad_value - ideal_bad_value) * 100

                # Ensure that the value is not negative
                bad_liabilities_to_total_assets = max(bad_liabilities_to_total_assets, 0)

                # Update the DataFrame for bad liabilities
                dynamic_fbs_projections_df.at[idx, 'bad_liabilities_to_total_assets'] = round(bad_liabilities_to_total_assets,0)


                # expense to income calculation
                actual_expense_to_income_value = matching_actual_row['actual_expense_to_income'].values[0]
                ideal_expense_to_income_value = matching_ideal_row['ideal_expense_to_income'].values[0]

                if actual_expense_to_income_value <= ideal_expense_to_income_value:
                    expense_to_income = 100 - ((100 - 75) / (ideal_expense_to_income_value - 0) / 100) * (actual_expense_to_income_value - 0) * 100
                else:
                    expense_to_income = 75 - 3 * ((100 - 75) / (ideal_expense_to_income_value - 0) / 100) * (actual_expense_to_income_value - ideal_expense_to_income_value) * 100

                # Ensure that the value is not negative
                expense_to_income = max(expense_to_income, 0)

                # Update the DataFrame for bad liabilities
                dynamic_fbs_projections_df.at[idx, 'expense_to_income'] = round(expense_to_income,0)


                #good_liability_linked_emi_to_income                                  
                actual_good_liability_linked_emi_to_income = matching_actual_row['actual_good_liability_linked_emi_to_income'].values[0]
                ideal_good_liability_linked_emi_to_income = matching_ideal_row['ideal_good_liability_linked_emi_to_income'].values[0]

                if actual_good_liability_linked_emi_to_income <= ideal_good_liability_linked_emi_to_income:
                    good_liability_linked_emi_to_income = 100 - ((100 - 50) / (ideal_good_liability_linked_emi_to_income - 0) / 100) * (ideal_good_liability_linked_emi_to_income - actual_good_liability_linked_emi_to_income) * 100
                else:
                    good_liability_linked_emi_to_income = 100 - 2 * ((100 - 50) / (ideal_good_liability_linked_emi_to_income - 0) / 100) * (actual_good_liability_linked_emi_to_income - ideal_good_liability_linked_emi_to_income) * 100

                # Ensure that the value is not negative
                good_liability_linked_emi_to_income = max(good_liability_linked_emi_to_income, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'good_liability_linked_emi_to_income'] = round(good_liability_linked_emi_to_income,0)                                     


                #bad_liability_linked_emi_to_income                                  
                actual_bad_liability_linked_emi_to_income = matching_actual_row['actual_bad_liability_linked_emi_to_income'].values[0]
                ideal_bad_liability_linked_emi_to_income = matching_ideal_row['ideal_bad_liability_linked_emi_to_income'].values[0]

                if actual_bad_liability_linked_emi_to_income <= ideal_bad_liability_linked_emi_to_income:
                    bad_liability_linked_emi_to_income = 100 - ((100 - 75) / (ideal_bad_liability_linked_emi_to_income - 0) / 100) * (actual_bad_liability_linked_emi_to_income - 0) * 100
                else:
                    bad_liability_linked_emi_to_income = 75 - 3 * ((100 - 75) / (ideal_bad_liability_linked_emi_to_income - 0) / 100) * (actual_bad_liability_linked_emi_to_income - ideal_bad_liability_linked_emi_to_income) * 100

                # Ensure that the value is not negative
                bad_liability_linked_emi_to_income = max(bad_liability_linked_emi_to_income, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'bad_liability_linked_emi_to_income'] = round(bad_liability_linked_emi_to_income,0)

                #investments_to_income                                  
                actual_investments_to_income = float(matching_actual_row['actual_investment_to_income'].values[0])
                ideal_investments_to_income = float(matching_ideal_row['ideal_investment_to_income'].values[0])

                if actual_investments_to_income <= ideal_investments_to_income:
                    investments_to_income = 75 - ((75 - 0) / (ideal_investments_to_income - 0) / 100) * (ideal_investments_to_income - actual_investments_to_income) * 100
                else:
                    investments_to_income = 75 - (2/9) * ((75 - 0) / (ideal_investments_to_income - 0) / 100) * ( ideal_investments_to_income - actual_investments_to_income ) * 100

                investments_to_income = min(max(investments_to_income, 0), 100)    

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'investment_to_income'] = round(investments_to_income,0)


                #equity                                  
                actual_equity = float(matching_actual_row['actual_equity'].values[0])
                ideal_equity = float(matching_ideal_row['ideal_equity'].values[0])

                if actual_equity <= ideal_equity:
                    equity = 100 - ((100 - 0) / (ideal_equity - 0) / 100) * (ideal_equity - actual_equity) * 100
                else:
                    equity = 100 - ((100 - 50) / (1 - ideal_equity) / 100) * ( actual_equity - ideal_equity) * 100

                # Ensure that the value is not negative
                equity = max(equity, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'equity'] = round(equity,0)


                #real_estate                                  
                actual_real_estate = float(matching_actual_row['actual_real_estate'].values[0])
                ideal_real_estate = float(matching_ideal_row['ideal_real_estate'].values[0])

                if actual_real_estate <= ideal_real_estate:
                    real_estate = 100 - ((100 - 0) / (ideal_real_estate - 0) / 100) * (ideal_real_estate - actual_real_estate) * 100
                else:
                    real_estate = 100 - ((100 - 0) / (1 - ideal_real_estate) / 100) * ( actual_real_estate - ideal_real_estate) * 100

                # if actual_real_estate <= ideal_real_estate:
                #     real_estate = 75
                # else:
                #     real_estate = 75   

                # Ensure that the value is not negative
                real_estate = max(real_estate, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'real_estate'] = round(real_estate,0)

                #passive income                                 
                actual_passive_income = float(matching_actual_row['actual_passive_income'].values[0])
                ideal_passive_income = float(matching_ideal_row['ideal_passive_income_assets'].values[0])

                if actual_passive_income <= ideal_passive_income:
                    passive_income = 100 - ((100 - 50) / (ideal_passive_income - 0) / 100) * (ideal_passive_income - actual_passive_income) * 100
                else:
                    passive_income = 100 - ((100 - 0) / (1 - ideal_passive_income) / 100) * ( actual_passive_income - ideal_passive_income) * 100

                # Ensure that the value is not negative
                passive_income = max(passive_income, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'passive_income'] = round(passive_income,0)


                #Debt                                 
                actual_debt = float(matching_actual_row['actual_debt'].values[0])
                ideal_debt = float(matching_ideal_row['ideal_debt'].values[0])

                if actual_debt <= ideal_debt:
                    debt = 100 - ((100 - 0) / (ideal_debt - 0) / 100) * (ideal_debt - actual_debt) * 100
                else:
                    debt = 100 - ((100 - 0) / (1 - ideal_debt) / 100) * ( actual_debt - ideal_debt) * 100

                # Ensure that the value is not negative
                debt = max(debt, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'debt'] = round(debt,0)

                #alternate_investment                                 
                actual_alternate_investment = float(matching_actual_row['actual_alternate_investments'].values[0])
                ideal_alternate_investment = float(matching_ideal_row['ideal_alternative_investments'].values[0])

                if actual_alternate_investment <= ideal_alternate_investment:
                    alternate_investment = 100 - ((100 - 75) / (ideal_alternate_investment - 0) / 100) * (ideal_alternate_investment - actual_alternate_investment) * 100
                else:
                    alternate_investment = 100 - ((100 - 0) / (1 - ideal_alternate_investment) / 100) * ( actual_alternate_investment - ideal_alternate_investment) * 100

                # Ensure that the value is not negative
                alternate_investment = max(alternate_investment, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'alternate_investments'] = round(alternate_investment,0)


                #emergency_funds                                 
                actual_emergency_funds = float(matching_actual_row['actual_emergency_funds'].values[0])
                ideal_emergency_funds = float(matching_ideal_emergency_plan_row['ideal_emergency_funds'].values[0])

                # SAFETY: if ideal is 0, use 1 just for calculation to avoid divide-by-zero
                safe_ideal_emergency_funds = ideal_emergency_funds if ideal_emergency_funds != 0 else 1.0

                if actual_emergency_funds <= ideal_emergency_funds:
                    emergency_funds = 100 - ((100 - 0) / (safe_ideal_emergency_funds - 0) / 100) * (safe_ideal_emergency_funds - actual_emergency_funds) * 100
                else:
                    emergency_funds = max( 50, 100 - ((100 - 75) / (safe_ideal_emergency_funds) / 100) * ( actual_emergency_funds - safe_ideal_emergency_funds) * 100)

                # Ensure that the value is not negative
                emergency_funds = max(emergency_funds, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'emergency_funds'] = round(emergency_funds,0)


                #health_insurance                                 
                actual_health_insurance = float(matching_actual_row['actual_health_insurance'].values[0])
                ideal_health_insurance = float(matching_ideal_emergency_plan_row['ideal_health_insurance'].values[0])

                if actual_health_insurance <= ideal_health_insurance:
                    health_insurance = (actual_health_insurance) / (ideal_health_insurance) * 100 
                else:
                    health_insurance = max( 75, 200 - ((actual_health_insurance) / (ideal_health_insurance)) * 100 )

                # Ensure that the value is not negative
                health_insurance = max(health_insurance, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'health_insurance'] = round(health_insurance,0)


                #life_insurance                                 
                actual_life_insurance = float(matching_actual_row['actual_life_insurance'].values[0])
                ideal_life_insurance = float(matching_ideal_emergency_plan_row['ideal_life_insurance'].values[0])

                if actual_life_insurance <= ideal_life_insurance:
                    life_insurance = (actual_life_insurance) / (ideal_life_insurance) * 100 

                elif ideal_life_insurance == 0 :
                    life_insurance = max( 75, 100 - ((actual_life_insurance) / 10) * 100 )

                else:
                    life_insurance = max( 75, 200 - ((actual_life_insurance) / (ideal_life_insurance)) * 100 )

                # Ensure that the value is not negative
                life_insurance = max(life_insurance, 0)

                # Update the DataFrame
                dynamic_fbs_projections_df.at[idx, 'life_insurance'] = round(life_insurance,0)
                # (Include the specific calculations from the original code provided)

                # Update the DataFrame with calculated values
                dynamic_fbs_projections_df.at[idx, 'good_liabilities_to_total_assets'] = round(good_liabilities_to_total_assets, 0)
                dynamic_fbs_projections_df.at[idx, 'bad_liabilities_to_total_assets'] = round(bad_liabilities_to_total_assets, 0)
                dynamic_fbs_projections_df.at[idx, 'expense_to_income'] = round(expense_to_income, 0)
                dynamic_fbs_projections_df.at[idx, 'good_liability_linked_emi_to_income'] = round(good_liability_linked_emi_to_income, 0)
                dynamic_fbs_projections_df.at[idx, 'bad_liability_linked_emi_to_income'] = round(bad_liability_linked_emi_to_income, 0)
                dynamic_fbs_projections_df.at[idx, 'investment_to_income'] = round(investments_to_income, 0)
                dynamic_fbs_projections_df.at[idx, 'equity'] = round(equity, 0)
                dynamic_fbs_projections_df.at[idx, 'real_estate'] = round(real_estate, 0)
                dynamic_fbs_projections_df.at[idx, 'passive_income'] = round(passive_income, 0)
                dynamic_fbs_projections_df.at[idx, 'debt'] = round(debt, 0)
                dynamic_fbs_projections_df.at[idx, 'alternate_investments'] = round(alternate_investment, 0)
                dynamic_fbs_projections_df.at[idx, 'emergency_funds'] = round(emergency_funds, 0)
                dynamic_fbs_projections_df.at[idx, 'health_insurance'] = round(health_insurance, 0)
                dynamic_fbs_projections_df.at[idx, 'life_insurance'] = round(life_insurance, 0)

                # Calculate the FBS
                fbs = (ideal_weightage_a * ((good_liabilities_to_total_assets + bad_liabilities_to_total_assets + expense_to_income + 
                                             good_liability_linked_emi_to_income + bad_liability_linked_emi_to_income + 
                                             investments_to_income) / 6.0)) + \
                      (ideal_weightage_b * ((equity + real_estate + passive_income + debt + alternate_investment) / 5.0)) + \
                      (ideal_weightage_c * ((emergency_funds + health_insurance + life_insurance) / 3.0))

                # Update the DataFrame with the calculated FBS
                dynamic_fbs_projections_df.at[idx, 'fbs'] = round(fbs, 0)

        return dynamic_fbs_projections_df

    # Function to save the FBS projections to the PostgreSQL database
    def save_dynamic_fbs_projections_df_to_db(self, dynamic_fbs_projections_df, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)
        from sqlalchemy.dialects.postgresql import UUID, BIGINT, TEXT, DATE, NUMERIC
        table_schema = {
            'user_code': UUID(as_uuid=True),
            'user_name': TEXT,
            'entry_date': DATE,
            'age': BIGINT,
            'equity': NUMERIC,
            'real_estate': NUMERIC,
            'passive_income': NUMERIC,
            'debt': NUMERIC,
            'alternate_investments': NUMERIC,
            'good_liabilities_to_total_assets': NUMERIC,
            'bad_liabilities_to_total_assets': NUMERIC,
            'expense_to_income': NUMERIC,
            'good_liability_linked_emi_to_income': NUMERIC,
            'bad_liability_linked_emi_to_income': NUMERIC,
            'investment_to_income': NUMERIC,
            'emergency_funds': NUMERIC,
            'health_insurance': NUMERIC,
            'life_insurance': NUMERIC,
            'fbs': NUMERIC
        }

        dynamic_fbs_projections_df.to_sql(
            'fbs_dynamic_projections_with_milestones',
            engine,
            if_exists='replace',
            index=False,
            dtype=table_schema
        )

        print("Data saved to PostgreSQL table 'fbs_dynamic_projections_with_milestones'")

    # Function to load the FBS projections from the PostgreSQL database
    def load_dynamic_fbs_projections_df_from_db(self, db_config):
        connection_string = f"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['database']}"
        engine = create_engine(connection_string)

        table_exists_query = text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'fbs_dynamic_projections_with_milestones'
            );
        """)

        with engine.connect() as connection:
            table_exists = connection.execute(table_exists_query).scalar_one()

        if not table_exists:
            print("Table 'fbs_dynamic_projections_with_milestones' does not exist.")
            return pd.DataFrame()  # Return an empty DataFrame
        else:
            return pd.read_sql('fbs_dynamic_projections_with_milestones', engine)
        
    # Method to transpose the dynamic_fbs_projections_df data
    def transpose_dynamic_fbs_projections_df_1(self, dynamic_fbs_projections_df):
        # Drop unnecessary columns
        dynamic_fbs_projections_df = dynamic_fbs_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_fbs_projections_df['entry_date'] = dynamic_fbs_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_fbs_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)

        return df_transposed 
    
    # Method to transpose the dynamic_fbs_projections_df data
    def transpose_display_dynamic_fbs_projections_df_1(self, dynamic_fbs_projections_df):
        # Drop unnecessary columns
        dynamic_fbs_projections_df = dynamic_fbs_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_fbs_projections_df['entry_date'] = dynamic_fbs_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_fbs_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'entry_date'}, inplace=True)
        df_transposed.set_index('entry_date',inplace = True)
        return df_transposed

    # Method to transpose the dynamic_fbs_projections_df data
    def transpose_dynamic_fbs_projections_df(self, dynamic_fbs_projections_df):
        dynamic_fbs_projections_df = self.transpose_and_sort_dates(dynamic_fbs_projections_df)
        # Drop unnecessary columns
        dynamic_fbs_projections_df = dynamic_fbs_projections_df.drop(columns=['user_code', 'user_name'])

        # Ensure entry_date is in string format
        #dynamic_fbs_projections_df['entry_date'] = dynamic_fbs_projections_df['entry_date'].dt.strftime('%d-%m-%Y')
        
        # Transpose the table
        df_transposed = dynamic_fbs_projections_df.set_index('entry_date').T
        
        # Reset index and rename the index column
        df_transposed.reset_index(inplace=True)
        df_transposed.rename(columns={'index': 'metrics'}, inplace=True)

        # Ensure the entry_date row matches the number of columns in df_transposed
        entry_date_row = pd.DataFrame([df_transposed.columns.tolist()], columns=df_transposed.columns)

        # Insert the entry_date row before the transposed data
        df_transposed = pd.concat([entry_date_row, df_transposed], ignore_index=True)

        return df_transposed 

    def delete_old_fbs_dynamic_projections_with_milestones_records(self):
        cursor = self.connection.cursor()
        current_date = datetime.now().strftime('%Y-%m-%d')
        delete_query = """
            DELETE FROM fbs_dynamic_projections_with_milestones 
            WHERE entry_date < %s;
        """
        cursor.execute(delete_query, (current_date,))
        self.connection.commit()
        cursor.close()
        print(f"Records with entry_date less than {current_date} have been deleted.")     


    # Function to run FBS dynamic projections with milestones
    def run_fbs_dynamic_projections_with_milestones(self, user_code, dob, retirement_age, month_choice):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)

        if inspector.has_table('fbs_dynamic_projections_with_milestones'):
            # Only delete old records if the table exists
            self.delete_old_fbs_dynamic_projections_with_milestones_records()


        user_name = self.fetch_user_name(user_code)

        # Load existing data from the database
        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(self.db_config)

        if dynamic_fbs_projections_df.empty:
            new_projections = self.create_dynamic_fbs_projections_table(dob, retirement_age, user_code, user_name, month_choice)
            dynamic_fbs_projections_df = pd.DataFrame(new_projections)
        else:
            # If the DataFrame is not empty, ensure that the user exists in it
            if user_id not in dynamic_fbs_projections_df['user_code'].unique():
                new_projections = self.create_dynamic_fbs_projections_table(dob, retirement_age, user_code, user_name, month_choice)
                dynamic_fbs_projections_df = pd.DataFrame(new_projections)

        # Update projections
        dynamic_fbs_projections_df = self.update_dynamic_fbs_projections(self.connection, dynamic_fbs_projections_df, user_code)

        # Transpose the data for the desired format
        transposed_df = self.transpose_display_dynamic_fbs_projections_df_1(dynamic_fbs_projections_df)
        st.write("Reshaped FBS Projection")
        st.dataframe(transposed_df)  # Display the transposed data in Streamlit
        st.success("Milestone FBS projection updated, and saved to the database.") 

        # Save updated projections back to the database
        self.save_dynamic_fbs_projections_df_to_db(dynamic_fbs_projections_df, self.db_config)
        st.write('fbs projection updated and save to the database')


    def plot_combined_graph_with_intersections(self, actual_df, ideal_df):
        from plotly.subplots import make_subplots
        import plotly.graph_objects as go

        # Multiply all the columns in actual_df and ideal_df by 100 to convert to percentages
        actual_df = actual_df.copy()
        ideal_df = ideal_df.copy()

        up_to_date = st.date_input("Select the end date for plotting", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = 'actual ideal charts duration') 

        actual_df['entry_date'] = pd.to_datetime(actual_df['entry_date'])
        ideal_df['entry_date'] = pd.to_datetime(ideal_df['entry_date'])

        up_to_date = pd.to_datetime(up_to_date)

        # Filter the data up to the specified entry date
        actual_df = actual_df[actual_df['entry_date'] <= up_to_date]
        ideal_df = ideal_df[ideal_df['entry_date'] <= up_to_date]

        actual_df.iloc[:, 4:] = actual_df.iloc[:, 4:] * 100  # Assuming the first column is 'entry_date'
        ideal_df.iloc[:, 2:] = ideal_df.iloc[:, 2:] * 100

        # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'passive_income_assets':'passive_income','alternative_investments': 'alternate_investments',
                                                'good_liability_to_total_assets' : 'good_liabilities_to_total_assets',
                                                'bad_liability_to_total_assets' : 'bad_liabilities_to_total_assets',
                                                'good_liability_emi_to_total_income':'good_liability_linked_emi_to_income',
                                                'bad_liability_emi_to_total_income': 'bad_liability_linked_emi_to_income'})

        # Function to add traces and intersection points to the subplots
        def add_projection_traces(fig, actual_column, ideal_column, row, col, title, show_legend=False):
            # Merge actual and ideal dataframes for each category
            merged_df = pd.merge(actual_df[['entry_date', actual_column]], ideal_df_temp[['entry_date', ideal_column]],
                                on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

            # Calculate the difference to identify intersections
            merged_df['difference'] = merged_df[f'{actual_column}_actual'] - merged_df[f'{ideal_column}_ideal']

            # Identify where the sign of the difference changes (intersection points)
            merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
            sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

            # Add the actual and ideal lines
            fig.add_trace(go.Scatter(x=merged_df['entry_date'], y=merged_df[f'{actual_column}_actual'], 
                                    mode='lines', name='Actual', line=dict(color='blue'), showlegend=show_legend),
                        row=row, col=col)
            fig.add_trace(go.Scatter(x=merged_df['entry_date'], y=merged_df[f'{ideal_column}_ideal'], 
                                    mode='lines', name='Ideal', line=dict(color='orange'), showlegend=show_legend),
                        row=row, col=col)

            # Adding markers for intersection points
            if not sign_change_index.empty:
                intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
                intersection_values = merged_df.loc[sign_change_index, f'{actual_column}_actual']

                fig.add_trace(
                    go.Scatter(
                        x=intersection_dates,
                        y=intersection_values,
                        mode='markers',
                        marker=dict(color='red', size=10),
                        name='Intersection Points',
                        showlegend=show_legend
                    ),
                    row=row, col=col
                )

                # Add annotations for the intersection dates
                for date, value in zip(intersection_dates, intersection_values):
                    fig.add_annotation(
                        x=date, y=value,
                        text=date.strftime('%Y-%m-%d'),
                        showarrow=True,
                        arrowhead=1,
                        ax=-40,
                        ay=-30,
                        row=row, col=col
                    )

        # Create subplots: 4 rows, 3 columns
        fig = make_subplots(rows=6, cols=2, subplot_titles=("Equity", 
                                                            "Real Estate", 
                                                            "Passive Income",
                                                            "Debt",
                                                            "Alternate Investments",
                                                            "Good Liabilities to Total Assets",
                                                            "Bad Liabilities to Total Assets",
                                                            "Expense to Income",
                                                            "Good Liability Linked Emi to Income",
                                                            "Bad Liability Linked Emi to Income",
                                                            "Investment to Income"))

        # Add Equity plot with intersection points (show legend only once)
        add_projection_traces(fig, 'equity', 'equity', row=1, col=1, title='Equity', show_legend=True)

        # Add other plots without repeating the legend
        add_projection_traces(fig, 'real_estate', 'real_estate', row=1, col=2, title='Real Estate', show_legend=False)
        add_projection_traces(fig, 'passive_income', 'passive_income', row=2, col=1, title='Passive Income', show_legend=False)
        add_projection_traces(fig, 'debt', 'debt', row=2, col=2, title='Debt', show_legend=False)
        add_projection_traces(fig, 'alternate_investments', 'alternate_investments', row=3, col=1, title='Alternate Investments', show_legend=False)
        add_projection_traces(fig, 'good_liabilities_to_total_assets', 'good_liabilities_to_total_assets', row=3, col=2, title='Good Liabilities to Total Assets', show_legend=False)
        add_projection_traces(fig, 'bad_liabilities_to_total_assets', 'bad_liabilities_to_total_assets', row=4, col=1, title='Bad Liabilities to Total Assets', show_legend=False)
        add_projection_traces(fig, 'expense_to_income', 'expense_to_income', row=4, col=2, title='Expense to Income', show_legend=False)
        add_projection_traces(fig, 'good_liability_linked_emi_to_income', 'good_liability_linked_emi_to_income', row=5, col=1, title='Good Liability Linked Emi to Income', show_legend=False)
        add_projection_traces(fig, 'bad_liability_linked_emi_to_income', 'bad_liability_linked_emi_to_income', row=5, col=2, title='Bad Liability Linked Emi to Income', show_legend=False)
        add_projection_traces(fig, 'investment_to_income', 'investment_to_income', row=6, col=1, title='Investment to Income', show_legend=False)

        # Update y-axis for all subplots to display as percentages
        #fig.update_yaxes(tickformat=".2f", range=[-100, 100], title_text="Percentage (%)") 
        
        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")


        
        # Update layout for better visualization
        fig.update_layout(height=1000, width=1500, title_text="Actual vs Ideal Max", showlegend=True,
                        legend=dict(
                                        x=0.5,  # Position legend in the middle horizontally
                                        y=-0.2,  # Position legend below the chart
                                        xanchor="center",
                                        orientation="h",  # Horizontal legend
                                        bgcolor="rgba(255, 255, 255, 0.5)"  # Transparent background for legend
                        ))

        # Show the plot in Streamlit
        # Update layout and show the plot
        #fig.update_layout(height=1200, width=1000, title_text="Combined Projection Plots with Fixed Y-Axis Scale (Including Negatives)")
    
        st.plotly_chart(fig)  
        

    def save_and_plot_all_charts_comparison(self, db_config, user_code):
        # Save the updated ideal max milestone metric to the database
        #self.save_ideal_max_milestone_metric_to_db(self.ideal_max_milestone_metric_df, db_config)

        ideal_max_milestone_metric_df = self.load_ideal_max_milestone_metric_from_db(db_config)

        # Load actual projections for comparison
        actual_projections_df = self.load_dynamic_actual_projections_df_from_db(db_config)

        self.plot_combined_graph_with_intersections(actual_projections_df, ideal_max_milestone_metric_df) 

    
    def save_and_plot_all_fbs_charts_comparison(self, db_config, user_code):
        # Save the updated ideal max milestone metric to the database
        #self.save_ideal_max_milestone_metric_to_db(self.ideal_max_milestone_metric_df, db_config)

        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(db_config)

        self.plot_combined_graph_of_fbs(dynamic_fbs_projections_df)    



    def plot_combined_graph_of_fbs(self, fbs_df):  

        up_to_date = st.date_input("Select the end date for plotting", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = 'fbs charts duration') 

        fbs_df['entry_date'] = pd.to_datetime(fbs_df['entry_date'])

        up_to_date = pd.to_datetime(up_to_date)

        # Filter the data up to the specified entry date
        fbs_df = fbs_df[fbs_df['entry_date'] <= up_to_date]  
        
        # Create subplots with 5 rows and 2 columns
        fig = make_subplots(rows=4, cols=3, subplot_titles=[
            "Equity", "Real Estate", "Passive Income", "Debt",
            "Alternate Investments", "Good Liabilities to Total Assets", 
            "Bad Liabilities to Total Assets", "Expense to Income", 
            "Good Liability EMI to Income", "Bad Liability EMI to Income","Investment to Income","Final FBS Score"
        ])

        # Add traces for each column
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['equity'], mode='lines', name='Equity'), row=1, col=1)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['real_estate'], mode='lines', name='Real Estate'), row=1, col=2)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['passive_income'], mode='lines', name='Passive Income'), row=1, col=3)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['debt'], mode='lines', name='Debt'), row=2, col=1)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['alternate_investments'], mode='lines', name='Alternate Investments'), row=2, col=2)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['good_liabilities_to_total_assets'], mode='lines', name='Good Liabilities to Total Assets'), row=2, col=3)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['bad_liabilities_to_total_assets'], mode='lines', name='Bad Liabilities to Total Assets'), row=3, col=1)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['expense_to_income'], mode='lines', name='Expense to Income'), row=3, col=2)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['good_liability_linked_emi_to_income'], mode='lines', name='Good Liability EMI to Income'), row=3, col=3)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['bad_liability_linked_emi_to_income'], mode='lines', name='Bad Liability EMI to Income'), row=4, col=1)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['investment_to_income'], mode='lines', name='Investment to Income'), row=4, col=2)
        fig.add_trace(go.Scatter(x=fbs_df['entry_date'], y=fbs_df['fbs'], mode='lines', name='Final FBS Score'), row=4, col=3)
        # Update layout for consistent y-axis scale
        fig.update_yaxes(range=[1, 100])

        # Update layout for better visualization
        fig.update_layout(height=1500, width=1500, title_text="FBS Dynamic Projections with Milestones", showlegend=False)

        #Show the plot
        #st.fig.show()
        st.plotly_chart(fig)


    def plot_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df, up_to_date):
        # Convert entry_date column to datetime
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])

        # Convert up_to_date to datetime if it's a date
        # Convert up_to_date to datetime
        up_to_date = pd.to_datetime(up_to_date)

        # Set up the first entry date month for annual projection
        start_month = dynamic_yearly_cf_projections_df['entry_date'].iloc[0].month

        # Filter the data up to the specified entry date
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df[dynamic_yearly_cf_projections_df['entry_date'] <= up_to_date]

        # Annual gross income: filter for the first entry month each year, then multiply by 12
        annual_projections = dynamic_yearly_cf_projections_df[
            dynamic_yearly_cf_projections_df['entry_date'].dt.month == start_month
        ].copy()
        annual_projections['annual_gross_income'] = annual_projections['gross_income'] * 12

        # Create subplots: 3 rows and 3 columns
        fig = make_subplots(
            rows=3, cols=3, 
            subplot_titles=[
                "Annual Gross Income", "Sum of Total Expense", "Total Investment",
                "Total EMI", "Total Surplus", "Total Liabilities",
                "Total Assets", "Total Networth"
            ]
        )

        # Plot the annual gross income with markers
        fig.add_trace(go.Scatter(
            x=annual_projections['entry_date'], 
            y=annual_projections['annual_gross_income'], 
            mode='lines', 
            name='Annual Gross Income'
        ), row=1, col=1)

        # Add marker for the first entry date of annual_gross_income
        first_entry_date_annual_income = annual_projections['entry_date'].iloc[0]
        first_annual_income = annual_projections['annual_gross_income'].iloc[0]
        fig.add_annotation(
            x=first_entry_date_annual_income,
            y=first_annual_income,
            text=f"First: â‚¹{first_annual_income:,.0f}",
            showarrow=True,
            arrowhead=2,
            row=1, col=1
        )

        # Plot the rolling sum of total expense (unchanged)
        rolling_sums_total_expense = dynamic_yearly_cf_projections_df['total_expense'].rolling(window=12).sum()
    
        # Find the first valid rolling sum after a full 12-month window
        first_valid_index = rolling_sums_total_expense.first_valid_index()
        if first_valid_index is not None:
            first_total_expense_date = dynamic_yearly_cf_projections_df['entry_date'].iloc[first_valid_index]
            first_total_expense_value = rolling_sums_total_expense.iloc[first_valid_index]
        else:
            # Fallback to the first date and zero value
            first_total_expense_date = dynamic_yearly_cf_projections_df['entry_date'].iloc[0]
            first_total_expense_value = 0

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=rolling_sums_total_expense.abs(), 
            mode='lines', 
            name='Sum of Total Expense (12 months)'
        ), row=1, col=2)

        # Add marker for the first entry date of total_expense
        first_entry_date_total_expense = dynamic_yearly_cf_projections_df['entry_date'].iloc[0]
        first_total_expense = rolling_sums_total_expense.iloc[11]  # first complete 12-month sum
        fig.add_annotation(
            x=first_total_expense_date,
            y=abs(first_total_expense_value),
            text=f"First: â‚¹{abs(first_total_expense):,.0f}",
            showarrow=True,
            arrowhead=2,
            row=1, col=2
        )

        # Plot other metrics
        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['total_investment'].abs(), 
            mode='lines', 
            name='Total Investment'
        ), row=1, col=3)

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['total_liabilities_outflows'].abs(), 
            mode='lines', 
            name='Total EMI'
        ), row=2, col=1)

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['end_total_surplus'], 
            mode='lines', 
            name='Total Surplus'
        ), row=2, col=2)

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['total_liabilities'], 
            mode='lines', 
            name='Total Liabilities'
        ), row=2, col=3)

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['total_assets'], 
            mode='lines', 
            name='Total Assets'
        ), row=3, col=1)

        fig.add_trace(go.Scatter(
            x=dynamic_yearly_cf_projections_df['entry_date'], 
            y=dynamic_yearly_cf_projections_df['total_networth'], 
            mode='lines', 
            name='Total Networth'
        ), row=3, col=2)

        # Update layout with axis titles and formatting
        fig.update_yaxes(tickprefix="â‚¹", tickformat=",.0f", title="Value")
        fig.update_xaxes(title="Date")
        fig.update_layout(
            title="Cash Flow Projections",
            height=1000, 
            width=1200,
            showlegend=False
        )
        
        # Show the plot
        st.plotly_chart(fig)

    def save_and_plot_all_yearly_cf_projections(self, db_config, user_code, up_to_date):
        # Load the existing data
        #st.write("All Cashflows Projections Charts")
        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()

        # Plot annual gross income in subplots
        self.plot_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df, up_to_date)

     

    #seperate graphs
    def plot_equity_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 
        # Merge actual and ideal projections based on entry_date

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['equity'] = actual_df['equity'] * 100
        ideal_df['equity'] = ideal_df['equity'] * 100

        merged_df = pd.merge(actual_df[['entry_date', 'equity']], ideal_df[['entry_date', 'equity']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['equity_actual'] - merged_df['equity_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['equity_actual', 'equity_ideal'],
                    labels={'value': 'Equity (%)', 'entry_date': 'Date'},
                    title='Equity Projection: Actual vs Ideal',
                    color_discrete_map={'equity_actual': 'blue', 'equity_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'equity_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")    

        st.plotly_chart(fig)

    def plot_real_estate_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['real_estate'] = actual_df['real_estate'] * 100
        ideal_df['real_estate'] = ideal_df['real_estate'] * 100

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'real_estate']], ideal_df[['entry_date', 'real_estate']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['real_estate_actual'] - merged_df['real_estate_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['real_estate_actual', 'real_estate_ideal'],
                    labels={'value': 'Real Estate (%)', 'entry_date': 'Date'},
                    title='Real Estate Projection: Actual vs Ideal',
                    color_discrete_map={'real_estate_actual': 'blue', 'real_estate_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'real_estate_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)  

    def plot_passive_income_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['passive_income'] = actual_df['passive_income'] * 100
        ideal_df['passive_income_assets'] = ideal_df['passive_income_assets'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'passive_income_assets':'passive_income'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'passive_income']], ideal_df_temp[['entry_date', 'passive_income']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['passive_income_actual'] - merged_df['passive_income_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['passive_income_actual', 'passive_income_ideal'],
                    labels={'value': 'Passive Inocme (%)', 'entry_date': 'Date'},
                    title='Passive Income Projection: Actual vs Ideal',
                    color_discrete_map={'passive_income_actual': 'blue', 'passive_income_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'passive_income_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)    

    def plot_debt_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['debt'] = actual_df['debt'] * 100
        ideal_df['debt'] = ideal_df['debt'] * 100

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'debt']], ideal_df[['entry_date', 'debt']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['debt_actual'] - merged_df['debt_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['debt_actual', 'debt_ideal'],
                    labels={'value': 'debt (%)', 'entry_date': 'Date'},
                    title='debt Projection: Actual vs Ideal',
                    color_discrete_map={'debt_actual': 'blue', 'debt_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'debt_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig) 

    def plot_alternate_investments_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['alternate_investments'] = actual_df['alternate_investments'] * 100
        ideal_df['alternative_investments'] = ideal_df['alternative_investments'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'alternative_investments':'alternate_investments'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'alternate_investments']], ideal_df_temp[['entry_date', 'alternate_investments']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['alternate_investments_actual'] - merged_df['alternate_investments_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['alternate_investments_actual', 'alternate_investments_ideal'],
                    labels={'value': 'Alternate Investments (%)', 'entry_date': 'Date'},
                    title='Alternate Investments Projection: Actual vs Ideal',
                    color_discrete_map={'alternate_investments_actual': 'blue', 'alternate_investments_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'alternate_investments_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)   

    def plot_good_liabilities_to_total_assets_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['good_liabilities_to_total_assets'] = actual_df['good_liabilities_to_total_assets'] * 100
        ideal_df['good_liability_to_total_assets'] = ideal_df['good_liability_to_total_assets'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'good_liability_to_total_assets':'good_liabilities_to_total_assets'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'good_liabilities_to_total_assets']], ideal_df_temp[['entry_date', 'good_liabilities_to_total_assets']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['good_liabilities_to_total_assets_actual'] - merged_df['good_liabilities_to_total_assets_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['good_liabilities_to_total_assets_actual', 'good_liabilities_to_total_assets_ideal'],
                    labels={'value': 'Good Liabilities to Total Assets (%)', 'entry_date': 'Date'},
                    title='Good Liabilities to Total Assets: Actual vs Ideal',
                    color_discrete_map={'good_liabilities_to_total_assets_actual': 'blue', 'good_liabilities_to_total_assets_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'good_liabilities_to_total_assets_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)  

    def plot_bad_liabilities_to_total_assets_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['bad_liabilities_to_total_assets'] = actual_df['bad_liabilities_to_total_assets'] * 100
        ideal_df['bad_liability_to_total_assets'] = ideal_df['bad_liability_to_total_assets'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'bad_liability_to_total_assets':'bad_liabilities_to_total_assets'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'bad_liabilities_to_total_assets']], ideal_df_temp[['entry_date', 'bad_liabilities_to_total_assets']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['bad_liabilities_to_total_assets_actual'] - merged_df['bad_liabilities_to_total_assets_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['bad_liabilities_to_total_assets_actual', 'bad_liabilities_to_total_assets_ideal'],
                    labels={'value': 'Bad Liabilities to Total Assets (%)', 'entry_date': 'Date'},
                    title='Bad Liabilities to Total Assets: Actual vs Ideal',
                    color_discrete_map={'bad_liabilities_to_total_assets_actual': 'blue', 'bad_liabilities_to_total_assets_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'bad_liabilities_to_total_assets_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)  

    def plot_expense_to_income_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['expense_to_income'] = actual_df['expense_to_income'] * 100
        ideal_df['expense_to_income'] = ideal_df['expense_to_income'] * 100

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'expense_to_income']], ideal_df[['entry_date', 'expense_to_income']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['expense_to_income_actual'] - merged_df['expense_to_income_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['expense_to_income_actual', 'expense_to_income_ideal'],
                    labels={'value': 'Expense to Income (%)', 'entry_date': 'Date'},
                    title='Expense to Income Projection: Actual vs Ideal',
                    color_discrete_map={'expense_to_income_actual': 'blue', 'expense_to_income_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'expense_to_income_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)

    def plot_good_liability_linked_emi_to_income_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['good_liability_linked_emi_to_income'] = actual_df['good_liability_linked_emi_to_income'] * 100
        ideal_df['good_liability_emi_to_total_income'] = ideal_df['good_liability_emi_to_total_income'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'good_liability_emi_to_total_income':'good_liability_linked_emi_to_income'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'good_liability_linked_emi_to_income']], ideal_df_temp[['entry_date', 'good_liability_linked_emi_to_income']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['good_liability_linked_emi_to_income_actual'] - merged_df['good_liability_linked_emi_to_income_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['good_liability_linked_emi_to_income_actual', 'good_liability_linked_emi_to_income_ideal'],
                    labels={'value': 'Good Liability Linked Emi to Income (%)', 'entry_date': 'Date'},
                    title='Good Liability Linked Emi to Income',
                    color_discrete_map={'good_liability_linked_emi_to_income_actual': 'blue', 'good_liability_linked_emi_to_income_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'good_liability_linked_emi_to_income_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig) 


    def plot_bad_liability_linked_emi_to_income_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['bad_liability_linked_emi_to_income'] = actual_df['bad_liability_linked_emi_to_income'] * 100
        ideal_df['bad_liability_emi_to_total_income'] = ideal_df['bad_liability_emi_to_total_income'] * 100

         # Create a temporary DataFrame with renamed columns
        ideal_df_temp = ideal_df.rename(columns={'bad_liability_emi_to_total_income':'bad_liability_linked_emi_to_income'})

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'bad_liability_linked_emi_to_income']], ideal_df_temp[['entry_date', 'bad_liability_linked_emi_to_income']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['bad_liability_linked_emi_to_income_actual'] - merged_df['bad_liability_linked_emi_to_income_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['bad_liability_linked_emi_to_income_actual', 'bad_liability_linked_emi_to_income_ideal'],
                    labels={'value': 'Bad Liability Linked Emi to Income (%)', 'entry_date': 'Date'},
                    title='Bad Liability Linked Emi to Income',
                    color_discrete_map={'bad_liability_linked_emi_to_income_actual': 'blue', 'bad_liability_linked_emi_to_income_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'bad_liability_linked_emi_to_income_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)  


    def plot_investment_to_income_line_graph(self, actual_df, ideal_df):
        import plotly.express as px
        import plotly.graph_objects as go 

        # Multiply the equity column by 100 to convert it into percentage
        actual_df['investment_to_income'] = actual_df['investment_to_income'] * 100
        ideal_df['investment_to_income'] = ideal_df['investment_to_income'] * 100

        # Merge actual and ideal projections based on entry_date
        merged_df = pd.merge(actual_df[['entry_date', 'investment_to_income']], ideal_df[['entry_date', 'investment_to_income']],
                            on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

        # Calculate the difference to identify intersections
        merged_df['difference'] = merged_df['investment_to_income_actual'] - merged_df['investment_to_income_ideal']
        
        # Identify where the sign of the difference changes
        merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
        sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

        # Plotting the data
        fig = px.line(merged_df, x='entry_date', y=['investment_to_income_actual', 'investment_to_income_ideal'],
                    labels={'value': 'Investment to Income (%)', 'entry_date': 'Date'},
                    title='Investment to Income Projection: Actual vs Ideal',
                    color_discrete_map={'investment_to_income_actual': 'blue', 'investment_to_income_ideal': 'orange'})  # Specify colors here

        # Adding markers for intersection points
        if not sign_change_index.empty:
            intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
            intersection_equities = merged_df.loc[sign_change_index, 'investment_to_income_actual']
            
            for date, equity in zip(intersection_dates, intersection_equities):
                fig.add_annotation(
                    x=date, y=equity,
                    text=date.strftime('%Y-%m-%d'),
                    showarrow=True,
                    arrowhead=1,
                    ax=-40,
                    ay=-30
                )

            # Add scatter plot for intersection points
            fig.add_trace(
                go.Scatter(
                    x=intersection_dates,
                    y=intersection_equities,
                    mode='markers',
                    marker=dict(color='red', size=10),
                    name='Intersection Points'
                )
            )

        # Update y-axes to add a percentage symbol after the digit
        fig.update_yaxes(ticksuffix="%")        

        st.plotly_chart(fig)         
                        


    def save_and_plot_seperate_metrics_affordability_checks(self, db_config, user_code):

        ideal_max_milestone_metric_df = self.load_ideal_max_milestone_metric_from_db(db_config)

        # Load actual projections for comparison
        actual_projections_df = self.load_dynamic_actual_projections_df_from_db(db_config)

        # Plot the equity comparison line graph
        self.plot_equity_line_graph(actual_projections_df, ideal_max_milestone_metric_df)   
        self.plot_real_estate_line_graph(actual_projections_df, ideal_max_milestone_metric_df) 
        self.plot_passive_income_line_graph(actual_projections_df , ideal_max_milestone_metric_df )
        self.plot_debt_line_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_alternate_investments_line_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_good_liabilities_to_total_assets_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_bad_liabilities_to_total_assets_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_expense_to_income_line_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_good_liability_linked_emi_to_income_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_bad_liability_linked_emi_to_income_graph(actual_projections_df, ideal_max_milestone_metric_df)
        self.plot_investment_to_income_line_graph(actual_projections_df, ideal_max_milestone_metric_df)




    def plot_combined_graph_of_assets(self, assets_checks_df):    

        up_to_date = st.date_input("Select the end date for plotting", value=date.today(),min_value=date(2000, 1, 1),max_value=date(2100, 12, 31), key = 'asset charts duration') 

        # Get unique asset categories
        unique_assets = assets_checks_df['assets_name'].unique()

        assets_checks_df['entry_date'] = pd.to_datetime(assets_checks_df['entry_date'])

        up_to_date = pd.to_datetime(up_to_date)
        
        # Filter the data up to the specified entry date
        assets_checks_df = assets_checks_df[assets_checks_df['entry_date'] <= up_to_date]

        # Create subplots, one for each asset category
        rows = len(unique_assets) // 2 + len(unique_assets) % 2  # Determine number of rows (2 plots per row)
        fig = make_subplots(rows=rows, cols=2, subplot_titles=unique_assets)

        # Iterate through unique asset categories and add each to the subplots
        for i, asset in enumerate(unique_assets):
            # Filter the dataframe for the current asset
            asset_df = assets_checks_df[assets_checks_df['assets_name'] == asset]
            
            # Determine row and column for subplot
            row = i // 2 + 1
            col = i % 2 + 1
            
            # Add line plot for the asset category
            fig.add_trace(
                go.Scatter(x=asset_df['entry_date'], y=asset_df['assets_value'], mode='lines', name=asset),
                row=row, col=col
            )

        # Update y-axis with currency format and prefix
        fig.update_yaxes(tickprefix="â‚¹", tickformat=",.0f")

        # Update layout for better visualization
        fig.update_layout(height=1500, width=1500, title_text="Asset Categories Projections", showlegend=False)

        # Show the plot
        st.plotly_chart(fig)    

    def save_and_plot_all_assets_charts_comparison(self, db_config, user_code):
        # Save the updated ideal max milestone metric to the database
        #self.save_ideal_max_milestone_metric_to_db(self.ideal_max_milestone_metric_df, db_config)

        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)

        self.plot_combined_graph_of_assets(dynamic_assets_projections_df)    
    
    def plot_emergency_planning_graph_with_intersections(self, actual_df, ideal_df):
        from plotly.subplots import make_subplots
        import plotly.graph_objects as go

        # Function to add traces and intersection points to the subplots
        def add_projection_traces(fig, actual_column, ideal_column, row, col, title, show_legend=False):
            # Merge actual and ideal dataframes for each category
            merged_df = pd.merge(actual_df[['entry_date', actual_column]], ideal_df[['entry_date', ideal_column]],
                                on='entry_date', suffixes=('_actual', '_ideal')).sort_values(by='entry_date')

            # Calculate the difference to identify intersections
            merged_df['difference'] = merged_df[f'{actual_column}_actual'] - merged_df[f'{ideal_column}_ideal']

            # Identify where the sign of the difference changes (intersection points)
            merged_df['sign_change'] = merged_df['difference'].apply(lambda x: 'positive' if x > 0 else 'negative')
            sign_change_index = merged_df[merged_df['sign_change'] != merged_df['sign_change'].shift(1)].index

            # Add the actual and ideal lines
            fig.add_trace(go.Scatter(x=merged_df['entry_date'], y=merged_df[f'{actual_column}_actual'], 
                                    mode='lines', name='Actual', line=dict(color='blue'), showlegend=show_legend),
                        row=row, col=col)
            fig.add_trace(go.Scatter(x=merged_df['entry_date'], y=merged_df[f'{ideal_column}_ideal'], 
                                    mode='lines', name='Ideal', line=dict(color='orange'), showlegend=show_legend),
                        row=row, col=col)

            # Adding markers for intersection points
            if not sign_change_index.empty:
                intersection_dates = merged_df.loc[sign_change_index, 'entry_date']
                intersection_values = merged_df.loc[sign_change_index, f'{actual_column}_actual']

                fig.add_trace(
                    go.Scatter(
                        x=intersection_dates,
                        y=intersection_values,
                        mode='markers',
                        marker=dict(color='red', size=10),
                        name='Intersection Points',
                        showlegend=show_legend
                    ),
                    row=row, col=col
                )

                # Add annotations for the intersection dates
                for date, value in zip(intersection_dates, intersection_values):
                    fig.add_annotation(
                        x=date, y=value,
                        text=date.strftime('%Y-%m-%d'),
                        showarrow=True,
                        arrowhead=1,
                        ax=-40,
                        ay=-30,
                        row=row, col=col
                    )

        # Create subplots: 3 rows, 1 column
        fig = make_subplots(rows=3, cols=1, subplot_titles=("Emergency Funds", 
                                                            "Health Insurance", 
                                                            "Life Insurance"
                                                            ))

        # Add Equity plot with intersection points (show legend only once)
        add_projection_traces(fig, 'emergency_funds', 'emergency_funds', row=1, col=1, title='Emergency Funds', show_legend=True)

        # Add other plots without repeating the legend
        add_projection_traces(fig, 'health_insurance', 'health_insurance', row=2, col=1, title='Health Insurance', show_legend=False)
        add_projection_traces(fig, 'life_insurance', 'life_insurance', row=3, col=1, title = "Life Insurance" , show_legend=False)

        # Update y-axis for all subplots to display as percentages
        #fig.update_yaxes(tickformat=".2f", range=[-100, 100], title_text="Percentage (%)") 

        # Update layout to show y-axis values as full numbers (Rupees)
        fig.update_yaxes(tickprefix="â‚¹", tickformat=",.0f")
        
        # Update layout for better visualization
        fig.update_layout(height=1500, width=1500, title_text="Actual Emegency planning vs Ideal Emergency planning", showlegend=True,
                        legend=dict(
                                        x=0.5,  # Position legend in the middle horizontally
                                        y=-0.2,  # Position legend below the chart
                                        xanchor="center",
                                        orientation="h",  # Horizontal legend
                                        bgcolor="rgba(255, 255, 255, 0.5)"  # Transparent background for legend
                        ))
        

        # Show the plot in Streamlit
        # Update layout and show the plot
        #fig.update_layout(height=1200, width=1000, title_text="Combined Projection Plots with Fixed Y-Axis Scale (Including Negatives)")
    
        st.plotly_chart(fig)  
        

    def plot_all_emergency_planning_charts(self, db_config, user_code):
        # Save the updated ideal max milestone metric to the database
        #self.save_ideal_max_milestone_metric_to_db(self.ideal_max_milestone_metric_df, db_config)

        ideal_emergency_planning_milestone_metric_df = self.load_dynamic_ideal_projections_emergency_planning_table_df_from_db(db_config)

        # Load actual projections for comparison
        actual_projections_df = self.load_dynamic_actual_projections_df_from_db(db_config)

        self.plot_emergency_planning_graph_with_intersections(actual_projections_df, ideal_emergency_planning_milestone_metric_df)



    def download_projections(self, dynamic_income_projection_df, investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df,
                             dynamic_liabilities_outflows_projections_df, milestone_calculation_projections_df,surplus_withdrawal_projections_df,
                             dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                             #milestone_withdrawal_projections_df, 
                             #dynamic_yearly_cf_projections_v1,
                             dynamic_yearly_cf_projections_df, dynamic_actual_projections_df, dynamic_ideal_projection_calculation, ideal_max_milestone_metric_df,
                             ideal_min_milestone_metric_df, dynamic_ideal_projections_emergency_planning_df, dynamic_fbs_projections_df, user_id):
        from io import BytesIO 
        # Transpose the dynamic_income_projection data
        transposed_income_df = self.transpose_dynamic_income_projection(dynamic_income_projection_df)
        #print('transposed_income_df',transposed_income_df)

        # Reshape the data for both investment and loan repayment projections
        reshaped_investment_df = self.reshape_investment_projections(investment_projections_df, user_id)
        reshaped_loan_repayment_df = self.reshape_loan_repayment_projections(loan_repayment_projections_df, user_id)
        reshaped_dynamic_liabilities_df = self.reshape_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_id)
        reshaped_liabilities_outflows_df = self.reshape_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
        reshape_milestone_projections_df = self.reshape_milestone_projections(milestone_calculation_projections_df, user_id)
        reshape_surplus_related_withdrawal_df = self.reshape_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        reshape_dynamic_assets_projections_df = self.reshape_dynamic_assets_projections(dynamic_assets_projections_df, user_id)

        transpose_dynamic_income_df = self.transpose_dynamic_milestone_income_projection(dynamic_milestone_income_projection)

        reshape_additional_income_expense_criteria_df = self.reshape_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)

        #reshape_milestone_withdrawal_projections_df = self.reshape_milestone_related_withdrawal_projections(milestone_withdrawal_projections_df, user_id)
        #transpose_dynamic_yearly_cf_projections_df_v1 = self.transpose_dynamic_yearly_cf_projections_v1(dynamic_yearly_cf_projections_v1)
        transpose_dynamic_yearly_cf_projections_df = self.transpose_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)
        transpose_dynamic_actual_projections_df = self.transpose_dynamic_actual_projections_df(dynamic_actual_projections_df)
        transpose_dynamic_ideal_projection_calculation = self.transpose_dynamic_ideal_projection_calculation(dynamic_ideal_projection_calculation)
        transpose_ideal_max_milestone_metric_df = self.transpose_ideal_max_milestone_metric(ideal_max_milestone_metric_df)
        transpose_ideal_min_milestone_metric_df = self.transpose_ideal_min_milestone_metric(ideal_min_milestone_metric_df)
        transpose_dynamic_ideal_projections_emergency_planning_df = self.transpose_dynamic_ideal_projections_emergency_planning(dynamic_ideal_projections_emergency_planning_df)
        transpose_dynamic_fbs_projections_df = self.transpose_dynamic_fbs_projections_df(dynamic_fbs_projections_df)

        

        # Create separate lists for entry_date and age for both DataFrames
        entry_dates_investment_df = reshaped_investment_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_investment_df = reshaped_investment_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_loan_repayment_df = reshaped_loan_repayment_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_loan_repayment_df = reshaped_loan_repayment_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_liabilities_df = reshaped_dynamic_liabilities_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_liabilities_df = reshaped_dynamic_liabilities_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_outflows_liabilities_df = reshaped_liabilities_outflows_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_outflows_liabilities_df = reshaped_liabilities_outflows_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_milestone_projections_df = reshape_milestone_projections_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_milestone_projections_df = reshape_milestone_projections_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_surplus_related_withdrawal_df = reshape_surplus_related_withdrawal_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_surplus_related_withdrawal_df = reshape_surplus_related_withdrawal_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_dynamic_assets_projections_df = reshape_dynamic_assets_projections_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_dynamic_assets_projections_df = reshape_dynamic_assets_projections_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        entry_dates_additional_income_expense_criteria_df = reshape_additional_income_expense_criteria_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        ages_additional_income_expense_criteria_df = reshape_additional_income_expense_criteria_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        #entry_dates_milestone_withdrawal_projections_df = reshape_milestone_withdrawal_projections_df.columns.get_level_values(0).tolist()  # First level of MultiIndex (date)
        #ages_milestone_withdrawal_projections_df = reshape_milestone_withdrawal_projections_df.columns.get_level_values(1).tolist()  # Second level of MultiIndex (age)

        # Insert a row for entry_date and age
        entry_date_row_investment_df = pd.DataFrame([entry_dates_investment_df], columns=reshaped_investment_df.columns)
        age_row_investment_df = pd.DataFrame([ages_investment_df], columns=reshaped_investment_df.columns)

        entry_date_row_loan_repayment_df = pd.DataFrame([entry_dates_loan_repayment_df], columns = reshaped_loan_repayment_df.columns)
        age_row_loan_repayment_df = pd.DataFrame([ages_loan_repayment_df], columns=reshaped_loan_repayment_df.columns)

        entry_date_liabilities_df = pd.DataFrame([entry_dates_liabilities_df], columns = reshaped_dynamic_liabilities_df.columns)
        age_row_liabilities_df = pd.DataFrame([ages_liabilities_df], columns=reshaped_dynamic_liabilities_df.columns)

        entry_date_outflows_liabilities_df = pd.DataFrame([entry_dates_outflows_liabilities_df], columns = reshaped_liabilities_outflows_df.columns)
        age_row_outflows_liabilities_df = pd.DataFrame([ages_outflows_liabilities_df], columns=reshaped_liabilities_outflows_df.columns)

        entry_date_milestone_projections_df = pd.DataFrame([entry_dates_milestone_projections_df], columns = reshape_milestone_projections_df.columns)
        age_row_milestone_projections_df = pd.DataFrame([ages_milestone_projections_df], columns=reshape_milestone_projections_df.columns)

        entry_dates_surplus_related_withdrawal_df = pd.DataFrame([entry_dates_surplus_related_withdrawal_df], columns = reshape_surplus_related_withdrawal_df.columns)
        ages_surplus_related_withdrawal_df = pd.DataFrame([ages_surplus_related_withdrawal_df], columns = reshape_surplus_related_withdrawal_df.columns)

        entry_dates_dynamic_assets_projections_df = pd.DataFrame([entry_dates_dynamic_assets_projections_df], columns = reshape_dynamic_assets_projections_df.columns)
        ages_dynamic_assets_projections_df = pd.DataFrame([ages_dynamic_assets_projections_df], columns = reshape_dynamic_assets_projections_df.columns)

        entry_dates_additional_income_expense_criteria_df = pd.DataFrame([entry_dates_additional_income_expense_criteria_df], columns = reshape_additional_income_expense_criteria_df.columns)
        ages_additional_income_expense_criteria_df = pd.DataFrame([ages_additional_income_expense_criteria_df], columns = reshape_additional_income_expense_criteria_df.columns)

        #entry_dates_milestone_withdrawal_projections_df = pd.DataFrame([entry_dates_milestone_withdrawal_projections_df], columns = reshape_milestone_withdrawal_projections_df.columns)
        #ages_milestone_withdrawal_projections_df = pd.DataFrame([ages_milestone_withdrawal_projections_df], columns = reshape_milestone_withdrawal_projections_df.columns)

        # Concat these rows at the top of the DataFrame
        reshaped_investment_df = pd.concat([entry_date_row_investment_df, age_row_investment_df, reshaped_investment_df], ignore_index=True)
        reshaped_loan_repayment_df = pd.concat([entry_date_row_loan_repayment_df, age_row_loan_repayment_df, reshaped_loan_repayment_df], ignore_index=True)
        reshaped_liabilities_df = pd.concat([entry_date_liabilities_df, age_row_liabilities_df, reshaped_dynamic_liabilities_df], ignore_index=True) 
        reshaped_outflows_liabilities_df = pd.concat([entry_date_outflows_liabilities_df, age_row_outflows_liabilities_df, reshaped_liabilities_outflows_df], ignore_index=True)  
        reshape_milestone_projections_df = pd.concat([entry_date_milestone_projections_df, age_row_milestone_projections_df, reshape_milestone_projections_df], ignore_index=True) 
        reshape_surplus_related_withdrawal_df = pd.concat([entry_dates_surplus_related_withdrawal_df, ages_surplus_related_withdrawal_df, reshape_surplus_related_withdrawal_df], ignore_index=True) 
        reshape_dynamic_assets_projections_df = pd.concat([entry_dates_dynamic_assets_projections_df, ages_dynamic_assets_projections_df, reshape_dynamic_assets_projections_df], ignore_index=True) 
        reshape_additional_income_expense_criteria_df = pd.concat([entry_dates_additional_income_expense_criteria_df, ages_additional_income_expense_criteria_df, reshape_additional_income_expense_criteria_df], ignore_index=True)  
        #reshape_milestone_withdrawal_projections_df = pd.concat([entry_dates_milestone_withdrawal_projections_df, ages_milestone_withdrawal_projections_df, reshape_milestone_withdrawal_projections_df], ignore_index=True)   

        # Rename columns to generic names to avoid MultiIndex issues in Excel export
        reshaped_investment_df.columns = range(len(reshaped_investment_df.columns))
        reshaped_loan_repayment_df.columns = range(len(reshaped_loan_repayment_df.columns))
        reshaped_liabilities_df.columns = range(len(reshaped_liabilities_df.columns))
        reshaped_outflows_liabilities_df.columns = range(len(reshaped_outflows_liabilities_df.columns))
        reshape_milestone_projections_df.columns = range(len(reshape_milestone_projections_df.columns))
        reshape_surplus_related_withdrawal_df.columns = range(len(reshape_surplus_related_withdrawal_df.columns))
        reshape_dynamic_assets_projections_df.columns = range(len(reshape_dynamic_assets_projections_df.columns))
        reshape_additional_income_expense_criteria_df.columns = range(len(reshape_additional_income_expense_criteria_df.columns))
        #reshape_milestone_withdrawal_projections_df.columns = range(len(reshape_milestone_withdrawal_projections_df.columns))

        # Create an Excel file in memory
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            worksheet = writer.book.add_worksheet('Projections')

            #comma_format = writer.book.add_format({'num_format': 'â‚¹ #,##0', 'align': 'left'})  # Format with â‚¹ symbol
            #worksheet.set_column('A:ZZ', None, comma_format)  # Apply comma formatting to all columns

            # Define bold format for table titles
            bold_format = writer.book.add_format({'bold': True, 'font_size': 12})

            # Write the header and table for Income Expense Projections
            worksheet.write(0, 0, 'Milestone Income Projections', bold_format)  # Header for Income Expense
            transpose_dynamic_income_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=1)

            # Calculate starting row for the additional income expense projection
            start_row_additional_income_expense_criteria = len(transpose_dynamic_income_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_additional_income_expense_criteria - 1, 0, 'Additional Expense Category Projections', bold_format)  # Header for Loan Repayment Projections
            reshape_additional_income_expense_criteria_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_additional_income_expense_criteria)

            # Calculate starting row for investment projection table
            start_row_milestone_projections = start_row_additional_income_expense_criteria + len(reshape_additional_income_expense_criteria_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_milestone_projections - 1, 0, 'Milestone Calculation Projections',bold_format)
            reshape_milestone_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_milestone_projections)

            # Calculate starting row for the Loan Repayment table
            start_row_dynamic_assets_projections = start_row_milestone_projections + len(reshape_milestone_projections_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_dynamic_assets_projections - 1, 0, 'Milestone Asset Projections', bold_format)  # Header for Loan Repayment Projections
            reshape_dynamic_assets_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow= start_row_dynamic_assets_projections)

            # Calculate starting row for the liabilities projection table
            start_row_investment = start_row_dynamic_assets_projections + len(reshape_dynamic_assets_projections_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_investment - 1, 0, 'Investment Projections', bold_format)  # Header for Loan Repayment Projections
            reshaped_investment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_investment)

            # Calculate starting row for the liabilities outflows projection table
            start_row_surplus_related_withdrawal = start_row_investment + len(reshaped_investment_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_surplus_related_withdrawal - 1, 0, 'Surplus Related Withdrawal Projections', bold_format)  # Header for Loan Repayment Projections
            reshape_surplus_related_withdrawal_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_surplus_related_withdrawal)

            # Calculate starting row for the Milestone calculation table
            start_row_loan_repayment = start_row_surplus_related_withdrawal + len(reshape_surplus_related_withdrawal_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_loan_repayment - 1, 0, 'Loan Repayment Projections', bold_format)  # Header for Loan Repayment Projections
            reshaped_loan_repayment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_loan_repayment)

            # Calculate starting row for the liabilities projection table
            start_row_liabilities = start_row_loan_repayment + len(reshaped_loan_repayment_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_liabilities - 1, 0, 'Liabilities Projections', bold_format)  # Header for Loan Repayment Projections
            reshaped_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_liabilities)

            # Calculate starting row for the liabilities outflows projection table
            start_row_liabilities_outflows = start_row_liabilities + len(reshaped_liabilities_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_liabilities_outflows - 1, 0, 'Liabilities Outflows Projections', bold_format)  # Header for Loan Repayment Projections
            reshaped_outflows_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_liabilities_outflows)


             # Calculate starting row for the milestone related withdrawal table
            #start_row_milestone_withdrawal_projections = start_row_additional_income_expense_criteria + len(reshape_additional_income_expense_criteria_df) + 4  # Leave 4 rows empty
            #worksheet.write(start_row_milestone_withdrawal_projections - 1, 0, 'Milestones Related Withdrawal Projections')  # Header for Loan Repayment Projections
            #reshape_milestone_withdrawal_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_milestone_withdrawal_projections)

            #Calculate starting row for the surplus related withdrawal table
            #start_row_yearly_cf_projections_df_v1 = start_row_additional_income_expense_criteria + len(reshape_additional_income_expense_criteria_df) + 4  # Leave 4 rows empty
            #worksheet.write(start_row_yearly_cf_projections_df_v1 - 1, 0, 'Total Cashflow Projections')  # Header for Loan Repayment Projections
            #transpose_dynamic_yearly_cf_projections_df_v1.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_yearly_cf_projections_df_v1)

            #Calculate starting row for the total Cashflow projection table
            start_row_yearly_cf_projections_df = start_row_liabilities_outflows + len(reshaped_outflows_liabilities_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_yearly_cf_projections_df - 1, 0, 'Total Cashflow Projections', bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_yearly_cf_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_yearly_cf_projections_df)

            #Calculate starting row for the actual projection with milestone table
            start_row_actual_projections_df = start_row_yearly_cf_projections_df + len(transpose_dynamic_yearly_cf_projections_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_actual_projections_df - 1, 0, 'Actual Projections with milestone', bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_actual_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_actual_projections_df)

            #Calculate starting row for the ideal projection table
            start_row_ideal_projection_calculation_df = start_row_actual_projections_df + len(transpose_dynamic_actual_projections_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_ideal_projection_calculation_df - 1, 0, 'Ideal Projection percentage', bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_ideal_projection_calculation.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_ideal_projection_calculation_df)
            
            #Calculate starting row for the ideal max projection table
            start_row_ideal_max_milestone_metric_df = start_row_ideal_projection_calculation_df + len(transpose_dynamic_ideal_projection_calculation) + 4  # Leave 4 rows empty
            worksheet.write(start_row_ideal_max_milestone_metric_df - 1, 0, 'Ideal Max Projection percentage', bold_format)  # Header for Loan Repayment Projections
            transpose_ideal_max_milestone_metric_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_ideal_max_milestone_metric_df)

            #Calculate starting row for the ideal min projection table
            start_row_ideal_min_milestone_metric_df = start_row_ideal_max_milestone_metric_df + len(transpose_ideal_max_milestone_metric_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_ideal_min_milestone_metric_df - 1, 0, 'Ideal Min Projection percentage', bold_format)  # Header for Loan Repayment Projections
            transpose_ideal_min_milestone_metric_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_ideal_min_milestone_metric_df)

            #Calculate starting row for the ideal min projection table
            start_row_dynamic_ideal_projections_emergency_planning_df = start_row_ideal_min_milestone_metric_df + len(transpose_ideal_min_milestone_metric_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_dynamic_ideal_projections_emergency_planning_df - 1, 0, 'Ideal Emergency Planning Projection',bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_ideal_projections_emergency_planning_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_dynamic_ideal_projections_emergency_planning_df)

            #Calculate starting row for the ideal min projection table
            start_row_fbs_projections_df = start_row_dynamic_ideal_projections_emergency_planning_df + len(transpose_dynamic_ideal_projections_emergency_planning_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_fbs_projections_df - 1, 0, 'FBS Projection', bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_fbs_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_fbs_projections_df)
            


        # Set the Excel file to the start of the buffers
        output.seek(0)

        # Return the file to download
        return output
    
    def reshape_filter_investment_projections(self, investment_projections_df, dynamic_yearly_cf_projections_df, user_id):
        #investment_projections_df = self.transpose_and_sort_dates(investment_projections_df)
        # Filter data for the specified user
        user_df = investment_projections_df[investment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')

        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_investment']],
            on='entry_date',
            how='left'
        )

        #st.write(merged_df)

        # Convert entry_date to string format to avoid frontend issues
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = merged_df.pivot_table(index='asset_name', 
                                          columns=['entry_date', 'age'],
                                          values='asset_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        
        #st.write('reshaped_df',reshaped_df)
        
        # Add total_investment as a row at the end
        total_investment_row = merged_df.groupby('entry_date')['total_investment'].first()
        #st.write('total_investment_row',total_investment_row)
        reshaped_df.loc['total_investment'] = total_investment_row.values
        #st.write(reshaped_df)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df
    

    def reshape_filter_dynamic_liabilities_outflows_projections(self, dynamic_liabilities_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_outflows_projections_df[dynamic_liabilities_outflows_projections_df['user_code'] == user_id]

        if user_df.empty:
            st.warning("No outflows liabilities projection data found for the selected user.")
            return pd.DataFrame()

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')
        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_liabilities_outflows']],
            on='entry_date',
            how='left'
        )

        #st.write(merged_df)

        # Convert entry_date to string format to avoid frontend issues
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Add total_investment as a row at the end
        total_emi_row = merged_df.groupby('entry_date')['total_liabilities_outflows'].first()
        #st.write('total_investment_row',total_investment_row)
        reshaped_df.loc['total_liabilities_outflows'] = total_emi_row.values
        #st.write(reshaped_df)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        #st.write(reshaped_df)

        return reshaped_df
    
    def reshape_filter_dynamic_insurance_outflows_projections(self, dynamic_insurance_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_insurance_outflows_projections_df[dynamic_insurance_outflows_projections_df['user_code'] == user_id]

        if user_df.empty:
            st.warning("No outflows liabilities projection data found for the selected user.")
            return pd.DataFrame()

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')
        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_insurance_outflows']],
            on='entry_date',
            how='left'
        )

        #st.write(merged_df)

        # Convert entry_date to string format to avoid frontend issues
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='insurance_name', 
                                          columns=['entry_date', 'age'],
                                          values='insurance_value', 
                                          aggfunc='sum', 
                                          fill_value=0)

        # Add total_investment as a row at the end
        total_emi_row = merged_df.groupby('entry_date')['total_insurance_outflows'].first()
        #st.write('total_investment_row',total_investment_row)
        reshaped_df.loc['total_insurance_outflows'] = total_emi_row.values
        #st.write(reshaped_df)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()
        #st.write(reshaped_df)

        return reshaped_df

    
    # Reshape the investment projections for the required format
    def reshape_filter_loan_repayment_projections(self, dynamic_loan_repayment_projections_df, dynamic_yearly_cf_projections_df, user_id):
        # Filter data for the specified user
        user_df = dynamic_loan_repayment_projections_df[dynamic_loan_repayment_projections_df['user_code'] == user_id]

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')

        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_repayment']],
            on='entry_date',
            how='left'
        )

        # Convert entry_date to string format to avoid frontend issues
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        
        # Add total_investment as a row at the end
        total_repayment_row = merged_df.groupby('entry_date')['total_repayment'].first()
        #st.write('total_investment_row',total_investment_row)
        reshaped_df.loc['total_repayment'] = total_repayment_row.values
        #st.write(reshaped_df)

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df    
    
    def reshape_filter_dynamic_liabilities_projections(self, dynamic_liabilities_projections_df,dynamic_yearly_cf_projections_df,  user_id):
        # Filter data for the specified user
        user_df = dynamic_liabilities_projections_df[dynamic_liabilities_projections_df['user_code'] == user_id]
        if user_df.empty:
            st.warning("No liabilities projection data found for the selected user.")
            return pd.DataFrame()

        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')

        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_liabilities']],
            on='entry_date',
            how='left'
        )

        # Convert entry_date to string format to avoid frontend issues
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)
        user_df['entry_date'] = user_df['entry_date'].astype(str)

        # Pivot the DataFrame to get asset names as row index, while entry_date becomes the columns
        reshaped_df = user_df.pivot_table(index='liabilities_name', 
                                          columns=['entry_date', 'age'],
                                          values='liabilities_value', 
                                          aggfunc='sum', 
                                          fill_value=0)
        
        # âœ… Only add total_liabilities row if the pivoted table is not empty
        if not reshaped_df.empty:
            total_liabilities_row = merged_df.groupby('entry_date')['total_liabilities'].first()
            reshaped_df.loc['total_liabilities'] = total_liabilities_row.values

        # Reset the index to bring asset_name as a column for better readability
        reshaped_df = reshaped_df.reset_index()

        return reshaped_df 
    
    def reshape_filter_dynamic_assets_projections(self, dynamic_assets_projections_df, dynamic_yearly_cf_projections_df, user_id):
        user_df = dynamic_assets_projections_df[dynamic_assets_projections_df['user_code'] == user_id]
        user_df['entry_date'] = pd.to_datetime(user_df['entry_date'])
        user_df = user_df.sort_values(by='entry_date')
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])
        dynamic_yearly_cf_projections_df = dynamic_yearly_cf_projections_df.sort_values(by='entry_date')
        # Merge with total_investment from dynamic_yearly_cf_projections_df
        merged_df = user_df.merge(
            dynamic_yearly_cf_projections_df[['entry_date', 'total_assets']],
            on='entry_date',
            how='left'
        )
        merged_df['entry_date'] = merged_df['entry_date'].astype(str)
        reshaped_df = user_df.pivot_table(index='assets_name',
                                          columns=['entry_date', 'age'],
                                          values='assets_value',
                                          aggfunc='sum',
                                          fill_value=0)
        # Add total_investment as a row at the end
        total_assets_row = merged_df.groupby('entry_date')['total_assets'].first()
        #st.write('total_investment_row',total_investment_row)
        reshaped_df.loc['total_assets'] = total_assets_row.values
        #st.write(reshaped_df)

        reshaped_df = reshaped_df.reset_index()


        return reshaped_df 
    
    # Method to transpose the dynamic_fbs_projections_df data
    def transpose_filter_dynamic_fbs_projections_df(self, dynamic_fbs_projections_df):
        # Filter only the 'fbs' column
        if 'fbs' in dynamic_fbs_projections_df.columns:
            filtered_df = dynamic_fbs_projections_df[['entry_date', 'fbs']]
        else:
            raise KeyError("The 'fbs' column does not exist in the input table.")

        # Convert entry_date to datetime for sorting
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')

        # Transpose to make 'fbs' horizontal
        transposed_df = filtered_df.set_index('entry_date').T

        # Add 'fbs' as the row name
        transposed_df.index = ['FBS']

        # Convert numeric values to integers (remove â‚¹ symbol formatting)
        transposed_df = transposed_df.astype(int)

        #st.write('transposed_df') 

        return transposed_df
    
    # Method to extract specific columns and transpose
    def transpose_networth_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df):

        # Filter only the 'fbs' column
        if 'total_networth' in dynamic_yearly_cf_projections_df.columns:
            filtered_df = dynamic_yearly_cf_projections_df[['entry_date', 'total_networth']]
        else:
            raise KeyError("The 'total_networth' column does not exist in the input table.")

        # Convert entry_date to datetime for sorting
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')

        # Transpose the required columns
        transposed_df = filtered_df.set_index('entry_date').T

        # Rename the index to the corresponding metrics for clarity
        transposed_df.index = ['Total Networth']

        # Convert numeric values to integers (or remove any formatting like â‚¹ symbols)
        transposed_df = transposed_df.astype(int)

        return transposed_df
    

    # Method to extract specific columns and transpose
    def transpose_total_surplus_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df):
        if 'total_surplus' in dynamic_yearly_cf_projections_df.columns:
            filtered_df = dynamic_yearly_cf_projections_df[['entry_date', 'total_surplus']]
        else:
            raise KeyError("The 'total_surplus' column does not exist in the input table.")

        # Convert entry_date to datetime for sorting
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')

        # Transpose the required columns
        transposed_df = filtered_df.set_index('entry_date').T

        # Rename the index to the corresponding metrics for clarity
        transposed_df.index = ['Monthly Surplus']

        # Safely fill NaN with 0 and then convert to integer
        transposed_df = transposed_df.fillna(0).astype(int)

        return transposed_df   
    
    # Method to extract specific columns and transpose
    def transpose_beg_total_surplus_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df):
        if 'beg_total_surplus' in dynamic_yearly_cf_projections_df.columns:
            filtered_df = dynamic_yearly_cf_projections_df[['entry_date', 'beg_total_surplus']]
        else:
            raise KeyError("The 'beg_total_surplus' column does not exist in the input table.")

        # Convert entry_date to datetime for sorting
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')

        # Transpose the required columns
        transposed_df = filtered_df.set_index('entry_date').T

        # Rename the index to the corresponding metrics for clarity
        transposed_df.index = ['Beg Total Surplus']

        # Convert numeric values to integers (or remove any formatting like â‚¹ symbols)
        transposed_df = transposed_df.fillna(0).astype(int)

        return transposed_df

    # Method to extract specific columns and transpose
    def transpose_end_total_surplus_dynamic_yearly_cf_projections(self, dynamic_yearly_cf_projections_df):

        # Filter only the 'fbs' column
        if 'end_total_surplus' in dynamic_yearly_cf_projections_df.columns:
            filtered_df = dynamic_yearly_cf_projections_df[['entry_date', 'end_total_surplus']]
        else:
            raise KeyError("The 'end_total_surplus' column does not exist in the input table.")

        # Convert entry_date to datetime for sorting
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')

        # Transpose the required columns
        transposed_df = filtered_df.set_index('entry_date').T

        # Rename the index to the corresponding metrics for clarity
        transposed_df.index = ['End Total Surplus']

        # Convert numeric values to integers (or remove any formatting like â‚¹ symbols)
        transposed_df = transposed_df.fillna(0).astype(int)

        return transposed_df 
    
    # Method to extract specific columns, transpose, and rename
    def transpose_income_selected_columns(self, dynamic_milestone_income_projection):
        # Check if required columns exist in the input DataFrame
        required_columns = ['entry_date', 'age', 'gross_income', 'taxes', 'net_income_post_tax', 'total_expense' ]
        for col in required_columns:
            if col not in dynamic_milestone_income_projection.columns:
                raise KeyError(f"The column '{col}' does not exist in the input table.")

        # Filter only the required columns
        filtered_df = dynamic_milestone_income_projection[required_columns]

        # Convert entry_date to datetime for sorting
        #filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'])
        filtered_df = filtered_df.sort_values(by='entry_date')
        #filtered_df = filtered_df['entry_date'].astype(str)
        filtered_df['entry_date'] = pd.to_datetime(filtered_df['entry_date'], format='%d-%m-%Y').dt.strftime('%b-%y')


        # Transpose the required columns
        transposed_df = filtered_df.set_index('entry_date').T

        # Convert numeric values to integers (or remove any formatting like â‚¹ symbols)
        transposed_df = transposed_df.fillna(0).astype(int)
        
        # Rename the index to the corresponding metrics for clarity
        transposed_df.index = ['Age', 'Gross Income', '- Tax Expense', 'Net Income' , 'Total Expense']

        return transposed_df
    

    def filter_download_projections(self, dynamic_income_projection_df, investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df,
                             dynamic_liabilities_outflows_projections_df, dynamic_insurance_outflows_projections_df, milestone_calculation_projections_df,surplus_withdrawal_projections_df,
                             dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                             #milestone_withdrawal_projections_df, 
                             #dynamic_yearly_cf_projections_v1,
                             dynamic_yearly_cf_projections_df, dynamic_fbs_projections_df, user_id):
        from io import BytesIO 

        # Reshape the data for both investment and loan repayment projections
        reshaped_investment_df = self.reshape_filter_investment_projections(investment_projections_df, dynamic_yearly_cf_projections_df, user_id)
       # Flatten MultiIndex columns for reshaped_investment_df
        reshaped_investment_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_investment_df.columns]

        reshaped_loan_repayment_df = self.reshape_loan_repayment_projections(loan_repayment_projections_df, user_id)
        # Flatten MultiIndex columns for reshaped_investment_df
        reshaped_loan_repayment_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_loan_repayment_df.columns]
        #reshaped_liabilities_df = self.reshape_filter_dynamic_liabilities_projections(dynamic_liabilities_projections_df, dynamic_yearly_cf_projections_df, user_id)

        #reshaped_liabilities_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_liabilities_df.columns] 

        #reshaped_outflows_liabilities_df = self.reshape_filter_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id)

        #reshaped_outflows_liabilities_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_outflows_liabilities_df.columns] 

        reshaped_outflows_insurance_df = self.reshape_filter_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id)

        reshaped_outflows_insurance_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_outflows_insurance_df.columns]

        reshape_milestone_projections_df = self.reshape_milestone_projections(milestone_calculation_projections_df, user_id)

        reshape_milestone_projections_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_milestone_projections_df.columns]

        reshape_surplus_related_withdrawal_df = self.reshape_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)

        reshape_surplus_related_withdrawal_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_surplus_related_withdrawal_df.columns]

        reshape_dynamic_assets_projections_df = self.reshape_filter_dynamic_assets_projections(dynamic_assets_projections_df, dynamic_yearly_cf_projections_df, user_id)

        reshape_dynamic_assets_projections_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_dynamic_assets_projections_df.columns]

        #transpose_dynamic_income_df = self.transpose_dynamic_milestone_income_projection(dynamic_milestone_income_projection)

        reshape_additional_income_expense_criteria_df = self.reshape_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)

        reshape_additional_income_expense_criteria_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_additional_income_expense_criteria_df.columns]

        #transpose_dynamic_yearly_cf_projections_df = self.transpose_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)
        transpose_dynamic_income_df = self.transpose_income_selected_columns(dynamic_milestone_income_projection)

        transposed_networth_monthly_cf = self.transpose_networth_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)
        #st.write(transposed_networth_monthly_cf)

        transposed_total_surplus_monthly_cf = self.transpose_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transposed_beg_total_surplus_monthly_cf = self.transpose_beg_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transposed_end_total_surplus_monthly_cf = self.transpose_end_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transpose_dynamic_fbs_projections_df = self.transpose_filter_dynamic_fbs_projections_df(dynamic_fbs_projections_df)

        # Create an Excel file in memory
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            worksheet = writer.book.add_worksheet('Projections')
            comma_format = writer.book.add_format({'num_format': 'â‚¹        #,##0', 'align': 'left'})  # Format with â‚¹ symbol
            
            worksheet.set_column('B:ZZ', None, comma_format)  # Apply comma formatting to all columns
            # Define bold format for table titles
            bold_format = writer.book.add_format({'bold': True})

            # Define custom format for black background and white text
            black_background_white_text = writer.book.add_format({'bg_color': 'black', 'font_color': 'white', 'align': 'center', 'valign': 'vcenter', 'bold': True})

            # Write the header and table for Income Expense Projections
            worksheet.write(0, 0, 'Milestone Income Projections',bold_format)  # Header for Income Expense
            transpose_dynamic_income_df.to_excel(writer, sheet_name='Projections', index=True, header=True, startrow=1)

            # Calculate starting row for the additional income expense projection
            # start_row_additional_income_expense_criteria = len(transpose_dynamic_income_df) + 4  # Leave 4 rows empty
            # worksheet.write(start_row_additional_income_expense_criteria - 1, 0, 'Additional Expense Category Projections',bold_format)  # Header for Loan Repayment Projections
            # reshape_additional_income_expense_criteria_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_additional_income_expense_criteria)

            # Calculate starting row for the liabilities projection table
            start_row_investment = len(transpose_dynamic_income_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_investment - 1, 0, 'Monthly Investments', bold_format)  # Header for Loan Repayment Projections
            reshaped_investment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_investment)

            # # Calculate starting row for the liabilities outflows projection table
            # start_row_liabilities_outflows = start_row_investment + len(reshaped_investment_df) + 2  # Leave 4 rows empty
            # worksheet.write(start_row_liabilities_outflows - 1, 0, 'EMIs', bold_format)  # Header for Loan Repayment Projections
            # reshaped_outflows_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_liabilities_outflows)

            # Calculate starting row for the liabilities outflows projection table
            start_row_insurance_outflows = start_row_investment + len(reshaped_investment_df) + 2  # Leave 4 rows empty
            worksheet.write(start_row_insurance_outflows - 1, 0, 'Insurance Payments', bold_format)  # Header for Loan Repayment Projections
            reshaped_outflows_insurance_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_insurance_outflows)

            start_row_total_surplus_cf_metrics = start_row_insurance_outflows + len(reshaped_outflows_insurance_df) + 1  # Adjust starting row
            #worksheet.write(start_row_networth_cf_metrics - 1, 0, 'Yearly CF Metrics (Networth, Surplus)', bold_format)
            transposed_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow = start_row_total_surplus_cf_metrics)

            start_row_beg_total_surplus_cf_metrics = start_row_total_surplus_cf_metrics + len(transposed_total_surplus_monthly_cf)  # Adjust starting row
            #worksheet.write(start_row_networth_cf_metrics - 1, 0, 'Yearly CF Metrics (Networth, Surplus)', bold_format)
            transposed_beg_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow = start_row_beg_total_surplus_cf_metrics)

            # Calculate starting row for the Milestone calculation table
            start_row_loan_repayment = start_row_beg_total_surplus_cf_metrics + len(transposed_beg_total_surplus_monthly_cf) + 2  # Leave 4 rows empty
            worksheet.write(start_row_loan_repayment - 1, 0, 'Loan Repayment Projections', bold_format)  # Header for Loan Repayment Projections
            reshaped_loan_repayment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_loan_repayment)

            # Calculate starting row for the liabilities outflows projection table
            start_row_surplus_related_withdrawal = start_row_loan_repayment + len(reshaped_loan_repayment_df) + 2  # Leave 4 rows empty
            worksheet.write(start_row_surplus_related_withdrawal - 1, 0, 'Milestone Withdrawals', bold_format)  # Header for Loan Repayment Projections
            reshape_surplus_related_withdrawal_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_surplus_related_withdrawal)

            # Calculate starting row for investment projection table
            start_row_milestone_projections = start_row_surplus_related_withdrawal + len(reshape_surplus_related_withdrawal_df) + 2  # Leave 4 rows empty
            worksheet.write(start_row_milestone_projections - 1, 0, 'Milestones', bold_format)
            reshape_milestone_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_milestone_projections)

            start_row_end_total_surplus_cf_metrics = start_row_milestone_projections + len(reshape_milestone_projections_df) + 1  # Adjust starting row
            #worksheet.write(start_row_networth_cf_metrics - 1, 0, 'Yearly CF Metrics (Networth, Surplus)', bold_format)
            transposed_end_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow = start_row_end_total_surplus_cf_metrics)

            # Calculate starting row for the liabilities projection table
            # start_row_liabilities = start_row_end_total_surplus_cf_metrics + len(transposed_end_total_surplus_monthly_cf) + 2  # Leave 4 rows empty
            # worksheet.write(start_row_liabilities - 1, 0, 'Liability Projection (Ending Outstanding Loan Amounts)',bold_format)  # Header for Loan Repayment Projections
            # reshaped_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_liabilities)

            # Calculate starting row for the Loan Repayment table
            start_row_dynamic_assets_projections = start_row_end_total_surplus_cf_metrics + len(transposed_end_total_surplus_monthly_cf) + 2  # Leave 4 rows empty
            worksheet.write(start_row_dynamic_assets_projections - 1, 0, 'Asset Projection', bold_format)  # Header for Loan Repayment Projections
            reshape_dynamic_assets_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow= start_row_dynamic_assets_projections)

            start_row_networth_cf_metrics = start_row_dynamic_assets_projections + len(reshape_dynamic_assets_projections_df) + 1  # Adjust starting row
            #worksheet.write(start_row_networth_cf_metrics - 1, 0, 'Yearly CF Metrics (Networth, Surplus)', bold_format)
            transposed_networth_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow = start_row_networth_cf_metrics)

            #Calculate starting row for the ideal min projection table
            start_row_fbs_projections_df = start_row_networth_cf_metrics + len(transposed_networth_monthly_cf) + 2  # Leave 4 rows empty
            worksheet.write(start_row_fbs_projections_df - 1, 0, 'FBS PROJECTIONS - With Milestones', bold_format)  # Header for Loan Repayment Projections
            transpose_dynamic_fbs_projections_df.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow = start_row_fbs_projections_df)

            # Apply black background and white font color formatting to row 2 (B:ZZ)
            worksheet.conditional_format('A2:ZZ2', {'type': 'no_blanks', 'format': black_background_white_text})

        # Set the Excel file to the start of the buffers
        output.seek(0)

        # Apply the bold formatting to the total_investment row
        formatted_output = self.apply_bold_to_total_investment(output)

        # Return the file to download
        return formatted_output
    

    def filter_download_projections_with_liabilities(self, dynamic_income_projection_df, investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df,
                             dynamic_liabilities_outflows_projections_df, dynamic_insurance_outflows_projections_df, milestone_calculation_projections_df,surplus_withdrawal_projections_df,
                             dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                             #milestone_withdrawal_projections_df, 
                             #dynamic_yearly_cf_projections_v1,
                             dynamic_yearly_cf_projections_df, dynamic_fbs_projections_df, user_id):
        from io import BytesIO 

        # Reshape the data for both investment and loan repayment projections
        reshaped_investment_df = self.reshape_filter_investment_projections(investment_projections_df, dynamic_yearly_cf_projections_df, user_id)
       # Flatten MultiIndex columns for reshaped_investment_df
        reshaped_investment_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_investment_df.columns]

        reshaped_loan_repayment_df = self.reshape_loan_repayment_projections(loan_repayment_projections_df, user_id)
        # Flatten MultiIndex columns for reshaped_investment_df
        reshaped_loan_repayment_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_loan_repayment_df.columns]
        reshaped_liabilities_df = self.reshape_filter_dynamic_liabilities_projections(dynamic_liabilities_projections_df, dynamic_yearly_cf_projections_df, user_id)

        if not reshaped_liabilities_df.empty:
            reshaped_liabilities_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_liabilities_df.columns]

        reshaped_outflows_liabilities_df = self.reshape_filter_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id)

        if not reshaped_outflows_liabilities_df.empty:
            reshaped_outflows_liabilities_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_outflows_liabilities_df.columns] 

        reshaped_outflows_insurance_df = self.reshape_filter_dynamic_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, dynamic_yearly_cf_projections_df, user_id)

        reshaped_outflows_insurance_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshaped_outflows_insurance_df.columns]

        reshape_milestone_projections_df = self.reshape_milestone_projections(milestone_calculation_projections_df, user_id)

        reshape_milestone_projections_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_milestone_projections_df.columns]

        reshape_surplus_related_withdrawal_df = self.reshape_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)

        reshape_surplus_related_withdrawal_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_surplus_related_withdrawal_df.columns]

        reshape_dynamic_assets_projections_df = self.reshape_filter_dynamic_assets_projections(dynamic_assets_projections_df, dynamic_yearly_cf_projections_df, user_id)

        reshape_dynamic_assets_projections_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_dynamic_assets_projections_df.columns]

        #transpose_dynamic_income_df = self.transpose_dynamic_milestone_income_projection(dynamic_milestone_income_projection)

        reshape_additional_income_expense_criteria_df = self.reshape_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)

        if not reshape_additional_income_expense_criteria_df.empty:
            reshape_additional_income_expense_criteria_df.columns = [f"{col[0]} | Age: {col[1]}" if isinstance(col, tuple) else col for col in reshape_additional_income_expense_criteria_df.columns]

        #transpose_dynamic_yearly_cf_projections_df = self.transpose_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)
        transpose_dynamic_income_df = self.transpose_income_selected_columns(dynamic_milestone_income_projection)

        transposed_networth_monthly_cf = self.transpose_networth_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)
        #st.write(transposed_networth_monthly_cf)

        transposed_total_surplus_monthly_cf = self.transpose_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transposed_beg_total_surplus_monthly_cf = self.transpose_beg_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transposed_end_total_surplus_monthly_cf = self.transpose_end_total_surplus_dynamic_yearly_cf_projections(dynamic_yearly_cf_projections_df)

        transpose_dynamic_fbs_projections_df = self.transpose_filter_dynamic_fbs_projections_df(dynamic_fbs_projections_df)

        # Create an Excel file in memory
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            worksheet = writer.book.add_worksheet('Projections')
            comma_format = writer.book.add_format({'num_format': 'â‚¹        #,##0', 'align': 'left'})  # Format with â‚¹ symbol
            
            worksheet.set_column('B:ZZ', None, comma_format)  # Apply comma formatting to all columns
            # Define bold format for table titles
            bold_format = writer.book.add_format({'bold': True})

            # Define custom format for black background and white text
            black_background_white_text = writer.book.add_format({'bg_color': 'black', 'font_color': 'white', 'align': 'center', 'valign': 'vcenter', 'bold': True})

            # Write the header and table for Income Expense Projections
            worksheet.write(0, 0, 'Milestone Income Projections',bold_format)  # Header for Income Expense
            transpose_dynamic_income_df.to_excel(writer, sheet_name='Projections', index=True, header=True, startrow=1)

            # Calculate starting row for the additional income expense projection
            # start_row_additional_income_expense_criteria = len(transpose_dynamic_income_df) + 4  # Leave 4 rows empty
            # worksheet.write(start_row_additional_income_expense_criteria - 1, 0, 'Additional Expense Category Projections',bold_format)  # Header for Loan Repayment Projections
            # reshape_additional_income_expense_criteria_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow = start_row_additional_income_expense_criteria)

            # Calculate starting row for the liabilities projection table
            start_row_investment = len(transpose_dynamic_income_df) + 4  # Leave 4 rows empty
            worksheet.write(start_row_investment - 1, 0, 'Monthly Investments', bold_format)  # Header for Loan Repayment Projections
            reshaped_investment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_investment)

            # Track last used row dynamically
            last_used_row = start_row_investment + len(reshaped_investment_df)

            # --- EMI Table (conditionally written) ---
            if not reshaped_outflows_liabilities_df.empty:
                start_row_liabilities_outflows = last_used_row + 2
                worksheet.write(start_row_liabilities_outflows - 1, 0, 'EMIs', bold_format)
                reshaped_outflows_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_liabilities_outflows)
                last_used_row = start_row_liabilities_outflows + len(reshaped_outflows_liabilities_df)

            # --- Insurance Payments Table ---
            if not reshaped_outflows_insurance_df.empty:
                start_row_insurance_outflows = last_used_row + 2
                worksheet.write(start_row_insurance_outflows - 1, 0, 'Insurance Payments', bold_format)
                reshaped_outflows_insurance_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_insurance_outflows)
                last_used_row = start_row_insurance_outflows + len(reshaped_outflows_insurance_df)


            # --- Total Surplus Monthly CF Table ---
            start_row_total_surplus_cf_metrics = last_used_row + 1
            transposed_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow=start_row_total_surplus_cf_metrics)
            last_used_row = start_row_total_surplus_cf_metrics + len(transposed_total_surplus_monthly_cf)

            # --- Begin Total Surplus CF ---
            start_row_beg_total_surplus_cf_metrics = last_used_row
            transposed_beg_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow=start_row_beg_total_surplus_cf_metrics)
            last_used_row = start_row_beg_total_surplus_cf_metrics + len(transposed_beg_total_surplus_monthly_cf)


            # --- Loan Repayment Table ---
            start_row_loan_repayment = last_used_row + 2
            worksheet.write(start_row_loan_repayment - 1, 0, 'Loan Repayment Projections', bold_format)
            reshaped_loan_repayment_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_loan_repayment)
            last_used_row = start_row_loan_repayment + len(reshaped_loan_repayment_df)

            # --- Milestone Withdrawals ---
            start_row_surplus_related_withdrawal = last_used_row + 2
            worksheet.write(start_row_surplus_related_withdrawal - 1, 0, 'Milestone Withdrawals', bold_format)
            reshape_surplus_related_withdrawal_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_surplus_related_withdrawal)
            last_used_row = start_row_surplus_related_withdrawal + len(reshape_surplus_related_withdrawal_df)

            # --- Milestones ---
            start_row_milestone_projections = last_used_row + 2
            worksheet.write(start_row_milestone_projections - 1, 0, 'Milestones', bold_format)
            reshape_milestone_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_milestone_projections)
            last_used_row = start_row_milestone_projections + len(reshape_milestone_projections_df)


            # --- End Total Surplus Monthly CF ---
            start_row_end_total_surplus_cf_metrics = last_used_row + 1
            transposed_end_total_surplus_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow=start_row_end_total_surplus_cf_metrics)
            last_used_row = start_row_end_total_surplus_cf_metrics + len(transposed_end_total_surplus_monthly_cf)

            # --- Liability Projection Table (conditionally written) ---
            if not reshaped_liabilities_df.empty:
                start_row_liabilities = last_used_row + 2
                worksheet.write(start_row_liabilities - 1, 0, 'Liability Projection (Ending Outstanding Loan Amounts)', bold_format)
                reshaped_liabilities_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_liabilities)
                last_used_row = start_row_liabilities + len(reshaped_liabilities_df)

            # --- Asset Projections ---
            start_row_dynamic_assets_projections = last_used_row + 2
            worksheet.write(start_row_dynamic_assets_projections - 1, 0, 'Asset Projection', bold_format)
            reshape_dynamic_assets_projections_df.to_excel(writer, sheet_name='Projections', index=False, header=False, startrow=start_row_dynamic_assets_projections)
            last_used_row = start_row_dynamic_assets_projections + len(reshape_dynamic_assets_projections_df)


            # --- Networth Monthly CF ---
            start_row_networth_cf_metrics = last_used_row + 1
            transposed_networth_monthly_cf.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow=start_row_networth_cf_metrics)
            last_used_row = start_row_networth_cf_metrics + len(transposed_networth_monthly_cf)

            # --- FBS Projections ---
            start_row_fbs_projections_df = last_used_row + 2
            worksheet.write(start_row_fbs_projections_df - 1, 0, 'FBS PROJECTIONS - With Milestones', bold_format)
            transpose_dynamic_fbs_projections_df.to_excel(writer, sheet_name='Projections', index=True, header=False, startrow=start_row_fbs_projections_df)

            # Apply black background and white font color formatting to row 2 (B:ZZ)
            worksheet.conditional_format('A2:ZZ2', {'type': 'no_blanks', 'format': black_background_white_text})

        # Set the Excel file to the start of the buffers
        output.seek(0)
        # Post-process with openpyxl to insert additional expense categories
        from openpyxl import load_workbook
        from openpyxl.utils import get_column_letter
        from openpyxl.styles import Alignment


        output.seek(0)
        workbook = load_workbook(output)
        worksheet = workbook['Projections']

        if not reshape_additional_income_expense_criteria_df.empty:
            # Locate the "Total Expense" row in column A
            total_expense_row = None
            for row in worksheet.iter_rows(min_row=1, max_row=worksheet.max_row, min_col=1, max_col=1):
                if row[0].value == "Total Expense":
                    total_expense_row = row[0].row
                    break

            # Insert and write the additional rows
            if total_expense_row:
                num_rows_to_insert = len(reshape_additional_income_expense_criteria_df)
                worksheet.insert_rows(idx=total_expense_row, amount=num_rows_to_insert)

                for i, (_, row) in enumerate(reshape_additional_income_expense_criteria_df.iterrows()):
                    for j, val in enumerate(row):
                        col_letter = get_column_letter(j + 1)
                        cell = worksheet[f"{col_letter}{total_expense_row + i}"] 
                        cell.value = val

                        # Apply â‚¹ formatting and left alignment only to numeric cells
                        if isinstance(val, (int, float)):
                            cell.number_format = 'â‚¹#,##0'
                            cell.alignment = Alignment(horizontal="left")



        # Save the updated Excel file to a new buffer
        final_output = BytesIO()
        workbook.save(final_output)
        final_output.seek(0)



        # Apply the bold formatting to the total_investment row
        formatted_output = self.apply_bold_to_total_investment(final_output)

        # Return the file to download
        return formatted_output


    def apply_bold_to_total_investment(self, output, worksheet_name='Projections'):
        """
        Apply bold formatting to the row containing 'total_investment' in column A of the Excel sheet.
        """
        from openpyxl import load_workbook
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils import get_column_letter

        # Load the Excel workbook from the in-memory buffer
        output.seek(0)
        workbook = load_workbook(output)
        worksheet = workbook[worksheet_name]

        # --- Set Column Widths (Step 7) ---
        worksheet.column_dimensions['A'].width = 55  # Column A -> width 55
        # For columns B..ZZ -> width 15
        for col_index in range(2, 703):  # B=2..ZZ=702
            col_letter = get_column_letter(col_index)
            worksheet.column_dimensions[col_letter].width = 22

        # --- STEP 1. REMOVE 'Milestone Income Projections' FROM A1 ---
        worksheet["A1"].value = None  # or "" to clear it out

        # # 2) A2: Write 'Month', white font on black background
        worksheet["A2"].value = "Month"
        worksheet["A2"].font = Font(bold=True)
        worksheet["A2"].font = Font(color="FFFFFF")  # White text
        worksheet["A2"].fill = PatternFill(
            fill_type="solid", start_color="000000", end_color="000000"
        )  # Black fill

        for cell in worksheet[2]:  # This iterates over all cells in the 2nd row
            cell.alignment = Alignment(horizontal='left')
        
        # --- STEP 3. INSERT AN ADDITIONAL ROW AFTER ROW 3 (INSERT AT ROW 4) ---
        worksheet.insert_rows(idx=4, amount=1) 

        worksheet["A4"].value = "Income"
        worksheet["A4"].font = Font(bold=True)   
        worksheet["A5"].font = Font(bold=False)
        worksheet["A6"].font = Font(bold=False)

        worksheet.insert_rows(idx=8, amount=1)
        
        

        # Define the keywords to look for and their replacements
        keyword_replacements = {
            'Net Income' : 'Net Income',
            'Total Expense' : 'Total Expense',
            'total_investment': 'Total Investment',
            'total_liabilities_outflows':'Total EMIs',
            'total_insurance_outflows':'Total Premium Payments',
            'Monthly Surplus':'Monthly Surplus',
            'Beg Total Surplus':'Beg Total Surplus',
            'End Total Surplus':'End Total Surplus',
            'total_liabilities': 'Total Liabilities',
            'total_assets': 'total_assets',
            'Total Networth': 'Total Networth',
            'FBS':'FBS'
        }

        # Iterate through rows in column A
        for row in worksheet.iter_rows(min_row=1, max_col=1):  # Check only column A
            cell_value = row[0].value
            if cell_value in keyword_replacements:
                # Rename the cell value
                row[0].value = keyword_replacements[cell_value]

                # Apply bold formatting to the entire row
                for cell in worksheet[row[0].row]:
                    cell.font = Font(bold=True,italic=True)

        # For negative values, Excel will use â€œâ‚¹ -#,##0â€ instead of â€œ-â‚¹ #,##0â€
        custom_neg_format = 'â‚¹ #,##0;â‚¹        -#,##0'  # Puts minus sign after 'â‚¹'
        for cells in worksheet.iter_rows(
            min_row=1, max_row=worksheet.max_row,
            min_col=2, max_col=702
        ):
            for cell in cells:
                if isinstance(cell.value, (int, float)) and cell.value < 0:
                    cell.number_format = custom_neg_format            

        for row in worksheet.iter_rows(min_row=3, max_row=3, min_col=2, max_col=702):
            for cell in row:
                # Simply set a plain number format without 'â‚¹'
                cell.number_format = '#,##0'    
                cell.alignment = Alignment(horizontal='left')

        for row in worksheet.iter_rows(min_row=1, max_col=1):  # Only check column A
            if row[0].value == 'FBS':
                row_num = row[0].row  # The row where "fbs" is found
                # Adjust columns B:ZZ -> columns 2 to 702
                for cells in worksheet.iter_rows(min_row=row_num, max_row=row_num, min_col=2, max_col=702):
                    for cell in cells:
                        # Set a plain number format (no currency symbol)
                        cell.number_format = '#,##0'   
                        cell.alignment = Alignment(horizontal='center')

        # --- PART 4: Replace numeric zero ("â‚¹0") with blank in ALL rows, columns B:ZZ ---
        for cells in worksheet.iter_rows(
            min_row=1, max_row=worksheet.max_row,  # or some other max_row limit
            min_col=2, max_col=702):
            for cell in cells:
                # Check if the cell's value is a numeric 0
                if isinstance(cell.value, (int, float)) and cell.value == 0:
                    # Make the cell blank
                    cell.value = None      

        # # --- PART 5: Remove all gridlines from entire workbook ---
        for ws in workbook.worksheets:
            ws.sheet_view.showGridLines = False   

        # Remove all borders from column A
        for row in worksheet.iter_rows(
            min_row=1, max_row=worksheet.max_row, min_col=1, max_col=1
        ):
            for cell in row:
                cell.border = Border(
                    left=Side(style=None),
                    right=Side(style=None),
                    top=Side(style=None),
                    bottom=Side(style=None),
                )

        worksheet.freeze_panes = "B4"         

        # LEFT-ALIGN the entire A column
        # We'll iterate all rows in column A and set alignment to left
        for row in worksheet.iter_rows(
            min_row=1, 
            max_row=worksheet.max_row,
            min_col=1, 
            max_col=1
        ):
            for cell in row:
                cell.alignment = Alignment(horizontal='left')
                           
                

        # Save the workbook back to the in-memory buffer
        from io import BytesIO
        formatted_output = BytesIO()
        workbook.save(formatted_output)
        formatted_output.seek(0)

        return formatted_output    


    def run_download_milestones_excel(self, user_id):
        # Load the data for the user
        dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
        investment_projections_df = self.load_investment_projections_from_db(user_id)
        loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)
        dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()
        dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()
        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        #milestone_withdrawal_projections_df = self.load_milestone_withdrawal_projections_from_db()
        #dynamic_yearly_cf_projections_v1 = self.load_dynamic_yearly_cf_projections_df_v1_from_db()
        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()
        dynamic_actual_projections_df = self.load_dynamic_actual_projections_df_from_db(self.db_config)
        dynamic_ideal_projection_calculation = self.load_dynamic_ideal_projection_calculation_from_db(self.db_config)
        ideal_max_milestone_metric = self.load_ideal_max_milestone_metric_from_db(self.db_config)
        ideal_min_milestone_metric = self.load_ideal_min_milestone_metric_from_db(self.db_config)
        dynamic_ideal_projections_emergency_planning_df = self.load_dynamic_ideal_projections_emergency_planning_table_df_from_db(self.db_config)
        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(self.db_config)

        # Fetch user name from database
        user_name = self.fetch_user_name(user_id)

        # Get current date in DDMMYYYY format
        current_date_str = datetime.today().strftime('%d%m%Y')

        # Construct the file name
        file_name = f"All Projection of Goal Planning of {user_name} v{current_date_str}.xlsx"


        # Prepare the Excel file for download
        excel_file = self.download_projections(dynamic_income_projection_df,investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df, 
                                               dynamic_liabilities_outflows_projections_df, milestone_calculation_projections_df, surplus_withdrawal_projections_df, 
                                               dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                                               #milestone_withdrawal_projections_df, 
                                               #dynamic_yearly_cf_projections_v1,
                                               dynamic_yearly_cf_projections_df, dynamic_actual_projections_df, dynamic_ideal_projection_calculation, 
                                               ideal_max_milestone_metric, ideal_min_milestone_metric, dynamic_ideal_projections_emergency_planning_df, 
                                               dynamic_fbs_projections_df, user_id)

        # Provide download link
        st.download_button(label="Download Milestone Projections",
                           data=excel_file,
                           file_name = file_name ,
                           mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')   

    def filter_run_download_milestones_excel(self, user_id):
        # Load the data for the user
        dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
        investment_projections_df = self.load_investment_projections_from_db(user_id)
        loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)
        dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()
        dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()
        dynamic_insurance_outflows_projections_df = self.load_dynamic_insurance_outflows_projections_df_from_db()
        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()
        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(self.db_config)


        # Fetch user name from database
        user_name = self.fetch_user_name(user_id)

        # Get current date in DDMMYYYY format
        current_date_str = datetime.today().strftime('%d%m%Y')

        # Construct the file name
        file_name = f"Goal Planning For {user_name} v{current_date_str}.xlsx"


        # Prepare the Excel file for download
        excel_file = self.filter_download_projections(dynamic_income_projection_df,investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df, 
                                               dynamic_liabilities_outflows_projections_df, dynamic_insurance_outflows_projections_df, milestone_calculation_projections_df, 
                                               surplus_withdrawal_projections_df, dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                                               #milestone_withdrawal_projections_df, 
                                               #dynamic_yearly_cf_projections_v1,
                                               dynamic_yearly_cf_projections_df, dynamic_fbs_projections_df, user_id)

        # Provide download link
        st.download_button(label="Download Milestone Projections excel",
                           data = excel_file,
                           file_name = file_name,
                           mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
        
    def filter_run_download_milestones_with_liabilities_excel(self, user_id):
        # Load the data for the user
        dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
        investment_projections_df = self.load_investment_projections_from_db(user_id)
        loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)
        dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()
        dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()
        dynamic_insurance_outflows_projections_df = self.load_dynamic_insurance_outflows_projections_df_from_db()
        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()
        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(self.db_config)

        # Fetch user name from database
        user_name = self.fetch_user_name(user_id)

        # Get current date in DDMMYYYY format
        current_date_str = datetime.today().strftime('%d%m%Y')

        # Construct the file name
        file_name = f"Goal Planning For {user_name} v{current_date_str}.xlsx"


        # Prepare the Excel file for download
        excel_file = self.filter_download_projections_with_liabilities(dynamic_income_projection_df,investment_projections_df, loan_repayment_projections_df, dynamic_liabilities_projections_df, 
                                               dynamic_liabilities_outflows_projections_df, dynamic_insurance_outflows_projections_df, milestone_calculation_projections_df, 
                                               surplus_withdrawal_projections_df, dynamic_assets_projections_df, dynamic_milestone_income_projection, additional_income_expense_criteria_df, 
                                               #milestone_withdrawal_projections_df, 
                                               #dynamic_yearly_cf_projections_v1,
                                               dynamic_yearly_cf_projections_df, dynamic_fbs_projections_df, user_id)

        # Provide download link
        st.download_button(label="Download Milestone Projections excel",
                           data = excel_file,
                           file_name = file_name,
                           mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')    



    def load_milestones_liabilities_from_db(self, user_code):
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)

        query = """
            SELECT purpose, milestone_year, outstanding_amount, amount, pdf_outstanding
            FROM milestones_liabilities
            WHERE user_code = %s;
        """

        try:
            return pd.read_sql(query, engine, params=(str(user_code),))
        except Exception as e:
            print(f"Error fetching 'milestones_liabilities' data: {e}")
            return pd.DataFrame()
        
    def format_amount(self,amount):
        """Format the amount in crore or lakh dynamically."""
        if amount >= 1e7:  # If amount is greater than or equal to 1 crore
            return f"{amount / 1e7:.1f} cr"
        elif amount >= 1e5:  # If amount is greater than or equal to 1 lakh
            return f"{amount / 1e5:.1f} lakh"
        else:  # If amount is less than 1 lakh
            return f"{amount:.1f}"
        
    def format_box_amount(self,amount):
        """Format the amount in crore or lakh dynamically."""
        if amount >= 1e7:  # If amount is greater than or equal to 1 crore
            return f"{amount / 1e7:.1f} cr"
        elif amount >= 1e5:  # If amount is greater than or equal to 1 lakh
            return f"{amount / 1e5:.1f} lakh"
        else:  # If amount is less than 1 lakh
            return f"{amount:.1f}"     

    def plot_total_networth_with_milestones(self, networth_df, milestones_df, up_to_date):
        networth_df['entry_date'] = pd.to_datetime(networth_df['entry_date'])
        milestones_df['milestone_year'] = pd.to_datetime(milestones_df['milestone_year'])
        up_to_date = pd.to_datetime(up_to_date)
        networth_df = networth_df[networth_df['entry_date'] <= up_to_date]
        merged_df = pd.merge(networth_df, milestones_df, left_on='entry_date', right_on='milestone_year', how='left')

        # Prepare custom data for hover
        networth_df['custom_data'] = networth_df['total_networth'].apply(lambda x: f"â‚¹{self.format_box_amount(x)}")

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=networth_df['entry_date'],
            y=networth_df['total_networth'],
            mode='lines',
            name='Total Networth',
            customdata=networth_df['custom_data'],
            hovertemplate='%{customdata}'  # Use custom data for hover
        ))

        annotation_offsets = []  # To store the offsets for dynamic adjustment
        #offset_step = 90  # Define the vertical offset step to avoid overlap

        # horizontal arrow offset (how far LEFT the label sits from the point)
        ax_offset_input = st.number_input(
            "Horizontal offset for milestone labels (ax): "
            "(negative = box to the left, positive = box to the right)",
            value=-50.0,  # default matches your old ax_offset = -50
            step=5.0,
            format="%.2f",
            key="networth_ax_offset"
        )

        # vertical base offset (ay). We'll stagger from this.
        ay_offset_input = st.number_input(
            "Vertical base offset for milestone labels (ay): "
            "(positive = box above point, negative = box below)",
            value=50.0,   # default matches your old starting 50
            step=5.0,
            format="%.2f",
            key="networth_ay_offset"
        )

        # how much to step each next milestone so they don't overlap
        offset_step = st.number_input(
            "Vertical separation between milestone labels",
            value=90.0,   # default was 90 in your code
            step=5.0,
            format="%.2f",
            key="networth_offset_step"
        )

        for i, row in enumerate(merged_df.dropna(subset=['purpose']).iterrows()):
            row = row[1]
            fig.add_trace(go.Scatter(
                x=[row['entry_date']],
                y=[row['total_networth']],
                mode='markers',
                marker=dict(size=10, color='red'), 
                #name=''
                showlegend=False
            ))

            # Dynamically adjust ax and ay for each milestone
            ax_offset = ax_offset_input
            ay_offset = ay_offset_input - (i * offset_step)  # Adjust ay to separate the boxes vertically
            annotation_offsets.append((ax_offset, ay_offset))
            formatted_networth = self.format_box_amount(row['total_networth'])

            fig.add_annotation(
                x=row['entry_date'],
                y=row['total_networth'],
                text=f"<b>{row['purpose']}</b>  <br>â‚¹{formatted_networth}",
                showarrow=True,
                arrowhead=4,
                arrowcolor="yellow",
                ax=ax_offset,
                ay=ay_offset,
                bgcolor="orange",
                bordercolor="black",
                font=dict(size=15)
            )

        fig.add_trace(go.Scatter(
            x=[None], y=[None],
            mode='markers',
            marker=dict(size=10, color='red'),
            name='Milestone'
        ))    

        # Format the Y-axis tick values
        # Format the Y-axis tick values dynamically
        max_value = networth_df['total_networth'].max()
        step = max_value / 6
        y_ticks = [step * i for i in range(7)]
        y_tick_labels = [self.format_amount(val) for val in y_ticks]   

        fig.update_layout(
            title="Total Networth Over Time with Milestones",
            xaxis_title="Year",
            yaxis_title="Total Networth (â‚¹)",
            #yaxis_tickprefix="â‚¹",
            #yaxis_tickformat=",.0f",
            yaxis=dict(
                tickvals=y_ticks,
                ticktext=y_tick_labels
            ),
            height=900,
            width=900,
            showlegend=True
        )
        return fig

    def plot_fbs_score(self, fbs_df, up_to_date):
        fbs_df['entry_date'] = pd.to_datetime(fbs_df['entry_date'])
        #st.write('up_to_date',up_to_date)
        #Filter the data up to the specified entry date
        #up_to_date = pd.to_datetime('2043-03-31')
        up_to_date = pd.to_datetime(up_to_date)
        
        fbs_df = fbs_df[fbs_df['entry_date'] <= up_to_date]

        # Set up the first entry date month for annual projection
        start_month = fbs_df['entry_date'].iloc[0].month

        # Annual gross income: filter for the first entry month each year, then multiply by 12
        annual_projections_1 = fbs_df[fbs_df['entry_date'].dt.month == start_month].copy() 
        
        annual_projections_1 = annual_projections_1.sort_values(by='entry_date') 
        # Annual active income
        annual_projections_1['annual_fbs'] = annual_projections_1['fbs'] 
        
        # Plot area graphs
        fig = go.Figure()

        # Add active income as an area plot
        fig.add_trace(go.Scatter(
            x=annual_projections_1['entry_date'], 
            y=annual_projections_1['annual_fbs'], 
            mode='lines',
            name='FBS'
        ))

        fig.update_layout(
            title="Financial Behaviour Score (FBS) Over Time",
            xaxis_title="Year",
            yaxis_title="Financial Behaviour Score (FBS)",
            yaxis_range=[1, 100],
            height=700,
            width=1000,
            showlegend=True
        )


        # ===================== X-AXIS LOGIC (updated) =====================
        # 1) Determine actual plotted data range
        if not annual_projections_1.empty:
            min_x = annual_projections_1['entry_date'].min()
            max_x = annual_projections_1['entry_date'].max()
        else:
            # fallback if somehow empty
            min_x = fbs_df['entry_date'].min()
            max_x = fbs_df['entry_date'].max()

        # 2) We want ticks every 2 years â†’ every 24 months
        dtick_val = "M24"

        # 3) Anchor first tick exactly at first plotted timestamp
        #    This prevents Plotly from drawing a tick (e.g. 2025)
        #    way to the left of your first actual point (e.g. 2026),
        #    which created the â€œempty gap on the leftâ€.
        tick0_date = min_x

        # 4) Also start the visible x-range at that same timestamp,
        #    so the first tick label sits right under the first point.
        x_start_display = min_x
        x_end_display = max_x

        fig.update_xaxes(
            tickmode='linear',
            dtick=dtick_val,          # every 24 months -> 2-year gaps: 2025, 2027, 2029, ...
            tick0=tick0_date,         # first tick = first real data timestamp
            tickformat="%Y",          # show only the year
            tickangle=0,              # horizontal labels
            ticklabelposition="outside bottom",
            showgrid=False,
            zeroline=False,
            range=[x_start_display, x_end_display]  # no useless padding on the left
        )


        return fig
    
    def plot_active_passive_income_area(self, first_table_dynamic_income_projection_df, dynamic_milestone_income_projection_df, up_to_date):
        # Convert entry_date to datetime and filter to the selected date
        dynamic_milestone_income_projection_df['entry_date'] = pd.to_datetime(dynamic_milestone_income_projection_df['entry_date'])
        up_to_date = pd.to_datetime(up_to_date)

        dynamic_milestone_income_projection_df = (
            dynamic_milestone_income_projection_df[dynamic_milestone_income_projection_df['entry_date'] <= up_to_date]
            .sort_values('entry_date')
        )

        if dynamic_milestone_income_projection_df.empty:
            st.warning("No data available up to the selected date.")
            return go.Figure()

        # ======================================================
        #   BUILD ANNUAL ACTIVE/PASSIVE (your existing logic)
        # ======================================================

        # One row per year (your existing approach)
        start_month = dynamic_milestone_income_projection_df['entry_date'].iloc[0].month
        annual_projections = dynamic_milestone_income_projection_df[
            dynamic_milestone_income_projection_df['entry_date'].dt.month == start_month
        ].copy()

        start_month_1 = dynamic_milestone_income_projection_df['entry_date'].iloc[0].month
        annual_projections_1 = dynamic_milestone_income_projection_df[
            dynamic_milestone_income_projection_df['entry_date'].dt.month == start_month_1
        ].copy()

        annual_projections = annual_projections.sort_values(by='entry_date')
        annual_projections_1 = annual_projections_1.sort_values(by='entry_date')

        additional_amount = st.number_input("Enter the additional amount to add to annual active income:", value=0)
        stop_date = st.date_input("Enter the stop date up to which the additional amount is applied:", value=datetime.now())
        stop_date = pd.to_datetime(stop_date)

        # Annual active income (+ add-on)
        annual_projections_1['annual_active_income'] = annual_projections_1['active_income'] * 12
        annual_projections_1.loc[
            annual_projections_1['entry_date'] <= stop_date, 'annual_active_income'
        ] += additional_amount

        # Annual passive income
        annual_projections['annual_passive_income'] = annual_projections['total_passive_income'] * 12

        # ======================================================
        #   BONUS INCOME USING ROLLING 12-MONTH SUM
        #   (NOT x12 like active/passive)
        # ======================================================

        # --- cutoff date JUST for bonus plotting (same idea you used for lifestyle extra expenses) ---
        stop_extra_date = st.date_input(
            "Select the final date after which additional lifestyle expense categories should stop increasing:",
            value=up_to_date, key='active passive stop date'
        )
        stop_extra_date = pd.to_datetime(stop_extra_date)

        bonus_df = dynamic_milestone_income_projection_df[['entry_date', 'bonus_income']].copy()
        bonus_df = bonus_df.sort_values('entry_date')

        # rolling 12-month sum of bonus_income
        bonus_df['annual_bonus_income'] = bonus_df['bonus_income'].rolling(window=12, min_periods=1).sum()

        # after stop_extra_date, do not let it keep going up / extend visually:
        # we stop plotting it by setting values after that date to NA
        bonus_df['annual_bonus_income_plot'] = bonus_df['annual_bonus_income'].where(
            bonus_df['entry_date'] <= stop_extra_date,
            other=pd.NA
        )

        # ======================================================
        #   PLOT
        # ======================================================
        fig = go.Figure()

        # --- Annual Active Income trace ---
        fig.add_trace(go.Scatter(
            x=annual_projections_1['entry_date'],
            y=annual_projections_1['annual_active_income'],
            mode='lines',
            fill='tozeroy',
            name='Annual Active Income',
            line=dict(width=0.5, color='blue')
        ))

        # Add first active income annotation
        if not annual_projections_1.empty:
            first_entry_date_annual_income = annual_projections_1['entry_date'].iloc[0]
            first_annual_income = annual_projections_1['annual_active_income'].iloc[0]
            formatted_first_total_income = self.format_amount(abs(first_annual_income))
            fig.add_annotation(
                x=first_entry_date_annual_income,
                y=first_annual_income,
                text=f"First: â‚¹{formatted_first_total_income}",
                showarrow=True,
                arrowhead=2
            )

        # --- Annual Passive Income trace ---
        fig.add_trace(go.Scatter(
            x=annual_projections['entry_date'],
            y=annual_projections['annual_passive_income'],
            mode='lines',
            fill='tozeroy',
            name='Annual Passive Income',
            line=dict(width=0.5, color='green')
        ))

        # Add first passive income annotation
        first_nonzero_passive_income = annual_projections[annual_projections['annual_passive_income'] > 0]
        if not first_nonzero_passive_income.empty:
            first_entry_date_passive_income = first_nonzero_passive_income['entry_date'].iloc[0]
            first_annual_passive_income = first_nonzero_passive_income['annual_passive_income'].iloc[0]
            formatted_first_total_passive_income = self.format_amount(abs(first_annual_passive_income))
            fig.add_annotation(
                x=first_entry_date_passive_income,
                y=first_annual_passive_income,
                text=f"First: â‚¹{formatted_first_total_passive_income}",
                showarrow=True,
                arrowhead=2
            )

        # --- Annual Bonus Income trace (rolling 12 mo sum, capped by stop_extra_date) ---
        fig.add_trace(go.Scatter(
            x=bonus_df['entry_date'],
            y=bonus_df['annual_bonus_income_plot'],
            mode='lines',
            fill='tozeroy',
            name='Annual Bonus Income',
            line=dict(width=0.5, color='orange')
        ))

        # ======================================================
        #   Y-AXIS TICKS (now must consider bonus too)
        # ======================================================
        max_active = annual_projections_1['annual_active_income'].max() if not annual_projections_1.empty else 0
        max_passive = annual_projections['annual_passive_income'].max() if not annual_projections.empty else 0
        max_bonus = bonus_df['annual_bonus_income_plot'].max() if not bonus_df.empty else 0

        max_value = max(max_active, max_passive, max_bonus)
        step = max_value / 6 if max_value else 1
        y_ticks = [step * i for i in range(7)]
        y_tick_labels = [self.format_amount(val) for val in y_ticks]

        # ======================================================
        #   LAYOUT (unchanged except yaxis ticks come from above)
        # ======================================================
        formatted_description = f"""
                <b>Active and Passive Income Over Time</b><br><br>
                <b>Active Income:</b> Earnings received from direct work, such as salaries, wages, and freelancing.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>
                <b>Passive Income:</b> Earnings generated with minimal effort, such as rental income, dividends, or investments.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br><br>
            """

        fig.update_layout(
            title=dict(
                text=formatted_description,
                x=0.5, y=0.98, xanchor='center', yanchor='top',
                font=dict(size=14)
            ),
            margin=dict(t=150),
            xaxis_title="Year",
            yaxis_title="Annual Income (â‚¹)",
            yaxis=dict(tickvals=y_ticks, ticktext=y_tick_labels),
            height=600,
            width=800,
            showlegend=True
        )

        # ======================================================
        #   X-AXIS (same logic you already had)
        #   start at later of current year or first data point,
        #   ticks every 2 years
        # ======================================================
        cur_year = datetime.now().year
        current_year_start = pd.Timestamp(cur_year, 1, 1)

        data_min_candidates, data_max_candidates = [], []
        if not annual_projections_1.empty:
            data_min_candidates.append(annual_projections_1['entry_date'].min())
            data_max_candidates.append(annual_projections_1['entry_date'].max())
        if not annual_projections.empty:
            data_min_candidates.append(annual_projections['entry_date'].min())
            data_max_candidates.append(annual_projections['entry_date'].max())
        if not bonus_df.empty:
            data_min_candidates.append(bonus_df['entry_date'].min())
            data_max_candidates.append(bonus_df['entry_date'].max())

        # If somehow no data at all, fall back to current year
        data_min = min(data_min_candidates) if data_min_candidates else current_year_start
        data_max = max(data_max_candidates) if data_max_candidates else current_year_start

        # Start where data actually begins, but never earlier than the current year
        x_start = max(current_year_start, data_min)

        # Anchor ticks on Jan-1 of the first shown year
        x_start_anchor = pd.Timestamp(x_start.year, 1, 1)

        # End range
        x_end = data_max

        fig.update_xaxes(
            range=[x_start, x_end],
            tick0=x_start_anchor,
            dtick="M24",          # every 24 months = 2 years
            tickformat="%Y"
        )

        return fig

    
    def plot_total_expense_area(self, dynamic_milestone_income_projection_df, up_to_date, user_code):
        import plotly.graph_objects as go
        import pandas as pd
        import streamlit as st
        import re

        # --- Filter Data ---
        dynamic_milestone_income_projection_df['entry_date'] = pd.to_datetime(dynamic_milestone_income_projection_df['entry_date'])
        up_to_date = pd.to_datetime(up_to_date)
        dynamic_milestone_income_projection_df = dynamic_milestone_income_projection_df[
            dynamic_milestone_income_projection_df['entry_date'] <= up_to_date
        ].sort_values('entry_date')

        if dynamic_milestone_income_projection_df.empty:
            st.warning("No data available up to the selected date.")
            return go.Figure()

        # --- Annual Household Expense (monthly Ã— 12) ---
        anchor_month = dynamic_milestone_income_projection_df['entry_date'].iloc[0].month
        annual_household_df = dynamic_milestone_income_projection_df[
            dynamic_milestone_income_projection_df['entry_date'].dt.month == anchor_month
        ].copy()
        annual_household_df['annual_household_expense'] = (
            annual_household_df['household_lifestyle_expense_amount'] * 12
        )

        # --- Create Figure ---
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=annual_household_df['entry_date'],
            y=annual_household_df['annual_household_expense'].abs(),
            mode='lines',
            fill='tozeroy',
            name='Annual Household Expense',
            line=dict(width=0.5, color='#7f7f7f')
        ))

        # --- Stop Date ---
        stop_extra_date = st.date_input(
            "Select the final date after which additional lifestyle expense categories should stop increasing:",
            value=up_to_date
        )
        stop_extra_date = pd.to_datetime(stop_extra_date)

        # --- Fetch Distinct Categories ---
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT DISTINCT expense_category_name
            FROM additional_income_expense_criteria
            WHERE user_code = %s;
        """, (user_code,))
        raw_categories = cursor.fetchall()
        cursor.close()

        # --- Dynamic Grouping ---
        child_keywords = ['child', 'education', 'school', 'college']
        travel_keywords = ['travel', 'trip', 'vacation']

        child1_categories, child2_categories, travel_categories, other_categories = [], [], [], []

        for (cat_name,) in raw_categories:
            cat_lower = cat_name.lower()
            if any(word in cat_lower for word in child_keywords):
                if 'child 1' in cat_lower:
                    child1_categories.append(cat_name)
                elif 'child 2' in cat_lower:
                    child2_categories.append(cat_name)
                else:
                    child1_categories.append(cat_name)  # fallback
            elif any(word in cat_lower for word in travel_keywords):
                travel_categories.append(cat_name)
            else:
                other_categories.append(cat_name)

        ordered_categories = child1_categories + child2_categories + travel_categories + other_categories

        # --- Improved Color Palettes ---
        child1_colors = ['#1f77b4', '#2ca02c', '#17becf']  # blue/green/teal
        child2_colors = ['#ff7f0e', '#d62728', '#9467bd']  # orange/red/purple
        travel_colors = ['#8c564b', '#e377c2']  # brown/pink
        other_colors = ['#7f7f7f', '#bcbd22', '#aec7e8', '#c5b0d5']

        category_color_map = {}
        for i, cat in enumerate(child1_categories):
            category_color_map[cat] = child1_colors[i % len(child1_colors)]
        for i, cat in enumerate(child2_categories):
            category_color_map[cat] = child2_colors[i % len(child2_colors)]
        for i, cat in enumerate(travel_categories):
            category_color_map[cat] = travel_colors[i % len(travel_colors)]
        for i, cat in enumerate(other_categories):
            category_color_map[cat] = other_colors[i % len(other_colors)]

        # --- Plot Dynamic Categories ---
        y_series_list = [annual_household_df['annual_household_expense'].abs()]
        for cat_name in ordered_categories:
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT entry_date, amount
                FROM additional_income_expense_criteria
                WHERE user_code = %s AND expense_category_name = %s;
            """, (user_code, cat_name))
            rows = cursor.fetchall()
            cursor.close()

            df = pd.DataFrame(rows, columns=['entry_date', 'amount'])
            if df.empty:
                continue

            df['entry_date'] = pd.to_datetime(df['entry_date'])
            merged_cat_df = pd.merge(
                dynamic_milestone_income_projection_df[['entry_date']],
                df.rename(columns={'amount': cat_name}),
                on='entry_date',
                how='left'
            )
            merged_cat_df[cat_name] = merged_cat_df[cat_name].fillna(0)

            rolling_sum_cat = merged_cat_df[cat_name].rolling(window=12, min_periods=1).sum()
            rolling_sum_cat_plot = rolling_sum_cat.where(
                merged_cat_df['entry_date'] <= stop_extra_date,
                other=pd.NA
            )

            y_series_list.append(rolling_sum_cat_plot.abs())

            fig.add_trace(go.Scatter(
                x=merged_cat_df['entry_date'],
                y=rolling_sum_cat_plot.abs(),
                mode='lines',
                fill='tozeroy',
                name=cat_name,
                line=dict(width=0.6, color=category_color_map.get(cat_name, '#555'))
            ))

        # --- Dynamic Y-Axis ---
        if y_series_list:
            max_value = max([s.max() for s in y_series_list if not s.empty])
        else:
            max_value = 0
        step = max_value // 6 if max_value > 0 else 1
        y_ticks = [step * i for i in range(7)]
        y_tick_labels = [self.format_amount(val) for val in y_ticks]

        # --- Description Block ---
        description_map = {
            "Annual Household Expense": "<b>Annual Household Expense:</b> Regular living expenses like housing, groceries, utilities, and essentials.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>",
            "Annual Kids Education": "<b>Annual Kids Education:</b> Kids College and Higher Education Expense.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>",
            "Annual Travel Expense": "<b>Annual Travel Expense:</b> Yearly budget set aside for domestic or international travel.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>",
            "Annual Vacation": "<b>Annual Vacation:</b> Yearly budget set aside for domestic or international travel.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>",
            "Sons Education": "<b>Sons Education:</b> Kids College Education Expense.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>"
        }

        selected_descriptions = st.multiselect(
            "Select the categories to include in the report description:",
            options=list(description_map.keys()),
            default=["Annual Household Expense", "Annual Travel Expense", "Annual Kids Education"]
        )

        formatted_description = "<b>Household and Lifestyle Expenses Over Time</b><br><br>"
        for desc_key in selected_descriptions:
            formatted_description += description_map[desc_key]

        # --- Layout ---
        x_min = dynamic_milestone_income_projection_df['entry_date'].min()
        x_max = dynamic_milestone_income_projection_df['entry_date'].max()

        fig.update_layout(
            title=dict(
                text=formatted_description,
                x=0.5, y=0.98, xanchor='center', yanchor='top',
                font=dict(size=14)
            ),
            margin=dict(t=150),
            xaxis_title="Year",
            yaxis_title="Annual Expense (â‚¹)",
            yaxis=dict(tickvals=y_ticks, ticktext=y_tick_labels, showgrid=True),
            xaxis=dict(
                tickmode='linear',
                dtick="M24",
                tick0=x_min,
                tickformat="%Y",
                range=[x_min, x_max],
                showgrid=False,
                zeroline=False
            ),
            height=600,
            width=850,
            showlegend=True,
            legend=dict(title="Expense Categories", bgcolor="rgba(0,0,0,0)")
        )

        return fig









    
    def plot_liabilities_assets_networth(self, dynamic_yearly_cf_projections_df, up_to_date):
        # Convert entry_date column to datetime
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])

        # Filter the data up to the specified entry date
        up_to_date = pd.to_datetime(up_to_date)
        filtered_df = dynamic_yearly_cf_projections_df[dynamic_yearly_cf_projections_df['entry_date'] <= up_to_date]

        # Prepare custom data for hover
        filtered_df['custom_data'] = filtered_df['total_assets'].apply(lambda x: f"â‚¹{self.format_box_amount(x)}")
        filtered_df['custom_data_1'] = filtered_df['total_networth'].apply(lambda x: f"â‚¹{self.format_box_amount(x)}")

        # Plot Total Liabilities, Total Assets, and Total Networth
        fig = go.Figure()
        
        # Total Networth
        fig.add_trace(go.Scatter(
            x=filtered_df['entry_date'],
            y=filtered_df['total_networth'],
            mode='lines',
            name='Total Networth',
            line=dict(color='yellow'),
            #customdata_1=filtered_df['custom_data_1'],
            #hovertemplate='%{customdata_1}'  # Use custom data for hover
        ))

        # Total Assets
        fig.add_trace(go.Scatter(
            x=filtered_df['entry_date'],
            y=filtered_df['total_assets'],
            mode='lines',
            name='Total Assets',
            line=dict(color='green'),
            customdata=filtered_df['custom_data'],
            hovertemplate='%{customdata}'  # Use custom data for hover
        ))

        max_value = filtered_df['total_assets'].max()
        step = max_value / 6
        y_ticks = [step * i for i in range(7)]
        y_tick_labels = [self.format_amount(val) for val in y_ticks]

        # Update layout
        fig.update_layout(
            title="Total Liabilities, Assets, and Networth Over Time",
            xaxis_title="Year",
            yaxis_title="Value (â‚¹)",
            #yaxis=dict(tickprefix="â‚¹", tickformat=",.0f"),
            yaxis=dict(
                tickvals=y_ticks,
                ticktext=y_tick_labels
            ),
            height=700,
            width=1000,
            showlegend=True
        )

        # Display the plot in Streamlit
        return fig
    
    def fetch_end_balance_data(self, user_id):
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT entry_date, SUM(principal_remaining::double precision) AS total_good_liabilities_1
            FROM all_cf_liabilities_calculation
            WHERE user_code = %s 
            GROUP BY entry_date;
        """, (user_id,))

        good_liabilities_data_1 = cursor.fetchall()
        cursor.close()

        good_liabilities_df_1 = pd.DataFrame(good_liabilities_data_1, columns=['entry_date', 'total_good_liabilities_1'])
        # Sort the DataFrame by 'entry_date'
        good_liabilities_df_1['entry_date'] = pd.to_datetime(good_liabilities_df_1['entry_date'])
        return good_liabilities_df_1.sort_values(by='entry_date')
    
    def plot_loan_repayment_liabilities(self, dynamic_yearly_cf_projections_df, good_liabilities_df_1, up_to_date):
        # Convert entry_date column to datetime
        dynamic_yearly_cf_projections_df['entry_date'] = pd.to_datetime(dynamic_yearly_cf_projections_df['entry_date'])

        # Filter the data up to the specified entry date
        up_to_date = pd.to_datetime(up_to_date)
        filtered_df = dynamic_yearly_cf_projections_df[dynamic_yearly_cf_projections_df['entry_date'] <= up_to_date]
        st.write('total liabilities', filtered_df['total_liabilities'])
        good_liabilities_df_1 = good_liabilities_df_1[good_liabilities_df_1['entry_date'] <= up_to_date]

        # Prepare custom data for hover
        filtered_df['custom_data'] = filtered_df['total_liabilities'].apply(lambda x: f"â‚¹{self.format_box_amount(x)}")

        # Plot Total Liabilities, Total Assets, and Good Liabilities (end_balance)
        fig = go.Figure()

        # Total Liabilities
        fig.add_trace(go.Scatter(
            x=filtered_df['entry_date'],
            y=abs(filtered_df['total_liabilities']),
            mode='lines',
            #name='Total Liabilities',
            name='With Pre-payments',
            # name = 'Home Loan',
            line=dict(color='red'),
            #customdata=filtered_df['custom_data'],
            #hovertemplate='%{customdata}'  # Use custom data for hover
        ))

        # # # End Balance
        # fig.add_trace(go.Scatter(
        #     x=good_liabilities_df_1['entry_date'],
        #     y=abs(good_liabilities_df_1['total_good_liabilities_1']),
        #     mode='lines',
        #     #name='Without Pre-payment',
        #     name = 'Without Home Purchase',
        #     line=dict(color='blue')
        # ))


        max_value = filtered_df['total_liabilities'].max()
        step = max_value / 6
        y_ticks = [step * i for i in range(7)]
        y_tick_labels = [self.format_amount(val) for val in y_ticks]  

        # Update layout
        fig.update_layout(
            title="Total liabilities over time",
            xaxis_title="Year",
            yaxis_title="Value (â‚¹)",
            #yaxis=dict(tickprefix="â‚¹", tickformat=",.0f"),
            yaxis=dict(
                tickvals=y_ticks,
                ticktext=y_tick_labels
            ),
            height=700,
            width=1000,
            showlegend=True
        )

        
        # ---------------- X-AXIS LOGIC (updated) ----------------
        if not filtered_df.empty:
            # 1. Actual first/last timestamp in the plotted data
            min_x = filtered_df['entry_date'].min()
            max_x = filtered_df['entry_date'].max()

            # 2. We want ticks every 2 years (24 months)
            dtick_val = "M24"

            # 3. First tick = first actual data point.
            #    This avoids the "2025 is way off on the left, line starts at 2026" visual.
            tick0_date = min_x

            # 4. Also start the visible x-axis range at that same timestamp â†’ no empty padding.
            x_start_display = min_x
            x_end_display = max_x

            fig.update_xaxes(
                tickmode='linear',
                dtick=dtick_val,           # one tick every 24 months => 2-year gaps: 2025, 2027, 2029, ...
                tick0=tick0_date,          # first tick exactly where the first data actually starts
                tickformat="%Y",           # show only the year label
                tickangle=0,
                ticklabelposition="outside bottom",
                showgrid=False,
                zeroline=False,
                range=[x_start_display, x_end_display]  # get rid of the useless left padding
            )

        return fig
    
    def display_goal_details_table(self, milestones_liabilities_df):
        st.subheader("Goal and Details Table")
        unique_purposes = milestones_liabilities_df['purpose'].dropna().unique().tolist()

        if "goal_details_table" not in st.session_state:
            st.session_state["goal_details_table"] = pd.DataFrame({
                "Goal": unique_purposes,
                "Details": ["" for _ in range(len(unique_purposes))]
            })

        goal_details_table = st.session_state["goal_details_table"]

        # Input popup for adding extra rows
        extra_rows = 1

        for _ in range(extra_rows):
            new_goal = st.text_input("Enter the Goal for the new row:", key=f"new_goal_{_}")
            if new_goal and new_goal not in unique_purposes:
                unique_purposes.append(new_goal)
                new_row = pd.DataFrame({"Goal": [new_goal], "Details": [""]})
                if st.button('add the new goal in the table', key = 'goal detail table'):
                    goal_details_table = pd.concat([goal_details_table, new_row], ignore_index=True)

        # Input popup for removing a goal
        if not goal_details_table.empty:
            goal_to_remove = st.selectbox("Select a Goal to Remove:", goal_details_table["Goal"].unique(), key="remove_goal_select")
            if st.button("Remove Selected Goal"):
                goal_details_table = goal_details_table[goal_details_table["Goal"] != goal_to_remove]
                unique_purposes.remove(goal_to_remove)            

        selected_purpose = st.selectbox("Select a Goal (Purpose):", goal_details_table["Goal"].unique(), key = 'select goal select')

        if selected_purpose:
            detail = st.text_input(f"Enter Details for the Goal '{selected_purpose}':")

            if st.button("Add Detail", key=f"add_detail_{selected_purpose}"):
                if detail.strip():
                    existing_details = goal_details_table.loc[goal_details_table["Goal"] == selected_purpose, "Details"].values[0]
                    existing_comments = existing_details.split("\n") if existing_details else []
                    new_comment = f"- {detail}"
                    updated_details = "\n".join(existing_comments + [new_comment])
                    goal_details_table.loc[goal_details_table["Goal"] == selected_purpose, "Details"] = updated_details
                else:
                    st.warning("Please enter a valid detail.")

        if selected_purpose:
            existing_details = goal_details_table.loc[goal_details_table["Goal"] == selected_purpose, "Details"].values[0]

            if existing_details:
                comments = existing_details.split("\n")
                comment_to_remove = st.selectbox("Select a Comment to Remove:", comments, key=f"remove_comment_{selected_purpose}")

                if st.button("Remove Comment", key=f"remove_comment_btn_{selected_purpose}"):
                    updated_comments = [c for c in comments if c != comment_to_remove]
                    updated_details = "\n".join(updated_comments)
                    goal_details_table.loc[goal_details_table["Goal"] == selected_purpose, "Details"] = updated_details

        st.session_state["goal_details_table"] = goal_details_table
        st.dataframe(goal_details_table)

    def prepare_goal_table(self, milestones_liabilities_df):
        milestones_liabilities_df['Target Year'] = pd.to_datetime(milestones_liabilities_df['milestone_year']).dt.strftime('%b %Y')
        milestones_liabilities_df['Current Value'] = milestones_liabilities_df['amount'].apply(self.format_box_amount)
        milestones_liabilities_df['Future Value'] = milestones_liabilities_df['pdf_outstanding'].apply(self.format_box_amount)

        if 'Achieved' not in milestones_liabilities_df:
            milestones_liabilities_df['Achieved'] = 'Not Set'

        for idx, row in milestones_liabilities_df.iterrows():
            achieved_status = st.selectbox(
                f"Is the Goal '{row['purpose']}' Achievable?",
                ["Not Set", "Yes", "No"],
                key=f"achieved_status_{idx}",
                index=["Not Set", "Yes", "No"].index(row['Achieved'])
            )
            milestones_liabilities_df.at[idx, 'Achieved'] = achieved_status

        goal_table = milestones_liabilities_df[['purpose', 'Target Year', 'Current Value', 'Future Value', 'Achieved']].copy()
        goal_table.rename(columns={'purpose': 'Goal Name'}, inplace=True)

        if "user_added_goals" not in st.session_state:
            st.session_state["user_added_goals"] = pd.DataFrame(columns=goal_table.columns)

        user_added_goals = st.session_state["user_added_goals"]

        st.write("### Existing Goals")
        st.dataframe(goal_table)

        new_goal_name = st.text_input("Enter the Goal Name:")
        new_start_date = st.date_input("Select Start Target Year:",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))
        add_range = st.checkbox("Add End Date for Goal Duration?", value=False)
        
        new_end_date = None
        if add_range:
            new_end_date = st.date_input("Select End Target Year (Optional):",value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31))

        new_current_value = st.text_input("Enter Current Value (in â‚¹):")
        new_future_value = st.text_input("Enter Future Value (in â‚¹):")
        new_achieved = st.selectbox("Is it Achievable?", ["Yes", "No"], key="achievable_input")

        if st.button("Add Goal", key="add_goal_prompt"):
            if add_range and new_end_date:
                target_year_str = f"{new_start_date.strftime('%b %Y')} â€“ {new_end_date.strftime('%b %Y')}"
                target_sort = new_start_date
            else:
                target_year_str = new_start_date.strftime('%b %Y')
                target_sort = new_start_date

            new_row = {
                "Goal Name": new_goal_name,
                "Target Year": target_year_str,
                "Current Value": new_current_value,
                "Future Value": new_future_value,
                "Achieved": new_achieved,
                "Target Sort": target_sort
            }

            user_added_goals = pd.concat([user_added_goals, pd.DataFrame([new_row])], ignore_index=True)
            st.session_state["user_added_goals"] = user_added_goals
            st.success(f"Goal '{new_goal_name}' added successfully!")

        # Combine and sort
        combined_goals = pd.concat([goal_table, user_added_goals], ignore_index=True)
        combined_goals['Target Sort'] = pd.to_datetime(combined_goals['Target Year'].str.split('â€“').str[0].str.strip(), format='%b %Y', errors='coerce')
        combined_goals = combined_goals.sort_values(by='Target Sort').drop(columns=['Target Sort'])

        st.write("### Final Goal Planning Table")
        st.dataframe(combined_goals)

        # Goal Removal Logic
        st.write("### Remove a Goal")
        if not combined_goals.empty:
            goal_to_remove = st.selectbox("Select a Goal to Remove:", combined_goals["Goal Name"].unique(), key="remove_goal_dropdown")
            if st.button("Remove Selected Goal", key='front value of goal'):
                if goal_to_remove in user_added_goals["Goal Name"].values:
                    user_added_goals = user_added_goals[user_added_goals["Goal Name"] != goal_to_remove]
                    st.session_state["user_added_goals"] = user_added_goals
                    st.success(f"Goal '{goal_to_remove}' removed successfully!")
                else:
                    st.warning(f"Goal '{goal_to_remove}' cannot be removed as it is from the original database!")

                combined_goals = pd.concat([goal_table, user_added_goals], ignore_index=True)
                combined_goals['Target Sort'] = pd.to_datetime(combined_goals['Target Year'].str.split('â€“').str[0].str.strip(), format='%b %Y', errors='coerce')
                combined_goals = combined_goals.sort_values(by='Target Sort').drop(columns=['Target Sort'])

                st.write("Updated Goal Planning Table:")
                st.dataframe(combined_goals)

        return combined_goals    
    
    def plot_actual_equity_real_estate_graph(self, actual_df, up_to_date, view_type, selected_month):
        import plotly.graph_objects as go
        import streamlit as st

        actual_df['entry_date'] = pd.to_datetime(actual_df['entry_date'])
        up_to_date = pd.to_datetime(up_to_date)
        actual_df = actual_df[actual_df['entry_date'] <= up_to_date]

        # keep earliest timestamp BEFORE annual/monthly filter
        global_min_x = actual_df['entry_date'].min()

        if view_type == "Annually" and selected_month:
            actual_df = actual_df[actual_df['entry_date'].dt.month == selected_month]

        # % to 0-100 scale
        actual_df['equity'] = actual_df['equity'] * 100
        actual_df['real_estate'] = actual_df['real_estate'] * 100
        actual_df['passive_income'] = actual_df['passive_income'] * 100
        actual_df['debt'] = actual_df['debt'] * 100
        actual_df['alternate_investments'] = actual_df['alternate_investments'] * 100

        # sort
        actual_df = actual_df.sort_values(by='entry_date')

        # build figure
        fig = go.Figure()

        fig.add_trace(go.Scatter(
            x=actual_df['entry_date'], y=actual_df['equity'],
            name='Equity', stackgroup='one', mode='none',
            fillcolor='rgba(144,190,248,1)'
        ))

        fig.add_trace(go.Scatter(
            x=actual_df['entry_date'], y=actual_df['real_estate'],
            name='Real Estate', stackgroup='one', mode='none',
            fillcolor='rgba(140,223,179,1)'
        ))

        fig.add_trace(go.Scatter(
            x=actual_df['entry_date'], y=actual_df['passive_income'],
            name='Passive Income', stackgroup='one', mode='none',
            fillcolor='rgba(255,165,0,0.8)'
        ))

        fig.add_trace(go.Scatter(
            x=actual_df['entry_date'], y=actual_df['debt'],
            name='Debt', stackgroup='one', mode='none',
            fillcolor='rgba(255,217,118,1)'
        ))

        fig.add_trace(go.Scatter(
            x=actual_df['entry_date'], y=actual_df['alternate_investments'],
            name='Alternate Investments', stackgroup='one', mode='none',
            fillcolor='rgba(255,139,129,1)'
        ))

        # layout basics
        fig.update_layout(
            title='Asset Allocation',
            xaxis_title='Year',
            yaxis_title='Percentage (%)',
            #legend_title='Asset Class',
            hovermode='x unified'
        )

        TITLE_SIZE = 20
        AXIS_TITLE_SIZE = 16
        TICK_SIZE = 16
        LEGEND_SIZE = 18

        fig.update_layout(
            title={'text': 'Asset Allocation', 'x': 0.5, 'xanchor': 'center', 'font': {'size': TITLE_SIZE}},
            width=1000,
            height=700,
            margin=dict(l=70, r=50, t=60, b=80),
            legend=dict(
                orientation='h',
                y=-0.2,
                x=0.5,
                xanchor='left',
                font=dict(size=LEGEND_SIZE)
            ),
            hovermode='x unified'
        )

        fig.update_yaxes(
            title='Percentage (%)',
            range=[0, 100],
            dtick=10,
            ticksuffix='%',
            tickfont=dict(size=TICK_SIZE),
            title_font=dict(size=AXIS_TITLE_SIZE)
        )

        fig.update_xaxes(
            title='Year',
            tickformat='%Y',
            tickfont=dict(size=TICK_SIZE),
            title_font=dict(size=AXIS_TITLE_SIZE)
        )

        # =============== DYNAMIC X-AXIS (2-year ticks, aligned to first data tick, BUT no visual left gap) ===============
        if not actual_df.empty:
            # after filtering (monthly or annually), this is what we are actually plotting now
            local_min_x = actual_df['entry_date'].min()
            max_x = actual_df['entry_date'].max()

            # ticks every 2 years
            dtick_val = "M24"

            # ticks should start from the FIRST-EVER year (so you still see 2025, 2027, 2029, ...)
            tick0_date = global_min_x

            # BUT the visible range should begin at the first actually-plotted point,
            # so the stack touches the y-axis (no giant empty space before the first polygon).
            x_start_display = local_min_x
            x_end_display = max_x

            fig.update_xaxes(
                tickmode='linear',
                dtick=dtick_val,          # 24 months between ticks â†’ 2-year steps
                tick0=tick0_date,         # anchor ticks at earliest overall year (e.g. 2025)
                tickformat="%Y",
                tickangle=0,
                ticklabelposition="outside bottom",
                showgrid=False,
                zeroline=False,
                range=[x_start_display, x_end_display]   # <- start viewport at first plotted point
            )

        # Display the chart in Streamlit
        #st.plotly_chart(fig)
        return fig

    def save_plots_to_pdf(self, fig1, fig2, fig3, fig4, fig6, fig7,
                      goal_details_table, user_name, logo_path, goal_table,
                      num_blank_pages, include_liabilities, disclaimer_text):
        """
        Faster PDF build: render Plotly figs to PNG via Selenium (no kaleido),
        fit images to page, keep existing page flow, return PDF path.
        """
        import tempfile, os
        from io import BytesIO

        # ---- helpers ----
        def write_tmp_png(png_bytes, suffix=".png"):
            f = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
            f.write(png_bytes); f.flush(); f.close()
            return f.name

        def add_image_fitted(pdf, img_path, y_top_mm=15):
            # Fit image inside printable area, keep aspect, center horizontally
            from PIL import Image
            with Image.open(img_path) as im:
                src_w_px, src_h_px = im.size
            max_w = pdf.w - pdf.l_margin - pdf.r_margin
            max_h = pdf.h - y_top_mm - 15  # 15mm bottom buffer
            aspect = src_w_px / float(src_h_px)
            draw_w = max_w
            draw_h = draw_w / aspect
            if draw_h > max_h:
                draw_h = max_h
                draw_w = draw_h * aspect
            x = (pdf.w - draw_w) / 2.0
            pdf.image(img_path, x=x, y=y_top_mm, w=draw_w)

        temp_files = []
        try:
            # ---- fast exports via Selenium (tune sizes for speed/quality) ----
            # Make the networth chart a bit taller so axes/annotations arenâ€™t clipped
            png1 = fig_to_png_via_selenium(fig1, width=1500, height=1000)
            p1 = write_tmp_png(png1); temp_files.append(p1)

            png2 = fig_to_png_via_selenium(fig2, width=1400, height=850)
            p2 = write_tmp_png(png2); temp_files.append(p2)

            png3 = fig_to_png_via_selenium(fig3, width=1400, height=850)
            p3 = write_tmp_png(png3); temp_files.append(p3)

            png4 = fig_to_png_via_selenium(fig4, width=1400, height=850)
            p4 = write_tmp_png(png4); temp_files.append(p4)

            if include_liabilities == "Yes" and fig6 is not None:
                png6 = fig_to_png_via_selenium(fig6, width=1400, height=850)
                p6 = write_tmp_png(png6); temp_files.append(p6)
            else:
                p6 = None

            png7 = fig_to_png_via_selenium(fig7, width=1400, height=850)
            p7 = write_tmp_png(png7); temp_files.append(p7)

            # ---- build PDF (same flow you had) ----
            pdf = PDF()
            pdf.add_custom_page(user_name, logo_path, goal_table)

            pdf.add_page(); add_image_fitted(pdf, p1, y_top_mm=15)   # networth
            pdf.add_page(); add_image_fitted(pdf, p2, y_top_mm=18)   # fbs
            pdf.add_page(); add_image_fitted(pdf, p3, y_top_mm=18)   # active/passive
            pdf.add_page(); add_image_fitted(pdf, p4, y_top_mm=18)   # expenses

            if include_liabilities == "Yes" and p6 and os.path.exists(p6):
                pdf.add_page(); add_image_fitted(pdf, p6, y_top_mm=18)  # liabilities

            pdf.add_page(); #add_image_fitted(pdf, p7, y_top_mm=15)   # asset allocation

            # Asset allocation (last graph) â€“ insert smaller than full width
            target_w_mm = 160  # try 150mm; adjust 130â€“160 to taste
            x_mm = (pdf.w - target_w_mm) / 2.0
            pdf.image(p7, x=x_mm, y=18, w=target_w_mm)

            # Disclaimer at bottom of last page
            y_after = max(pdf.get_y(), pdf.h - 38)
            pdf.set_xy(pdf.l_margin, y_after)
            pdf.set_font("Arial", "B", 10); pdf.cell(25, 5, "Disclaimer:", ln=0)
            pdf.set_font("Arial", "", 10);  pdf.multi_cell(0, 5, disclaimer_text or "")

            if num_blank_pages and isinstance(num_blank_pages, int) and num_blank_pages > 0:
                pdf.add_blank_pages(num_pages=num_blank_pages)

            pdf_file = "milestone_charts.pdf"
            pdf.output(pdf_file)
            return pdf_file

        except Exception as e:
            print(f"An unexpected error occurred: {e}")
            raise e
        finally:
            for p in temp_files:
                try: os.remove(p)
                except Exception: pass

        
    def run_pdf_generator_code(self, user_id):
        try:
            try:
                up_to_date = st.date_input(
                    "Select the end date for plotting",
                    value=date.today(),
                    min_value=date(2000, 1, 1),
                    max_value=date(2100, 12, 31)
                )

                # ---- Load data ----
                first_table_dynamic_income_projection_df = self.load_dynamic_income_projection_from_db()
                networth_df = self.load_dynamic_yearly_cf_projections_df_from_db()
                milestones_df = self.load_milestones_liabilities_from_db(user_id)
                fbs_df = self.load_dynamic_fbs_projections_df_from_db(db_config)
                dynamic_milestone_income_projection_df = self.load_dynamic_milestone_income_projection_from_db()
                good_liabilities_df_1 = self.fetch_end_balance_data(user_id)
                user_name = self.fetch_user_name(user_id)
                goal_table = self.prepare_goal_table(milestones_df)
                actual_projections_df = self.load_dynamic_actual_projections_df_from_db(db_config)

                # ---- Build figures ----
                fig1 = self.plot_total_networth_with_milestones(networth_df, milestones_df, up_to_date)
                fig2 = self.plot_fbs_score(fbs_df, up_to_date)
                fig3 = self.plot_active_passive_income_area(first_table_dynamic_income_projection_df,
                                                            dynamic_milestone_income_projection_df, up_to_date)
                fig4 = self.plot_total_expense_area(dynamic_milestone_income_projection_df, up_to_date, user_id)

                include_liabilities = st.radio("Do you want to include the liabilities page?",
                                            ["No", "Yes"], index=0)
                if include_liabilities == "Yes" and not good_liabilities_df_1.empty:
                    fig6 = self.plot_loan_repayment_liabilities(networth_df, good_liabilities_df_1, up_to_date)
                else:
                    fig6 = None

                view_type = st.radio("Choose view type", ["Monthly", "Annually"], horizontal=True)
                month_options = [
                    ("January", 1), ("February", 2), ("March", 3), ("April", 4),
                    ("May", 5), ("June", 6), ("July", 7), ("August", 8),
                    ("September", 9), ("October", 10), ("November", 11), ("December", 12)
                ]
                selected_month = None
                if view_type == "Annually":
                    selected_month = st.selectbox(
                        "Select the month to filter annually:",
                        options=month_options,
                        format_func=lambda x: x[0],
                        index=3  # April
                    )[1]

                disclaimer_text = st.text_area(
                    "Enter a disclaimer to show at the bottom of the Actual Equity vs Real Estate Projection page:"
                )

                fig7 = self.plot_actual_equity_real_estate_graph(
                    actual_projections_df, up_to_date, view_type, selected_month
                )

                # ---- Show figures in the app ----
                PLOTLY_CONFIG = {"displaylogo": False, "scrollZoom": False}
                st.plotly_chart(fig1, width='stretch', config=PLOTLY_CONFIG)
                st.plotly_chart(fig2, width='stretch', config=PLOTLY_CONFIG)
                st.plotly_chart(fig3, width='stretch', config=PLOTLY_CONFIG)
                st.plotly_chart(fig4, width='stretch', config=PLOTLY_CONFIG)
                if fig6 is not None:
                    st.plotly_chart(fig6, width='stretch', config=PLOTLY_CONFIG)
                st.plotly_chart(fig7, width='stretch', config=PLOTLY_CONFIG)

                # ---- Logo + options ----
                # Use whichever path you prefer; continue if not found
                logo_path = r"D:\Goal Planning Files 1\1-Finance-Logo_Final_1.png"
                if not os.path.exists(logo_path):
                    st.info(f"Logo not found at: {os.path.abspath(logo_path)}. Proceeding without logo.")
                    logo_path = ""  # PDF code checks os.path.exists before adding

                num_blank_pages = st.number_input(
                    "How many blank pages do you want to add after the chart?",
                    min_value=0, max_value=10, step=1, value=0
                )

                goal_details_table = st.session_state.get("goal_details_table", pd.DataFrame())

                # ---- Generate on demand (prevents continuous running) ----
                if st.button("Generate PDF"):
                    with st.spinner("Generating PDFâ€¦"):
                        pdf_file = self.save_plots_to_pdf(
                            fig1, fig2, fig3, fig4, fig6, fig7,
                            goal_details_table, user_name, logo_path, goal_table,
                            num_blank_pages, include_liabilities, disclaimer_text
                        )

                    user_name_pdf = self.fetch_user_name(user_id)
                    current_date_str = datetime.today().strftime('%d%m%Y')
                    file_name = f"Goal Planning PDF For {user_name_pdf} v{current_date_str}.pdf"

                    with open(pdf_file, "rb") as pdf:
                        st.download_button(
                            label="Download PDF",
                            data=pdf,
                            file_name=file_name,
                            mime="application/pdf"
                        )

            except IndexError:
                st.warning("No data available up to the selected date. Please select a different date range.")

        except ValueError:
            st.error("Invalid user code format. Please enter a valid UUID.")
  
        

    def update_display_surplus_related_withdrawal_projections(self, user_id, surplus_withdrawal_projections_df, distinct_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        unique_asset_names = surplus_withdrawal_projections_df['asset_name'].unique()

        if entry_type == 'increment':
            asset_name = increment_params.get('asset_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return surplus_withdrawal_projections_df

            # Apply increment
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['asset_name'] == matched_asset_name):
                    previous_amount = float(projection.get('asset_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return surplus_withdrawal_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in surplus_withdrawal_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['asset_name'] == matched_asset_name):
                    surplus_withdrawal_projections_df.at[idx, 'asset_value'] = -abs(incremented_amount)

        return surplus_withdrawal_projections_df 

    def update_display_loan_repayment_projections(self, user_id, dynamic_loan_repayment_projections_df, distinct_liabilities_names, entry_type, single_date=None, range_dates=None, increment_params=None):
        unique_liabilities_names = dynamic_loan_repayment_projections_df['liabilities_name'].unique()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'increment':
            liability_name = increment_params.get('liability_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_liability_name = None
            for db_liability_name in unique_liabilities_names:
                if db_liability_name.strip().lower() == liability_name.strip().lower():
                    matched_liability_name = db_liability_name  # Match found
                    break
            
            if matched_liability_name is None:
                print(f"No matching liability found for '{liability_name}'.")
                return dynamic_loan_repayment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['liabilities_name'] == matched_liability_name):
                    previous_amount = float(projection.get('liabilities_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return dynamic_loan_repayment_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in dynamic_loan_repayment_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['liabilities_name'] == matched_liability_name):
                    dynamic_loan_repayment_projections_df.at[idx, 'liabilities_value'] = -abs(incremented_amount)

        return dynamic_loan_repayment_projections_df   


    def update_display_investment_projections(self, user_id, investment_projections_df, distinct_names, entry_type, growth_month=None, investment_growth=None, single_date=None, range_dates=None, increment_params=None):
        unique_asset_names = investment_projections_df['asset_name'].unique()
        #print("Current unique assets:", unique_asset_names)

        if entry_type == 'increment':
            asset_name = increment_params.get('asset_name')
            increment_percentage = increment_params['percentage'] / 100
            entry_date = increment_params['entry_date']
            
            # Get the previous month's date
            prev_date = (datetime.strptime(entry_date, "%Y-%m-%d").replace(day=1) - timedelta(days=1)).strftime("%Y-%m-%d")

            # Perform case-insensitive and space-insensitive match to find the correct asset name
            matched_asset_name = None
            for db_asset_name in unique_asset_names:
                if db_asset_name.strip().lower() == asset_name.strip().lower():
                    matched_asset_name = db_asset_name  # Match found
                    break
            
            if matched_asset_name is None:
                print(f"No matching asset found for '{asset_name}'.")
                return investment_projections_df

            #print(f"Asset matched: '{matched_asset_name}'")
            
            # Apply increment
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and projection['entry_date'] == prev_date and projection['asset_name'] == matched_asset_name):
                    previous_amount = float(projection.get('asset_value', 0))
                    incremented_amount = previous_amount * (1 + increment_percentage)
                    break
            else:
                print(f"No matching entry_date found for {prev_date}. Please ensure the previous month's data exists.")
                return investment_projections_df

            end_date_increment = increment_params['end_date']
            for idx, projection in investment_projections_df.iterrows():
                if (projection['user_code'] == user_id and entry_date <= projection['entry_date'] <= end_date_increment and projection['asset_name'] == matched_asset_name):
                    investment_projections_df.at[idx, 'asset_value'] = -abs(incremented_amount)

        return investment_projections_df

    
    def run_display_all_transpose_milestone_table(self, user_id, month_choice):

        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        milestone_income_transposed_df = self.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
        st.write("Milestone Income Projection")
        st.dataframe(milestone_income_transposed_df)  # Display the transposed data in Streamlit

        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        additional_expense_transposed_df = self.reshape_display_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)
        st.write("Milestone additional expense Projection")
        st.dataframe(additional_expense_transposed_df)  # Display the transposed data in Streamlit
        

        st.write("##### Milestone Investment Projection table")
        entry_type = st.radio("Choose entry type:", ('increment', 'stop'), key="investment_entry_type")
        investment_projections_df = self.load_investment_projections_from_db(user_id)
        investment_reshaped_updated_df = self.reshape_display_investment_projections(investment_projections_df, user_id)
        if entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="investment_increment_entry")
            percentage = st.number_input("Increment percentage:", key="investment_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="investment_increment_end")
            asset_name = st.selectbox("Select asset name for increment:", investment_reshaped_updated_df.index.tolist(), key="investment_increment_asset")

            if st.button("Apply Increment Update", key="apply_investment_increment_update"):
                investment_projections_df = self.update_display_investment_projections(
                    user_id,
                    investment_projections_df,
                    distinct_names = investment_reshaped_updated_df.index.tolist(),
                    entry_type=entry_type,
                    increment_params={
                        'entry_date': entry_date.strftime('%Y-%m-%d'),
                        'percentage': percentage,
                        'end_date': end_date_increment.strftime('%Y-%m-%d'),
                        'asset_name': asset_name
                    }
                )
                self.save_investment_projections_to_db(investment_projections_df, user_id)
                st.success("Increment update applied and saved to the database.")


        
        investment_reshaped_df = self.reshape_display_investment_projections(investment_projections_df, user_id)
        
        investment_editable_reshaped_df = st.data_editor(investment_reshaped_df, use_container_width=True, key = 'Invest_reshaped_editor_3')

        # Save changes back to the database
        if st.button("Save Changes", key = 'save transpose investment projection'):
            # Unpivot the reshaped DataFrame to its original format
            investment_reshaped_df.reset_index(inplace=True)  # Reset index before unpivoting
            investment_updated_unpivoted_df = self.unpivot_reshaped_data(investment_editable_reshaped_df)

            # Update the main DataFrame with new values
            investment_projections_df = self.update_main_dataframe(investment_projections_df, investment_updated_unpivoted_df)

            # Save the updated DataFrame to the database
            self.save_investment_projections_to_db(investment_projections_df, user_id)

            st.success("Changes of investment projection saved successfully!")



        st.write("##### Milestone loan repayment Projection table")
        entry_type = st.radio("Choose entry type:", ('increment', 'stop'), key="loan_repayment_entry_type")
        dynamic_loan_repayment_projections_df = self.load_dynamic_loan_repayment_projections_from_db(user_id)
        loan_repayment_reshaped_df = self.reshape_display_loan_repayment_projections(dynamic_loan_repayment_projections_df, user_id)
        if entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="loan_repayment_increment_entry")
            percentage = st.number_input("Increment percentage:", key="loan_repayment_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="loan_repayment_increment_end")
            liability_name = st.selectbox("Select asset name for increment:", loan_repayment_reshaped_df.index.tolist(), key="loan_repayment_increment_liabilities")

            if st.button("Apply Increment Update", key="apply_loan_repayment_increment_update"):
                dynamic_loan_repayment_projections_df = self.update_display_loan_repayment_projections(
                    user_id,
                    dynamic_loan_repayment_projections_df,
                    distinct_liabilities_names = loan_repayment_reshaped_df.index.tolist(),
                    entry_type=entry_type,
                    increment_params={
                        'entry_date': entry_date.strftime('%Y-%m-%d'),
                        'percentage': percentage,
                        'end_date': end_date_increment.strftime('%Y-%m-%d'),
                        'liability_name': liability_name
                    }
                )
                projection_updater.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)
                st.success("Increment update applied and saved to the database.")

        loan_repayment_reshaped_df = self.reshape_display_loan_repayment_projections(dynamic_loan_repayment_projections_df, user_id)
        
        loan_repayment_editable_reshaped_df = st.data_editor(loan_repayment_reshaped_df, use_container_width=True, key = 'reshaped_editor_4')

        # Save changes back to the database
        if st.button("Save Changes", key = 'save transpose loan repayment projection'):
            # Unpivot the reshaped DataFrame to its original format
            loan_repayment_reshaped_df.reset_index(inplace=True)  # Reset index before unpivoting
            loan_repayment_updated_unpivoted_df = self.liabilities_unpivot_reshaped_data(loan_repayment_editable_reshaped_df)

            # Update the main DataFrame with new values
            dynamic_loan_repayment_projections_df = self.liabilities_update_main_dataframe(dynamic_loan_repayment_projections_df, loan_repayment_updated_unpivoted_df)

            # Save the updated DataFrame to the database
            self.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)

            st.success("Changes of loan repayment projection saved successfully!")    
        

        milestone_calculation_projections_df = self.load_milestone_calculation_projections_from_db()
        # Display the updated milestone projections in a table
        st.write("##### Milestone Calculation Projections")
        reshaped_df = self.display_reshape_milestone_projections(milestone_calculation_projections_df, user_id)
        st.dataframe(reshaped_df)

        dynamic_assets_projections_df = self.load_dynamic_assets_projections_df_from_db(user_id)
        asset_reshaped_df = self.display_reshape_dynamic_assets_projections(dynamic_assets_projections_df, user_id)
        st.write("##### Milestone Asset Projections")
        st.dataframe(asset_reshaped_df)

        st.write("##### Milestone Surplus Projection table")
        entry_type = st.radio("Choose entry type:", ('increment', 'stop'), key="surplus_entry_type")
        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        reshaped_updated_df = self.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        if entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="surplus_increment_entry")
            percentage = st.number_input("Increment percentage:", key="surplus_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="surplus_increment_end")
            asset_name = st.selectbox("Select asset name for increment:", reshaped_updated_df.index.tolist(), key="surplus_increment_asset")

            if st.button("Apply Increment Update", key="apply_surplus_increment_update"):
                surplus_withdrawal_projections_df = projection_updater.update_display_surplus_related_withdrawal_projections(
                    user_id,
                    surplus_withdrawal_projections_df,
                    distinct_names = reshaped_df.index.tolist(),
                    entry_type=entry_type,
                    increment_params={
                        'entry_date': entry_date.strftime('%Y-%m-%d'),
                        'percentage': percentage,
                        'end_date': end_date_increment.strftime('%Y-%m-%d'),
                        'asset_name': asset_name
                    }
                )
                projection_updater.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                st.success("Increment update applied and saved to the database.")

        reshaped_updated_df = self.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        
        editable_reshaped_df = st.data_editor(reshaped_updated_df, use_container_width=True, key = 'reshaped_editor_2')

        # Save changes back to the database
        if st.button("Save Changes", key = 'save transpose surplus projection'):
            # Unpivot the reshaped DataFrame to its original format
            reshaped_updated_df.reset_index(inplace=True)  # Reset index before unpivoting
            updated_unpivoted_df = self.unpivot_reshaped_data(editable_reshaped_df)

            # Update the main DataFrame with new values
            surplus_withdrawal_projections_df = self.update_main_dataframe(surplus_withdrawal_projections_df, updated_unpivoted_df)

            # Save the updated DataFrame to the database
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

            st.success("Changes saved successfully!") 

        dynamic_liabilities_projections_df = self.load_dynamic_liabilities_projections_df_from_db()  
        liabilities_reshaped_df = self.reshape_display_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_id)
        st.write("##### Milestone Liabilities Projections")
        st.dataframe(liabilities_reshaped_df) 

        dynamic_liabilities_outflows_projections_df = self.load_dynamic_liabilities_outflows_projections_df_from_db()
        liabilities_outflows_reshaped_df = self.reshape_display_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
        st.write("##### Milestone Liabilities Outflows Projections")
        st.dataframe(liabilities_outflows_reshaped_df) 

        dynamic_insurance_outflows_projections_df = self.load_dynamic_insurance_outflows_projections_df_from_db()
        insurance_outflows_reshaped_df = self.reshape_display_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
        st.write("##### Milestone Insurance Outflows Projections")
        st.dataframe(insurance_outflows_reshaped_df)

        dynamic_yearly_cf_projections_df = self.load_dynamic_yearly_cf_projections_df_from_db()
        cashflows_reshaped_df = self.transpose_display_dynamic_yearly_cf_projections_1(dynamic_yearly_cf_projections_df)
        st.write("##### Milestone CashFlows Projections")
        st.dataframe(cashflows_reshaped_df) 

        dynamic_actual_projections_df = self.load_dynamic_actual_projections_df_from_db(self.db_config)
        # Transpose the data for the desired format
        actual_transposed_df = self.transpose_display_dynamic_actual_projections_df_1(dynamic_actual_projections_df)
        st.write("Milestone Actual Projection")
        st.dataframe(actual_transposed_df)  # Display the transposed data in Streamlit

        dynamic_ideal_projection_calculation = self.load_dynamic_ideal_projection_calculation_from_db(db_config)
        # Transpose the data for the desired format
        ideal_transposed_df = self.transpose_display_dynamic_ideal_projection_calculation_1(dynamic_ideal_projection_calculation)
        st.write("Milestone Ideal Projection")
        st.dataframe(ideal_transposed_df)  # Display the transposed data in Streamlit 

        ideal_max_milestone_metric_df = self.load_ideal_max_milestone_metric_from_db(db_config)
        # Transpose the data for the desired format
        ideal_max_transposed_df = self.transpose_display_ideal_max_milestone_metric_1(ideal_max_milestone_metric_df)
        st.write("Milestone Ideal Max Projection")
        st.dataframe(ideal_max_transposed_df)  # Display the transposed data in Streamlit 

        ideal_min_milestone_metric_df = self.load_ideal_min_milestone_metric_from_db(db_config)
        # Transpose the data for the desired format
        ideal_min_transposed_df = self.transpose_display_ideal_min_milestone_metric_1(ideal_min_milestone_metric_df)
        st.write("Milestone Ideal Min Projection")
        st.dataframe(ideal_min_transposed_df)  # Display the transposed data in Streamlit 
        
        dynamic_ideal_projections_emergency_planning_df = self.load_dynamic_ideal_projections_emergency_planning_table_df_from_db(self.db_config)
        # Transpose the data for the desired format
        emergency_planning_transposed_df = self.transpose_display_dynamic_ideal_projections_emergency_planning_1(dynamic_ideal_projections_emergency_planning_df)
        st.write("Milestone Emergency Planning Projection")
        st.dataframe(emergency_planning_transposed_df)  # Display the transposed data in Streamlit 
        
        dynamic_fbs_projections_df = self.load_dynamic_fbs_projections_df_from_db(self.db_config)
        # Transpose the data for the desired format
        FBS_transposed_df = self.transpose_display_dynamic_fbs_projections_df_1(dynamic_fbs_projections_df)
        st.write("Milestone FBS Projection")
        st.dataframe(FBS_transposed_df)  # Display the transposed data in Streamlit 
        

        projection_updater.save_and_plot_all_assets_charts_comparison(db_config, user_id)  
        
        st.write("All Cashflows Projections Charts")
        try:
            up_to_date_cashflows = st.date_input("Select the end date for plotting cashflows", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = 'cashflow charts duration')
            projection_updater.save_and_plot_all_yearly_cf_projections(db_config, user_id, up_to_date_cashflows)
        except IndexError:
            st.warning("No data available up to the selected date. Please select a different date range.")

        projection_updater.save_and_plot_all_charts_comparison(db_config, user_id)  
        projection_updater.plot_all_emergency_planning_charts(db_config, user_id) 
        projection_updater.save_and_plot_all_fbs_charts_comparison(db_config, user_id) 


    def run_all_check_charts(self, user_id, month_choice):  

        projection_updater.save_and_plot_all_assets_charts_comparison(db_config, user_id)  
        
        st.write("All Cashflows Projections Charts")
        try:
            up_to_date_cashflows = st.date_input("Select the end date for plotting cashflows", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = 'cashflow charts duration')
            projection_updater.save_and_plot_all_yearly_cf_projections(db_config, user_id, up_to_date_cashflows)
        except IndexError:
            st.warning("No data available up to the selected date. Please select a different date range.")

        projection_updater.save_and_plot_all_charts_comparison(db_config, user_id)  
        
        seperate_actual_ideal_charts = st.radio("Do you to want to see the seperate affordability check charts?", ["No", "Yes"], index=0)
        if seperate_actual_ideal_charts == "Yes":
            projection_updater.save_and_plot_seperate_metrics_affordability_checks(db_config, user_id) 

        projection_updater.plot_all_emergency_planning_charts(db_config, user_id) 
        projection_updater.save_and_plot_all_fbs_charts_comparison(db_config, user_id)   


    def run_display_2_surplus_withdrawal_projections(self, user_id, month_choice):
        
        # Check if the investment_projections table exists
        connection_string = f"postgresql+psycopg2://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
        engine = create_engine(connection_string)
        inspector = inspect(engine)
        
        if inspector.has_table('surplus_withdrawal_projections'):
            # Only delete old records if the table exists
            self.delete_old_surplus_records()

        surplus_withdrawal_projections_df = self.load_surplus_withdrawal_projections_from_db(user_id)
        dob, retirement_age = self.fetch_user_data(user_id)
        user_name = self.fetch_user_name(user_id)

        assets_with_categories = self.fetch_assets_with_categories_1(user_id)
        surplus_relate_purpose = self.fetch_purpose_for_surplusr_projections(user_id)
        unique_assets = [asset_name for asset_name, _ in assets_with_categories]

        assets_dict = {
            18: "Public Stock (India)",
            19: "Equity Mutual Funds",
            21: "Unlisted Stocks",
            22: "Public Stocks (International)",
            23: "Equity ETFs",
            24: "International Funds",
            25: "Direct Bonds",
            26: "Liquid Debt Funds",
            27: "Debt Funds",
            28: "Hybrid Funds",
            29: "Rental Yielding (Residential)",
            30: "Rental Yielding (Commercial)",
            31: "Non-Yielding (Residential)",
            32: "Non-Yielding (Commercial)",
            33: "Occupied Home",
            34: "Physical Gold",
            35: "Gold ETFs",
            36: "Sovereign Gold Bonds",
            37: "Bank FD",
            38: "Corporate FD",
            39: "Post Office Monthly Income Scheme (POMIS)",
            40: "Senior Citizen Savings Scheme (SCSS)",
            41: "Sukanya Samriddhi Yojana (SSY)",
            42: "National Savings Certificate (NSC)",
            43: "EPF",
            44: "PPF",
            45: "Savings",
            46: "NPS Tier I",
            47: "NPS Tier II",
            48: "Pradhan Mantri Vaya Vandana Yojana (PMVVY)",
            49: "Atal Pension Yojana (APY)",
            50: "Direct Cryptos",
            51: "Coin Baskets",
            53: "Loans Given",
            54: "Free Debt Instruments",
            90: "Physical Silver",
            91: "Silver ETFs",
            120: "Free Debt Instruments",
            235: "ESOP",
            236: "REITs/InvITs",
            237: "Bank RD",
            238: "P2P Lending"
        }

        # Check if the DataFrame is empty and create initial projections if needed
        if not self.user_exists_in_surplus_withdrawal_proj_db(user_id):
            if surplus_withdrawal_projections_df.empty:
                new_projections = self.create_surplus_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name)
                surplus_withdrawal_projections_df = pd.DataFrame(new_projections)
            else:
                new_projections = self.create_surplus_related_withdrawal_projection_table(dob, retirement_age, assets_with_categories, surplus_relate_purpose, user_id, user_name)
                surplus_withdrawal_projections_df = pd.concat([surplus_withdrawal_projections_df, pd.DataFrame(new_projections)], ignore_index=True)

            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)    

        # Reshape and display the existing investment projections for the user
        #st.write("### Surplus Projections")
        reshaped_df = self.reshape_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
        #st.dataframe(reshaped_df)

        # Dropdown to select an asset to add as a new asset
        additional_asset_name = st.selectbox("Select asset name to add:", list(assets_dict.values()), key="surplus_add_asset")
        if st.button("Add Asset", key="surplus_add_button"):
            assets_with_categories = self.fetch_assets_with_categories_1(user_id)
            surplus_withdrawal_projections_df, assets_with_categories = self.add_additional_asset_for_surplus_withdrawal(surplus_withdrawal_projections_df, assets_dict, assets_with_categories, user_id, dob, retirement_age, additional_asset_name, month_choice)
            #print('surplus_withdrawal_projections_df check', surplus_withdrawal_projections_df)
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.success(f"Added {additional_asset_name} to projections and saved to the database.")

        # Fetch distinct asset names for the dropdowns
        unique_assets_surplus_projections = surplus_withdrawal_projections_df[surplus_withdrawal_projections_df['user_code'] == user_id]['asset_name'].unique().tolist()

        entry_type = st.radio("Choose entry type:", ('increment', 'stop'), key="surplus_entry_type")

        if entry_type == 'increment':
            entry_date = st.date_input("Entry Date:", key="surplus_increment_entry")
            percentage = st.number_input("Increment percentage:", key="surplus_increment_percentage")
            end_date_increment = st.date_input("End Date for Increment:", key="surplus_increment_end")
            asset_name = st.selectbox("Select asset name for increment:", reshaped_df['asset_name'], key="surplus_increment_asset")

            if st.button("Apply Increment Update", key="apply_surplus_increment_update"):
                surplus_withdrawal_projections_df = projection_updater.update_display_surplus_related_withdrawal_projections(
                    user_id,
                    surplus_withdrawal_projections_df,
                    distinct_names=reshaped_df['asset_name'].tolist(),
                    entry_type=entry_type,
                    increment_params={
                        'entry_date': entry_date.strftime('%Y-%m-%d'),
                        'percentage': percentage,
                        'end_date': end_date_increment.strftime('%Y-%m-%d'),
                        'asset_name': asset_name
                    }
                )
                projection_updater.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
                st.success("Increment update applied and saved to the database.")

        elif entry_type == 'stop':
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.write("Stop function executed. No changes applied.") 

        st.write("### Delete an Asset Category")
        
        # Dropdown for selecting an asset category to delete
        asset_to_delete = st.selectbox("Select asset category to delete from projections:", unique_assets_surplus_projections, key="surplus_delete_asset")
        
        # Confirm deletion
        if st.button("Delete Selected Asset Category", key="delete_surplus_asset"):
            surplus_withdrawal_projections_df = self.delete_asset_category_from_projections(surplus_withdrawal_projections_df, user_id, asset_to_delete)
            self.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)
            st.success(f"Asset category '{asset_to_delete}' has been deleted from projections for user_id {user_id}.")     

        reshaped_df = self.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)

        st.write("### Editable Surplus Projections")
        edited_df = st.data_editor(reshaped_df, use_container_width=True)

        # Save changes back to the database
        if st.button("Save Changes"):
            # Unpivot the reshaped DataFrame to its original format
            unpivoted_df = self.unpivot_reshaped_data(edited_df)

            # Update the main DataFrame with new values
            updated_surplus_withdrawal_projections_df = self.update_main_dataframe(surplus_withdrawal_projections_df, unpivoted_df)

            # Save the updated DataFrame to the database
            self.save_surplus_withdrawal_projections_to_db(updated_surplus_withdrawal_projections_df, user_id)

            st.success("Changes saved successfully!")       

    def run_display_all_transpose_milestone_table_1(self, user_id, month_choice):    

        dynamic_milestone_income_projection = self.load_dynamic_milestone_income_projection_from_db()
        milestone_income_transposed_df = self.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
        st.write("Milestone Income Projection")
        st.dataframe(milestone_income_transposed_df)  # Display the transposed data in Streamlit

        additional_income_expense_criteria_df = self.load_additional_income_expense_criteria_df_from_db()
        additional_expense_transposed_df = self.reshape_display_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)
        st.write("Milestone additional expense Projection")
        st.dataframe(additional_expense_transposed_df)  # Display the transposed data in Streamlit
        
        #if st.button("Do you want to shift the dates", key = 'save milestone calculation'):
        self.run_milestone_calculation_projections(user_id, month_choice)

        self.run_display_2_surplus_withdrawal_projections(user_id, month_choice)

        self.manage_downpayment_outstanding_amount()

        self.run_all_cf_calculation_projection(user_id)

        self.run_dynamic_liabilities_projections(user_id, dob, retirement_age, month_choice)

        self.run_dynamic_liabilities_outflows_projections(user_id, month_choice)

        self.run_dynamic_yearly_cf_projections(user_id, dob, retirement_age, month_choice)

        projection_updater.save_and_plot_all_assets_charts_comparison(db_config, user_id)  
        
        st.write("All Cashflows Projections Charts")
        try:
            up_to_date_cashflows = st.date_input("Select the end date for plotting cashflows", value=date.today(), min_value=date(2000, 1, 1), max_value=date(2100, 12, 31), key = 'cashflow 1 charts duration')
            projection_updater.save_and_plot_all_yearly_cf_projections(db_config, user_id, up_to_date_cashflows)
        except IndexError:
            st.warning("No data available up to the selected date. Please select a different date range.")

        projection_updater.save_and_plot_all_charts_comparison(db_config, user_id)  
        projection_updater.plot_all_emergency_planning_charts(db_config, user_id) 
        projection_updater.save_and_plot_all_fbs_charts_comparison(db_config, user_id)
        
        
         


# Streamlit App starts here
st.title("Projection Updater")


# Setup database configuration

db_config = {
    "host": "ec2-13-235-15-173.ap-south-1.compute.amazonaws.com",
    "database": "Lakemaster_milestone",  
    "user": "pguser",
    "password": "R5sWDsMWc7aYHfQc",
    "port": "5432"
}


# #Setup database configuration
# db_config = {
#     "host": "localhost",
#     "database": "Milestone_planning_04092024",  
#     "user": "postgres",
#     "password": "root",
#     "port": "5432"
# }

# Create an instance of the ProjectionUpdater class
projection_updater = ProjectionUpdater(db_config)

#month_choice = st.selectbox( "Select the stopping month for projection (March or December):", [3, 12],format_func=lambda x: "March" if x == 3 else "December")

# Streamlit select box for stopping month
#month_choice = st.selectbox( "Select the stopping month for projection (March, May, or December):", [3, 5, 12],format_func=lambda x: {3: "March", 5: "May", 12: "December"}[x])

month_dict = {
    1: "January", 2: "February", 3: "March", 4: "April",
    5: "May", 6: "June", 7: "July", 8: "August",
    9: "September", 10: "October", 11: "November", 12: "December"
}

month_choice = st.selectbox("Select the stopping month for projection:", list(month_dict.keys()), format_func=lambda x: month_dict[x])

# User input for the user code
user_id = st.text_input("Enter the user code", key="user_code_input")

# Run the projection process when the user_id is entered
# Sidebar Navigation
st.sidebar.title("Navigation")

# Create navigation options in the sidebar
option = st.sidebar.radio(
    "Select a Projection or Calculation:",
    [   "Insert and update the milestone, Income, Assets and liability data",
        "Dynamic Income Projection",
        "Outstanding Amount Table and All liabilities Calculation Projection",
        "Pre Goal Planning Details Tables",
        "Liabilities Section",
        "Assets Section",
        "Income Section",
        "Cashflow, Actual, Ideal and FBS Projection Data",
        "Update the Asset and liabilities table Manually",
        "Display All Goal Planning Table",
        "Display All Check Charts",
        "Generate the PDF of Milestone Report",
        "Download Goal Projections Excel File"
    ]
)

# Main content based on the sidebar option
if user_id:

    projection_updater.initialize_user_if_first_time(user_id)

    if st.button("Reset user copy logic"):
        cursor = projection_updater.connection.cursor()
        cursor.execute("""
            DELETE FROM user_initialization_tracker
            WHERE user_id = %s;
        """, (user_id,))
        projection_updater.connection.commit()
        cursor.close()
        st.success("Initialization reset! The copy functions will run next time for this user.")

    # Fetch user data (DOB, retirement age)
    dob, retirement_age = projection_updater.fetch_user_data(user_id)

    if option == "Insert and update the milestone, Income, Assets and liability data":

        st.subheader("Insert, Update and Delete Milestones Liabilities")
        manage_input_goal_table = st.radio("Do you want to update the user goal details?", ["No", "Yes"], index=0) 
        if manage_input_goal_table == "Yes":
            #st.write("### Insert, Update and Delete Milestones Liabilities")
            projection_updater.manage_milestones_liabilities(user_id)  

        st.write("### Changing Milestone Customer Profile (DOB and Retirement Age)")    
        manage_customer_profile_table = st.radio("Do you want to update the milestone customer profile table?", ["No", "Yes"], index=0) 
        if manage_customer_profile_table == "Yes":
            projection_updater.manage_milestone_customer_profile()


        st.write("### Changing life stage growth table")    
        manage_income_table = st.radio("Do you want to update the life stage growth table?", ["No", "Yes"], index=0) 
        if manage_income_table == "Yes":
                projection_updater.manage_life_stage_growth_milestone(user_id)          
                 

        st.write("### Changing Milestone Income")    
        manage_income_table = st.radio("Do you want to update the milestone income table?", ["No", "Yes"], index=0) 
        if manage_income_table == "Yes":
            projection_updater.manage_milestone_income() 

        st.write("### Changing Customer Details (Tax Deduction Amount and Non Taxable Income)")    
        manage_customer_details_table = st.radio("Do you want to update the customer details table?", ["No", "Yes"], index=0) 
        if manage_customer_details_table == "Yes":
            projection_updater.manage_milestone_customer_details(user_id)

        st.write("### Changing user expenses")    
        manage_expenses_table = st.radio("Do you want to update the expense table?", ["No", "Yes"], index=0) 
        if manage_expenses_table == "Yes":
            projection_updater.manage_milestone_expenses(user_id)    

        st.write("### Changing Assets Data")    
        manage_asset_table = st.radio("Do you want to update the asset table?", ["No", "Yes"], index=0) 
        if manage_asset_table == "Yes":
            projection_updater.manage_assets_milestones()     

        st.write("### Changing Liabilities Data")
        manage_liability_table = st.radio("Do you want to update the liability table?", ["No", "Yes"], index=0)
        if manage_liability_table == "Yes":
            projection_updater.manage_liabilities_milestones()     

        st.write("### Changing asset Category table")    
        manage_asset_category_table = st.radio("Do you want to update the Asset Category table?", ["No", "Yes"], index=0) 
        if manage_asset_category_table == "Yes":
            projection_updater.manage_asset_category_table() 

        st.write("### Changing Milestone Category table")    
        manage_milestone_category_table = st.radio("Do you want to update the Milestone Category table?", ["No", "Yes"], index=0) 
        if manage_milestone_category_table == "Yes":
            projection_updater.manage_milestones_category()

        if st.button('Display milestone category table',key = 'milestone category 1'):
            st.write("### Milestone Category Name")
            projection_updater.display_milestone_category_data(user_id)   

        if st.button('Display asset category table',key = 'asset category 1'):
            st.write("### Asset Category Names")
            projection_updater.display_asset_category_data(user_id)     

        if st.button('Display the customer profile (DOB and Retirement Age) table',key = 'customer profile table display 1'):
            st.write("### User Assets")
            projection_updater.display_customer_profile_data(user_id)     

        if st.button('Display the asset table',key = 'asset table display 1'):
            st.write("### User Assets")
            projection_updater.display_assets_data(user_id)  

        if st.button('Display the life stage growth table', key = 'life stage growth table display 1'):
            st.write("### User life stage growth percentage")
            projection_updater.display_life_stage_growth_data(user_id)    

        if st.button('Display the income table',key = 'income table display 1'):
            st.write("### User income table")
            projection_updater.display_income_data(user_id)  


        if st.button('Display the customer details (Tax Deduction Amount and Non Taxable Income) table',key = 'customer details table display 1'):
            st.write("### User customer details (Tax Deduction Amount and Non Taxable Income) table")
            projection_updater.display_customer_details_data(user_id)  

        if st.button('Display the customer expense table',key = 'customer expense table display 1'):
            st.write("### User customer expense table")
            projection_updater.display_customer_expense_data(user_id)  


        if st.button('Display the customer liabilities table',key = 'customer liabilities table display 1'):
            st.write("### User customer liabilities table")
            projection_updater.display_customer_liabilities_data(user_id) 


        st.write("### Changing Milestone Calculation Projection Data")
        manage_milestone_calculation_table = st.radio("Do you want to update the milestone calculation table?", ["No", "Yes"], index=0)
        if manage_milestone_calculation_table == "Yes":
            projection_updater.run_milestone_calculation_projections(user_id, month_choice)     


    elif option == "Dynamic Income Projection":

        copy_user_income_table = st.radio("Do you want run the  user income projection?", ["No", "Yes"], index=0)
        if copy_user_income_table == "Yes":
            projection_updater.run_dynamic_income_projection(user_id) 

        copy_user_nominee_income_table = st.radio("Do you want run the user wife projection?", ["No", "Yes"], index=0)
        if copy_user_nominee_income_table == "Yes":
            projection_updater.run_dynamic_nominee_income_projection(user_id)  
        
        combine_user_nominee_income_table = st.radio("Do you combine the user and user's wife income data?", ["No", "Yes"], index=0)
        if combine_user_nominee_income_table == "Yes":
            projection_updater.run_dynamic_combine_income_projection()  

        # st.write("### Running Dynamic Income Projection")
        # projection_updater.run_dynamic_income_projection(user_id)

    elif option == "Outstanding Amount Table and All liabilities Calculation Projection":
        #st.write("### Running Outstanding Amount Table")
        projection_updater.run_outstanding_amount_table(user_id)

        st.subheader("All liabilities Calculation Projection")
        projection_updater.run_all_cf_calculation_projection(user_id)    
    
    elif option == "Pre Goal Planning Details Tables":
        st.write("### Running All Pre Planning Tables")  
        manage_pre_planning_table = st.radio("Do you want to load all pre planning tables?", ["No", "Yes"], index=0) 
        if manage_pre_planning_table == "Yes":
            projection_updater.run_all_pre_goal_planning_projections(user_id)

        st.write("### Select the Range of Pre Goal Planning Tables")  
        manage_loan_repayment_table = st.radio("Do you want to see the pre goal planning details as per the selected range?", ["No", "Yes"], index=0) 
        if manage_loan_repayment_table == "Yes":
            projection_updater.run_all_pre_goal_planning_projections_1(user_id)    

    elif option == "Liabilities Section":        

        st.write("### Changing Loan Repayment Projection Data")   
        manage_loan_repayment_table = st.radio("Do you want to update the Loan Repayment Projection table?", ["No", "Yes"], index=0) 
        if manage_loan_repayment_table == "Yes":
            projection_updater.run_loan_repayment_projections(user_id, month_choice)

        st.write("### Changing Loan Surplus Repayment Projection Data")   
        manage_loan_surplus_repayment_table = st.radio("Do you want to update the Loan surplus Repayment Projection table?", ["No", "Yes"], index=0) 
        if manage_loan_surplus_repayment_table == "Yes":
            projection_updater.run_loan_surplus_repayment_projections(user_id, month_choice)    

        st.write("### Changing Liabilities Projection Data")   
        manage_liability_projection_table = st.radio("Do you want to update the Liabilities Projection table?", ["No", "Yes"], index=0) 
        if manage_liability_projection_table == "Yes":
            projection_updater.run_dynamic_liabilities_projections(user_id, dob, retirement_age, month_choice)

        
        st.write("### Changing Liabilities Outflows Projection Data")
        manage_liability_outflows_projection_table = st.radio("Do you want to update the Liabilities Outflows Projection table?", ["No", "Yes"], index=0) 
        if manage_liability_outflows_projection_table == "Yes":
            if st.button("Update the Liabilities Outflows Projection", key = 'all outflows liabilities'):
                projection_updater.run_dynamic_liabilities_outflows_projections(user_id, month_choice) 

        st.write("### Changing Insurance Outflows Projection Data")
        manage_insurance_outflows_projection_table = st.radio("Do you want to update the Insurance Outflows Projection table?", ["No", "Yes"], index=0) 
        if manage_insurance_outflows_projection_table == "Yes":
            if st.button("Update the Insurance Outflows Projection", key = 'all insurance outflows liabilities'):
                projection_updater.run_dynamic_insurance_outflows_projections(user_id, month_choice)

        try:
            loan_repayment_df_updated = projection_updater.load_dynamic_loan_repayment_projections_from_db(user_id)
            if loan_repayment_df_updated.empty:
                st.warning("âš ï¸ Loan repayment projections not yet calculated for this user.")
            else:
                loan_repayment_reshaped_df = projection_updater.reshape_display_loan_repayment_projections(loan_repayment_df_updated, user_id)
                loan_repayment_editable_reshaped_df = st.data_editor(loan_repayment_reshaped_df, use_container_width=True, key = 'reshaped_editor_4')
                # Save changes back to the database
                if st.button("Save Changes", key = 'save transpose loan repayment projection'):
                    # Unpivot the reshaped DataFrame to its original format
                    loan_repayment_reshaped_df.reset_index(inplace=True)  # Reset index before unpivoting
                    loan_repayment_updated_unpivoted_df = projection_updater.liabilities_unpivot_reshaped_data(loan_repayment_editable_reshaped_df)

                    # Update the main DataFrame with new values
                    dynamic_loan_repayment_projections_df = projection_updater.liabilities_update_main_dataframe(loan_repayment_df_updated, loan_repayment_updated_unpivoted_df)

                    # Save the updated DataFrame to the database
                    projection_updater.save_dynamic_loan_repayment_projections_to_db(dynamic_loan_repayment_projections_df, user_id)

                    st.success("Changes of loan repayment projection saved successfully!")
                
        except Exception as e:
            st.error(f"âŒ Failed to load Loan Repayment Projections: {str(e)}")


        try:
            dynamic_liabilities_projections_df = projection_updater.load_dynamic_liabilities_projections_df_from_db()
            if dynamic_liabilities_projections_df.empty:
                st.warning("âš ï¸ Liabilities projections not yet calculated for this user.")
            else:
                reshaped_liabilities_df = projection_updater.reshape_display_dynamic_liabilities_projections(dynamic_liabilities_projections_df, user_id)
                st.write("### ðŸŸ¢ Updated Liabilities projections")
                st.dataframe(reshaped_liabilities_df)
        except Exception as e:
            st.error(f"âŒ Failed to load Liabilities projections: {str(e)}")


        try:
            dynamic_liabilities_outflows_projections_df = projection_updater.load_dynamic_liabilities_outflows_projections_df_from_db()
            if dynamic_liabilities_outflows_projections_df.empty:
                st.warning("âš ï¸ Liabilities outflows projections not yet calculated for this user.")
            else:
                reshaped_liabilities_outflows_df = projection_updater.reshape_display_dynamic_liabilities_outflows_projections(dynamic_liabilities_outflows_projections_df, user_id)
                st.write("### ðŸŸ¢ Updated Liabilities outflows projections")
                st.dataframe(reshaped_liabilities_outflows_df)
        except Exception as e:
            st.error(f"âŒ Failed to load Liabilities outflows projections: {str(e)}") 


        try:
            dynamic_insurance_outflows_projections_df = projection_updater.load_dynamic_insurance_outflows_projections_df_from_db()
            if dynamic_insurance_outflows_projections_df.empty:
                st.warning("âš ï¸ Insurance outflows projections not yet calculated for this user.")
            else:
                reshaped_insurance_outflows_df = projection_updater.reshape_display_insurance_outflows_projections(dynamic_insurance_outflows_projections_df, user_id)
                st.write("### ðŸŸ¢ Updated Insurance outflows projections")
                st.dataframe(reshaped_insurance_outflows_df)
        except Exception as e:
            st.error(f"âŒ Failed to load Insurance outflows projections: {str(e)}")             
        
    elif option == "Assets Section":

        st.write("### Changing Investment Projection Data")   
        manage_investment_table = st.radio("Do you want to update the Investment Projection table?", ["No", "Yes"], index=0) 
        if manage_investment_table == "Yes":
            projection_updater.run_investment_projections(user_id, month_choice)    

        st.write("### Running Surplus Withdrawal Projection")
        manage_surplus_withdrawal_projection_table = st.radio("Do you want to update the surplus withdrawal Projection table?", ["No", "Yes"], index=0) 
        if manage_surplus_withdrawal_projection_table == "Yes":
            projection_updater.run_surplus_withdrawal_projections(user_id, month_choice) 
            
    
        st.write("### Changing Assets Projection Data")
        manage_assets_projection_table = st.radio("Do you want to update the assets Projection table?", ["No", "Yes"], index=0) 
        if manage_assets_projection_table == "Yes":
            if st.button("Update the Asset Projection", key = 'all asset outflows liabilities'):
                projection_updater.run_dynamic_assets_projections(user_id, month_choice)

        
        st.write("### Add Downpayment Data")
        manage_down_payment_table = st.radio("Do you want to do downpayment?", ["No", "Yes"], index=0) 
        if manage_down_payment_table == "Yes":
                projection_updater.manage_downpayment_outstanding_amount() 

        try:
            investment_df_updated = projection_updater.load_investment_projections_from_db(user_id)
            if investment_df_updated.empty:
                st.warning("âš ï¸ Investment projections not yet calculated for this user.")
            else:
                investment_reshaped_df = projection_updater.reshape_display_investment_projections(investment_df_updated, user_id)
                st.write("### ðŸŸ¢ Updated Investment Projections")
                investment_editable_reshaped_df = st.data_editor(investment_reshaped_df, use_container_width=True, key = 'reshaped_editor_3')

                # Save changes back to the database
                if st.button("Save Changes", key = 'save transpose investment projection'):
                    # Unpivot the reshaped DataFrame to its original format
                    investment_reshaped_df.reset_index(inplace=True)  # Reset index before unpivoting
                    investment_updated_unpivoted_df = projection_updater.unpivot_reshaped_data(investment_editable_reshaped_df)

                    # Update the main DataFrame with new values
                    investment_df_updated = projection_updater.update_main_dataframe(investment_df_updated, investment_updated_unpivoted_df)

                    # Save the updated DataFrame to the database
                    projection_updater.save_investment_projections_to_db(investment_df_updated, user_id)

            st.success("Changes of investment projection saved successfully!")
        except Exception as e:
            st.error(f"âŒ Failed to load Investment Projections: {str(e)}")


        try:
            surplus_withdrawal_projections_df = projection_updater.load_surplus_withdrawal_projections_from_db(user_id)
            if surplus_withdrawal_projections_df.empty:
                st.warning("âš ï¸ Surplus withdrawal projections not yet calculated for this user.")
            else:
                reshaped_surplus_withdrawal_df = projection_updater.reshape_display_surplus_related_withdrawal_projections(surplus_withdrawal_projections_df, user_id)
                withdrawal_editable_reshaped_df = st.data_editor(reshaped_surplus_withdrawal_df, use_container_width=True, key = 'reshaped_editor_4')
                # Save changes back to the database
                if st.button("Save Changes", key = 'save transpose surplus projection'):
                    # Unpivot the reshaped DataFrame to its original format
                    reshaped_surplus_withdrawal_df.reset_index(inplace=True)  # Reset index before unpivoting
                    updated_unpivoted_df = projection_updater.unpivot_reshaped_data(withdrawal_editable_reshaped_df)

                    # Update the main DataFrame with new values
                    surplus_withdrawal_projections_df = projection_updater.update_main_dataframe(surplus_withdrawal_projections_df, updated_unpivoted_df)

                    # Save the updated DataFrame to the database
                    projection_updater.save_surplus_withdrawal_projections_to_db(surplus_withdrawal_projections_df, user_id)

                    st.success("Changes saved successfully!") 

                st.write("### ðŸŸ¢ Updated surplus withdrawal projections")
                st.dataframe(reshaped_surplus_withdrawal_df)
        except Exception as e:
            st.error(f"âŒ Failed to load surplus withdrawal projections: {str(e)}") 


        try:
            dynamic_assets_projections_df = projection_updater.load_dynamic_assets_projections_df_from_db(user_id)
            if dynamic_assets_projections_df.empty:
                st.warning("âš ï¸ Assets projections not yet calculated for this user.")
            else:
                reshaped_assets_df = projection_updater.display_reshape_dynamic_assets_projections(dynamic_assets_projections_df, user_id)
                st.write("### ðŸŸ¢ Updated Assets projections")
                st.dataframe(reshaped_assets_df)
        except Exception as e:
            st.error(f"âŒ Failed to load assets projections: {str(e)}")


    elif option == "Income Section":    

        st.write("### Changing milestone income projection")  
        manage_goal_income_table_1 = st.radio("Do you want to update income projection?", ["No", "Yes"], index=0)
        if manage_goal_income_table_1 == "Yes":
            update_user_income_table = st.radio("Do you copy and update user income projection?", ["No", "Yes"], index=0)
            if update_user_income_table == "Yes":
                st.write("### Changing milestone income projection")
                projection_updater.run_dynamic_milestone_income_projection(user_id)

            update_user_combine_income_table = st.radio("Do you copy and update user combine income projection?", ["No", "Yes"], index=0)
            if update_user_combine_income_table == "Yes":
                st.write("### Changing combine milestone income projection")
                projection_updater.run_dynamic_combine_milestone_income_projection(user_id)   

        st.write("### Add the Additional Income Expense Category")
        manage_additional_expense_table = st.radio("Do you want to update additional expense projection?", ["No", "Yes"], index=0)
        if manage_additional_expense_table == "Yes":
            projection_updater.run_additional_income_expense_criteria(user_id, month_choice) 

        try:
            dynamic_milestone_income_projection = projection_updater.load_dynamic_milestone_income_projection_from_db()
            if dynamic_milestone_income_projection.empty:
                st.warning("âš ï¸ Income projections not yet calculated for this user.")
            else:
                reshaped_goal_income_df = projection_updater.transpose_display_dynamic_milestone_income_projection_1(dynamic_milestone_income_projection)
                st.write("### ðŸŸ¢ Updated Income projections")
                st.dataframe(reshaped_goal_income_df)
        except Exception as e:
            st.error(f"âŒ Failed to load income projections: {str(e)}")   

        try:
            additional_income_expense_criteria_df = projection_updater.load_additional_income_expense_criteria_df_from_db()
            if additional_income_expense_criteria_df.empty:
                st.warning("âš ï¸ Additional expense projections not yet calculated for this user.")
            else:
                reshape_additional_expense_df = projection_updater.reshape_display_additional_income_expense_criteria(additional_income_expense_criteria_df, user_id)
                st.write("### ðŸŸ¢ Updated Additional Expense projections")
                st.dataframe(reshape_additional_expense_df)
        except Exception as e:
            st.error(f"âŒ Failed to load Additional Expense projections: {str(e)}")    

            
    elif option == "Cashflow, Actual, Ideal and FBS Projection Data":        
        st.write("### Changing cashflow, Actual, Ideal and FBS Projection Data")
        manage_automated_run_projection_table = st.radio("Do you want to update the Summary of all projections, Actual, Ideal and FBS Projection table?", ["No", "Yes"], index=0) 
        if manage_automated_run_projection_table == "Yes":
            if st.button("Update the Summary of all projections", key = 'all total of projections'):
                projection_updater.run_dynamic_yearly_cf_projections(user_id, dob, retirement_age, month_choice) 

            if st.button("Update the User Actual projection", key = 'User Actual projections'):
                projection_updater.run_actual_projections_with_milestones(user_id, dob, retirement_age, month_choice) 

            manage_ideal_projection_table = st.radio("Do you want to update ideal projection?", ["No", "Yes"], index=0)
            if manage_ideal_projection_table == "Yes":
                projection_updater.run_dynamic_ideal_projection_calculation(user_id) 

            if st.button("Update the User Ideal Emergency projection", key = 'User Ideal Emergency projections'):
                projection_updater.run_ideal_projections_emergency_fund_with_milestones(user_id, dob, retirement_age, month_choice)     

            if st.button("Update the User FBS projection", key = 'User FBS projections'):
                projection_updater.run_fbs_dynamic_projections_with_milestones(user_id, dob, retirement_age, month_choice)     

        try:
            dynamic_yearly_cf_projections_df = projection_updater.load_dynamic_yearly_cf_projections_df_from_db()
            if dynamic_yearly_cf_projections_df.empty:
                st.warning("âš ï¸ all cashflow summary projections not yet calculated for this user.")
            else:
                reshape_cashflow_summary_df = projection_updater.transpose_display_dynamic_yearly_cf_projections_1(dynamic_yearly_cf_projections_df)
                st.write("### ðŸŸ¢ Updated cashflow summary projections")
                st.dataframe(reshape_cashflow_summary_df)
        except Exception as e:
            st.error(f"âŒ Failed to load cashflow summary projections: {str(e)}")    


        try:
            dynamic_actual_projections_df = projection_updater.load_dynamic_actual_projections_df_from_db(projection_updater.db_config)
            if dynamic_actual_projections_df.empty:
                st.warning("âš ï¸ Actual projections not yet calculated for this user.")
            else:
                reshaped_actual_projections_df = projection_updater.transpose_display_dynamic_actual_projections_df_1(dynamic_actual_projections_df)
                st.write("### ðŸŸ¢ Updated Actual projections")
                st.dataframe(reshaped_actual_projections_df)
        except Exception as e:
            st.error(f"âŒ Failed to load actual projections: {str(e)}") 


        try:
            dynamic_ideal_projection_calculation = projection_updater.load_dynamic_ideal_projection_calculation_from_db(db_config)
            if dynamic_ideal_projection_calculation.empty:
                st.warning("âš ï¸ Ideal projections not yet calculated for this user.")
            else:
                reshaped_ideal_projections_df = projection_updater.transpose_display_dynamic_ideal_projection_calculation_1(dynamic_ideal_projection_calculation)
                st.write("### ðŸŸ¢ Updated Ideal projections")
                st.dataframe(reshaped_ideal_projections_df)
        except Exception as e:
            st.error(f"âŒ Failed to load ideal projections: {str(e)}")   

        try:
            dynamic_ideal_projections_emergency_planning_df = projection_updater.load_dynamic_ideal_projections_emergency_planning_table_df_from_db(projection_updater.db_config)
            if dynamic_ideal_projections_emergency_planning_df.empty:
                st.warning("âš ï¸ Ideal emergency projections not yet calculated for this user.")
            else:
                reshaped_ideal_emergency_projections_df = projection_updater.transpose_display_dynamic_ideal_projections_emergency_planning_1(dynamic_ideal_projections_emergency_planning_df)
                st.write("### ðŸŸ¢ Updated Ideal Emergency projections")
                st.dataframe(reshaped_ideal_emergency_projections_df)
        except Exception as e:
            st.error(f"âŒ Failed to load ideal Emergency projections: {str(e)}")   

        try:
            dynamic_fbs_projections_df = projection_updater.load_dynamic_fbs_projections_df_from_db(projection_updater.db_config)
            if dynamic_fbs_projections_df.empty:
                st.warning("âš ï¸ FBS projections not yet calculated for this user.")
            else:
                reshaped_fbs_projections_df = projection_updater.transpose_display_dynamic_fbs_projections_df_1(dynamic_fbs_projections_df)
                st.write("### ðŸŸ¢ Updated FBS projections")
                st.dataframe(reshaped_fbs_projections_df)
        except Exception as e:
            st.error(f"âŒ Failed to load FBS projections: {str(e)}")       

        
    elif option == "Update the Asset and liabilities table Manually":
        st.write("### Update the Asset and liabilities table Manually")
        projection_updater.update_assets_and_liabilities_projections(user_id)             

    elif option == "Display All Goal Planning Table":
        #st.write("### Calculating the FBS Projection")
        projection_updater.run_display_all_transpose_milestone_table(user_id, month_choice)

    elif option == "Display All Check Charts":
        #st.write("### Calculating the FBS Projection")
        projection_updater.run_all_check_charts(user_id, month_choice)         

    elif option == "Download Goal Projections Excel File":
    #if user_id:
        st.write('### Download all Goal Planning Projections Excel File')
        all_projections = st.radio("Do you want to Download all Goal Planning Projections Excel file?", ["No", "Yes"], index=0)
        if all_projections == "Yes":
            projection_updater.run_download_milestones_excel(user_id) 

        st.write('### Download User Goal Planning Projections Excel File')
        user_define_projections = st.radio("Do you want to Download Goal Planning Projections Excel File?", ["No", "Yes"], index=0)
        if user_define_projections == "Yes":
            projection_updater.filter_run_download_milestones_with_liabilities_excel(user_id)

    elif option == "Generate the PDF of Milestone Report" : 
        st.write('### Generating the all charts of user') 
        projection_updater.run_pdf_generator_code(user_id)  
    else:
        st.error("Please enter a valid user code.")      

else:
    st.error("Please enter a valid user code.")          
